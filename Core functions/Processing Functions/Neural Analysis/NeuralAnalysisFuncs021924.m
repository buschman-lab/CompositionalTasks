classdef NeuralAnalysisFuncs
    %NEURALANALYSISFUNCS Summary of this class goes here
    %   Set of functions to analyse Neural data
    properties
        PSTH_Bin=0.15; % 150 ms bins
        PSTH_BinShift=0.01; % 10 ms bin shift
        SpkStr=0;     %when to start counting spikes
        SpkStp=0.1;   % when to stop sounting spikes
        PSTHTimRef='leading'; % 'leading','trailing','centered'
        RasterTimStep=0.001; % 1ms raster time bins
        n_movavg=10;   % moving average
        n_TrlAvg=10   % number of trials to average from
        ZscoreFlag=0; % zscore this data across neurons
        NShuffle=100;
        SubtractBaseLine=0; % subtract baseline for PSTH or anything else
        NPnts_SubtractBaseLine=[] % number of points that we need to subtract the baseline
        UseFakeNeurons=0; % are we using fake neurons for our analysis
        UseSavedData=1; % are we using the saved data or regenerating the data again
        NormalizebyMax=0; % are we normalizing by max
        NormalizebyMean=0;% are we normalizing by mean
        MeanSubtractByRule=0; % are we zscoring the spike data in time based on each rule?
        MeanDataByRule=[]; % mean vlaue for each rule based on time 
        MeanDataByRule_SpkCnt=[];% mean vlaue for each rule based on time on a specific period
        TargetArea=[1:5]; % which area we are looking at
        MeanStdPlotType=1; %0 normal error bar 1 shaded errorbar  2 bar 3 plot
        PlotResults=0;
        SpkCountPeriod  % period we want to do spike count
        Neu2Use=[]; % which neurons are we using
        ThisColor=''; % color we want for current object
        caxis_limits='auto'; % limit the Caxis
        ThisLineStyle='-'; %
        font_size=18; % font size for plot
        ThisMarker='none'; % what the marker we are using
        ThisMarkerSize=5; % what is the marker size 
        ThisSubtitle=''; % add subtitle
        ThisTitle; % this title we want to put
        ThisXLabel;%  This XLabel we want to put
        ThisYLabel;%  This YLabel we want to put
        ThisLegendTxt=''; % what is the current legend text
        WidthSmoothing=15;% what is width of our smooting
        WidthSmoothingDim2=3; % what is width of our smooting Dim2
        SmoothingMethod='movmean' %method of smoothing binom gauss movmean
        ExtraPSTHRaster % if we have other PSTH raster data that we might use
        Remove50MLFactor=1 % are we removing 50% and 150% from factor data?
        PlotType % what type of plot we are using 'Image','Line' etc
        ExtraData=[]; % if we are passing extra data anywhere
        image_colormap=[]; % colormap of this image 
        %% GLM model
        GLMalpha=1;   % alpha of glm model (0,1]. 1 is lasso and 0 is Ridge regularization. between 0 and 1 is elastic net
        GLMCV=5;      % x fold cross validation for GLM
        GLMnMdlCompRuns=200% How many runs to compare models
        GLMTrainTestRatio=0.75; %ratio to devide train and test data
        GLMmdl='Rule' % can be Rule or FeatureAxis
        GLMfitMethod='FactorOmit' % fits GLM model to data using "regular" or "FactorOmit" methods
        GLMfullMdlType='FullModel_Interaction' % Type of full model we are using for GLM "FullModel' or "FullModel_Interaction"
        GLMLambda=[0]; % lambda values to look at
        GLMstatTestData=[];  % significance for the neurons using stattest
        GLMshuffleFlag=0; % are we shuffling the regressors with respect to spiking data
        GLMmainLambdaInd=1; % index of the lambda we want to look at in all of our analysis
        
        %% Classifier anlaysis
        MaxMatchTrialConds=1; % are we maximally matching trial conditions
        Classifier_TaskName='';
        ClassifierAngleCalMethod='Angle'; % how are we calculating relationship between classifiers : 'Angle' or 'Corr'
        ZscoreFactorData=0; % are we zscoring factor data for each neuron?
        DetrendFactorData=0; % are we detrending factor data?
        TrlRngNum=1; % what is the current trial range we are working on
        StimCongruencyConds={[0],[1],[-1],[0 1],[0 1 -1],[0 0;1 1;0 1;1 0],[0 1],[1 2;3 4;1 2],[1 2;3 4;1 2],...
            [0 1],[0 1;0 2;1 1;1 2],[0 0;0 1],[0 1],[1 2;3 4;1 2],[1 0;2 1;1 1;2 0],[0 1;0 2]};       
        % 0: No Balance
        % 1: Balance Incongruent
        % 2: Balance Congruent
        % 3: Balance Ambiguous 
        % 4: Balance Congruency
        % 5: Balance All
        % 6: Balance Congruency and Reward ( should be used with ResponseLoc as Target factor)(the first column is congruency and second column is corrincorr) 
        % 7: Balance Reward
        % 8: Balance Response Direction 4 Rule specific Response
        % 9: Balance Response Direction and SeqHist
        % 10: Balance Congruency and SeqHist
        % 11: Balance Congruency and Response Direction for specific rule
        % 12: Balance Incongruent and Reward
        % 13: Balance Reward and SeqHist
        % 14: Balance response direction and SeqHist 
        % 15: Balance Congruency, Color Category and SeqHist (DOES NOT WORK)
        % 16: Balance Incongruent and response direction
        StimCongruencyTrialDim=[2,2,2,2,2,1,2,2,2,2,1,2,2,2,1]; % which dimension is the effect trial order
        StimCongruencyFactorName={'Congruency','Congruency','Congruency','Congruency','Congruency',{'Congruency','Reward'},...
            'Reward','ResponseLoc',{'SeqHist','ResponseLoc'},{'SeqHist','Congruency'},{'Congruency','ResponseLoc'},...
            {'Congruency','Reward'},{'SeqHist','Reward'},{'SeqHist','ResponseLoc'},{'Congruency','ColorCat','SeqHist'},{'Congruency','ResponseLoc'}}; % what is the name of factor we are limiting
        SeqHistCond % condition of SeqHist
        ThisTargetFactor % are we using a specific target factor?
        ThisExtraTargetFactor % are we using an extra target factor?
        RunCrossTemporalClassifer=0 % are we running CrossTemporal Classifer
        CalShuff=0; % are we calculating the shuffled data
        CalShuffTrlOrder=0; % are we shuffling based on the trial order 
        ClassifierResults_Shuff=[]; % data for permutation results
        ClassifierResults_Observed=[]; %observed data for permutation results
        ClassifierResults_Loaded=[]; % preloaded data for classifier results 
        ClassifierOpts_Loaded=[]; % reloaded data for classifier opts 
        ClassifierOptsShuff_Loaded=[]; % reloaded data for classifier opts 
        StatTest=[]; % statitical tests
        StatTestTrlShuff=[];
        LookatDim2=0; % are we looking at second dimension in the classifier data now
        ThisClassifierCond % current cundition of the classifier
        TakeCorrectTrlsOnly=0; % are we limiting this analysis only to correct trials 
        ClassifierShuffleLabel=[]; % shuffle labels for classifier analysis
        ShuffObservedRoundObj=[]; % are we running shuffle(1) or observed(0)
        GrabbingTestData % are we grabbing test data now
        CalOnlyStat=0; % are we calculating only stattest right now
        %% statistical test
        ClustStatTst_dependent_samples=0;  %are these samples independant 
        ClustStatTst_p_threshold=0.05; % pvalue trheshold
        ClustStatTst_num_permutations=10000; % number of permutations
        ClustStatTst_two_sided=1;  % is this two sided test
        ClustStatTst_num_clusters =inf;  % maximim number of clusters
        ImgPlotSigPval=[0.01 0.001]; % what is the significance value that we want the image plot to show
        performtrend_stattest=0; % are we performing trend statistical test
        %% behavioral Model
        BhvMdlType='Hybrid' ;% type of behavioral model can be Hybrid, InferenceAxisFeature, Inference
        BhvMdlFactor=''; % what factor of the behavioral model are we looing at
        
        %% PCA analysis
        PCAremove50ML=1; % are we removing 50% and 150% morphlevels from the analysis
        PCAonlyCorrTrls=1; % are we only doing the analysis on correct trials
        
        %% Subspace analysis
        SubspaceAna_TaskName % task name to do subspace analysis
        SubspaceAna_Shuff % shuffle data for subspace
        UsePCA4AxB=0; % are we taking PCA of all time points before feeding it intot the algorithm
    end
    properties (Access=private)
        ManData=ManipulateData;
        TrialFunc=TrialFuncs;
        FigParams=fig_params;
        ArtSimFunc=ArtificialSimFuncs;
        RSAFunc=RSA_AnalysisFuncs;
        AxBFunc=AxB_AnalysisFuncs;
        BhvAna=BhvAnalysisFuncs;
    end
    methods
        function  obj=NeuralAnalysisFuncs(varargin)
            global AnalysisOpts
            if nargin~=0 % initialize vars
                obj=obj.ParseParams(varargin) ; %%Process optional inputs
            end
        end
        
        function  obj=ParseParams(obj,InputArgs)
            %Process optional inputs
            if mod(length(InputArgs), 2) ~= 0, error('Must pass key/value pairs for options.'); end
            for i = 1:2:length(InputArgs)
                try
                    obj.(InputArgs{i}) = InputArgs{i+1};
                catch
                    error('Couldn''t set option ''%s''.', InputArgs{i});
                end
            end
        end       
        function [PSTHRaster]=ProcessSpikeCountingRec(obj,TrialSpikeData,SpkCntStartFieldName,TrlSpkTimeFieldName,varargin) % this function is mainly for rule representation project
            % processes spike counting for multiple recordings
            %TrialSpikeTime includes both spike count and critical times
            % SpkCntStartFieldName: what is the time point in the trial we
            % are locking everything "SAMPLE_ON"
            % TrialReference: what type of reference for trial want from
            % AnalysisOpts.BlockSpecsFeilds e.g. "AroundSwitch"
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %
            PSTH=[];Raster=[];
            % plot some raster and PSTH
            cnt=1;
            for r=1:size(TrialSpikeData,1)
                Nch=length(TrialSpikeData{r, 1});
                for i=1:Nch
                    Nblks=length(TrialSpikeData{r,2}(i).Rule);
                    [PSTHRaster(cnt).PSTH,PSTHRaster(cnt).Raster,PSTHRaster(cnt).SpkCount,PSTHRaster(cnt).SpkCountTim,PSTHRaster(cnt).RasterTim]=...
                        arrayfun(@(x) obj.ProcessSpikeCounting(TrialSpikeData{r,1}(i).TrialSpikeTime{x},...
                        TrialSpikeData{r,2}(i).CriticalTimes{x},SpkCntStartFieldName),1:Nblks,'Uniformoutput',0);
                    cnt=cnt+1;
                end
            end
            %% concatinate PSTH and Rasters
            %  [CatPSTH,CatRaster]=obj.CatRasterPSTH(PSTH,Raster,PSTHThisNeu{1}.SpkCountTim-0.2,[]);
            
        end
        function [PSTH,Raster,SpkCount,SpkCountTim,RasterTim]=ProcessSpikeCounting(obj,SpikeTimesData,CriticalTimes,StartFieldName,varargin) % this function is mainly for rule representation project
            % processes spike counting
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isempty(StartFieldName)
                StartFieldNameAnalysisOpts.SpkParams.StartFieldName;
            end
            
            %%% find when we want to count the number of spikes related to the task
            StartCountInd=strcmp(AnalysisOpts.TrialTimesFields,StartFieldName);
            StopCountInd=strcmp(AnalysisOpts.TrialTimesFields,AnalysisOpts.SpkParams.StopFiledName);
            
            Period(:,1)=CriticalTimes(:,StartCountInd)-AnalysisOpts.SpkParams.BaselineDelay;
            % replace NaN values with mean of the other timigns( usually
            % this is used with Reward trials
            if sum(isnan(Period))
                warning('Replacing NaN timings with mean in calculating PSTH')
                MeanTiming=mean(Period(~isnan(Period)));
                Period(isnan(Period))=MeanTiming;
            end
            Period(:,2)=Period(:,1)+AnalysisOpts.SpkParams.PeriodLength;
            
            % now use our built in functions to calculate PSTH and Raster
            [PSTH,Raster,SpkCount,SpkCountTim,RasterTim] = obj.CalRasterPSTH(SpikeTimesData,Period);
        end
        function [PSTH,Raster,SpkCount,SpkCountTim,RasterTim] = CalRasterPSTH(obj,spktimMat,Period,varargin)  % calculates raster and psth
            % data is spike timing; each cell is one trial or one neuron
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %% set up Period so that it accepts trial times as well
            if isscalar(Period)  % if it is scalar we take it as length of all of trials
                PeriodLength=Period;
                Period=[zeros(size(Period,1),1) PeriodLength*ones(size(Period,1),1)];
            else  % it is matrix each raw is timing of one trial
                Period=[Period(:,1) Period(:,end)];
                PeriodLength=max(Period(:,2)-Period(:,1));
            end
            %%
            obj.SpkStr=0;obj.SpkStp=PeriodLength;  % start and stop counting
            Bin=obj.PSTH_Bin;
            BinShift=obj.PSTH_BinShift;
            numbins=(PeriodLength-Bin)/BinShift+1;
            NumTrial=size(Period,1);
            Raster=zeros(NumTrial,floor(PeriodLength/obj.RasterTimStep)); % raster
            SpkCount=zeros(NumTrial,1);    % spike count
            for Tri=1:NumTrial
                if iscell(spktimMat) %then it is the trial spike time
                    spktim=spktimMat{Tri};
                else % this is a countinous spike time fo rth ewhole epxeriment
                    spktim=spktimMat;
                end
                
                TrlStrTim=Period(Tri,1);
                TrlStpTim=Period(Tri,2);
                %% calculate PSTH
                for Nbin=1:numbins
                    Stp=TrlStrTim+Bin+BinShift*(Nbin-1);
                    Str=Stp-Bin;
                    PSTH(Tri,Nbin)=length(find(spktim>=Str & spktim<Stp));
                    SpkCountTim(Nbin)=Stp-TrlStrTim;
                end
                %% Calculte Raster
                ThisTrlSpkTim=spktim(spktim>=TrlStrTim & spktim<TrlStpTim)-TrlStrTim;
                SpkTimIndCh=floor(ThisTrlSpkTim/obj.RasterTimStep);
                SpkTimIndCh(SpkTimIndCh==0)=1;
                Raster(Tri,SpkTimIndCh)=arrayfun(@(x) sum(SpkTimIndCh==x),SpkTimIndCh);
                %% calculte spike count
                SpkCount(Tri,1)=length(find(spktim>=(TrlStrTim+obj.SpkStr) & spktim<(TrlStrTim+obj.SpkStp)));
            end
            RasterTim=[0:size(Raster,2)-1]*obj.RasterTimStep;
            %% adjust timing based on a the reference
            switch obj.PSTHTimRef
                case 'leading' % start of spike count
                    SpkCountTim=SpkCountTim-Bin;
                case 'trailing' % this is what we are comuting
                    %   SpkCountTim=SpkCountTim;
                case 'centered'  % centered
                    SpkCountTim=SpkCountTim-Bin/2;
            end
        end
        function SpkCount=GetPeriodSpikeCount(obj,Raster,Period,Time,varargin) % gets the spike count from raster data for a period
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            TimeInds=Time>=Period(1) & Time<=Period(2);
            SpkCount=sum(Raster(:,TimeInds),2);
        end
        function varargout=PlotPSTH(obj,PSTH,Time,Col,LevelValues,Title,NormBin,h,Sp,varargin)  % plots PSTH
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NFactor=size(PSTH,2);
            if isempty(Col);Col=obj.FigParams.getColorPalet(NFactor);end
            
            if ~iscell(LevelValues)
                LevelValues=arrayfun(@num2str,LevelValues,'UniformOutput',false) ;
            end
            
            if isempty(h)
                h=obj.FigParams.RenderFigure(1,[]); % create figures
            end
            figure(h{1});
            subplot(Sp)
            
            if size(PSTH(1).SpkCountBin,1)>1 % if we are more than one neuron then us ethe zscore
                FieldtoUse='ZSpkCountBin';
                NormBin=0;
                NormalizeFRtxt='Norm ';
            else
                FieldtoUse='SpkCountBin';
                NormBin=1;
                NormalizeFRtxt='';
            end
            
            hold on % now plot data
            
            if NormBin %(obj,X,Y,YSTD,Xlbl,Ylbl,Col,Shaded,Title,varargin)
                
                hp=arrayfun(@(x)  obj.FigParams.PlotMeanStd(Time(obj.n_movavg:end),obj.ManData.MoveMean(PSTH(x).(FieldtoUse),...
                    obj.n_movavg,'valid')/obj.PSTH_Bin,[],...
                    AnalysisOpts.Xlabel,[NormalizeFRtxt 'Firing Rate(Hz)'],Col(x,:),1,Title),...
                    1:NFactor,'UniformOutput',true);
            else
                hp=arrayfun(@(x)  obj.FigParams.PlotMeanStd(Time(obj.n_movavg:end),obj.ManData.MoveMean(PSTH(x).(FieldtoUse),...
                    obj.n_movavg,'valid'),[],...
                    AnalysisOpts.Xlabel,[NormalizeFRtxt 'Firing Rate(Hz)'],Col(x,:),1,Title),...
                    1:NFactor,'UniformOutput',true);
            end
            legend(hp,LevelValues,'Location','Bestoutside','FontSize',9);% add legends percondition
            legend('boxoff');
            varargout=h;
        end
        function varargout=PlotRaster(obj,Raster,Col,Title,h)  % plots Raster
            timeStepS=obj.RasterTimStep;
            %  times = [0:timeStepS:timeStepS * (size(spikes) - 1)];
            trains = size(Raster, 1);
            axis([0, length(Raster) - 1, 0, 1]);
            ticMargin = 0.01;                                      % gap between spike trains (full scale is 1)
            ticHeight = (1.0 - (trains + 1) * ticMargin) / trains;
            hold on
            if isempty(Col);Col=repmat([0 0 1],trains,1);end
            for train = 1:trains
                spikeTimes = find(Raster(train, :) == 1);
                yOffset = ticMargin + (train - 1) * (ticMargin + ticHeight);
                for i = 1:length(spikeTimes)
                    %    line([spikeTimes(i), spikeTimes(i)], [yOffset, yOffset + ticHeight],'Color',Col(train,:),'LineWidth',4);
                    plot(spikeTimes(i),yOffset,'.','Color',Col(train,:),'MarkerSize',4)
                end
            end
            xlabel('Time(s)')
            title(Title)
            obj.FigParams.FormatAxes(h)
            varargout{1}=h;
        end
        function [CatPSTH,CatRaster,Color]=CatRasterPSTH(obj,PSTH,Raster,Time,Col,SubBaseLine)  % Concatinates different cells of PSTH and raster into one matrix and gives a
            % color for each one of them
            NNeu=length(PSTH);
            
            % subtract mean baseline activity for each cell and Zscore them
            %  BaseLineTim=Time<0;
            
            % check if this is factor name or factor level
            if isfield(PSTH,'factornames')
                FactorField='factornames';
                type=1;
            elseif isfield(PSTH,'FactorLevels')
                FactorField='FactorLevels';
                type=2;
            end
            
            switch type
                case 1
                    for i=1:NNeu
                        MeanPSTH=mean(PSTH(i).data,1);
                        BaseLineFir=mean(MeanPSTH(Time<0));
                        MeanPSTHBaseLineSub=MeanPSTH-BaseLineFir;
                        if SubBaseLine
                            CatPSTH.ZSpkCountBin(i,:)=MeanPSTHBaseLineSub/max(MeanPSTHBaseLineSub(:));
                        else
                            CatPSTH.ZSpkCountBin(i,:)=MeanPSTH/max(MeanPSTH(:));
                        end
                        CatPSTH.SpkCountBin(i,:)=MeanPSTH;
                    end
                case 2
                    for i=1:NNeu
                        
                        % to get the normalization devide by max firing and
                        % subtract the baseline from each condition
                        ThisPSTH=obj.ManData.ReshapeCell2Mat(PSTH(i).data,62);
                        MeanThisPSTH=mean(ThisPSTH,1);
                        if SubBaseLine
                            BaselineFR=mean(MeanThisPSTH(Time<0));
                        end
                        
                        NFactor=length(PSTH(i).(FactorField)); % number of different factors
                        for f=1:NFactor
                            MeanPSTH=mean(PSTH(i).data{f},1);
                            if SubBaseLine
                                CatPSTH(f).ZSpkCountBin(i,:)=(MeanPSTH-BaselineFR)/max(MeanThisPSTH(:));
                            else
                                CatPSTH(f).ZSpkCountBin(i,:)=MeanPSTH/max(MeanThisPSTH(:));
                            end
                            CatPSTH(f).SpkCountBin(i,:)=MeanPSTH;
                        end
                    end
            end
            
            if ~isempty(Raster)
                % cat raster now
                CatRaster=transpose(cell2mat(arrayfun(@(x) (Raster{x})',1:NNeu,'uniformoutput',0)));
                if isempty(Col) % we just generate our own color
                    Col=distinguishable_colors(NNeu);
                    Color=transpose(cell2mat(arrayfun(@(x) repmat(Col(x,:)',1,size(Raster{x},1)),1:NNeu,'uniformoutput',0)));
                else
                    Color=transpose(cell2mat(arrayfun(@(x) repmat(Col(x,:)',1,size(Raster{x},1)),1:NNeu,'uniformoutput',0)));
                end
            else
                Raster=[];Color=[];
            end
        end
        function varargout=PlotPSTHbyFactor(obj,FactorizedData,Time,TargetFactor,varargin) % plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % make sure this function can handle lotting information for
            % multiple neurons
            % get the infor for the factor we care about
            NTargFactors=length(TargetFactor);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            [h,Sp]=obj.FigParams.RenderSubplots([],[],[],NTargFactors);
            
            for f=1:NTargFactors % loop on the factors we want
                factind=TargetFactorInds(f);
                FactorColor=AnalysisOpts.([TargetFactor{f} 'Colors']);
                for Neu=1:length(FactorizedData) % loop on the neurons
                    % find the data for this factor
                    [SortFactorizedData(Neu).data,SortFactorizedData(Neu).FactorLevels]=obj.SortFactorDatabyLevel(FactorizedData(Neu),TargetFactor{factind});
                end
                % now concatinate the PSTH for each neuron based on the value of the factor for each level
                [CatPSTH]=obj.CatRasterPSTH(SortFactorizedData,[],Time,[],obj.SubtractBaseLine);
                % plot PSTH percondition
                Legends=arrayfun(@(x) [TargetFactor{f} ' ' num2str(SortFactorizedData(1).FactorLevels(x))],...
                    1:length(SortFactorizedData(1).FactorLevels),'UniformOutput',false);
                obj.PlotPSTH(CatPSTH,Time,FactorColor,Legends,TargetFactor{f},0,h,Sp(f));
            end
            
            varargout=[h];
            
        end
        
        function varargout=PlotResponseLatencies(obj,FactorizedData,FactorizedData_SACCADE_START,varargin) % plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            Time=AnalysisOpts.Time;
            %%   plot the full PSTH with a histogram of Reation times so we have a clue of where are the response times
            NNeu=length(FactorizedData);
            
            [CatPSTH]=obj.CatRasterPSTH(FactorizedData,[],Time,[],obj.SubtractBaseLine);
            MeanPSTH=mean(CatPSTH.ZSpkCountBin,1);
            [CatPSTH_SACCADE_START]=obj.CatRasterPSTH(FactorizedData_SACCADE_START,[],Time,[],obj.SubtractBaseLine);
            MeanPSTH_SACCADE_START=mean(CatPSTH_SACCADE_START.ZSpkCountBin,1);
            %% plot mean PSTH
            [h,Sp]=obj.FigParams.RenderSubplots(2,2,[],[]);
            obj.FigParams.Plot(Time,CatPSTH.ZSpkCountBin',[0.8 0.8 0.8],AnalysisOpts.Xlabel,'Normalized FR','',Sp(1),'p_line_width',1);
            obj.PlotPSTH(CatPSTH,Time,'','','',0,h,Sp(2)); % plot PSTH from Sample On
            
            %% Plot response onset
            [P1,OnSetLatencySec]=obj.PlotRespOnsetLatencyLine(MeanPSTH,Time);
            
            %% plot the distribution of RT times on here as well (needs to be fixed as this is not correct value for RT)
            P2=obj.PlotRTdistLine(FactorizedData);
            legend([P1 P2],{'Onset Latency','Saccade'})
            title(['Avg PSTH, Latency:' num2str(OnSetLatencySec*1000) 'ms'])
            xlabel(AnalysisOpts.Xlabel);ylabel('Normalized FR');
            %% plot distribution of latencies for these cells
            [OnSetLatencySecDist]=cell2mat(arrayfun(@(x) obj.CalculateLatency(CatPSTH.SpkCountBin(x,:),Time,0.2),1:NNeu,'UniformOutput',false));
            OnSetLatencySecDist=OnSetLatencySecDist(OnSetLatencySecDist<0.5);
            [HistLatency,edges]=histcounts(OnSetLatencySecDist,10);
            edges=arrayfun(@(x) mean([edges(x) edges(x+1)]),1:(length(edges)-1));
            axes(Sp(3))
            obj.FigParams.BarPlot(edges,HistLatency,'k','Latency(s)','Cell Count','Distribution of onset latencies');
            %% plot PSTH for SACCADE Start
            CurrXlabel=AnalysisOpts.Xlabel;
            AnalysisOpts.Xlabel='Time(s) from SACCADE_START';
            obj.PlotPSTH(CatPSTH_SACCADE_START,Time,'b','','Avg PSTH',0,h,Sp(4)); % plot PSTH from Sample On
            AnalysisOpts.Xlabel=CurrXlabel;
            legend off
            varargout=[h];
        end
        
        function [P1,OnSetLatencySec]=PlotRespOnsetLatencyLine(obj,MeanPSTH,Time) % superimposes a line on the current plot for latency
            [OnSetLatencySec]=obj.CalculateLatency(MeanPSTH,Time,0.2);
            if isempty(OnSetLatencySec);OnSetLatencySec=nan;end
            v=gca;
            P1=obj.FigParams.Plot([OnSetLatencySec OnSetLatencySec],[v.YLim(1) v.YLim(2)],'r',v.XLabel.String,v.YLabel.String,v.Title.String,gca);
            
        end
        
        function P1=PlotRTdistLine(obj,FactorizedData) % superimposes a line on the current plot for RT dist
            v=gca;
            RTind=strcmp(FactorizedData(1).factornames,'RT');
            RT=FactorizedData(1).factors{RTind};
            MeanRT=nanmean(RT);
            StdRT=nanstd(RT);
            P1=obj.FigParams.Plot([MeanRT MeanRT],[v.YLim(1) v.YLim(2)],'k',[],[],[],gca);
            obj.FigParams.Plot([MeanRT+StdRT MeanRT+StdRT],[v.YLim(1) v.YLim(2)],'k',v.XLabel.String,v.YLabel.String,v.Title.String,gca,'p_line_style','--');
            obj.FigParams.Plot([MeanRT-StdRT MeanRT-StdRT],[v.YLim(1) v.YLim(2)],'k',v.XLabel.String,v.YLabel.String,v.Title.String,gca,'p_line_style','--');
        end
        
        function [OnSetLatencySec]=CalculateLatency(~,MeanPSTH,Time,TH)
            % TH is the treshold where we consider the rise time
            SampleOnset=find(Time>=0,1,'first');
            BaselineFR=mean(MeanPSTH(1:SampleOnset-1));
            FRrange=max(MeanPSTH(:))-BaselineFR;
            OnSetLatencyInd=find(MeanPSTH(SampleOnset:end)>=(TH*FRrange+BaselineFR),1,'first')+SampleOnset;
            OnSetLatencySec=Time(OnSetLatencyInd);
        end
        
        %% Tuning Curve Analysis
        function varargout=PlotTuningCurvesbyFactor(obj,FactorizedData,Time,TargetFactor,varargin) % plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % make sure this function can handle lotting information for
            % multiple neurons
            % get the infor for the factor we care about
            NTargFactors=length(TargetFactor);
            [h,Sp]=obj.FigParams.RenderSubplots(4,2,[],[]);
            Col=obj.FigParams.getColorPalet(length(FactorizedData(1).factornames));
            % get data for specific time epoch now for the factor we care
            % about
            FactorizedData=obj.GetTimeEpochDatainFactorizedData(FactorizedData,Time,[0 0.2]);
            
            % do this analysis for all data and for each rule to see if
            % there is a different in tuning across rules
            RuleInd=strcmp(FactorizedData(1).factornames,'Rule');
            ColorMLInd=strcmp(FactorizedData(1).factornames,'ColorML');
            ShapeMLInd=strcmp(FactorizedData(1).factornames,'ShapeML');
            MLs=unique(FactorizedData(1).factors{ColorMLInd});nMLs=length(MLs);
            NNeu=length(FactorizedData);
            
            for R=0:3
                if R==0 % then we are looking at all of the rules together
                    ThisRuleFactorizedData=FactorizedData;
                    RuleTxt{R+1}='ALL';
                    % calculate indivisual stim FR
                    MLsFr=arrayfun(@(Neu) cell2mat(arrayfun(@(y) cell2mat(arrayfun(@(x) mean(FactorizedData(Neu).data(FactorizedData(1).factors{ColorMLInd}==x & FactorizedData(1).factors{ShapeMLInd}==y)),MLs,'UniformOutput',0))',MLs,'UniformOutput',0)),1:NNeu,'uniformoutput',0);
                    MLsFrTot{R+1}=mean(obj.ManData.ReshapeCell2Mat(MLsFr,3),3);
                    MLsInd=arrayfun(@(y) arrayfun(@(x) [x,y],MLs,'UniformOutput',0)',MLs,'UniformOutput',0);
                    
                else
                    for Neu=1:NNeu
                        ThisRuleTrls=FactorizedData(Neu).factors{RuleInd}==R;
                        ThisRuleFactorizedData(Neu).data=FactorizedData(Neu).data(ThisRuleTrls,:);
                        ThisRuleFactorizedData(Neu).factors=cellfun(@(x) x(ThisRuleTrls),FactorizedData(Neu).factors,'UniformOutput',false);
                    end
                    RuleTxt{R+1}=num2str(R);
                    % calculate indivisual stim FR
                    MLsFr=arrayfun(@(Neu) cell2mat(arrayfun(@(y) cell2mat(arrayfun(@(x) mean(FactorizedData(Neu).data(FactorizedData(1).factors{ColorMLInd}==x & FactorizedData(1).factors{ShapeMLInd}==y & ThisRuleTrls)),MLs,'UniformOutput',0))',MLs,'UniformOutput',0)),1:NNeu,'uniformoutput',0);
                    MLsFrTot{R+1}=mean(obj.ManData.ReshapeCell2Mat(MLsFr,3),3);
                end
                for f=1:NTargFactors % loop on the factors we want
                    for Neu=1:NNeu % loop on the neurons
                        % find the data for this factor
                        [SortFactorizedData(Neu).data,SortFactorizedData(Neu).FactorLevels]=obj.SortFactorDatabyLevel(ThisRuleFactorizedData(Neu),TargetFactor{f});
                        
                        % calculate average modulation index for each of the
                        % factors in each of the rules
                        FactInd=strcmp(FactorizedData(1).factornames,TargetFactor{f});
                        [MI(f,R+1,Neu),zMI(f,R+1,Neu)]=obj.ManData.CalModulationIndex(obj.ManData.CategorizeData(ThisRuleFactorizedData(Neu).factors{FactInd}),...
                            ThisRuleFactorizedData(Neu).data',obj.NShuffle);
                        % estimate the tuning curve
                        [AngleFit,~,~,AngleFit2,GLM_weights]=obj.EstimateTuningAngle(ThisRuleFactorizedData(Neu).factors{FactInd}',ThisRuleFactorizedData(Neu).data);
                        
                    end
                    % now concatinate the PSTH for each neuron based on the value of the factor for each level
                    [CatPSTH]=obj.CatRasterPSTH(SortFactorizedData,[],Time,[],0);
                    % plot polar tuning curve per condition
                    Sign1=(1-sign(AngleFit(1)))/2;Sign2=(1-sign(AngleFit2(1)))/2;SignGLM=(1-sign(GLM_weights(2)))/2;
                    %         if Sign2~=(1-sign(AngleFit2(2)))/2;error('Check angles');end
                    TuningAngle1=floor(wrapTo360(rad2deg(AngleFit(2)+Sign1*pi)));
                    TuningAngle2=floor(wrapTo360(atand(AngleFit2(2)/AngleFit2(1))+Sign2*pi ));
                    TuningAngle2_GLM=floor(wrapTo360(atand(GLM_weights(3)/GLM_weights(2))+SignGLM*pi));
                    obj.PlotPolarTuningCurve(CatPSTH,Col(f,:),SortFactorizedData(Neu).FactorLevels,...
                        [TargetFactor{f} ' Rule' RuleTxt{R+1} ' Theta=' num2str(TuningAngle1) ',' num2str(TuningAngle2) ',' num2str(TuningAngle2_GLM)] ,h,Sp(f+R*2));
                end
            end
            
            %% Plot color and shape firing together
            [h2,Sp2]=obj.FigParams.RenderSubplots(1,5,[],[]);
            ClrMap=parula(128);
            
            for R=1:4
                axes(Sp2(R));
                %  args = {MLs,MLs,MLsFrTot{R}};
                %  AX=surf(args{:},'edgecolor','none');
                %   view(0,90);
                imagesc(MLs,MLs,MLsFrTot{R})
                axis tight;
                colormap(ClrMap);
                clbr = colorbar;
                %  clbr.Label.String = 'Firing Rate(Hz)';
                xlabel('Shape Morph Level'); ylabel('Color Morph Level');
                shading interp;
                set(gca,'YDir','normal')
                set(gcf,'renderer','painters')
                obj.FigParams.FormatAxes(gca);
                title(['Tuning in Rule ' RuleTxt{R}])
                xticks(MLs)
                yticks(MLs)
            end
            % plot modulation index
            axes(Sp2(5));
            bar(mean(MI,3)')
            ylabel('Z-MI');
            title('Modulation Index')
            legend(TargetFactor,'Location','best')
            xticklabels({'ALL','Rule1','Rule2','Rule3'})
            obj.FigParams.FormatAxes(gca);
            
            varargout=[h h2];
            
        end
        function varargout=PlotPolarTuningCurve(obj,PSTH,Col,LevelValues,Title,h,Sp,varargin)  % plots PSTH
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NFactor=size(PSTH,2);
            if isempty(Col);Col=obj.FigParams.getColorPalet(NFactor);end
            
            if isempty(h)
                h=obj.FigParams.RenderFigure(1,[]); % create figures
            end
            figure(h{1});
            subplot(Sp)
            
            if size(PSTH(1).SpkCountBin,1)>1 % if we are more than one neuron then us ethe zscore
                FieldtoUse='ZSpkCountBin';
            else
                FieldtoUse='SpkCountBin';
            end
            
            % normalize level values and turn them into radians
            LevelValues=[LevelValues 200];
            LevelValuesRad=[LevelValues*2*pi/200];
            FR=mean([PSTH.(FieldtoUse)],1);
            FR=[FR FR(LevelValues==0)]/max(FR);
            
            hp=obj.FigParams.PolarPlot(LevelValuesRad,FR,...
                arrayfun(@num2str,LevelValues,'UniformOutput',false), ...
                Col(1,:),Title);
            rlim([0 1])
            varargout=h;
        end
        
        
        %% functions for analysis of single cell information in Time only
        function varargout=SetupSingleCellAnalysis(obj,data,TimingStimData,varargin) % prepare the data for single cell analysis of spiking data
            global AnalysisOpts AnalysisData
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %data is usually the PSTH
            %factor data is stimlus dimensions we care about
            
            % get the spiking data for one cell and concatinate the
            % information
            AnalysisOpts.Xlabel=['Time(s) from ' strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ')];
            AnalysisOpts.Time=obj.ManData.GenerateTimeAxis;
            %% get data for each of the neurons
            if AnalysisOpts.ProcessingStep~=3 && AnalysisOpts.ProcessingStep~=4 && AnalysisOpts.ProcessingStep~=5
                NNeu=length(data);
                Time=data(1).SpkCountTim{1}-AnalysisOpts.SpkParams.BaselineDelay;
                RasterTime=data(1).RasterTim{1}-AnalysisOpts.SpkParams.BaselineDelay;
                obj.ManData.CopyVars2AnalysisOpts('Time',Time,'RasterTime',RasterTime,'NNeu',NNeu);
                for Neu=1:NNeu
                    % get factorized
                    [FactorizedData(Neu).data,FactorizedData(Neu).factors,FactorizedData(Neu).factornames,....
                        FactorizedData(Neu).TimingTaskData,FactorizedData(Neu).StimInfoData]=obj.GetFactorDataForThisNeuron(data(Neu),TimingStimData(Neu),'PSTH');
                    
                    [FactorizedData_Raster(Neu).data,FactorizedData_Raster(Neu).factors,FactorizedData_Raster(Neu).factornames]=obj.GetFactorDataForThisNeuron(data(Neu),TimingStimData(Neu),'Raster');
                    
                    if obj.UseFakeNeurons % if we are using fake neurons then generate fake data and replace it with what we have
                        Factors=obj.GenFakeNeuronFactorSet(AnalysisOpts.Ch_2look(Neu));
                        [PSTHRaster]=obj.FakeNeuronRespWithFactors(FactorizedData,Factors);
                        % replace the factorized data with simulated neuron data
                        FactorizedData(Neu).data=PSTHRaster.PSTH;
                        FactorizedData_Raster(Neu).data=PSTHRaster.Raster;
                    end
                end
            end
            
            if obj.UseFakeNeurons
                AnalysisOpts.ExtraStr='Sim';
            end
            
            %% deviding this function into processing steps so that we can
            %% run it in different modes
            varargout=cell(1,AnalysisOpts.NfigProcesStep(AnalysisOpts.ProcessingStep));
            switch AnalysisOpts.ProcessingStep
                
                %% Fit GLM models
                case 1
                    
                    Models2Test={'HybridbhvMdlFull','InferAFbhvMdlFull'};
                    
                    % Check if we are shuffling the data
                    obj.GLMshuffleFlag=AnalysisOpts.CalShuffleGLM;
                    cellfun(@(mdl) obj.FitGLMmdls2data(FactorizedData,'GLMmdl',mdl,'UseSavedData',0,'PlotResults',0,...
                        'GLMfitMethod','FactorOmit'),Models2Test,'UniformOutput',0);
                    
                    %% GLM model comparision(run on cluster)
                case 2
                    obj.GLMmodelComparision_Hierarchical(FactorizedData)
                    
                    %% plot GLM model comparision results
                case 3
                    np=3;
                    for Neu=AnalysisOpts.nCh_2look
                        close all
                        obj.TrialFunc.UpdateCurrentCh(Neu);
                        
                        %  [varargout{1:np}]       =obj.PlotGLMmodelComparision_Hierarchical('HybridbhvMdlFullReduce');
                        %  [varargout{np+1:2*np}]  =obj.PlotGLMmodelComparision_Hierarchical('InferAFbhvMdlFullReduce');
                        [varargout{1:np}]=obj.PlotGLMmodelComparision_Hierarchical('CompareBhvModels');
                        
                        [~,~,SingCellAnaFigsFileName]=obj.ManData.GetFileName([],...
                            ['SingCellAna' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName 'Prstp' num2str(AnalysisOpts.ProcessingStep)],...
                            'SaveInResults',1,'WantedDate',AnalysisOpts.CurrentCh_RecDate);
                        obj.FigParams.SaveFigSeries([],SingCellAnaFigsFileName,[varargout],'SaveEachFrame',0)
                    end
                    
                    %% generate a summery file for population or single cells
                case 4
                    nar=length(obj.TargetArea);
                    np=2*nar;AnalysisOpts.np=np;
                    
                    obj.CreateNeuronSummeryFile;
                    
                    %[varargout{(1:np)}]       =obj.PlotSignificantGLMfactors([],'HybridbhvMdlFull','PlotResults',1);
                    %                     [varargout{(1:np)}]       =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                     obj.TrialFunc.RevertCh_2look;
                    %                     [varargout{(np+1:2*np)}]  =obj.PlotSignificantGLMfactors([],'SensoryMotorMdl','PlotResults',1);
                    %                     obj.TrialFunc.RevertCh_2look;
                    %                     [varargout{(2*np+1:3*np+1)}]=obj.PlotSignificantGLMfactors('CompareBhvModels','','PlotResults',1);
                    
                    % now plot model comparision results
                    %   obj.TrialFunc.RevertCh_2look;
                    %      [varargout{(1:np)}]       =obj.PlotSignificantGLMfactors('CompareBhvModels','','PlotResults',1);
                    
                    %% generate a summery plot for population or single cells
                case 5
                    
                    % Plot Information by Area
                    %   obj.PlotInformaitonByArea(Time,factornames,'')
                    % [varargout{2:3}]=obj.PlotwPEVbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames);
                    % [varargout{5:6}]=obj.PlotInformationbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames);
                    
                    % plot basic charactristics of the neuron
                    %                     [varargout{1}]=obj.PlotResponseLatencies(FactorizedData,Time);
                    %                     [varargout{2}]=obj.PlotPSTHbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames(1:9));
                    %                     [varargout{3:4}]=obj.PlotTuningCurvesbyFactor(FactorizedData_Raster,RasterTime,{'ColorML','ShapeML'});
                    
                    % plot GLM models
                    base=4;
                    nar=length(obj.TargetArea);
                    np=2*nar;AnalysisOpts.np=np;
                    [varargout{base+(1:np)}]       =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                   obj.TrialFunc.RevertCh_2look;
                    %                   [varargout{base+(np+1:2*np)}]  =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                   obj.TrialFunc.RevertCh_2look;
                    %                   [varargout{base+(2*np+1:3*np)}]=obj.PlotSignificantGLMfactors([],'SensoryMotorMdl','PlotResults',1);
                    %
                    %                   % plot GLM model comparison results
                    %                   [varargout{base+3*np+(1:3)}]=obj.PlotGLMmodelComparision_Hierarchical('CompareBhvModels');
            end
        end
        function varargout=SetupSingleCellAnalysis_TrialTime(obj,data,TimingStimData,varargin) % prepare the data for single cell analysis of spiking data in time and trial
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %data is usually the PSTH
            %factor data is stimlus dimensions we care about
            
            % get the spiking data for one cell and concatinate the
            % information
            
            NNeu=length(data);
            Time=data(1).SpkCountTim{1}-AnalysisOpts.SpkParams.BaselineDelay;
            %% get data for each of the neurons
            for Neu=1:NNeu
                [FactorizedData(Neu).data,FactorizedData(Neu).factors,FactorizedData(Neu).factornames]=...
                    obj.GetFactorDataForThisNeuron(data(Neu),TimingStimData(Neu),1);
            end
            factornames=FactorizedData(Neu).factornames;
            
            %% plot GLM by factor
            %   varargout(2)=obj.PlotGLMfitbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames);
            
            %% plot information by factor
            varargout=cell(1);
            [varargout{:}]=obj.PlotInformationbyFactor_TrialTime(FactorizedData,Time,FactorizedData(Neu).factornames);
        end
        
        function [databyFactor,factors,factornames,TimingTaskData,StimInfoData,SpkCntbyFactor,obj]=GetFactorDataForThisNeuron(obj,data,TimingStimData,DataType,varargin)
            % DataType: can be 'PSTH' or 'Raster'
            % time
            global AnalysisOpts
            if ~isempty(varargin);TrlTimAna=varargin{1};else;TrlTimAna=0;end
            
            if TrlTimAna
                Dim=63;
            else
                Dim=62;
            end
            nBlks=length(TimingStimData.CriticalTimes);
            databyFactor=obj.ManData.ReshapeCell2Mat(data.(DataType),Dim); % put all of the trails in a big matrix
            TimingTaskData=obj.ManData.ReshapeCell2Mat(TimingStimData.CriticalTimes,Dim); % the the crital times data
            TrialTimesData=obj.ManData.ReshapeCell2Mat(TimingStimData.TrialTimes,Dim); % the the trial times data
            StimInfoData=obj.ManData.ReshapeCell2Mat(TimingStimData.StimulusInfo,Dim); % the the crital times data
            % add information about trial number, block histroy and block order
            SeqHist=cell2mat(arrayfun(@(x) TimingStimData.SeqHist(x)*ones(1,TimingStimData.ThisBlkTrialNum(x)),1:length(TimingStimData.SeqHist),'UniformOutput',0));
            TrialNum=cell2mat(arrayfun(@(x) 1:TimingStimData.ThisBlkTrialNum(x),1:length(TimingStimData.ThisBlkTrialNum),'UniformOutput',0));
            TrialNumReverse=cell2mat(arrayfun(@(x) -TimingStimData.ThisBlkTrialNum(x):-1,1:length(TimingStimData.ThisBlkTrialNum),'UniformOutput',0));
            BlkOrder=cell2mat(arrayfun(@(x) ones(1,TimingStimData.ThisBlkTrialNum(x))*TimingStimData.ThisBlkOrder(x),1:length(TimingStimData.ThisBlkOrder),'UniformOutput',0));
            NTrl=size(databyFactor,1);
            % get the behvioral perfromance from switch
            FromSwitchBhvPerf=cell2mat(arrayfun(@(x) TimingStimData.BlkPerf{x}.All(1)*ones(1,TimingStimData.ThisBlkTrialNum(x)),1:nBlks,'UniformOutput',0));
            % get behavioral performance for each feature 
            RESLOC_NUM_OFFSET_IND=strcmp(AnalysisOpts.TrialTimesFields,'RESLOC_NUM_OFFSET');
            [PerfShape10,PerfColor10]=arrayfun(@(x) obj.BhvAna.CalculateBhvFeaturePerformance(TimingStimData.StimulusInfo{x}(:,3),TimingStimData.StimulusInfo{x}(:,4),...
                TimingStimData.TrialTimes{x}(:,RESLOC_NUM_OFFSET_IND),TimingStimData.Rule(x),10),1:nBlks,'UniformOutput',0);
            PerfShapeData10=obj.ManData.ReshapeCell2Mat(PerfShape10,Dim)'; % the the trial times data
            PerfColorData10=obj.ManData.ReshapeCell2Mat(PerfColor10,Dim)'; % the the trial times data
            % do for 50 trials
            [PerfShape50,PerfColor50]=arrayfun(@(x) obj.BhvAna.CalculateBhvFeaturePerformance(TimingStimData.StimulusInfo{x}(:,3),TimingStimData.StimulusInfo{x}(:,4),...
                TimingStimData.TrialTimes{x}(:,RESLOC_NUM_OFFSET_IND),TimingStimData.Rule(x),50),1:nBlks,'UniformOutput',0);
            PerfShapeData50=obj.ManData.ReshapeCell2Mat(PerfShape50,Dim)'; % the the trial times data
            PerfColorData50=obj.ManData.ReshapeCell2Mat(PerfColor50,Dim)'; % the the trial times data

            % concatinate all of the data of the behavioral model
            HybridMdlData=obj.ManData.ReshapeCell2Mat(TimingStimData.HybridBhvMdl,Dim);
            InferFeatureAxisMdlData=obj.ManData.ReshapeCell2Mat(TimingStimData.InferenceAxisFeatureBhvMdl,Dim);
            % get specific values we care about from both behavioral models
            % Hybrid model
            try
                HybridMdl.Beliefs_over_axes=obj.ManData.ReshapeStruct2Mat(HybridMdlData,'Beliefs_over_axes',Dim);
                HybridMdl.Q_values=obj.ManData.ReshapeStruct2Mat(HybridMdlData,'Q_values',Dim);
                HybridMdl.Weights_values=obj.ManData.ReshapeStruct2Mat(HybridMdlData,'Weights_w',Dim);
                
                % inference feature axis model
                InferFeatureAxisMdl.Beliefs_over_axes=obj.ManData.ReshapeStruct2Mat(InferFeatureAxisMdlData,'Beliefs_over_axes',Dim);
                InferFeatureAxisMdl.Beliefs_over_features=obj.ManData.ReshapeStruct2Mat(InferFeatureAxisMdlData,'Beliefs_over_features',Dim);
                InferFeatureAxisMdl.Q_values=obj.ManData.ReshapeStruct2Mat(InferFeatureAxisMdlData,'Q_values',Dim);
            catch
                warning('found an error in processing the belief data...')
                HybridMdl.Beliefs_over_axes=zeros(NTrl,2);
                HybridMdl.Q_values=zeros(NTrl,4);
                HybridMdl.Weights_values= zeros(NTrl,8);
                
                % inference feature axis model
                InferFeatureAxisMdl.Beliefs_over_axes= zeros(NTrl,2);
                InferFeatureAxisMdl.Beliefs_over_features= zeros(NTrl,2);
                InferFeatureAxisMdl.Q_values= zeros(NTrl,4);
            end
            %% double check code
            if sum(sum(AnalysisOpts.StimMap.cuemapshape(TrialTimesData(:,14),2:end)~=StimInfoData))
                error('StimCode is not matching')
            end
            %%
            % now wPEV for each data point in time
            %% prepare data for differnt factors we care about
            %% f1= color morphlevel
            ColorMLInd=strcmp(AnalysisOpts.StimMap.FieldNames,'ColorML');
            f1=squeeze(StimInfoData(:,ColorMLInd,:))';
            %% f2=shape morphlevel
            ShapeMLInd=strcmp(AnalysisOpts.StimMap.FieldNames,'ShapeML');
            f2=squeeze(StimInfoData(:,ShapeMLInd,:))';
            %% f3= Color category
            ColorCatInd=strcmp(AnalysisOpts.StimMap.FieldNames,'ColorCat');
            f3=squeeze(StimInfoData(:,ColorCatInd,:))';
            %% f4= Shape category
            ShapeCatInd=strcmp(AnalysisOpts.StimMap.FieldNames,'ShapeCat');
            f4=squeeze(StimInfoData(:,ShapeCatInd,:))';
            %% f=23 Congruency
            f23=obj.ManData.DetermineStimCongruency(f3,f4);
            %% f5=Rule
            RuleInd=strcmp(AnalysisOpts.TrialTimesFields,'CONDITION_NUM_OFFSET');
            f5=squeeze(TimingTaskData(:,RuleInd,:))';
            %% f26=SeqHist history of rule squences for each trial
            f26=SeqHist;
            %% f27=TrialNumber from beginning of a block
            f27=TrialNum;
            %% f28=TrialNumber Reverse from end of block
            f28=TrialNumReverse;
            %% block order
            f29=BlkOrder;
            %% f24=feature
            f24=zeros(size(f5));
            f24(f5==1)=1; % shape feature
            f24(f5==2 | f5==3)=2; % color feature
            if sum(f24==0); error('Soemthing wrong with rule indexes');end
            %% f25=axis
            f25=zeros(size(f5));
            f25(f5==1 | f5==3)=1; % Axis1
            f25(f5==2 )=2; % Axis 2
            if sum(f25==0); error('Soemthing wrong with rule indexes');end
            %% f6 response location
            ResponseLocInd=strcmp(AnalysisOpts.TrialTimesFields,'RESLOC_NUM_OFFSET');
            f6=squeeze(TimingTaskData(:,ResponseLocInd,:))';
            %% f7 Reward
            RewardInd=strcmp(AnalysisOpts.TrialTimesFields,'REWARD_START');
            f7=~isnan(squeeze(TimingTaskData(:,RewardInd,:))');
            CorrectIncorrectInd=strcmp(AnalysisOpts.TrialTimesFields,'CORRECT_TRIAL');
            CorrectIncorrect=~isnan(squeeze(TimingTaskData(:,CorrectIncorrectInd,:))');
            if sum(f7~=CorrectIncorrect);error('error in processing reward');end
            %% f8 Reaction Time
            % SampleOnsetInd=strcmp(AnalysisOpts.TrialTimesFields,'SAMPLE_ON');
            % f8=squeeze(TimingTaskData(:,RewardInd,:))'-squeeze(TimingTaskData(:,SampleOnsetInd,:))';
            RT_EyeTrackerInd=strcmp(AnalysisOpts.TrialTimesFields,'RT_EyeTracker');
            f8=squeeze(TimingTaskData(:,RT_EyeTrackerInd,:))';
            %% f9 Trial Time
            TrialTimeInd=strcmp(AnalysisOpts.TrialTimesFields,'START_TRIAL');
            f9=TrialTimesData(:,TrialTimeInd)';
            f9=mapminmax(f9,0,1); % normalize time to run between 0 and 1
            % get elements of Hybrid model
            %% f10 Hybrid Qvalues
            f10=HybridMdl.Q_values';
            % f11 get RPE for hybrid moel. For now we defien the RPE as r-Q(a); where a is the action taken
            f11=arrayfun(@(x) f7(x)-f10(f6(x),x),1:NTrl);
            % f12 and f13 get W per rule for hybrid model
            % get the information from the weight matrix first
            % [xcol xshp xcol xshp xcol xshp xcol xshp]
            W_Rule_ind={[1 2 1 2 0 0 0 0],[0 0 0 0 1 2 1 2],[1 2 1 2 0 0 0 0]};
            % multiply this matrix to the W matrix to get the value of
            % shape and color based on axis of response
            W_Rule=cell2mat(arrayfun(@(x) abs(HybridMdl.Weights_values(x,W_Rule_ind{f5(x)}~=0)),1:NTrl,'UniformOutput',0)')';
            % take W color at both response locations as the average W value of color
            f12=W_Rule(W_Rule_ind{1}==1,:); % take color values for two locations
            % take W shape at both response locations as the average W value of shape
            f13=W_Rule(W_Rule_ind{1}==2,:); % take shape values for two locations
            % take difference of absolute value of color and shape for two
            % locations
            f22=f12-f13;
            % f14 Hybrid Beliefs_over_axes
            f14=HybridMdl.Beliefs_over_axes(:,1)';
            
            %% get elements of inference axis feature model inference feature axis model
            % f15 Infernece Feature Axis model Qvalues
            f15=InferFeatureAxisMdl.Q_values';
            % f16 get RPE for inference axis feature model. For now we defien the RPE as r-Q(a); where a is the action taken
            f16=arrayfun(@(x) f7(x)-f15(f6(x),x),1:NTrl);
            % f13 Infernece Feature Axis model Beliefs_over_axes
            f17=InferFeatureAxisMdl.Beliefs_over_axes(:,1)';
            % f14 Infernece Feature Axis model Beliefs_over_features
            f18=InferFeatureAxisMdl.Beliefs_over_features(:,1)';
            
            %% get elements of inference over rule model
            % f19 Q values for the rule model
            f19=InferFeatureAxisMdl.Q_values';
            % f20 get RPE for inference rule model.  = RPE of inference
            % feature axis
            f20=f16;
            % f21 Infernece rule model belief over rule which is the
            % InferFeatureAxisMdl.Beliefs_over_axes * InferFeatureAxisMdl.Beliefs_over_features
            Axis_rule_ind=[1 2 1]; Feature_Rule_ind=[2 1 1];
            f21=arrayfun(@(x)  InferFeatureAxisMdl.Beliefs_over_axes(x,Axis_rule_ind(f5(x)))*InferFeatureAxisMdl.Beliefs_over_features(x,Feature_Rule_ind(f5(x))),1:NTrl);
            % f21=cell2mat(arrayfun(@(x)  InferFeatureAxisMdl.Beliefs_over_axes(:,Axis_rule_ind(x)).*InferFeatureAxisMdl.Beliefs_over_features(:,Feature_Rule_ind(x)),1:3,'UniformOutput',0))';
            % get the behavioral perromance from switch
            f30=FromSwitchBhvPerf;
            % get local behavioral performance for shape and color features 
            f31=PerfShapeData50;f32=PerfColorData50;f33=PerfShapeData10;f34=PerfColorData10;
            %% concatinate all of the factors together %% important %% factors should be in increasing order and match
            %% factor names
            factors={f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f22,f23,f24,...
                f25,f26,f27,f28,f29,f30,f31,f32,f33,f34};
            factornames={'ColorML','ShapeML','ColorCat','ShapeCat','Rule','ResponseLoc','Reward','RT','Time',...
                'Hybrid_Q1','Hybrid_Q2','Hybrid_Q3','Hybrid_Q4','Hybrid_RPE','Hybrid_W_Color1','Hybrid_W_Color2',...
                'Hybrid_W_Shape1','Hybrid_W_Shape2','Hybrid_Baxes',...
                'InferAF_Q1','InferAF_Q2','InferAF_Q3','InferAF_Q4','InferAF_RPE','InferAF_Baxes','InferAF_Bfeature',...
                'InferRule_Q1','InferRule_Q2','InferRule_Q3','InferRule_Q4','InferRule_RPE','InferRule_Brule','Hybrid_W_Diff1','Hybrid_W_Diff2',...
                'Congruency','Feature','Axis','SeqHist','TrialNum','TrialNumReverse','BlkOrder','FromSwitchBhvPerf',...
                'BhvPerfShape50','BhvPerfColor50','BhvPerfShape10','BhvPerfColor10'};
            AnalysisOpts.factornames=factornames;
            % generate factor index; with factor index it will be easy to
            % find the index of each factor in factors based on their name
            AnalysisOpts.factorindex=[cell2mat(arrayfun(@(x) x*ones(1,size(factors{x},1)),1:length(factors),'uniformoutput',0)),...
                ; cell2mat(arrayfun(@(x) 1:size(factors{x},1),1:length(factors),'uniformoutput',0))];
            
            %% if we want to remove all of the trials with 50% and 150% morph levels
            if obj.Remove50MLFactor
                ColorCatInd=obj.GetFactornameInd('ColorCat');
                ShapeCatInd=obj.GetFactornameInd('ShapeCat');
                WantedTrls=factors{ColorCatInd}~=-1 & factors{ShapeCatInd}~=-1;    
                try
                factors=cellfun(@(x) x(:,WantedTrls),factors,'UniformOutput',0);
                catch me
                    disp(me.message)
                end
                databyFactor=databyFactor(WantedTrls,:);
                TimingTaskData=TimingTaskData(WantedTrls,:);
                StimInfoData=StimInfoData(WantedTrls,:);
            end
            %% if we are detrending the data before everything else?
            if obj.DetrendFactorData
                %               below is to use detrend which doesn't look right
                %                 reorganize data based on their block order
                %                 NumBlksSet=unique(f29);
                %                 BlkSortData=cell2mat(arrayfun(@(x) databyFactor(f29==x,:)',NumBlksSet,'UniformOutput',0))';
                %                 BlkSortDataRS=reshape(BlkSortData,[1 size(BlkSortData,1)*size(BlkSortData,2)]);
                %                % figure
                %                % plot(movmean(BlkSortDataRS,100));
                %                  DTBlkSortDataRS=detrend(BlkSortDataRS,1);
                %                % hold on;plot(movmean(DTBlkSortDataRS,100),'r')
                FactorizedData.factors=factors;
                FactorizedData.data=databyFactor;
                [GLMfit]=obj.GLMfit_time(FactorizedData,'GLMmdl','TimeMdl'); % fit GLM using regular method
                % now plot and compare
                %   sizedatabyFactor=length(databyFactor(:));
                %  figure
                %  hold on
                %   plot(movmean(reshape(databyFactor,[1 sizedatabyFactor]),100),'r')
                % [~, MinMSEInd]=min(GLMfit.MSE);
                databyFactor=databyFactor-GLMfit.Yhat{3}; % taking the third lambda
                %  plot(movmean(reshape(databyFactor,[1 sizedatabyFactor]),100),'k')
            end
            
            %% if we need to zscore factor data for each neuron?
            if obj.ZscoreFactorData
                fprintf(2,'\n Warning: we are zeroscoring the data for each neuron ...');
                SizeDatabyFactor=size(databyFactor);
                databyFactor=zscore(reshape(databyFactor,[1 SizeDatabyFactor(1)*SizeDatabyFactor(2)]));
                databyFactor=reshape(databyFactor,SizeDatabyFactor);
            end
            %% if we also want spike count data for a specific time period
            if ~isempty(obj.SpkCountPeriod)
                RasterByFactor=obj.ManData.ReshapeCell2Mat(data.Raster,62); % put all of the trails in a big matrix
                if obj.Remove50MLFactor;RasterByFactor=RasterByFactor(WantedTrls,:);end
                for i=1:size(obj.SpkCountPeriod,1) % loop on number of spike count periods we want
                    % eval(sprintf('SpkCntbyFactor%i=obj.GetPeriodSpikeCount(RasterByFactor,obj.SpkCountPeriod(i,:),AnalysisOpts.RasterTime);',i));
                    SpkCntbyFactor{i}=obj.GetPeriodSpikeCount(RasterByFactor,obj.SpkCountPeriod(i,:),AnalysisOpts.RasterTime);
                    if obj.ZscoreFactorData
                        SizeDatabyFactor=size(SpkCntbyFactor{i});
                        SpkCntbyFactor{i}=zscore(SpkCntbyFactor{i});
                    end
                end
            else
                SpkCntbyFactor=[];
            end
            %% do you want to apply some transformation to the data?
            if obj.MeanSubtractByRule==1 % we are zero meaning the data for each neuron for each rule
                RuleInd=obj.GetFactornameInd('Rule');
                Rule=factors{RuleInd};%eval(['Rule=f' num2str(find(RuleInd)) ';']);
                MeanRuleData=arrayfun(@(x) mean(databyFactor(Rule==x,:),1),1:3,'UniformOutput',0);
                MeanRuleData_SpkCnt=[];
                for R=1:3
                    databyFactor(Rule==R,:)= databyFactor(Rule==R,:)-repmat(MeanRuleData{R},[size(databyFactor(Rule==R,:),1) 1]);
                    if ~isempty(obj.SpkCountPeriod)
                        for i=1:size(obj.SpkCountPeriod,1)
                            MeanRuleData_SpkCnt{R}(i)=mean(SpkCntbyFactor{i}(Rule==R)); 
                            SpkCntbyFactor{i}(Rule==R)=SpkCntbyFactor{i}(Rule==R)-MeanRuleData_SpkCnt{R}(i);                           
                        end
                    end
                end
                % save mean data for each neuron since we might use it in the future 
                obj=obj.ParseParams({'MeanDataByRule',cat(1,obj.MeanDataByRule,MeanRuleData),...
                    'MeanDataByRule_SpkCnt',cat(1,obj.MeanDataByRule_SpkCnt,MeanRuleData_SpkCnt)});  
            end
            
        end
        function FactorInd=GetFactornameInd(~,FactorName) % get the ind of the a specific factor in factornames
            global AnalysisOpts
            FactorInd=strcmp(AnalysisOpts.factornames,FactorName);
        end
        function FactorInd=GetFactornameIndConML2Cat(~,FactorName) % converts ML to Catget the ind of the a specific factor in factornames
            global AnalysisOpts

            if contains(FactorName,'ML')
                FactorName=[FactorName(1:5) 'Cat'];
            end

            FactorInd=strcmp(AnalysisOpts.factornames,FactorName);
        end
        function FactorData=MeanSubtractRuleCombs(~,FactorData,CombTrainRule) % subtract the mean of two rules from all rules
            % only used for classfier trained on Rule compositionality condition
            global AnalysisOpts
            for Neu=1:length(FactorData)
                MeanRule=mean([FactorData(Neu).data{CombTrainRule(1)};FactorData(Neu).data{CombTrainRule(2)}],1);
                FactorData(Neu).data=cellfun(@(x) x-MeanRule,FactorData(Neu).data,'UniformOutput',0);
                %  FactorData(Neu).data{CombTrainRule(1)}=FactorData(Neu).data{CombTrainRule(1)}-MeanRule;
                %  FactorData(Neu).data{CombTrainRule(2)}=FactorData(Neu).data{CombTrainRule(2)}-MeanRule;
            end
            
        end
        function [FactorData,FactorLevels]=SortFactorDatabyLevel(obj,FactorizedData,TargetFactor,varargin) % sorts the given factor data and gives the inds for trials based on factor
            %  IntegTimeEpoch is the time epoch that we want to sum the
            %  number of spikes ; leave empty if you don't want it
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            factornames=FactorizedData.factornames;
            TargFactorInd=strcmp(factornames,TargetFactor);
            ThisFactor=FactorizedData.factors{TargFactorInd};
            
            if strcmp(TargetFactor,'RT')  % if this is RT then use hist to chunk the distribution
                MeanRT=nanmean(ThisFactor);StdRT=nanstd(ThisFactor);
                Edges=[min(ThisFactor) MeanRT-StdRT MeanRT+StdRT  max(ThisFactor)+0.001];
                FactorData=arrayfun(@(x) FactorizedData.data(ThisFactor>=Edges(x) & ThisFactor<Edges(x+1),:),1:(length(Edges)-1),'UniformOutput',false);
                FactorLevels=arrayfun(@(x) mean([Edges(x) Edges(x+1)]),1:(length(Edges)-1));
            elseif contains(TargetFactor,'Hybrid_Q') ||  strcmp(TargetFactor,'Hybrid_Baxes') || strcmp(TargetFactor,'Time') ...
                    || contains(TargetFactor,'InferAF_Q') || strcmp(TargetFactor,'InferAF_Baxes') || strcmp(TargetFactor,'InferAF_Bfeature') % if this is Qval or axis belief then get value for one of them only
                ThisFactor=ThisFactor(1,:);
                MeanVal=nanmean(ThisFactor);StdVal=nanstd(ThisFactor);
                Edges=[min(ThisFactor) MeanVal-StdVal MeanVal+StdVal  max(ThisFactor)+0.001];
                FactorData=arrayfun(@(x) FactorizedData.data(ThisFactor>=Edges(x) & ThisFactor<Edges(x+1),:),1:(length(Edges)-1),'UniformOutput',false);
                FactorLevels=arrayfun(@(x) mean([Edges(x) Edges(x+1)]),1:(length(Edges)-1));
            else
                FactorLevels=unique(ThisFactor);
                FactorData=arrayfun(@(x) FactorizedData.data(ThisFactor==x,:),FactorLevels,'UniformOutput',false);
            end
            % remove data that are non existant
            isemptyFactor=~cellfun(@isempty,FactorData);
            FactorData=FactorData(isemptyFactor);
            FactorLevels=FactorLevels(isemptyFactor);
        end
        function FactorizedData=GetTimeEpochDatainFactorizedData(~,FactorizedData,Time,TimeEpoch)% the the data from specific time epoch in trial in factorized data
            EpochLength=TimeEpoch(2)-TimeEpoch(1);
            TimeEpochInd=Time>=TimeEpoch(1) & Time<TimeEpoch(2);
            for Neu=1:length(FactorizedData)
                FactorizedData(Neu).data=sum(FactorizedData(Neu).data(:,TimeEpochInd),2)/EpochLength;
            end
        end
        function [CatFactorizedData]=CatFactorizedFata(~,FactorizedData,FactorDimension,ZscoreFlag,ShuffleData)  % Concatinates factorized data acorss neurons
            % Factorzied data is the data that has been processed based on
            % the factors
            % Factor dimension is the dimension where the factor is
            % ZscoreFlag: 1:are we zscording the data based on the time course of the neuonr
            % ZscoreFlag: 2:are we zscording the data based on the ShuffleData
            % ShuffleData shuffle data to calculate zscore from
            DataFields=fieldnames(FactorizedData)';
            NNeu=length(FactorizedData);
            NFactor=size(FactorizedData(1).(DataFields{1}),FactorDimension); % number of different factors
            zscor_xnan = @(x) bsxfun(@rdivide, bsxfun(@minus, x, mean(x(:),'omitnan')), std(x(:), 'omitnan'));
            
            % subtract mean baseline activity for each cell and Zscore them
            for field=DataFields % loop on fields
                field=field{1};
                NFactor=size(FactorizedData(1).(field),FactorDimension); % number of different factors
                for f=1:NFactor % loop on factors
                    for Neu=1:NNeu % loop on neurons
                        if FactorDimension==3 % for time and trial processing
                            if ZscoreFlag==1
                                CatFactorizedData(f).(field)(:,:,Neu)=zscor_xnan(FactorizedData(Neu).(field)(:,:,f));
                            else
                                CatFactorizedData(f).(field)(:,:,Neu)=FactorizedData(Neu).(field)(:,:,f);
                            end
                        elseif FactorDimension==1 % mainly for time processing
                            if ZscoreFlag==1
                                CatFactorizedData(f).(field)(Neu,:)=zscor_xnan(FactorizedData(Neu).(field)(f,:));
                            elseif ZscoreFlag==2
                                
                            else
                                CatFactorizedData(f).(field)(Neu,:)=FactorizedData(Neu).(field)(f,:);
                            end
                        elseif FactorDimension==2
                            CatFactorizedData.(field)(Neu,:)=FactorizedData(Neu).(field);
                        end
                    end
                end
            end
        end
        function varargout=PlotFactorizedData(obj,data,Time,TargetFactorInd,Col,FieldtoUse,Title,Xlabel,Ylabel,h,sp,varargin)  % plots factorzied data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isempty(h)
                h=obj.FigParams.RenderFigure(1,[]); % create figures
            end
            figure(h{1});
            subplot(sp)
            % only use significant neurons if we are doing statistical
            % analysis
            if ~isempty(obj.Neu2Use) & sum(obj.Neu2Use)~=0
                Neu2Use=obj.Neu2Use;
            elseif ~isempty(obj.Neu2Use) & sum(obj.Neu2Use)==0
                Neu2Use=[];
            else
                Neu2Use=1:size(data(TargetFactorInd).(FieldtoUse),1);
            end
            
            Title=strrep(Title,'_',' '); % replace _ with space
            %% if this is only a one dimensional data the plot line
            if size(data(1).(FieldtoUse),3)==1
                hp=obj.FigParams.PlotMeanStd(Time,data(TargetFactorInd).(FieldtoUse)(Neu2Use,:),[],Xlabel,Ylabel,Col,obj.MeanStdPlotType,Title,'NormalizebyMax',obj.NormalizebyMax,...
                    'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',obj.ThisLegendTxt,'LegendLoc','best','p_line_style',obj.ThisLineStyle,...
                    'NPnts_SubtractBaseLine',obj.NPnts_SubtractBaseLine,'SubtractBaseLine',obj.SubtractBaseLine,...
                    'font_size',obj.font_size,'NormalizebyMean',obj.NormalizebyMean,'p_marker',obj.ThisMarker);
            else
                %% then we are plotting things in time and trial
                NNeu=size(data(TargetFactorInd).(FieldtoUse),3);
                ThisData=nanmean(data(TargetFactorInd).(FieldtoUse),3);
                [ThisData,TimeInds]=obj.ManData.MoveMean(ThisData,obj.WidthSmoothing,'valid');
                Time=Time(TimeInds(:,2));
                hp=helperCWTTimeFreqPlot(ThisData,Time,1:size(ThisData,1),'justplot1',...
                    [Title ',n=' num2str(NNeu)] ,...
                    [Xlabel] ,Ylabel,0);
            end
            varargout{1}=h;
            varargout{2}=hp;
        end
        
        %% functions for ePEV analysis
        function [wPEV,Eta]=wPEV_time(obj,FactorizedData,varargin) % calculate wPEV for trials and factors across time points
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            NTim=size(FactorizedData.data,2);
            for t=1:NTim
                [wPEV(:,t),Eta(:,t)]=obj.CalwPEV(FactorizedData.data(:,t),FactorizedData.factors,FactorizedData.factornames);
            end
        end
        function [wPEV,Eta]=CalwPEV(obj,data,factors,factornames)  % calculates wPEV for the data
            global AnalysisOpts
            % do the anova on all of the factors we care about
            [~,tbl]=anovan(data,factors,'varnames',factornames,'display','off');
            % calculate degrees of freedom
            DF=cellfun(@(x) length(unique(x))-1,factors);
            % find where is error in here
            ErrInd=(strcmp(tbl(:,1),'Error'));
            MeanSqrInd=(strcmp(tbl(1,:),'Mean Sq.'));
            TotalInd=(strcmp(tbl(:,1),'Total'));
            SumSqInd=(strcmp(tbl(1,:),'Sum Sq.'));
            FactorInds=cellfun(@(x) find(strcmp(tbl(:,1),x)),factornames);
            % now calculate R2 and wPEV for each factor
            MSE=tbl{ErrInd,MeanSqrInd};
            SStot=tbl{TotalInd,SumSqInd};
            wPEV=arrayfun(@(x) (tbl{FactorInds(x),2}-DF(x)*MSE)/(SStot+MSE),1:length(FactorInds));
            Eta=arrayfun(@(x) (tbl{FactorInds(x),2})/SStot,1:length(FactorInds));
        end
        function varargout=PlotwPEVbyFactor(obj,FactorizedData,Time,TargetFactor,varargin)% plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            %% now get the information about each factor using ANOVA and wPEV analysis
            for Neu=1:length(FactorizedData)
                fprintf('\nCalculating wPEV for Neuron %i',Neu)
                [AnovaAna(Neu).wPEV,AnovaAna(Neu).Eta]=obj.wPEV_time(FactorizedData(Neu));
            end
            [CatAnovaAna]=obj.CatFactorizedFata(AnovaAna,1,obj.ZscoreFlag);
            
            NTargFactors=length(TargetFactor);
            [h1,Sp]=obj.FigParams.RenderSubplots([],[],[],NTargFactors);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            arrayfun(@(x) obj.PlotFactorizedData(CatAnovaAna,Time,x,[1 0 0],'wPEV',FactorizedData(1).factornames{x},AnalysisOpts.Xlabel,'wPEV',h1,Sp(x)),TargetFactorInds);
            
            
            Col=obj.FigParams.getColorPalet(NTargFactors);
            [h2,Sp]=obj.FigParams.RenderSubplots([],[],[],1);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            [~,Legs]=arrayfun(@(x) obj.PlotFactorizedData(CatAnovaAna,Time,x,Col(x,:),'wPEV',FactorizedData(1).factornames{x},AnalysisOpts.Xlabel,'wPEV',h2,Sp),TargetFactorInds);
            legend(Legs,TargetFactor)
            varargout=[h1 h2];
            
            %% Save vars
            AnalysisOpts.CurrentCh='';
            obj.ManData.SaveVar([],AnovaAna,'AnovaAna',['SingCellAna_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt])
        end
        
        %% functions for information theory analysis
        function [I,Iz]=Information_TrialTime(obj,FactorizedData,varargin) % calculate mututal info for resp and factors across time points
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            NTim=size(FactorizedData.data,2);
            NTrl=size(FactorizedData.data,1);
            NFactors=length(FactorizedData.factornames);
            TrlAvgInd=obj.ManData.GenMovAvgInds(NTrl,obj.n_TrlAvg,'valid');
            
            for f=1:NFactors
                for t=1:NTim
                    % waitbar(t/NTim,sprintf('Processing Factor %i',f));
                    for trl=1:size(TrlAvgInd,1)
                        ThisTrls=[TrlAvgInd(trl,1):TrlAvgInd(trl,2)];
                        ThisTrlsData=squeeze(FactorizedData.data(ThisTrls,t,:))';
                        ThisTrlsFactors=FactorizedData.factors{f}(:,ThisTrls);
                        [I(trl,t,f),~,Iz(trl,t,f)]=obj.ManData.CalculateInformation(obj.ManData.CategorizeData(ThisTrlsFactors(:)),....
                            ThisTrlsData(:));
                        %   [I(trl,t,f)]=abs(corr(obj.ManData.CategorizeData(ThisTrlsFactors(:)),ThisTrlsData(:)));
                    end
                end
            end
        end
        function [I,Ish,Iz]=Information_time(obj,FactorizedData,varargin) % calculate  mututal info between resp and  factors across tials and time points
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            NTim=size(FactorizedData.data,2);
            NFactors=length(FactorizedData.factornames);
            for f=1:NFactors
                %% if this information is about color or shape morph level then use the modulation index
                if strcmp(FactorizedData.factornames{f},'ColorML') | strcmp(FactorizedData.factornames{f},'ShapeML')
                    for t=1:NTim
                        [I(f,t),Iz(f,t)]=obj.ManData.CalModulationIndex(obj.ManData.CategorizeData(FactorizedData.factors{f}),...
                            FactorizedData.data(:,t)',obj.NShuffle);
                        %  [I(f,t),Iz(f,t)]=obj.ManData.CalSelectivityIndex(obj.ManData.CategorizeData(FactorizedData.factors{f}),...
                        %      FactorizedData.data(:,t)',obj.NShuffle);
                    end
                else
                    for t=1:NTim
                        [I(f,t),Ish,Iz(f,t)]=obj.ManData.CalculateInformation(obj.ManData.CategorizeData(FactorizedData.factors{f}),....
                            FactorizedData.data(:,t)');
                    end
                end
            end
        end
        function varargout=PlotInformationbyFactor(obj,FactorizedData,Time,TargetFactor,varargin)% plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            %% now get the information about each factor using ANOVA and wPEV analysis
            for Neu=1:length(FactorizedData)
                fprintf('\nCalculating Information for Neuron %i',Neu)
                [InformationAna(Neu).I,~,InformationAna(Neu).Iz]=obj.Information_time(FactorizedData(Neu));
            end
            
            [CatInformationAna]=obj.CatFactorizedFata(InformationAna,1,obj.ZscoreFlag);
            
            NTargFactors=length(TargetFactor);
            [h1,Sp]=obj.FigParams.RenderSubplots([],[],[],NTargFactors);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            arrayfun(@(x) obj.PlotFactorizedData(CatInformationAna,Time,x,[1 0 0],'Iz',FactorizedData(1).factornames{x},...
                AnalysisOpts.Xlabel,'I(bits)',h1,Sp(x)),TargetFactorInds);
            
            Col=obj.FigParams.getColorPalet(NTargFactors);
            [h2,Sp]=obj.FigParams.RenderSubplots([],[],[],1);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            [~,Legs]=arrayfun(@(x) obj.PlotFactorizedData(CatInformationAna,Time,x,Col(x,:),'Iz',FactorizedData(1).factornames{x},...
                AnalysisOpts.Xlabel,'I(bits)',h2,Sp),TargetFactorInds);
            legend(Legs,TargetFactor)
            
            varargout=[h1 h2];
            
            %% save the data
            AnalysisOpts.CurrentCh='';
            obj.ManData.SaveVar([],InformationAna,'InformationAna',['SingCellAna_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt])
            
        end
        function varargout=PlotInformaitonByArea(obj,Time,factornames,TargetFactor,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            Col=obj.FigParams.getColorPalet(5);
            if isempty(TargetFactor);TargetFactor=factornames;end
            NFactors=length(TargetFactor);
            TargetFactorInds=cellfun(@(x) find(strcmp(factornames,x)),TargetFactor);
            [h2,Sp]=obj.FigParams.RenderSubplots([],[],[],NFactors);
            
            % load realated area information
            AnalysisOpts.Xlabel=['Time(s) from ' strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ')];
            AnalysisOpts.RecDate=AnalysisOpts.DateSet{1};
            AnalysisOpts.CurrentCh='';Legs=[];
            FieldToPlot='I';
            for Area=1:5
                InformationAna=obj.ManData.LoadVar([],'InformationAna',['SingCellAna_' AnalysisOpts.AreaNames{Area} '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt],0);
                [CatInformationAna]=obj.CatFactorizedFata(InformationAna,1,obj.ZscoreFlag);
                for f=1:NFactors
                    [~,Legs(Area)]=obj.PlotFactorizedData(CatInformationAna,Time,TargetFactorInds(f),Col(Area,:),FieldToPlot,factornames{TargetFactorInds(f)},...
                        AnalysisOpts.Xlabel,'I(bits)',h2,Sp(f));
                end
            end
            legend(Legs,AnalysisOpts.AreaNames,'Location','Best')
            %% save this fugure
            [~,~,SingCellAnaFigsFileName]=obj.ManData.GetFileName([],['SingCellAnaByArea_' FieldToPlot '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt],'SaveInResults',1,'WantedDate','ALL');
            obj.FigParams.SaveFigSeries([],SingCellAnaFigsFileName,[{h2}],'SaveEachFrame',1)
            
            varargout=[h2];
        end
        function varargout=PlotInformationbyFactor_TrialTime(obj,FactorizedData,Time,TargetFactor,varargin)% plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            %% now get the information about each factor using ANOVA and wPEV analysis
            for Neu=1:length(FactorizedData)
                fprintf('\nCalculating Information for Neuron %i',Neu)
                [InformationAna(Neu).I,InformationAna(Neu).Iz]=obj.Information_TrialTime(FactorizedData(Neu));
            end
            [CatInformationAna]=obj.CatFactorizedFata(InformationAna,3,obj.ZscoreFlag);
            
            obj.ManData.SaveVar([],InformationAna,'InformationAna',['SingCellAnaTimTrl_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt])
            
            NTargFactors=length(TargetFactor);
            [h,Sp]=obj.FigParams.RenderSubplots([],[],[],NTargFactors);
            TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            arrayfun(@(x) obj.PlotFactorizedData(CatInformationAna,Time,x,[1 0 0],'Iz',FactorizedData(1).factornames{x},'Time(s)','I(bits)',h,Sp(x)),TargetFactorInds);
            
            %             Col=distinguishable_colors(NTargFactors);
            %             [h,Sp]=obj.FigParams.RenderSubplots([],[],[],1);
            %             TargetFactorInds=cellfun(@(x) find(strcmp(FactorizedData(1).factornames,x)),TargetFactor);
            %             arrayfun(@(x) obj.PlotFactorizedData(CatInformationAna,Time,x,Col(x,:),'I',FactorizedData(1).factornames{x},'I(bits)',h,Sp),TargetFactorInds);
            
            varargout=h;
            %% save varaibles
            AnalysisOpts.CurrentCh='';
            obj.ManData.SaveVar([],InformationAna,'InformationAna',['SingCellAnaTimTrl_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName 'R' AnalysisOpts.RuleTxt])
            
        end
        
        %% do GLM fit analysis
        function [GLMfit]=GLMfit_time(obj,FactorizedData,varargin) % fit GLM  across time points
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NTim=size(FactorizedData.data,2);
            X=obj.ManData.ReshapeCell2Mat(FactorizedData.factors,1);
            Y=FactorizedData.data;
            MaxY=max(Y(:));
            Y=Y/MaxY(1); % normalize spiking
            % define the GLM models now
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            GLMmodelSet=rmfield(GLMmodelSet,'FactorNameSet');GLMmodelSet=rmfield(GLMmodelSet,'nFactorNameSet');
            
            ModelDef=GLMmodelSet.(obj.GLMmdl); % get model factors
            
            fprintf('Running GLM %s model on the data...\n',obj.GLMmdl)
            %   for t=1:NTim
            %eval(['[GLM_weights(:,t),R2(:,t),resid(:,t),GLMfactorsnames]=obj.GLMfit_' obj.GLMmdl '(X,Y(:,t),FactorizedData.factornames,0);']);
            %[GLMfit.GLM_weights(:,t),GLMfit.R2(:,t),GLMfit.resid(:,t),GLMfit.GLMfactorsnames,~,GLMfit.GLM_weights_full(:,:,t)]...
            GLMfit  =obj.GLM_FullModel(X,Y,AnalysisOpts.factornames,ModelDef,0);
            %  end
            
            if AnalysisOpts.SingCellAna.SaveGLMmdls
                % Save vars first
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' obj.GLMmdl],...
                    ['SingCellAna' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName ]);
            end
        end
        function obj=DetermineGLMFullMdlType(obj,varargin)% determines the type of GLM full model
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if contains(obj.GLMmdl,'bhv','IgnoreCase',true)
                obj.GLMfullMdlType='FullModel';
            else
                obj.GLMfullMdlType='FullModel_Interaction';
            end
            
        end
        function [GLMfit]=GLMfit_time_FactorOmit(obj,FactorizedData,varargin) % GLM fit with factor omission method to calculate Coefficient of Partial Determination(CPD)
            % FullMdlName is the name of the full model. The rest of the
            % models will be reduced versions of this model
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % get model information
            FullMdlName=obj.GLMmdl;
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            GLMmodelSet=rmfield(GLMmodelSet,'FactorNameSet');GLMmodelSet=rmfield(GLMmodelSet,'nFactorNameSet');
            
            Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,FullMdlName)];
            % Models2Test=[{'NullMdl'},'HybridbhvMdlFull','InferAFbhvMdlFull','SensoryMotorMdl'];
            nModels2Test=length(Models2Test);
            
            % prepapre data for this neuron
            [X,Y,FactorNames,NTim,NTrl]=obj.PrepareData4GLMfit(FactorizedData);
            
            %% see if we are shuffling the data
            if obj.GLMshuffleFlag
                rng(AnalysisOpts.CalShuffleGLM_Cond);
                NTrls=size(Y,1);
                X=X(randsample(NTrls,NTrls),:);
                AnalysisOpts.ShuffleStr=sprintf('%i',AnalysisOpts.CalShuffleGLM_Cond);
                FileType='GLMfitSh';
                SaveAnalysisOpts=0;
            else
                AnalysisOpts.ShuffleStr='';
                FileType='GLMfit';
                SaveAnalysisOpts=1;
            end
            %% Run GLM fit now
            Tstart=tic;
            % if we are running each model on the cluster then use AnalysisOpts.PairNum
            % if ~isempty(AnalysisOpts.PairNum);Models2Run=AnalysisOpts.PairNum;else;Models2Run=1:nModels2Test;end
            
            % Run series of models we want to do
            for m= 1:nModels2Test% loop on models
                fprintf('\nrunning %s model %s%s ...',Models2Test{m},FileType,AnalysisOpts.ShuffleStr);
                tic;
                ModelDef=GLMmodelSet.(Models2Test{m}); % get model factors
                [GLMfit.(Models2Test{m})]=obj.(['GLM_' obj.GLMfullMdlType])(X,Y,FactorNames,ModelDef,0);
                Tend=toc;
                GLMfit.RunTime=Tend;
                fprintf('\nRun Time for this model=%.4f(Secs)',Tend);
            end
            GLMfit.X=X;  % save X  so that we have it for future calculations
            GLMfit.Y=Y;  % save Y  so that we have it for future calculations
            GLMfit.RunTimeTot=toc(Tstart);
            %% calculate CPD here as well
            GLMfit.CPD=obj.CalCoefPartialDet(GLMfit,GLMmodelSet.(FullMdlName),FullMdlName);
            
            %% if we are doing a shuffle remove execss data and only keep the data for the main model and CPD(to reduce size)
            if obj.GLMshuffleFlag
                GLMfit.(FullMdlName)=obj.ManData.rmfieldExept(GLMfit.(FullMdlName),{'GLM_weights_full','Lambda','Alpha'});
                GLMfit=obj.ManData.rmfieldExept(GLMfit,{FullMdlName,'CPD','RunTimeTot'});
            end
            %% save the file now
            ExtraTxt=obj.GetExtraStr4Cond(FileType);
            try  % try to save the file in the previously built file
                [~,~,FullPath]=obj.ManData.GetFileName('GLM',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                MatFile=load(FullPath); % see if you can load the file
                % save each run if we are running it on the cluster
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
            catch ME % if you catch error then delete file and save it again
                fprintf('\n%s',ME.message);
                obj.ManData.DeleteFile('GLM',ExtraTxt,1,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
            end
            fprintf('\nRun Time for all models=%.4f(Secs)',GLMfit.RunTimeTot);
        end
          
        function [GLMfit]=GLMfit_time_FactorOmitSingFactorShuff(obj,FactorizedData,varargin) % GLM fit with factor omission method to calculate Coefficient of Partial Determination(CPD)
            % This version only shuffles a single factor instead of shuffling everything
            % FullMdlName is the name of the full model. The rest of the
            % models will be reduced versions of this model
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % get model information
            FullMdlName=obj.GLMmdl;
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            GLMmodelSet=rmfield(GLMmodelSet,'FactorNameSet');GLMmodelSet=rmfield(GLMmodelSet,'nFactorNameSet');
            
            Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,FullMdlName)];
            % Models2Test=[{'NullMdl'},'HybridbhvMdlFull','InferAFbhvMdlFull','SensoryMotorMdl'];
            nModels2Test=length(Models2Test);
            
            % prepapre data for this neuron
            [X,Y,FactorNames,NTim,NTrls]=obj.PrepareData4GLMfit(FactorizedData);
            
            %% we are shuffling the data as well
            obj.GLMshuffleFlag=1;
            rng('shuffle');
            AnalysisOpts.ShuffleStr='';
            FileType='GLMfitSh';
            SaveAnalysisOpts=1;
            
            %% Run GLM fit for observed data
            % Run series of models we want to do
            Tstart=tic;
            for m= 1:nModels2Test% loop on models
                fprintf('\nrunning %s model %s%s ...',Models2Test{m},FileType,AnalysisOpts.ShuffleStr);
                tic;
                ModelDef=GLMmodelSet.(Models2Test{m}); % get model factors
                [GLMfit.(Models2Test{m})]=obj.(['GLM_' obj.GLMfullMdlType])(X,Y,FactorNames,ModelDef,0);
                Tend=toc;
                GLMfit.RunTime=Tend;
                fprintf('Run Time=%.4f(Secs)',Tend);
            end
            GLMfit.X=X;  % save X  so that we have it for future calculations
            GLMfit.Y=Y;  % save Y  so that we have it for future calculations
            GLMfit.RunTimeTot=toc(Tstart);
            GLMfit.CPD=obj.CalCoefPartialDet(GLMfit,GLMmodelSet.(FullMdlName),FullMdlName);


            %% Run GLM fit for shuffle data now
            Tstart=tic;
            % if we are running each model on the cluster then use AnalysisOpts.PairNum
            % if ~isempty(AnalysisOpts.PairNum);Models2Run=AnalysisOpts.PairNum;else;Models2Run=1:nModels2Test;end
             %% do the GLM fit without shuffeing the data now
            % Run series of models we want to do
            IndRedFactors=cellfun(@(x) contains(x,'_No_'),Models2Test,'UniformOutput',1); % find ind of reduced factors
          %  GLMfitSh.Y=Y;  % save Y  so that we have it for future calculations
          
            for nrepshuff=1:AnalysisOpts.SingCellAna.GLMShuffleRuns
                for m= find(IndRedFactors)% loop on models
                    fprintf('\nrunning %s model %s%s rep %i ...',Models2Test{m},FileType,AnalysisOpts.ShuffleStr,nrepshuff);
                    tic;
                    % find what is the factor that is being shuffled here
                    Xshuff=X;
                    ThisFactor=Models2Test{m}(strfind(Models2Test{m},'_No_')+4:end);
                    ThisFactorInd=strcmp(AnalysisOpts.factornames,ThisFactor);
                    ThisFactorValShuff=X(randsample(NTrls,NTrls),ThisFactorInd);
                    Xshuff(:,ThisFactorInd)=ThisFactorValShuff;
                    ModelDef=GLMmodelSet.(FullMdlName); % get model factors
                    % fit the full model with reduced factors now
                    [GLMfitShThisRep.([FullMdlName '_Shuff' ThisFactor])]=obj.(['GLM_' obj.GLMfullMdlType])(Xshuff,Y,FactorNames,ModelDef,0);

                    GLMfitShThisRep.(['XShuff_' ThisFactor])=Xshuff;  % save X  so that we have it for future calculations

                    Tend=toc;
                    GLMfitShThisRep.RunTime=Tend;
                    fprintf('Run Time=%.4f(Secs)',Tend);
                end
                %% calculate CPD for the shuffle
                GLMfitSh(nrepshuff).CPD=obj.CalCoefPartialDetSingFactShuff(GLMfit,GLMfitShThisRep,GLMmodelSet.(FullMdlName),FullMdlName);
            end
            toc(Tstart)
           
            %% save the file now
            ExtraTxt=obj.GetExtraStr4Cond(FileType);
            try  % try to save the file in the previously built file
                [~,~,FullPath]=obj.ManData.GetFileName('GLM',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                MatFile=load(FullPath); % see if you can load the file
                % save each run if we are running it on the cluster
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
                obj.ManData.SaveVar('GLM',GLMfitSh,['GLMfitSh_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
            catch ME % if you catch error then delete file and save it again
                fprintf('\n%s',ME.message);
                obj.ManData.DeleteFile('GLM',ExtraTxt,1,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
                obj.ManData.SaveVar('GLM',GLMfitSh,['GLMfitSh_' FullMdlName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'SaveAnalysisOpts',SaveAnalysisOpts);
            end
            fprintf('\nRun Time for all models=%.4f(Secs)',GLMfit.RunTimeTot);
        end
        
        function GLMfit=FitGLMmdls2data(obj,FactorizedData,varargin) % fits GLM models to neural data defind by GLMfit_method
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            obj=obj.DetermineGLMFullMdlType; %determine type of full model we are using
            for Neu=AnalysisOpts.nCh_2look
                fprintf('Calculating GLM fit for Neuron %i\n',Neu)
                obj.TrialFunc.UpdateCurrentCh(Neu);
                switch obj.GLMfitMethod
                    case 'regular'
                        [GLMfit(Neu)]=obj.GLMfit_time(FactorizedData(Neu)); % fit GLM using regular method
                    case 'FactorOmit'
                        if AnalysisOpts.SingCellAna.GLM_UseSingFactorShuff
                            [GLMfit(Neu)]=obj.GLMfit_time_FactorOmitSingFactorShuff(FactorizedData(Neu)); % fit GLM using factor omit method
                        else 
                            [GLMfit(Neu)]=obj.GLMfit_time_FactorOmit(FactorizedData(Neu)); % fit GLM using factor omit method
                        end
                end
            end
        end
        %% set of GLM models
        function [GLM_weights,z_GLM_weights,residrule]=GLMfit_costum(obj,X,Y,varargin)% build a costum GLM model of neural firing and fits it using lsqcurvefit or fmincon
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            options = optimoptions('lsqcurvefit','display','off');
            xdata_rule=double(obj.ManData.GenCategoricalVars(X(:,5))); % rule information
            %   xdata_resloc=double(obj.ManData.GenCategoricalVars(X(:,6))); % response loc information
            xdata=[xdata_rule];% xdata_resloc];
            %% build the model now
            %   fun=@(x,xdata) x(1).*xdata(:,1)+x(2).*xdata(:,2)+x(3).*xdata(:,3)+x(4).*xdata(:,4)+x(5).*xdata(:,5)+x(6).*xdata(:,6)+x(7).*xdata(:,7)+x(8);
            fun=@(x,xdata) x(1).*xdata(:,1)+x(2).*xdata(:,2)+x(3).*xdata(:,3)+x(4);
            Nvars=size(xdata,2)+1;
            N=size(xdata,1);
            x0=zeros(1,Nvars);
            GLM_weights = lsqcurvefit(fun,x0,xdata,Y,[],[],options);
            % now calculate the shuffle values and get the zscore
            GLM_weights_shuffle=cell2mat(arrayfun(@(x) lsqcurvefit(fun,x0,...
                xdata(cell2mat(arrayfun(@(x) randperm(N)',1:Nvars,'UniformOutput',false))),Y(randperm(N)),[],[],options)',...
                1:obj.NShuffle,'UniformOutput',false))';
            z_GLM_weights=zscore([GLM_weights;GLM_weights_shuffle],0,1);
            z_GLM_weights=z_GLM_weights(1,:);
            %% let's look at the residuals
            Yhat=fun(GLM_weights,xdata);
            resid=Y-Yhat;
            R2=obj.ManData.CalR2(Y,Yhat);
            residrule=[arrayfun(@(x) mean(resid(xdata(:,x)==1)),1:3) R2];
        end
        function [GLM_weights,R2,resid,GLMfactorsnames,mdl]=GLMfit_costum_rulecolorshape(obj,X,Y,factornames,varargin)% build a costum GLM model of neural firing based on rule color and shape ML
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            factorIndColor=strcmp(factornames,'ColorML'); % get color values
            xdata_color=(obj.ManData.CategorizeData(X(:,factorIndColor))-1)*2*pi/8;
            factorIndShape=strcmp(factornames,'ShapeML'); % get shape values
            xdata_shape=(obj.ManData.CategorizeData(X(:,factorIndShape))-1)*2*pi/8;
            
            factorIndRule=strcmp(factornames,'Rule'); % get rule values
            xdata_rule=double(obj.ManData.GenCategoricalVars(X(:,factorIndRule))); % rule information
            
            % build GLM predictor matrix
            xdata=[ sin(xdata_color) cos(xdata_color) sin(xdata_shape) cos(xdata_shape) xdata_rule];
            % build the model now
            %             mdl=fitglm(xdata,Y);
            %             GLM_weights = mdl.Coefficients.Estimate';
            %             R2=mdl.Rsquared.Ordinary;
            %             resid =mdl.Residuals.Raw; %Y - predict(mdl,xdata);
            %  GLMfactorsnames={'Bias','ColorML1','ColorML2','ShapeML1','ShapeML2','Rule1','Rule2','Rule3'};
            
            
            [B,FitInfo] = lassoglm(xdata,Y,'normal','CV',5);
            GLM_weights = B(:,25);R2=0;resid=0;
            
            GLMfactorsnames={'ColorML1','ColorML2','ShapeML1','ShapeML2','Rule1','Rule2','Rule3'};
        end
        function [GLM_weights,R2,resid,GLMfactorsnames,mdl]=GLMfit_costum_color(obj,X,Y,factornames,varargin)% build a costum GLM model of neural firing based on only color information
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            factorIndColor=strcmp(factornames,'ColorML');
            xdata_color=(obj.ManData.CategorizeData(X(:,factorIndColor))-1)*2*pi/8;
            xdata=[ sin(xdata_color) cos(xdata_color) ];% xdata_resloc];
            % build the model now
            mdl=fitglm(xdata,Y);
            GLM_weights = mdl.Coefficients.Estimate';
            R2=mdl.Rsquared.Ordinary;
            resid = Y - predict(mdl,xdata);
            
            GLMfactorsnames={'Bias','ColorML1','ColorML2'};
        end
        %% define GLM models
        function [GLM_weights,R2,resid,GLMfactorsnames,xdata]=GLMfit_Rule(obj,X,Y,factornames,OnlyPrepXdata,varargin)% build a costum GLM model of neural firing for Rule Model Meaning Rule 1 2 and 3 instead of axis and feature
            % use OnlyPrepXdata when we don't want to fit but only give out
            % the prepred xdata matrix(used for refitting to test)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            factorIndColor=strcmp(factornames,'ColorML'); % get color values
            xdata_color=(obj.ManData.CategorizeData(X(:,factorIndColor))-1)*2*pi/8;
            
            factorIndShape=strcmp(factornames,'ShapeML'); % get shape values
            xdata_shape=(obj.ManData.CategorizeData(X(:,factorIndShape))-1)*2*pi/8;
            
            %           factorIndColorCat=strcmp(factornames,'ColorCat'); % get color values
            %           xdata_color=(obj.ManData.CategorizeData(X(:,factorIndColorCat))-1)*2*pi/8;
            %
            %           factorIndShape=strcmp(factornames,'ShapeCat'); % get shape values
            %           xdata_shape=(obj.ManData.CategorizeData(X(:,factorIndShape))-1)*2*pi/8;
            
            factorIndRule=strcmp(factornames,'Rule'); % get rule values
            xdata_rule=double(obj.ManData.GenCategoricalVars(X(:,factorIndRule))); % rule information
            
            factorIndResLoc=strcmp(factornames,'ResponseLoc'); % response location information
            xdata_resloc=double(obj.ManData.GenCategoricalVars(X(:,factorIndResLoc))); % rule information
            
            % build GLM predictor matrix
            xdata=[(sin(xdata_color)+1)/2 (cos(xdata_color)+1)/2 (sin(xdata_shape)+1)/2 (cos(xdata_shape)+1)/2 xdata_rule xdata_resloc];
            GLMfactorsnames={'Bias','ColorML1','ColorML2','ShapeML1','ShapeML2','Rule1','Rule2','Rule3','RespLoc1','RespLoc2','RespLoc3','RespLoc4'};
            
            if OnlyPrepXdata;GLM_weights=[];R2=[];resid=[];return;end
            % fit the model now
            [B,FitInfo] = lassoglm(xdata,Y,'normal','CV',obj.GLMCV,'PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false);
            B0 = FitInfo.Intercept(FitInfo.IndexMinDeviance);
            GLM_weights = [B0;B(:,FitInfo.IndexMinDeviance)];R2=FitInfo.Deviance(FitInfo.IndexMinDeviance);resid=NaN;
        end
        function [GLMfit,xdata]=GLM_FullModel(obj,X,Y,factornames,ModelDef,OnlyPrepXdata,varargin)% build a costum GLM model of neural firing for Rule Model Meaning Rule 1 2 and 3 instead of axis and feature
            % use OnlyPrepXdata when we don't want to fit but only give out
            % the prepred xdata matrix(used for refitting to test)
            % generates the full model for GLM any variation from this
            % model can be generated by selecting the desired components
            % defined in ModelDef
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % build full model here
            % color ML
            factorIndColor=strcmp(factornames,'ColorML'); % get color values
            xdata_color=obj.ManData.CovertMorphLvl2Angle(X(:,factorIndColor)) ;
            ModelInfo(1).Name='ColorML';
            ModelInfo(1).GLMName={'ColorML1','ColorML2'};
            ModelInfo(1).Value=[(sin(xdata_color)+1)/2 (cos(xdata_color)+1)/2];
            % shape ML
            factorIndShape=strcmp(factornames,'ShapeML'); % get shape values
            xdata_shape=obj.ManData.CovertMorphLvl2Angle(X(:,factorIndShape));
            ModelInfo(2).Name='ShapeML';
            ModelInfo(2).GLMName={'ShapeML1','ShapeML2'};
            ModelInfo(2).Value=[(sin(xdata_shape)+1)/2 (cos(xdata_shape)+1)/2];
            % ColorCat
            factorIndColorCat=strcmp(factornames,'ColorCat'); % get color values
            xdata_colorCat=double(obj.ManData.GenCategoricalVars(X(:,factorIndColorCat)));
            ModelInfo(3).Name='ColorCat';
            ModelInfo(3).GLMName={'ColorCat0','ColorCat1','ColorCat2'};
            ModelInfo(3).Value=xdata_colorCat;
            % ShapeCat
            factorIndShapeCat=strcmp(factornames,'ShapeCat'); % get shape values
            xdata_shapeCat=double(obj.ManData.GenCategoricalVars(X(:,factorIndShapeCat)));
            ModelInfo(4).Name='ShapeCat';
            ModelInfo(4).GLMName={'ShapeCat0','ShapeCat1','ShapeCat2'};
            ModelInfo(4).Value=xdata_shapeCat;
            % Feature
            factorIndRule=strcmp(factornames,'Rule'); % get rule ind
            xdata_feature=double([X(:,factorIndRule)==1 X(:,factorIndRule)==2 | X(:,factorIndRule)==3]); % feature information
            ModelInfo(5).Name='Feature';
            ModelInfo(5).GLMName={'FeatureSh','FeatureCol'};
            ModelInfo(5).Value=xdata_feature;
            % Axis
            xdata_axis=double([X(:,factorIndRule)==1 | X(:,factorIndRule)==3 X(:,factorIndRule)==2]); % axis information
            ModelInfo(6).Name='Axis';
            ModelInfo(6).GLMName={'Axis1','Axis2'};
            ModelInfo(6).Value=xdata_axis;
            % Rule
            factorIndRule=strcmp(factornames,'Rule'); % get rule values
            xdata_rule=double(obj.ManData.GenCategoricalVars(X(:,factorIndRule))); % rule information
            ModelInfo(7).Name='Rule';
            ModelInfo(7).GLMName={'Rule1','Rule2','Rule3'};
            ModelInfo(7).Value=xdata_rule;
            % RespLoc
            factorIndResLoc=strcmp(factornames,'ResponseLoc'); % response location information
            xdata_resloc=double(obj.ManData.GenCategoricalVars(X(:,factorIndResLoc))); % rule information
            ModelInfo(8).Name='ResponseLoc';
            ModelInfo(8).GLMName={'ResponseLoc1','ResponseLoc2','ResponseLoc3','ResponseLoc4'};
            ModelInfo(8).Value=xdata_resloc;
            % Reward
            factorReward=strcmp(factornames,'Reward');
            xdata_Reward=double(X(:,factorReward));
            ModelInfo(9).Name='Reward';
            ModelInfo(9).GLMName={'Reward'};
            ModelInfo(9).Value=xdata_Reward;
            % Time
            factorTime=strcmp(factornames,'Time');
            xdata_Time=double(X(:,factorTime));
            ModelInfo(10).Name='Time';
            ModelInfo(10).GLMName={'Time'};
            ModelInfo(10).Value=xdata_Time;
            % elements of hybrid behavioral model
            factorHybrid_Q=contains(factornames,'Hybrid_Q');
            xdata_Hybrid_Q=double(X(:,factorHybrid_Q));
            ModelInfo(11).Name='Hybrid_Q';
            ModelInfo(11).GLMName={'Hybrid_Q1','Hybrid_Q2','Hybrid_Q3','Hybrid_Q4'};
            ModelInfo(11).Value=xdata_Hybrid_Q;
            
            factorHybrid_RPE=strcmp(factornames,'Hybrid_RPE');
            xdata_Hybrid_RPE=double(X(:,factorHybrid_RPE));
            ModelInfo(12).Name='Hybrid_RPE';
            ModelInfo(12).GLMName={'Hybrid_RPE'};
            ModelInfo(12).Value=xdata_Hybrid_RPE;
            
            factorHybrid_W_Color=contains(factornames,'Hybrid_W_Color');
            xdata_Hybrid_W_Color=double(X(:,factorHybrid_W_Color));
            ModelInfo(13).Name='Hybrid_W_Color';
            ModelInfo(13).GLMName={'Hybrid_W_Color1','Hybrid_W_Color2'};
            ModelInfo(13).Value=xdata_Hybrid_W_Color;
            
            factorHybrid_W_Shape=contains(factornames,'Hybrid_W_Shape');
            xdata_Hybrid_W_Shape=double(X(:,factorHybrid_W_Shape));
            ModelInfo(14).Name='Hybrid_W_Shape';
            ModelInfo(14).GLMName={'Hybrid_W_Shape1','Hybrid_W_Shape2'};
            ModelInfo(14).Value=xdata_Hybrid_W_Shape;
            
            factorHybrid_W_Diff=contains(factornames,'Hybrid_W_Diff');
            xdata_Hybrid_W_Diff=double(X(:,factorHybrid_W_Diff));
            ModelInfo(23).Name='Hybrid_W_Diff';
            ModelInfo(23).GLMName={'Hybrid_W_Diff1','Hybrid_W_Diff2'};
            ModelInfo(23).Value=xdata_Hybrid_W_Diff;
            
            factorHybrid_Baxes=strcmp(factornames,'Hybrid_Baxes');
            xdata_Hybrid_Baxes=double(X(:,factorHybrid_Baxes));
            ModelInfo(15).Name='Hybrid_Baxes';
            ModelInfo(15).GLMName={'Hybrid_Baxes'};
            ModelInfo(15).Value=xdata_Hybrid_Baxes;
            
            % elements of inference axis feature model
            factorInferAF_Q=contains(factornames,'InferAF_Q');
            xdata_InferAF_Q=double(X(:,factorInferAF_Q));
            ModelInfo(16).Name='InferAF_Q';
            ModelInfo(16).GLMName={'InferAF_Q1','InferAF_Q2','InferAF_Q3','InferAF_Q4'};
            ModelInfo(16).Value=xdata_InferAF_Q;
            
            factorInferAF_RPE=strcmp(factornames,'InferAF_RPE');
            xdata_InferAF_RPE=double(X(:,factorInferAF_RPE));
            ModelInfo(17).Name='InferAF_RPE';
            ModelInfo(17).GLMName={'InferAF_RPE'};
            ModelInfo(17).Value=xdata_InferAF_RPE;
            
            factorInferAF_Baxes=strcmp(factornames,'InferAF_Baxes');
            xdata_InferAF_Baxes=double(X(:,factorInferAF_Baxes));
            ModelInfo(18).Name='InferAF_Baxes';
            ModelInfo(18).GLMName={'InferAF_Baxes'};
            ModelInfo(18).Value=xdata_InferAF_Baxes;
            
            factorInferAF_Bfeature=strcmp(factornames,'InferAF_Bfeature');
            xdata_InferAF_Bfeature=double(X(:,factorInferAF_Bfeature));
            ModelInfo(19).Name='InferAF_Bfeature';
            ModelInfo(19).GLMName={'InferAF_Bfeature'};
            ModelInfo(19).Value=xdata_InferAF_Bfeature;
            
            % elements of inference rule model
            factorInferRule_Q=contains(factornames,'InferRule_Q');
            xdata_InferRule_Q=double(X(:,factorInferRule_Q));
            ModelInfo(20).Name='InferRule_Q';
            ModelInfo(20).GLMName={'InferRule_Q1','InferRule_Q2','InferRule_Q3','InferRule_Q4'};
            ModelInfo(20).Value=xdata_InferRule_Q;
            
            factorInferRule_RPE=strcmp(factornames,'InferRule_RPE');
            xdata_InferRule_RPE=double(X(:,factorInferRule_RPE));
            ModelInfo(21).Name='InferRule_RPE';
            ModelInfo(21).GLMName={'InferRule_RPE'};
            ModelInfo(21).Value=xdata_InferRule_RPE;
            
            factorInferRule_Brule=strcmp(factornames,'InferRule_Brule');
            xdata_InferRule_Brule=double(X(:,factorInferRule_Brule));
            ModelInfo(22).Name='InferRule_Brule';
            ModelInfo(22).GLMName={'InferRule_Brule'};
            ModelInfo(22).Value=xdata_InferRule_Brule;
            
            % build GLM predictor matrix based on the ModelDef
            IndModelDef=find(arrayfun(@(x) sum(strcmp(ModelInfo(x).Name,ModelDef)),1:length(ModelInfo))); % find the factor we care about
            xdata=cell2mat(arrayfun(@(x) ModelInfo(x).Value,IndModelDef,'UniformOutput',false)) ;
            GLMfactorsnames=['Bias',arrayfun(@(x) ModelInfo(x).GLMName,IndModelDef,'UniformOutput',false)];
            GLMfactorsnames=obj.ManData.ConcatinateCellValls(GLMfactorsnames);
            if isempty(xdata);xdata=[zeros(size(X,1),1)];GLMfactorsnames={'Bias','null'};end
            
            if OnlyPrepXdata;GLMfit=[];return;end
            
            % if we are fitting this GLM model then go ahead and do it
            % fit the model now
            %tic;[B,FitInfo] = lassoglm(xdata,Y,'normal','CV',obj.GLMCV,'PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false);toc
            NTim=size(Y,2);
            for t=1:NTim
                [B,FitInfo] = lassoglm(xdata,Y(:,t),'normal','PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false,'Lambda',AnalysisOpts.SingCellAna.GLMLamda);
                [~,FitInfo.IndexMinDeviance]=min(FitInfo.Deviance);FitInfo.IndexMinDeviance=FitInfo.IndexMinDeviance(1);
                GLMfit.GLM_weights_full(:,:,t)=[FitInfo.Intercept;B];
                
                %% add in the future
                % B0 = FitInfo.Intercept(FitInfo.IndexMinDeviance);
                % GLMfit.GLM_weights(:,t) = [B0;B(:,FitInfo.IndexMinDeviance)];
                % GLMfit.Deviance(:,t)=FitInfo.Deviance;
                % GLMfit.DF(:,t)=FitInfo.DF;
            end
            GLMfit.Lambda=FitInfo.Lambda;
            GLMfit.GLMfactorsnames=GLMfactorsnames;
            GLMfit.Alpha=FitInfo.Alpha;
            
            %  Calculate fit perfromance
            GLMfit=obj.CalculateGLMmdlFitPerf(GLMfit,xdata,Y);
            %  GLMfit=rmfield(GLMfit,'Yhat'); % we can recompute it again.
        end
        function [GLMfit,xdata]=GLM_FullModel_Interaction(obj,X,Y,factornames,ModelDef,OnlyPrepXdata,varargin)% build a costum GLM model of neural firing with interaction terms
            % use OnlyPrepXdata when we don't want to fit but only give out
            % the prepred xdata matrix(used for refitting to test)
            % generates the full model for GLM any variation from this
            % model can be generated by selecting the desired components
            % defined in ModelDef
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % build full model here
            % color ML
            factorIndColor=strcmp(factornames,'ColorML'); % get color values
            xdata_color=obj.ManData.CovertMorphLvl2Angle(X(:,factorIndColor)) ;
            ModelInfo(1).Name='ColorML';
            ModelInfo(1).GLMName={'ColorML1','ColorML2'};
            ModelInfo(1).Value=[(sin(xdata_color)+1)*0.5 (cos(xdata_color)+1)*0.5];
            % shape ML
            factorIndShape=strcmp(factornames,'ShapeML'); % get shape values
            xdata_shape=obj.ManData.CovertMorphLvl2Angle(X(:,factorIndShape));
            ModelInfo(2).Name='ShapeML';
            ModelInfo(2).GLMName={'ShapeML1','ShapeML2'};
            ModelInfo(2).Value=[(sin(xdata_shape)+1)*0.5 (cos(xdata_shape)+1)*0.5];
            % ColorCat
            factorIndColorCat=strcmp(factornames,'ColorCat'); % get color values
            xdata_colorCat=double(obj.ManData.GenCategoricalVars(X(:,factorIndColorCat)));
            ModelInfo(3).Name='ColorCat';
            if obj.Remove50MLFactor
                ModelInfo(3).GLMName={'ColorCat1','ColorCat2'};
            else
                ModelInfo(3).GLMName={'ColorCat0','ColorCat1','ColorCat2'};
            end
            ModelInfo(3).Value=xdata_colorCat;
            
            % ShapeCat
            factorIndShapeCat=strcmp(factornames,'ShapeCat'); % get shape values
            xdata_shapeCat=double(obj.ManData.GenCategoricalVars(X(:,factorIndShapeCat)));
            ModelInfo(4).Name='ShapeCat';
            if obj.Remove50MLFactor
                ModelInfo(4).GLMName={'ShapeCat1','ShapeCat2'};
            else
                ModelInfo(4).GLMName={'ShapeCat0','ShapeCat1','ShapeCat2'};
            end
            ModelInfo(4).Value=xdata_shapeCat;
            % Rule
            factorIndRule=strcmp(factornames,'Rule'); % get rule values
            xdata_rule=double(obj.ManData.GenCategoricalVars(X(:,factorIndRule))); % rule information
            ModelInfo(7).Name='Rule';
            ModelInfo(7).GLMName={'Rule1','Rule2','Rule3'};
            ModelInfo(7).Value=xdata_rule;
            % RespLoc
            factorIndResLoc=strcmp(factornames,'ResponseLoc'); % response location information
            xdata_resloc=double(obj.ManData.GenCategoricalVars(X(:,factorIndResLoc))); % rule information
            ModelInfo(8).Name='ResponseLoc';
            ModelInfo(8).GLMName={'ResponseLoc1','ResponseLoc2','ResponseLoc3','ResponseLoc4'};
            ModelInfo(8).Value=xdata_resloc;
            % Reward
            factorReward=strcmp(factornames,'Reward');
            xdata_Reward=double(X(:,factorReward));
            ModelInfo(9).Name='Reward';
            ModelInfo(9).GLMName={'Reward'};
            ModelInfo(9).Value=xdata_Reward;
            % Time
            factorTime=strcmp(factornames,'Time');
            xdata_Time=double(X(:,factorTime));
            ModelInfo(10).Name='Time';
            ModelInfo(10).GLMName={'Time'};
            ModelInfo(10).Value=xdata_Time;
            
            % ColorML and Rule Interaction
            ModelInfo(11).Name='ColorMLxRule1';
            ModelInfo(11).GLMName={'ColorML1xRule1','ColorML2xRule1'};
            ModelInfo(11).Value=[ModelInfo(1).Value.*ModelInfo(7).Value(:,1)];
            
            ModelInfo(12).Name='ColorMLxRule2';
            ModelInfo(12).GLMName={'ColorML1xRule2','ColorML2xRule2'};
            ModelInfo(12).Value=[ ModelInfo(1).Value.*ModelInfo(7).Value(:,2)];
            
            ModelInfo(13).Name='ColorMLxRule3';
            ModelInfo(13).GLMName={'ColorML1xRule3','ColorML2xRule3'};
            ModelInfo(13).Value=[ModelInfo(1).Value.*ModelInfo(7).Value(:,3)];
            
            % ShapeML and Rule Interaction
            ModelInfo(14).Name='ShapeMLxRule1';
            ModelInfo(14).GLMName={'ShapeML1xRule1','ShapeML2xRule1'};
            ModelInfo(14).Value=[ModelInfo(2).Value.*ModelInfo(7).Value(:,1)];
            
            ModelInfo(15).Name='ShapeMLxRule2';
            ModelInfo(15).GLMName={'ShapeML1xRule2','ShapeML2xRule2'};
            ModelInfo(15).Value=[ModelInfo(2).Value.*ModelInfo(7).Value(:,2)];
            
            ModelInfo(16).Name='ShapeMLxRule3';
            ModelInfo(16).GLMName={'ShapeML1xRule3','ShapeML2xRule3'};
            ModelInfo(16).Value=[ModelInfo(2).Value.*ModelInfo(7).Value(:,3)];
            
            % 'ColorMLSing' define each color morph level as a separate coeeficient
            factorIndColorMLSing=strcmp(factornames,'ColorML'); % get color values
            [xdata_ColorMLSing,ColorMLSingLevel,ColorMLSingLevelVals]=(obj.ManData.GenCategoricalVars(X(:,factorIndColorMLSing)));
            xdata_ColorMLSing=double(xdata_ColorMLSing);
            ColorMLSingLevelValsInd=1:length(ColorMLSingLevelVals);
            ModelInfo(17).Name='ColorMLSing';
            ModelInfo(17).GLMName=arrayfun(@(x) [ModelInfo(17).Name num2str(x)],ColorMLSingLevelValsInd,'UniformOutput',0);
            ModelInfo(17).Value=xdata_ColorMLSing;
            ModelInfo(17).LevelVals=ColorMLSingLevelVals;
            if length(ColorMLSingLevelValsInd)<6;error(' we are missign objects');end
            
            % 'ShapeMLSing' define each shape morph level as a separate coeeficient
            factorIndShapeMLSing=strcmp(factornames,'ShapeML'); % get color values
            [xdata_ShapeMLSing,ShapeMLSingLevel,ShapeMLSingLevelVals]=(obj.ManData.GenCategoricalVars(X(:,factorIndShapeMLSing)));
            ShapeMLSingLevelValsInd=1:length(ShapeMLSingLevelVals);
            xdata_ShapeMLSing=double(xdata_ShapeMLSing);
            ModelInfo(18).Name='ShapeMLSing';
            ModelInfo(18).GLMName=arrayfun(@(x) [ModelInfo(18).Name num2str(x)],ShapeMLSingLevelValsInd,'UniformOutput',0);
            ModelInfo(18).Value=xdata_ShapeMLSing;
            ModelInfo(18).LevelVals=ShapeMLSingLevelVals;
            if length(ShapeMLSingLevelValsInd)<6;error(' we are missign objects');end
            
            % 'Objs' define each object as a separate coeeficient
            ObjComb=[sort(repmat(ShapeMLSingLevelValsInd',[length(ShapeMLSingLevelValsInd) 1])) repmat(ColorMLSingLevelValsInd',[length(ColorMLSingLevelValsInd) 1])];
            ObjCombValsInd=1:size(ObjComb,1);
            xdata_Objs=cell2mat(arrayfun(@(x) ShapeMLSingLevel==ObjComb(x,1) & ColorMLSingLevel==ObjComb(x,2),ObjCombValsInd,'UniformOutput',0));
            xdata_Objs=double(xdata_Objs);
            ModelInfo(19).Name='Objs';
            ModelInfo(19).GLMName=arrayfun(@(x) [ModelInfo(19).Name num2str(x)],ObjCombValsInd,'UniformOutput',0);
            ModelInfo(19).Value=xdata_Objs;
            ModelInfo(19).LevelVals=ObjComb;
            if length(ObjCombValsInd)<36;error(' we are missign objects');end

            % build GLM predictor matrix based on the ModelDef
            IndModelDef=find(arrayfun(@(x) sum(strcmp(ModelInfo(x).Name,ModelDef)),1:length(ModelInfo))); % find the factor we care about
            xdata=cell2mat(arrayfun(@(x) ModelInfo(x).Value,IndModelDef,'UniformOutput',false)) ;
            GLMfactorsnames=['Bias',arrayfun(@(x) ModelInfo(x).GLMName,IndModelDef,'UniformOutput',false)];
            GLMfactorsnames=obj.ManData.ConcatinateCellValls(GLMfactorsnames);
            if isempty(xdata);xdata=[zeros(size(X,1),1)];GLMfactorsnames={'Bias','null'};end
            
            if OnlyPrepXdata;GLMfit=[];return;end
            
            % if we are fitting this GLM model then go ahead and do it
            % fit the model now
            %tic;[B,FitInfo] = lassoglm(xdata,Y,'normal','CV',obj.GLMCV,'PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false);toc
            NTim=size(Y,2);
            for t=1:NTim
                [B,FitInfo] = lassoglm(xdata,Y(:,t),'normal','PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false,'Lambda',AnalysisOpts.SingCellAna.GLMLamda);
                [~,FitInfo.IndexMinDeviance]=min(FitInfo.Deviance);FitInfo.IndexMinDeviance=FitInfo.IndexMinDeviance(1);
                GLMfit.GLM_weights_full(:,:,t)=[FitInfo.Intercept;B];
                
                %% add in the future
                % B0 = FitInfo.Intercept(FitInfo.IndexMinDeviance);
                % GLMfit.GLM_weights(:,t) = [B0;B(:,FitInfo.IndexMinDeviance)];
                % GLMfit.Deviance(:,t)=FitInfo.Deviance;
                % GLMfit.DF(:,t)=FitInfo.DF;
            end
            GLMfit.Lambda=FitInfo.Lambda;
            GLMfit.GLMfactorsnames=GLMfactorsnames;
            GLMfit.Alpha=FitInfo.Alpha;
            
            %  Calculate fit perfromance
            GLMfit=obj.CalculateGLMmdlFitPerf(GLMfit,xdata,Y);
            %  GLMfit=rmfield(GLMfit,'Yhat'); % we can recompute it again.
        end
        
        function GLMfit=CalculateGLMmdlFitPerf(obj,GLMfit,xdata,Y) % calculates glmfit performance
            % calculate a mix of model caractrization values for each lambda value (R2, MSE, AIC) for this model
            GLMfit.Yhat=obj.PredictGLMval(GLMfit,xdata); % calculate Yhat it for each lambda
            [GLMfit.R2time,GLMfit.R2trl] =cellfun(@(x) obj.ManData.CalR2time(Y,x),GLMfit.Yhat); % calculate R2
            GLMfit.MSE=cellfun(@(x) obj.ManData.MeanSquaredErrorTrial(x,Y),GLMfit.Yhat); % calculate MSE
        end
        
        function [Yhat]=PredictGLMval(obj,GLMfit,xdata) % predicts value of Yhat for all of the lambdas in the GLM fit
            NTim=size(GLMfit.GLM_weights_full,3);
            Yhat=arrayfun(@(lambda) cell2mat(arrayfun(@(t) glmval(squeeze(GLMfit.GLM_weights_full(:,lambda,t)),xdata,'identity'),1:NTim,'UniformOutput',0)),1:length(GLMfit.Lambda),'UniformOutput',0);
        end
        
        function [GLM_weights,R2,resid,GLMfactorsnames,xdata]=GLMfit_Color(obj,X,Y,factornames,OnlyPrepXdata,varargin)% build a costum GLM model of neural firing for Color Model Meaning Rule 1 2 and 3 instead of axis and feature
            % use OnlyPrepXdata when we don't want to fit but only give out
            % the prepred xdata matrix(used for refitting to test)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            factorIndColor=strcmp(factornames,'ColorML'); % get color values
            xdata_color=(obj.ManData.CategorizeData(X(:,factorIndColor))-1)*2*pi/8;
            
            % build GLM predictor matrix
            xdata=[(sin(xdata_color)+1)/2 (cos(xdata_color)+1)/2];
            GLMfactorsnames={'Bias','ColorML1','ColorML2'};
            
            if OnlyPrepXdata;GLM_weights=[];R2=[];resid=[];return;end
            
            % fit the model now
            [B,FitInfo] = lassoglm(xdata,Y,'normal','CV',obj.GLMCV,'PredictorNames',GLMfactorsnames(2:end),'Alpha',obj.GLMalpha,'Standardize',false);
            B0 = FitInfo.Intercept(FitInfo.IndexMinDeviance);
            GLM_weights = [B0;B(:,FitInfo.IndexMinDeviance)];R2=FitInfo.Deviance(FitInfo.IndexMinDeviance);resid=NaN;
        end
        function [GLMmodelSet,ModelFactors,nModelFactors]=DefineGLMmodelSet(obj,varargin) % defines a set of GLM models that can be used in future analysis
            global AnalysisOpts
            
            MainNonSensoryFactors={'ResponseLoc','Time','Reward','Rule'}; % factors that are not sensory
            
            % these are all of the factors we use for all of  our GLM
            % models
            GLMmodelSet.FactorNameSet={'ColorML','ShapeML','ColorCat','ShapeCat','Feature','Axis','Rule','ResponseLoc','Reward','Time'};
            GLMmodelSet.nFactorNameSet=length(GLMmodelSet.FactorNameSet);
            % build a full model that includes all of these factors
            GLMmodelSet.FullMdl=GLMmodelSet.FactorNameSet;
            
            % build null model (only has the bias term)
            GLMmodelSet.NullMdl=[];
            
            % build time model
            GLMmodelSet.TimeMdl={'Time'};
            
            % build models that include all of the data now
            % cellfun(@(x) eval(sprintf('GLMmodelSet.%s={''%s''};',x,x)),GLMmodelSet.FactorNameSet,'UniformOutput',false);
            for i=1:GLMmodelSet.nFactorNameSet
                GLMmodelSet.(GLMmodelSet.FactorNameSet{i})=GLMmodelSet.FactorNameSet(i);
            end
            
            % now build a full model that lacks each component
            for i=1:GLMmodelSet.nFactorNameSet
                Compset=setdiff(1:GLMmodelSet.nFactorNameSet,i);
                GLMmodelSet.(['FullMdl_No_' GLMmodelSet.FactorNameSet{i}])=GLMmodelSet.FactorNameSet(Compset);
            end
            % define full model hierarchical (reverse)
            
            GLMmodelSet.FulMdlRevHier={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat','Rule','Feature','Axis'};
            
            % now move through Heirarchy levels in Rule model and go
            % level by level
            GLMmodelSet.FulMdlRevHier_1_1={'ColorML'};
            GLMmodelSet.FulMdlRevHier_1_2={'ShapeML'};
            GLMmodelSet.FulMdlRevHier_1_3={'ResponseLoc'};
            GLMmodelSet.FulMdlRevHier_1_0={'ResponseLoc','ShapeML','ColorML'};
            GLMmodelSet.FulMdlRevHier_2_1={'ResponseLoc','ShapeML','ColorML','ShapeCat'};
            GLMmodelSet.FulMdlRevHier_2_2={'ResponseLoc','ShapeML','ColorML','ColorCat'};
            GLMmodelSet.FulMdlRevHier_2_0={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat'};
            GLMmodelSet.FulMdlRevHier_3_1={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat','Rule'};
            GLMmodelSet.FulMdlRevHier_3_2={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat','Rule','Feature'};
            GLMmodelSet.FulMdlRevHier_3_3={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat','Rule','Axis'};
            
            % define feature axis model
            GLMmodelSet.FeatureAxisMdlFull={'ColorML','ShapeML','ColorCat','ShapeCat','Feature','Axis','ResponseLoc'};
            
            % now move through Heirarchy levels in FeatureAxis model and go
            % level by level
            GLMmodelSet.FeatureAxisMdl_1_1={'Feature'};
            GLMmodelSet.FeatureAxisMdl_1_2={'Axis'};
            GLMmodelSet.FeatureAxisMdl_1_0={'Axis','Feature'};
            GLMmodelSet.FeatureAxisMdl_2_1={'Axis','Feature','ColorCat'};
            GLMmodelSet.FeatureAxisMdl_2_2={'Axis','Feature','ShapeCat'};
            GLMmodelSet.FeatureAxisMdl_2_3={'Axis','Feature','ResponseLoc'};
            GLMmodelSet.FeatureAxisMdl_2_0={'Axis','Feature','ResponseLoc','ColorCat','ShapeCat'};
            GLMmodelSet.FeatureAxisMdl_3_1={'Axis','Feature','ColorCat','ShapeCat','ResponseLoc','ColorML'};
            GLMmodelSet.FeatureAxisMdl_3_2={'Axis','Feature','ColorCat','ShapeCat','ResponseLoc','ShapeML'};
            
            % define reverse feature axis model
            GLMmodelSet.FeatureAxisMdlRevFull={'ColorML','ShapeML','ColorCat','ShapeCat','Feature','Axis','ResponseLoc'};
            
            % now move through Heirarchy levels in FeatureAxis reverse model and go
            % level by level
            GLMmodelSet.FeatureAxisMdlRev_1_1={'ColorML'};
            GLMmodelSet.FeatureAxisMdlRev_1_2={'ShapeML'};
            GLMmodelSet.FeatureAxisMdlRev_1_3={'ResponseLoc'};
            GLMmodelSet.FeatureAxisMdlRev_1_0={'ColorML','ShapeML','ResponseLoc'};
            GLMmodelSet.FeatureAxisMdlRev_2_1={'ColorML','ShapeML','ResponseLoc','ColorCat'};
            GLMmodelSet.FeatureAxisMdlRev_2_2={'ColorML','ShapeML','ResponseLoc','ShapeCat'};
            GLMmodelSet.FeatureAxisMdlRev_2_0={'ColorML','ShapeML','ResponseLoc','ColorCat','ShapeCat'};
            GLMmodelSet.FeatureAxisMdlRev_3_1={'Axis','ColorML','ShapeML','ResponseLoc','ColorCat','ShapeCat'};
            GLMmodelSet.FeatureAxisMdlRev_3_2={'Feature','ColorML','ShapeML','ResponseLoc','ColorCat','ShapeCat'};
            
            % define Rule Model
            GLMmodelSet.RuleMdlFull={'ColorML','ShapeML','ColorCat','ShapeCat','Rule','ResponseLoc'};
            
            % now move through Heirarchy levels in Rule model and go
            % level by level
            GLMmodelSet.RuleMdl_1_1={'Rule'};
            GLMmodelSet.RuleMdl_2_1={'Rule','ColorCat'};
            GLMmodelSet.RuleMdl_2_2={'Rule','ShapeCat'};
            GLMmodelSet.RuleMdl_2_3={'Rule','ResponseLoc'};
            GLMmodelSet.RuleMdl_2_0={'Rule','ResponseLoc','ColorCat','ShapeCat'};
            GLMmodelSet.RuleMdl_3_1={'Rule','ColorCat','ShapeCat','ResponseLoc','ColorML'};
            GLMmodelSet.RuleMdl_3_2={'Rule','ColorCat','ShapeCat','ResponseLoc','ShapeML'};
            
            % build Rule reverse model
            GLMmodelSet.RuleMdlRevFull={'ColorML','ShapeML','ColorCat','ShapeCat','Rule','ResponseLoc'};
            
            % now move through Heirarchy levels in Rule model and go
            % level by level
            GLMmodelSet.RuleMdlRev_1_1={'ColorML'};
            GLMmodelSet.RuleMdlRev_1_2={'ShapeML'};
            GLMmodelSet.RuleMdlRev_1_3={'ResponseLoc'};
            GLMmodelSet.RuleMdlRev_1_0={'ResponseLoc','ShapeML','ColorML'};
            GLMmodelSet.RuleMdlRev_2_1={'ResponseLoc','ShapeML','ColorML','ShapeCat'};
            GLMmodelSet.RuleMdlRev_2_2={'ResponseLoc','ShapeML','ColorML','ColorCat'};
            GLMmodelSet.RuleMdlRev_2_0={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat'};
            GLMmodelSet.RuleMdlRev_3_1={'ResponseLoc','ShapeML','ColorML','ColorCat','ShapeCat','Rule'};
            
            % define a model that only includes sensory and motor
            % components
            GLMmodelSet.SensoryMotorMdl={'ColorML','ShapeML','ColorCat','ShapeCat','ResponseLoc','Time','Reward'};
            
            % define GLM models based on the behavioral model set
            % hybrid model
            GLMmodelSet.HybridbhvMdlFull={'ColorML','ShapeML','ColorCat','ShapeCat','ResponseLoc','Time','Reward',...
                'Hybrid_RPE','Hybrid_W_Color','Hybrid_W_Shape','Hybrid_W_Diff','Hybrid_Baxes'};
            
            % now build a full model that lacks each component
            for i=1:length(GLMmodelSet.HybridbhvMdlFull)
                Compset=setdiff(1:length(GLMmodelSet.HybridbhvMdlFull),i);
                GLMmodelSet.(['HybridbhvMdlFull_No_' GLMmodelSet.HybridbhvMdlFull{i}])=GLMmodelSet.HybridbhvMdlFull(Compset);
            end
            
            % inference feature axis model
            GLMmodelSet.InferAFbhvMdlFull={'ColorML','ShapeML','ColorCat','ShapeCat','ResponseLoc','Time','Reward',...
                'InferAF_RPE','InferAF_Baxes','InferAF_Bfeature'};
            % now build a full model that lacks each component
            for i=1:length(GLMmodelSet.InferAFbhvMdlFull)
                Compset=setdiff(1:length(GLMmodelSet.InferAFbhvMdlFull),i);
                GLMmodelSet.(['InferAFbhvMdlFull_No_' GLMmodelSet.InferAFbhvMdlFull{i}])=GLMmodelSet.InferAFbhvMdlFull(Compset);
            end
            
            % inference rule model
            GLMmodelSet.InferRulebhvMdlFull={'ColorML','ShapeML','ColorCat','ShapeCat','ResponseLoc','Time','Reward',...
                'InferRule_RPE','InferRule_Brule'};
            % now build a full model that lacks each component
            for i=1:length(GLMmodelSet.InferRulebhvMdlFull)
                Compset=setdiff(1:length(GLMmodelSet.InferRulebhvMdlFull),i);
                GLMmodelSet.(['InferRulebhvMdlFull_No_' GLMmodelSet.InferRulebhvMdlFull{i}])=GLMmodelSet.InferRulebhvMdlFull(Compset);
            end
            
            % define a sensory motor model that also has interaction
            % components
            GLMmodelSet=obj.AddNewGLMmodel(GLMmodelSet,'SensoryMotorInteractMdl',['ColorML','ShapeML',MainNonSensoryFactors,...
                'ColorMLxRule1','ColorMLxRule2','ColorMLxRule3','ShapeMLxRule1','ShapeMLxRule2','ShapeMLxRule3']);
            
            % define a color and shape model with color and shape that have sperate coeeficient per morphlevel
            GLMmodelSet=obj.AddNewGLMmodel(GLMmodelSet,'SensoryMLSing',[MainNonSensoryFactors,'ColorMLSing','ShapeMLSing']);
            
            % define a color and shape model with color and shape that have sperate coeeficient per morphlevel
            % add color and shape category
            GLMmodelSet=obj.AddNewGLMmodel(GLMmodelSet,'SensoryMLCatSing',[MainNonSensoryFactors,'ColorMLSing','ShapeMLSing','ColorCat','ShapeCat']);
            
            % define a color and shape model with color and shape that have sperate coeeficient per morphlevel
            % add color and shape category and single objects
            GLMmodelSet=obj.AddNewGLMmodel(GLMmodelSet,'SensoryMLCatObjSing',[MainNonSensoryFactors,'ColorMLSing','ShapeMLSing',...
                'ColorCat','ShapeCat','Objs']);

            % define a model that has shape and color category as coeffcients. 
            GLMmodelSet=obj.AddNewGLMmodel(GLMmodelSet,'SensoryCat',[MainNonSensoryFactors,'ColorCat','ShapeCat']);

            %% if there is an argument with the name of the model passed then output that model's specs
            if nargin>0
                ModelFactors=cellfun(@(x) GLMmodelSet.(x),varargin,'UniformOutput',0);
                nModelFactors=cellfun(@length ,ModelFactors);
                if nargin==2;ModelFactors=ModelFactors{1};end
            end
            
        end
        function GLMmodelSet=AddNewGLMmodel(obj,GLMmodelSet,FullModelName,FullModelFactors,varargin) % creates a new GLM model and adds it to the current sets of models
            %GLMmodelSet structure of current models
            % FullModelName name of the full model
            % FullModelFactors cell array of factors of the full model
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            GLMmodelSet.(FullModelName)=FullModelFactors;
            
            % now build a full model that lacks each component
            for i=1:length(GLMmodelSet.(FullModelName))
                Compset=setdiff(1:length(GLMmodelSet.(FullModelName)),i);
                GLMmodelSet.([FullModelName '_No_' GLMmodelSet.(FullModelName){i}])=GLMmodelSet.(FullModelName)(Compset);
            end
        end
        function [Models2TestSet,ThisModels2Test,FullModelFactors,FullMdlName]=DefineModels2Test(obj,varargin) % defines what are the models we want to compare against each other and their stat test
            
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            % compare to full models and individual models
            Models2TestSet(1).Models=[{'NullMdl'},'FullMdl','FeatureAxisFull','RuleFull','ShapeML','ColorML','ColorCat','ShapeCat','Feature','Axis','Rule','ResponseLoc'];
            nModels2Test=length(Models2TestSet(1).Models);
            Models2TestSet(1).Ref=[ones(1,nModels2Test)]; % what model is our reference statistical test
            Models2TestSet(1).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(1).Name='FullandIndModels';
            Models2TestSet(1).TtestTail='right';
            Models2TestSet(1).BarColor=[1 20 ones(1,nModels2Test-2)];
            
            % do heirarchical feature axis analysis
            Models2TestSet(2).Models=[{'NullMdl'},'FeatureAxisMdlFull','FeatureAxisMdl_1_1','FeatureAxisMdl_1_2','FeatureAxisMdl_1_0','FeatureAxisMdl_2_1',...
                'FeatureAxisMdl_2_2','FeatureAxisMdl_2_3','FeatureAxisMdl_2_0','FeatureAxisMdl_3_1','FeatureAxisMdl_3_2'];
            nModels2Test=length(Models2TestSet(2).Models);
            Models2TestSet(2).Ref=[1,1,1,1,1,5,5,5,5,9,9]; % what model is our reference statistical test
            Models2TestSet(2).Alpha=[0.05*ones(1,5) 0.05*ones(1,4)/2 0.05*ones(1,2)/4];% bonferroni correction
            Models2TestSet(2).Name='FeatureAxisHierarchical';
            Models2TestSet(2).TtestTail='right';
            Models2TestSet(2).BarColor=[1 20 2,2,2,3,3,3,3,4,4];
            
            % do reverse hierarchical feature axis model
            Models2TestSet(3).Models=[{'NullMdl'},'FeatureAxisMdlRevFull','FeatureAxisMdlRev_1_1','FeatureAxisMdlRev_1_2','FeatureAxisMdlRev_1_3','FeatureAxisMdlRev_1_0',...
                'FeatureAxisMdlRev_2_1','FeatureAxisMdlRev_2_2','FeatureAxisMdlRev_2_0','FeatureAxisMdlRev_3_1','FeatureAxisMdlRev_3_2'];
            nModels2Test=length(Models2TestSet(3).Models);
            Models2TestSet(3).Ref=[1,1,1,1,1,1,6,6,6,9,9]; % what model is our reference statistical test
            Models2TestSet(3).Alpha=[0.05*ones(1,6) 0.05*ones(1,3)/2 0.05*ones(1,2)/4];% bonferroni correction
            Models2TestSet(3).Name='FeatureAxisHierarchicalRev';
            Models2TestSet(3).TtestTail='right';
            Models2TestSet(3).BarColor=[1 20 2,2,2,2,3,3,3,4,4];
            
            % do reverse hierarchical rule model
            Models2TestSet(4).Models=[{'NullMdl'},'RuleMdlRevFull','RuleMdlRev_1_1','RuleMdlRev_1_2','RuleMdlRev_1_3','RuleMdlRev_1_0',...
                'RuleMdlRev_2_1','RuleMdlRev_2_2','RuleMdlRev_2_0','RuleMdlRev_3_1'];
            nModels2Test=length(Models2TestSet(4).Models);
            Models2TestSet(4).Ref=[1,1,1,1,1,1,6,6,6,9]; % what model is our reference statistical test
            Models2TestSet(4).Alpha=[0.05*ones(1,6) 0.05*ones(1,3)/2 0.05*ones(1,1)/4];% bonferroni correction
            Models2TestSet(4).Name='RuleHierarchicalRev';
            Models2TestSet(4).TtestTail='right';
            Models2TestSet(4).BarColor=[1 20 2,2,2,2,3,3,3,4];
            
            % do full model with reduction (taking away each component one
            % by one
            Models2TestSet(5).Models=[{'NullMdl'},'FullMdl','FullMdl_No_ShapeML','FullMdl_No_ColorML','FullMdl_No_ColorCat',...
                'FullMdl_No_ShapeCat','FullMdl_No_Feature','FullMdl_No_Axis','FullMdl_No_Rule','FullMdl_No_ResponseLoc'];
            nModels2Test=length(Models2TestSet(5).Models);
            Models2TestSet(5).Ref=[2*ones(1,nModels2Test)]; % compare to full model
            Models2TestSet(5).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(5).Name='FullModelReduce';
            Models2TestSet(5).TtestTail='left';
            Models2TestSet(5).BarColor=[1 20 ones(1,nModels2Test-2)];
            
            % do reverse hierarchical on full model
            Models2TestSet(6).Models=[{'NullMdl'},'FulMdlRevHier','FulMdlRevHier_1_1','FulMdlRevHier_1_2','FulMdlRevHier_1_3','FulMdlRevHier_1_0',...
                'FulMdlRevHier_2_1','FulMdlRevHier_2_2','FulMdlRevHier_2_0','FulMdlRevHier_3_1','FulMdlRevHier_3_2','FulMdlRevHier_3_3'];
            nModels2Test=length(Models2TestSet(6).Models);
            Models2TestSet(6).Ref=[1,1,1,1,1,1,6,6,6,9,9,9]; % what model is our reference statistical test
            Models2TestSet(6).Alpha=[0.05*ones(1,6) 0.05*ones(1,3)/2 0.05*ones(1,3)/4];% bonferroni correction
            Models2TestSet(6).Name='FulMdlRevHier';
            Models2TestSet(6).TtestTail='right';
            Models2TestSet(6).BarColor=[1 20 2,2,2,2,3,3,3,4,4,4];
            
            % do Hybrid Bhv model full with reduction
            Models2TestSet(7).Models=[{'NullMdl'},'HybridbhvMdlFull','HybridbhvMdlFull_No_ColorML','HybridbhvMdlFull_No_ShapeML',...
                'HybridbhvMdlFull_No_ColorCat','HybridbhvMdlFull_No_ShapeCat','HybridbhvMdlFull_No_Rule','HybridbhvMdlFull_No_ResponseLoc',...
                'HybridbhvMdlFull_No_Time','HybridbhvMdlFull_No_Reward','HybridbhvMdlFull_No_Hybrid_Q','HybridbhvMdlFull_No_Hybrid_Baxes'];
            nModels2Test=length(Models2TestSet(7).Models);
            Models2TestSet(7).Ref=[2*ones(1,nModels2Test)]; % compare to full model
            Models2TestSet(7).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(7).Name='HybridbhvMdlFullReduce';
            Models2TestSet(7).TtestTail='left';
            Models2TestSet(7).BarColor=[1 20 ones(1,nModels2Test-2)];
            Models2TestSet(7).FullMdlName='HybridbhvMdlFull';
            
            % do Inference Axis and Feature with reduction
            Models2TestSet(8).Models=[{'NullMdl'},'InferAFbhvMdlFull','InferAFbhvMdlFull_No_ColorML','InferAFbhvMdlFull_No_ShapeML',...
                'InferAFbhvMdlFull_No_ColorCat','InferAFbhvMdlFull_No_ShapeCat','InferAFbhvMdlFull_No_Rule','InferAFbhvMdlFull_No_ResponseLoc',...
                'InferAFbhvMdlFull_No_Time','InferAFbhvMdlFull_No_Reward','InferAFbhvMdlFull_No_InferAF_Q','InferAFbhvMdlFull_No_InferAF_Baxes',...
                'InferAFbhvMdlFull_No_InferAF_Bfeature'];
            nModels2Test=length(Models2TestSet(8).Models);
            Models2TestSet(8).Ref=[2*ones(1,nModels2Test)]; % compare to full model
            Models2TestSet(8).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(8).Name='InferAFbhvMdlFullReduce';
            Models2TestSet(8).TtestTail='left';
            Models2TestSet(8).BarColor=[1 20 ones(1,nModels2Test-2)];
            Models2TestSet(8).FullMdlName='InferAFbhvMdlFull';
            
            % compare different types of bhv models and the null model
            Models2TestSet(9).Models=[{'NullMdl'},'HybridbhvMdlFull','InferAFbhvMdlFull','SensoryMotorMdl'];
            nModels2Test=length(Models2TestSet(9).Models);
            Models2TestSet(9).Ref=[1 1 2 2]; % compare to null model
            Models2TestSet(9).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(9).Name='CompareBhvModels';
            Models2TestSet(9).TtestTail='both';
            Models2TestSet(9).BarColor=[20 1 2 3];
            Models2TestSet(9).FullMdlName='HybridbhvMdlFull';
            
            % compare different types of sensory coding models and the null model
            Models2TestSet(10).Models=[{'NullMdl'},'SensoryMLSing','SensoryMLCatSing','SensoryMLCatObjSing'];
            nModels2Test=length(Models2TestSet(10).Models);
            Models2TestSet(10).Ref=[1 1 2 3]; % compare to null model
            Models2TestSet(10).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(10).Name='CompareSensoryModels';
            Models2TestSet(10).TtestTail='right';
            Models2TestSet(10).BarColor=[1 2 3 4];
            Models2TestSet(10).FullMdlName='SensoryMLCatObjSing';

            % compare sensory category models and the null model
            Models2TestSet(11).Models=[{'NullMdl'},'SensoryCat'];
            nModels2Test=length(Models2TestSet(10).Models);
            Models2TestSet(11).Ref=[1 1]; % compare to null model
            Models2TestSet(11).Alpha=[0.05*ones(1,nModels2Test)/nModels2Test];% bonferroni correction
            Models2TestSet(11).Name='CompareSensoryCatModel';
            Models2TestSet(11).TtestTail='right';
            Models2TestSet(11).BarColor=[1 2];
            Models2TestSet(11).FullMdlName='SensoryCat';
            
            if nargin>1
                Models2TestName=varargin{1};
                ThisModels2Test=Models2TestSet(arrayfun(@(x) strcmp(Models2TestSet(x).Name,Models2TestName),1:length(Models2TestSet)));
                FullModelFactors=GLMModelSet.(ThisModels2Test.FullMdlName); % to be changed
                FullMdlName=ThisModels2Test.FullMdlName;
            end
        end
        %% prepare data for each GLM fit
        function [X,Y,FactorNames,NTim,NTrl]=PrepareData4GLMfit(obj,FactorizedData)
            
            NTim=size(FactorizedData.data,2); % number of time points
            NTrl=size(FactorizedData.data,1); % number of time trials
            FactorNames=FactorizedData.factornames; % Factor Names
            X=obj.ManData.ReshapeCell2Mat(FactorizedData.factors,1); % Regressors
            Y=FactorizedData.data; % spiking data
            MaxY=max(Y(:));
            Y=Y/MaxY(1); % normalize spiking to have max of 1
        end
        %% perfrom model comparision and statistical tests
        function GLMmodelComparision(obj,FactorizedData,varargin)
            % Performs model comparision for different types of GLM model,
            % for now we are looking at Rule and Axis/Feature model
            % steps to perform model comparison
            % 1-divide the data into train and test (make sure each rule
            % has a proportion of trials so the training is not biased)
            % perfom GLM on differnt models and use CV, then test it on remaining test data
            % and calculate R2.
            % Repeat this process to get a significance level
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NTim=size(FactorizedData.data,2);
            FactorNames=FactorizedData.factornames;
            X=obj.ManData.ReshapeCell2Mat(FactorizedData.factors,1);
            Y=FactorizedData.data;
            MaxY=max(Y(:));
            Y=Y/MaxY(1); % normalize spiking
            rng(obj.GLMnMdlCompRuns); % change the rng seed
            % split data into training and testing keeping the rule ratio
            % constant
            for nRun=obj.GLMnMdlCompRuns % run many times so that we get statistics of the model
                fprintf('\nComparing GLM models run %i\n',nRun);
                if length(obj.GLMnMdlCompRuns)==1;nRun=1;end
                [X_train,Y_train,X_test,Y_test,TrainSetInd,TestSetInd]=obj.SplitTrainTest(X,Y,FactorNames,1);
                for t=1:NTim
                    % fit the Rule model first on training data
                    [RuleMdl(nRun).GLM_weights(:,t),~,~,RuleModel.GLMfactorsnames]=obj.GLMfit_Rule(X_train,Y_train(:,t),FactorNames,0);
                    
                    % fit the Feature-Axis model on training data
                    [FeatureAxisMdl(nRun).GLM_weights(:,t),~,~,FeatureAxisModel.GLMfactorsnames]=obj.GLMfit_FeatureAxis(X_train,Y_train(:,t),FactorNames,0);
                    
                    % fit the Color model on training data
                    [ColorMdl(nRun).GLM_weights(:,t),~,~,ColorMdl.GLMfactorsnames]=obj.GLMfit_Color(X_train,Y_train(:,t),FactorNames,0);
                end
                % rule model on the the test dataset
                [~,~,~,~,Xdata_test]=obj.GLMfit_Rule(X_test,[],FactorNames,1);
                RuleMdl(nRun).Yhat=cell2mat(arrayfun(@(x) glmval(RuleMdl(nRun).GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                RuleMdl(nRun).R2=arrayfun(@(x)obj.ManData.CalR2(Y_test(:,x),RuleMdl(nRun).Yhat(:,x)),1:NTim);
                
                % feature axis model on test dataset
                [~,~,~,~,Xdata_test]=obj.GLMfit_FeatureAxis(X_test,[],FactorNames,1);
                FeatureAxisMdl(nRun).Yhat=cell2mat(arrayfun(@(x) glmval(FeatureAxisMdl(nRun).GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                FeatureAxisMdl(nRun).R2=arrayfun(@(x)obj.ManData.CalR2(Y_test(:,x),FeatureAxisMdl(nRun).Yhat(:,x)),1:NTim);
                
                % color model on test dataset
                [~,~,~,~,Xdata_test]=obj.GLMfit_Color(X_test,[],FactorNames,1);
                ColorMdl(nRun).Yhat=cell2mat(arrayfun(@(x) glmval(ColorMdl(nRun).GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                ColorMdl(nRun).R2=arrayfun(@(x)obj.ManData.CalR2(Y_test(:,x),ColorMdl(nRun).Yhat(:,x)),1:NTim);
                
                % save our opts for model comparision
                MdlCmpOpts(nRun).Y_test=Y_test; % save Y test so that we have it for future calculations
                MdlCmpOpts(nRun).X_test=X_test; % save X test so that we have it for future calculations
                MdlCmpOpts(nRun).TrainSetInd=TrainSetInd; % save the indexs
                MdlCmpOpts(nRun).TestSetInd=TestSetInd; % save the indexs
                MdlCmpOpts(nRun).RngSeed=rng;
                
                % save each run if we are running it on the cluster
                SaveFileName=['_MdlComp_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName '_Run' num2str(obj.GLMnMdlCompRuns)];
                obj.ManData.SaveVar('GLM',RuleMdl,'RuleMdl',SaveFileName);
                obj.ManData.SaveVar('GLM',FeatureAxisMdl,'FeatureAxisMdl',SaveFileName);
                obj.ManData.SaveVar('GLM',ColorMdl,'ColorMdl',SaveFileName);
                obj.ManData.SaveVar('GLM',MdlCmpOpts,'MdlCmpOpts',SaveFileName);
            end
        end
        function GLMmodelComparision_Hierarchical(obj,FactorizedData,Models2TestName,varargin)
            % similar to methods used by
            % Meinshausen, N. (2008). Hierarchical Testing of Variable Importance. Biometrika 95, 265278. .
            %Hastie, T., Tibshirani, R., Botstein, D., and Brown, P. (2001). Supervised harvesting of expression trees. Genome Biology 2, research0003.1. https://doi.org/10.1186/gb-2001-2-1-research0003.
            
            % Performs model comparision for different types of GLM models including hierarchical models,
            % for now we are looking at Rule and Axis/Feature model
            % steps to perform model comparison
            % 1-divide the data into train and test (make sure each rule
            % has a proportion of trials so the training is not biased)
            % perfom GLM on differnt models and use CV, then test it on remaining test data
            % and calculate R2.
            % Repeat this process to get a significance level
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            GLMmodelSet=rmfield(GLMmodelSet,'FactorNameSet');GLMmodelSet=rmfield(GLMmodelSet,'nFactorNameSet');
            
            %Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,'FullMdl'),...
            %Models2Test=[{'NullMdl'},'HybridbhvMdlFull','InferAFbhvMdlFull','SensoryMotorMdl'];
           % Models2Test=[{'NullMdl'},'SensoryMLSing','SensoryMLCatSing','SensoryMLCatObjSing'];
           % Models2Test=[{'NullMdl'},'SensoryMLSing','SensoryCat'];

            % load the models we care about
            Models2TestSet=obj.DefineModels2Test; % get the set of GLM models to compare
            ThisModels2Test=Models2TestSet(arrayfun(@(x) strcmp(Models2TestSet(x).Name,Models2TestName),1:length(Models2TestSet)));
            Models2Test=ThisModels2Test.Models;
            nModels2Test=length(Models2Test);
            
            % prepapre data now
            [X,Y,FactorNames,NTim,NTrl]=obj.PrepareData4GLMfit(FactorizedData);
            rng(obj.GLMnMdlCompRuns(end)); % change the rng seed
            obj=obj.DetermineGLMFullMdlType; %determine type of full model we are using
            AnalysisOpts.GLMmdlCompStr=''; % initialize
            WantedTime=AnalysisOpts.Time>=0; %this is the time period we are intrested to calclute R2
            if ~AnalysisOpts.RunOnCluster;obj.GLMnMdlCompRuns=1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns;end
            % split data into training and testing keeping the rule ratio
            % constant
            for nRun=obj.GLMnMdlCompRuns % run many times so that we get statistics of the model
                fprintf('\nComparing GLM models run %i\n',nRun);
                if length(obj.GLMnMdlCompRuns)==1;nRun=1;AnalysisOpts.GLMmdlCompStr=num2str(nRun);else;AnalysisOpts.GLMmdlCompStr='';end
                
                [X_train,Y_train,X_test,Y_test,TrainSetInd,TestSetInd]=obj.SplitTrainTest(X,Y,FactorNames,1);
                % Run series of models we want to do
                for m=1:nModels2Test % loop on models
                    fprintf('\nrunning %s model...',Models2Test{m});
                    tic;
                    %% fit the model on train data
                    ModelDef=GLMmodelSet.(Models2Test{m}); % get model factors
                    [ModelOutput(nRun).(Models2Test{m})]=obj.(['GLM_' obj.GLMfullMdlType])(X_train,Y_train,FactorNames,ModelDef,0);
                    
                    %% test each model on the the test dataset
                    [~,Xdata_test]=obj.(['GLM_' obj.GLMfullMdlType])(X_test,[],FactorNames,ModelDef,1); % get test data
                    Yhat_test=obj.PredictGLMval(ModelOutput(nRun).(Models2Test{m}),Xdata_test); % calculate Yhat it for each lambda
                    [ModelOutput(nRun).(Models2Test{m}).R2timeTest,ModelOutput(nRun).(Models2Test{m}).R2trlTest,ModelOutput(nRun).(Models2Test{m}).R2TimePoint] =...
                        cellfun(@(x) obj.ManData.CalR2time(Y_test(:,WantedTime),x(:,WantedTime)),Yhat_test); % calculate R2
                    ModelOutput(nRun).(Models2Test{m}).MSETest=cellfun(@(x) obj.ManData.MeanSquaredErrorTrial(x(:,WantedTime),Y_test(:,WantedTime)),Yhat_test); % calculate MSE
                    % remove yhat from GLM fit
                    ModelOutput(nRun).(Models2Test{m})=rmfield(ModelOutput(nRun).(Models2Test{m}),'Yhat');
                    Tend=toc;
                    fprintf('Elapsed Time=%i',Tend);
                end
                % save our opts for model comparision
                % ModelOutput(nRun).X_train=X_train;% save X train so that we have it for future calculations
                % ModelOutput(nRun).Y_train=Y_train;% save Y train so that we have it for future calculations
                % ModelOutput(nRun).Y_test=Y_test;  % save Y test  so that we have it for future calculations
                % ModelOutput(nRun).X_test=X_test;  % save X test  so that we have it for future calculations
            end
            % save each run if we are running it on the cluster
            ExtraTxt=obj.GetExtraStr4Cond('ModelComp');
            %ExtraTxt=['_MdlComp' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_Run' num2str(obj.GLMnMdlCompRuns)];
            try  % try to save the file in the previously built file
                [~,~,FullPath]=obj.ManData.GetFileName('GLM',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                MatFile=load(FullPath); % see if you can load the file
                % save each run if we are running it on the cluster
                obj.ManData.SaveVar('GLM',ModelOutput,'ModelOutput',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            catch ME % if you catch error then delete file and save it again
                fprintf('\n%s',ME.message);
                obj.ManData.DeleteFile('GLM',ExtraTxt,1,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                obj.ManData.SaveVar('GLM',ModelOutput,'ModelOutput',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            end
        end
        function GLMmodelComparision_HierarchicalCluster(obj,FactorizedData,varargin) % breakes the tasks more so that it can be used with the cluster
            % similar to methods used by
            % Meinshausen, N. (2008). Hierarchical Testing of Variable Importance. Biometrika 95, 265278. .
            %Hastie, T., Tibshirani, R., Botstein, D., and Brown, P. (2001). Supervised harvesting of expression trees. Genome Biology 2, research0003.1. https://doi.org/10.1186/gb-2001-2-1-research0003.
            
            % Performs model comparision for different types of GLM models including hierarchical models,
            % for now we are looking at Rule and Axis/Feature model
            % steps to perform model comparison
            % 1-divide the data into train and test (make sure each rule
            % has a proportion of trials so the training is not biased)
            % perfom GLM on differnt models and use CV, then test it on remaining test data
            % and calculate R2.
            % Repeat this process to get a significance level
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            temp=AnalysisOpts.RunLocator(obj.GLMnMdlCompRuns,:);nRun=temp(1);m=temp(2);
            
            GLMmodelSet=obj.DefineGLMmodelSet; % get the set of GLM models we have
            GLMmodelSet=rmfield(GLMmodelSet,'FactorNameSet');GLMmodelSet=rmfield(GLMmodelSet,'nFactorNameSet');
            
            %             Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,'FullMdl'),...
            %                 obj.ManData.FindFieldinStruct(GLMmodelSet,'FeatureAxisMdl'),...
            %                 obj.ManData.FindFieldinStruct(GLMmodelSet,'RuleMdl')];
            
            %             Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,'FulMdlRevHier'),...
            %                 obj.ManData.FindFieldinStruct(GLMmodelSet,'FullMdl')];
            
            Models2Test=[{'NullMdl'},obj.ManData.FindFieldinStruct(GLMmodelSet,'HybridbhvMdlFull'),...
                obj.ManData.FindFieldinStruct(GLMmodelSet,'InferAFbhvMdlFull')];
            
            nModels2Test=length(Models2Test);
            % prepapre data now
            NTim=size(FactorizedData.data,2);
            FactorNames=FactorizedData.factornames;
            % add a random delay so that if channels arrive at the same
            % time one of them is out sooner
            if obj.GLMnMdlCompRuns~=1;pause(1);end
            % generate a unique set of train and test set for each run and
            % save them off
            TrnTstSetFileName=['TrnTstSet_MdlComp' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName ];
            X_train=obj.ManData.LoadVar('GLM','X_train',TrnTstSetFileName,0);
            Y_train=obj.ManData.LoadVar('GLM','Y_train',TrnTstSetFileName,0);
            X_test=obj.ManData.LoadVar('GLM','X_test',TrnTstSetFileName,0);
            Y_test=obj.ManData.LoadVar('GLM','Y_test',TrnTstSetFileName,0);
            
            if isempty(X_train) % then generate it
                X=obj.ManData.ReshapeCell2Mat(FactorizedData.factors,1);
                Y=FactorizedData.data;
                MaxY=max(Y(:));
                Y=Y/MaxY(1); % normalize spiking
                rng(obj.GLMnMdlCompRuns); % change the rng seed
                
                % split data into training and testing keeping the rule ratio
                % constant
                [X_train,Y_train,X_test,Y_test]=arrayfun(@(x) obj.SplitTrainTest(X,Y,FactorNames,1),1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns,'UniformOutput',false);
                obj.ManData.SaveVar('GLM',X_train,'X_train',TrnTstSetFileName);
                obj.ManData.SaveVar('GLM',X_train,'Y_train',TrnTstSetFileName);
                obj.ManData.SaveVar('GLM',X_train,'X_test',TrnTstSetFileName);
                obj.ManData.SaveVar('GLM',X_train,'Y_test',TrnTstSetFileName);
            end
            X_train=X_train{nRun};Y_train=Y_train{nRun};X_test=X_test{nRun};Y_test=Y_test{nRun};
            
            fprintf('\nComparing GLM models run %i\n',nRun);
            
            % Run series of models we want to do
            fprintf('\nrunning %s model...',Models2Test{m});
            tic;
            for t=1:NTim  % loop on time points
                
                ModelDef=GLMmodelSet.(Models2Test{m}); % get model factors
                [ModelOutput.(Models2Test{m}).GLM_weights(:,t),~,~,ModelOutput.(Models2Test{m}).GLMfactorsnames,~,...
                    ModelOutput.(Models2Test{m}).GLM_weights_full(:,:,t)]...
                    =obj.GLM_FullModel(X_train,Y_train(:,t),FactorNames,ModelDef,0);
                
            end
            
            % run each model on the the test dataset
            ModelDef=GLMmodelSet.(Models2Test{m}); % get model factors
            [~,~,~,~,Xdata_test]=obj.GLM_FullModel(X_test,[],FactorNames,ModelDef,1);
            ModelOutput.(Models2Test{m}).Yhat=cell2mat(arrayfun(@(x) glmval(ModelOutput.(Models2Test{m}).GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
            ModelOutput.(Models2Test{m}).R2=arrayfun(@(x)obj.ManData.CalR2(Y_test(x,:),ModelOutput.(Models2Test{m}).Yhat(x,:)),1:size(Y_test,1));
            %    % save our opts for model comparision
            %    ModelOutput.(Models2Test{m}).Y_test=Y_test; % save Y test so that we have it for future calculations
            %    ModelOutput.(Models2Test{m}).X_test=X_test; % save X test so that we have it for future calculations
            Tend=toc;
            fprintf('Elapsed Time=%i',Tend);
            
            ModelOutput.RngSeed=rng;
            
            % save each run if we are running it on the cluster
            SaveFileName=['_MdlComp' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_Run' num2str(nRun)];
            obj.ManData.SaveVar('GLM',ModelOutput,['ModelOutput_' Models2Test{m}],SaveFileName);
        end
        
        %% plot model comparision results
        function PlotGLMmodelComparision(obj,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % plots model comparision for GLM model
            % loop through channel we want to look at
            LoadFileName=['_MdlComp_' AnalysisOpts.Area2look '_' AnalysisOpts.SpkCntStartFieldName '_Run' ];
            
            for Neu=AnalysisOpts.Ch_2look
                % load all of the file we have calculated for this neuron
                AnalysisOpts.CurrentCh=Neu;
                
                RuleMdl=obj.ManData.LoadVarSeries2('GLM','RuleMdl',[],LoadFileName,1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                FeatureAxisMdl=obj.ManData.LoadVarSeries2('GLM','FeatureAxisMdl',[],LoadFileName,1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                ColorMdl=obj.ManData.LoadVarSeries2('GLM','ColorMdl',[],LoadFileName,1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                ModlCompOpts=obj.ManData.LoadVarSeries2('GLM','MdlCmpOpts',[],LoadFileName,1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                
                NYtest=length(ModlCompOpts(1).Y_test);
                NRep=AnalysisOpts.SingCellAna.GLMnMdlCompRuns;
                
                MSERuleMdl{Neu}=arrayfun(@(x) mean(arrayfun(@(y) obj.ManData.CalR2(ModlCompOpts(x).Y_test(y,:),RuleMdl(x).Yhat(y,:)),1:NYtest,'UniformOutput',1)),1:NRep,'Uniformoutput',1);
                MSEFeatureAxisMdl{Neu}=arrayfun(@(x) mean(arrayfun(@(y) obj.ManData.CalR2(ModlCompOpts(x).Y_test(y,:),FeatureAxisMdl(x).Yhat(y,:)),1:NYtest,'UniformOutput',1)),1:NRep,'Uniformoutput',1);
                MSEColorMdl{Neu}=arrayfun(@(x) mean(arrayfun(@(y) obj.ManData.CalR2(ModlCompOpts(x).Y_test(y,:),ColorMdl(x).Yhat(y,:)),1:NYtest,'UniformOutput',1)),1:NRep,'Uniformoutput',1);
                
                
                R2RuleMdl{Neu}=arrayfun(@(x) max(RuleMdl(x).R2),1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                R2FeatureAxisMdl{Neu}=arrayfun(@(x) max(FeatureAxisMdl(x).R2),1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                R2ColorMdl{Neu}=arrayfun(@(x) max(ColorMdl(x).R2),1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
                
                % plot some comparisions of the models to get a sense of
                % what is going on
                MdlNames={'ColorMdl','RuleMdl','FeatureAxisMdl'};
                figure
                subplot(221);hold on
                plot(AnalysisOpts.Time,ColorMdl(1).Yhat')
                plot(AnalysisOpts.Time,mean(ModlCompOpts(1).Y_test,1),'LineWidth',5)
                title('ColorModel')
                xlabel('Time')
                
                subplot(222);hold on
                plot(AnalysisOpts.Time,RuleMdl(1).Yhat')
                plot(AnalysisOpts.Time,mean(ModlCompOpts(1).Y_test,1),'LineWidth',5)
                title('RuleModel')
                
                subplot(223);hold on
                plot(AnalysisOpts.Time,FeatureAxisMdl(1).Yhat')
                plot(AnalysisOpts.Time,mean(ModlCompOpts(1).Y_test,1),'LineWidth',5)
                title('FeatureAxisModel')
                
                subplot(224);hold on
                for i=1:length(MdlNames)
                    eval(['MSE=arrayfun(@(y) obj.ManData.CalR2(ModlCompOpts(1).Y_test(y,:),' MdlNames{i} '(1).Yhat(y,:)),1:NYtest,''UniformOutput'',1)']);
                    plot(MSE)
                end
                legend(MdlNames)
                xlabel('Trial')
                title('MSE')
                
                
            end
            
        end
        function varargout=PlotGLMmodelComparision_Hierarchical(obj,Models2TestName,PlotFlag,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % plots model comparision for GLM model
            % loop through channel we want to look at
            varargout=cell(1,3);
             
            % load the models we care about
            GLMModelSet=obj.DefineGLMmodelSet;
            Models2TestSet=obj.DefineModels2Test; % get the set of GLM models to compare
            ThisModels2Test=Models2TestSet(arrayfun(@(x) strcmp(Models2TestSet(x).Name,Models2TestName),1:length(Models2TestSet)));
            Models2Test=ThisModels2Test.Models;
            nModels2Test=length(Models2Test);
            ModelComp=[];
            ModelComp.ThisModels2Test=ThisModels2Test;
            % load all of the file we have calculated for this neuron
            ExtraTxt=obj.GetExtraStr4Cond('ModelComp');
            [ModelOutput,FileExist]=obj.ManData.LoadVar('GLM','ModelOutput',ExtraTxt,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            if ~FileExist % try and see if individual files are saves
                ModelOutput=obj.ManData.LoadVarSeries2('GLM','ModelOutput',[],ExtraTxt,1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns);
            end
            if isempty(ModelOutput);return;end
            EmptyMdls=arrayfun(@(x) ~isempty(ModelOutput(x).NullMdl),1:length(ModelOutput));
            ModelOutput=ModelOutput(EmptyMdls);
            NTim=size(ModelOutput(1).NullMdl.GLM_weights_full,3);
            NRep=length(ModelOutput);
            if NRep<0.2*AnalysisOpts.SingCellAna.GLMnMdlCompRuns;return;end % if we have less than 20% of target number of repetition then return
            
            %% Re Caluclate some metrics if we have the Y and X test data saved
            if isfield(ModelOutput,'Y_test')
                NYtest=size(ModelOutput(1).Y_test,1);
                for m=1:nModels2Test % loop on models
                    % recompute distance metrics for the default lambda using mean squared error and R2
                    MSE=arrayfun(@(x) nanmean(arrayfun(@(y) obj.ManData.MeanSquaredError(ModelOutput(x).Y_test(y,:),ModelOutput(x).(Models2Test{m}).Yhat(y,:)),1:NYtest,'UniformOutput',1)),1:NRep,'Uniformoutput',1);
                    %  R2=arrayfun(@(x) nanmean(arrayfun(@(y) obj.ManData.CalR2(ModelOutput(x).Y_test(y,:),ModelOutput(x).(Models2Test{m}).Yhat(y,:)),1:NYtest,'UniformOutput',1)),1:NRep,'Uniformoutput',1);
                    R2=arrayfun(@(x) obj.ManData.CalR2time(ModelOutput(x).Y_test,ModelOutput(x).(Models2Test{m}).Yhat),1:NRep,'Uniformoutput',1);
                    % compute distance for different lamda values as well
                    ModelDef=GLMModelSet.(Models2Test{m}); % get model factors
                    for rep=1:NRep
                        [~,~,~,~,Xdata_test]=obj.GLM_FullModel(ModelOutput(rep).X_test,[],AnalysisOpts.factornames,ModelDef,1);
                        Yhat=arrayfun(@(lambda) cell2mat(arrayfun(@(x) glmval(squeeze(ModelOutput(rep).(Models2Test{m}).GLM_weights_full(:,lambda,x)),Xdata_test,'identity'),1:NTim,'UniformOutput',0)),AnalysisOpts.SingCellAna.GLMLamdaVals,'UniformOutput',false);
                        MSE_lambda(rep,:)=arrayfun(@(x) mean(arrayfun(@(y) obj.ManData.MeanSquaredError(ModelOutput(rep).Y_test(y,:),Yhat{x}(y,:)),1:NYtest,'UniformOutput',1)),1:length(AnalysisOpts.SingCellAna.GLMLamdaVals));
                        R2_lambda(rep,:)=arrayfun(@(x)   obj.ManData.CalR2time(ModelOutput(rep).Y_test,Yhat{x}),1:length(AnalysisOpts.SingCellAna.GLMLamdaVals));
                    end
                    ModelComp.(Models2Test{m}).MSE=[MSE;MSE_lambda'];
                    ModelComp.(Models2Test{m}).R2=[R2;R2_lambda'];
                end
            else
                MetricSet={'MSETest','R2trlTest','R2TimePoint','R2timeTest'};
                for m=1:nModels2Test
                    for Metric=MetricSet
                        ModelComp.(Models2Test{m}).(Metric{1})=(cell2mat(arrayfun(@(rep) ModelOutput(rep).(Models2Test{m}).(Metric{1})',1:NRep,'UniformOutput',0)));
                    end
                end
            end
            ModelComp.GLMLamdaVals=ModelOutput(1).NullMdl.Lambda ;%[0 AnalysisOpts.SingCellAna.GLMLamdaVals]; % default lambda values and extra labmda
            nGLMLamdaVals=length(ModelComp.GLMLamdaVals);
            % concatinate different MSE and R2 across models and Lambdas
            MSEfield='MSETest';R2Field='R2trlTest';R2FieldTimePoint='R2TimePoint'; % what are the R2 and MSE fields we are intrested to look at
            for Lambda=[ModelComp.GLMLamdaVals]
                LamInd=find(ModelComp.GLMLamdaVals==Lambda);
                ModelComp.MSEDiffs{LamInd}=cell2mat(arrayfun(@(x) ModelComp.("NullMdl").(MSEfield)(LamInd,:)'-ModelComp.(Models2Test{x}).(MSEfield)(LamInd,:)',1:nModels2Test,'uniformoutput',0));
                ModelComp.R2Diffs{LamInd}=cell2mat(arrayfun(@(x) ModelComp.(Models2Test{x}).(R2Field)(LamInd,:)',1:nModels2Test,'uniformoutput',0));
                ModelComp.R2DiffTimePoint{LamInd}=cell2mat(arrayfun(@(x) ModelComp.(Models2Test{x}).(R2FieldTimePoint)(LamInd,:)',1:nModels2Test,'uniformoutput',0));
            end
            % find the lambda that has max R2 for all of the models aprat
            % from null model
            MeanR2=cell2mat(cellfun(@(x) mean(x,1)',ModelComp.R2Diffs,'UniformOutput',0));
            MeanR2TimePoint=cell2mat(cellfun(@(x) mean(x,1)',ModelComp.R2DiffTimePoint,'UniformOutput',0));
            IndNullModel=strcmp(Models2Test,'NullMdl');
            [~,ModelComp.LambdaIndMaxR2]=max(mean(MeanR2(~IndNullModel,:)),[],2);
            [~,ModelComp.LambdaIndMaxR2TimePoint]=max(mean(MeanR2TimePoint(~IndNullModel,:)),[],2);
            %% perfrom statistical tests on the models for MSE and R2
            [~,ModelComp.StatTest.MSE]=arrayfun(@(lambda) arrayfun(@(x) ttest(ModelComp.(Models2Test{ThisModels2Test.Ref(x)}).(MSEfield)(lambda,:)',ModelComp.(Models2Test{x}).(MSEfield)(lambda,:)',...
                'tail',ThisModels2Test.TtestTail),1:nModels2Test),1:length(ModelComp.GLMLamdaVals),'UniformOutput',0);
            % R2 test's tail is the reverse of the MSE because we want the
            % MSE to be lower and R2 higher than null model
            [~,ModelComp.StatTest.R2]=arrayfun(@(lambda) arrayfun(@(x) ttest(ModelComp.(Models2Test{x}).(R2Field)(lambda,:)',ModelComp.(Models2Test{ThisModels2Test.Ref(x)}).(R2Field)(lambda,:)',...
                'tail',ThisModels2Test.TtestTail),1:nModels2Test),1:length(ModelComp.GLMLamdaVals),'UniformOutput',0);
            [~,ModelComp.StatTest.R2TimePoint]=arrayfun(@(lambda) arrayfun(@(x) ttest(ModelComp.(Models2Test{x}).(R2FieldTimePoint)(lambda,:)',ModelComp.(Models2Test{ThisModels2Test.Ref(x)}).(R2FieldTimePoint)(lambda,:)',...
                'tail',ThisModels2Test.TtestTail),1:nModels2Test),1:length(ModelComp.GLMLamdaVals),'UniformOutput',0);
            
            %% calculate category tuning index now
            if isfield(ModelOutput(1),'SensoryMLSing')
                ThisModelFactors=ModelOutput(1).('SensoryMLSing').GLMfactorsnames;
                ColorMLFactorInd=arrayfun(@(x) find(strcmp(ThisModelFactors,['ColorMLSing' num2str(x)])),1:6);
                ColorMLBeta=squeeze(ModelOutput(1).('SensoryMLSing').GLM_weights_full(ColorMLFactorInd,ModelComp.LambdaIndMaxR2,:));
                ModelComp.GLMCategoryTuningIndexFull=obj.ManData.CalGLMCategoryTuningIndex(ColorMLBeta,AnalysisOpts.StimulusMorphLevelsNo50);
                WantedTime=AnalysisOpts.Time>=0;AnalysisOpts.Time<=0.25;
                ModelComp.GLMCategoryTuningIndex=obj.ManData.CalGLMCategoryTuningIndex(mean(ColorMLBeta(:,WantedTime),2),AnalysisOpts.StimulusMorphLevelsNo50);
                % do this for Time point as well
                ColorMLBeta=squeeze(ModelOutput(1).('SensoryMLSing').GLM_weights_full(ColorMLFactorInd,ModelComp.LambdaIndMaxR2TimePoint,:));
                ModelComp.GLMCategoryTuningIndexFullTimePoint=obj.ManData.CalGLMCategoryTuningIndex(ColorMLBeta,AnalysisOpts.StimulusMorphLevelsNo50);
                ModelComp.GLMCategoryTuningIndexTimePoint=obj.ManData.CalGLMCategoryTuningIndex(mean(ColorMLBeta(:,WantedTime),2),AnalysisOpts.StimulusMorphLevelsNo50);
            end
            % save our results for future use
            ExtraStr=obj.GetExtraStr4Cond('SummeryFile');
            obj.ManData.SaveVar('GLM',ModelComp,['ModelComp_' Models2TestName],ExtraStr,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            
            if PlotFlag
                %%  plot the model comparision results
                h=obj.FigParams.RenderFigure(2,[]);
                % show charactristics of the model
                figure(h{1});
                arrayfun(@(x) text(0,x*0.75,strrep([Models2Test{x} ':' cell2mat(arrayfun(@(y) [GLMModelSet.(Models2Test{x}){y} ','],...
                    1:length(GLMModelSet.(Models2Test{x})),'UniformOutput',0))],'_',''),'Fontsize',9),1:nModels2Test)
                ylim([0,nModels2Test+1])
                axis off

                %% now plot details model comparision
                % [h1,Sp]=obj.FigParams.RenderSubplots([],[],h{2},length(ModelComp.GLMLamdaVals));
                [h1,Sp]=obj.FigParams.RenderSubplots([2],[3],h{2},6);
                % only show MSE and R2 for the first lamda(usually 0) and show
                % the rest of them all together
                AnalysisOpts.CurrColorPalett=AnalysisOpts.ColorPalettCamden;
                % plot MSE for each model in a bar plot
                obj.PlotMdlCompMetrics('MSE',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,1,ModelComp.LambdaIndMaxR2,'bar')
                % plot R2 for each model in a bar plot
                obj.PlotMdlCompMetrics('R2',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,2,ModelComp.LambdaIndMaxR2,'bar')
                % plot R2TimePoint for each model in a bar plot
                obj.PlotMdlCompMetrics('R2TimePoint',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,3,ModelComp.LambdaIndMaxR2TimePoint,'bar')

                % plot MSE and R2 across differernt lambda values
                obj.PlotMdlCompMetrics('MSE',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,4,1:nGLMLamdaVals,'line')
                obj.PlotMdlCompMetrics('R2',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,5,1:nGLMLamdaVals,'line')
                obj.PlotMdlCompMetrics('R2TimePoint',ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,6,1:nGLMLamdaVals,'line')

                %% in a new figure plot distribution of responses per
                %% condition
                FullFactors=ModelOutput(1).(ThisModels2Test.FullMdlName).GLMfactorsnames;
                FullFactors=FullFactors(~strcmp(FullFactors,'Bias'));
                nFactors=length(FullFactors);
                [h2,Sp2]=obj.FigParams.RenderSubplots(nModels2Test,1,[],[]);hold on
                % go through each model and get distribution
                for m=2:nModels2Test
                    MeanDist=zeros(1,nFactors);
                    ThisModelFactors=ModelOutput(1).(Models2Test{m}).GLMfactorsnames;
                    % ThisModelFactors=ThisModelFactors(~strcmp(ThisModelFactors,'Bias'));
                    for f=1:nFactors
                        ThisFactorInd=find(strcmp(ThisModelFactors,FullFactors{f}));
                        Dist= ModelOutput(1).(Models2Test{m}).GLM_weights_full(ThisFactorInd,ModelComp.LambdaIndMaxR2,:);
                        MeanDist(f)=mean(Dist(Dist~=0));
                    end
                    subplot(Sp2(m-1));
                    bar(1:nFactors,MeanDist,'barwidth',0.5);
                    if m==nModels2Test
                        xticks(1:nFactors)
                        xticklabels(FullFactors);
                        xtickangle(45)
                    end
                    yticks((max(MeanDist)+min(MeanDist))/2);
                    yticklabels(strrep(Models2Test{m},'_',''))
                end
                % add category tuning index
                if isfield(ModelOutput(1),'SensoryMLSing')
                    obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ModelComp.GLMCategoryTuningIndexFull,[],'Time','CTI',1,3,...
                        ['Color category tuning index:' num2str(ModelComp.GLMCategoryTuningIndex,3)],'Sp',Sp2(m));
                end
                varargout=[h h2];
            end
        end
        function PlotMdlCompMetrics(obj,Metric,ModelComp,ThisModels2Test,Models2Test,nModels2Test,Sp,nsp,IndLamb,plottype) % plots R2 and MSE for model comparision
            subplot(Sp(nsp))
            hold on
            switch plottype
                case 'bar' % use this to plot the values with a bar andsignificance levels
                    if strcmp(Metric,'MSE')
                        [hp,MeanMetric,STDMetric]=arrayfun(@(x) obj.FigParams.PlotMeanStd(x,ModelComp.MSEDiffs{IndLamb}(:,x),[],'Models','MSE Null-MSE Model',ThisModels2Test.BarColor(x),2,'model comparision'),1:nModels2Test,'UniformOutput',0);
                    elseif strcmp(Metric,'R2')
                        [hp,MeanMetric,STDMetric]=arrayfun(@(x) obj.FigParams.PlotMeanStd(x,ModelComp.R2Diffs{IndLamb}(:,x),[],'Models','R2 Model',ThisModels2Test.BarColor(x),2,'model comparision'),1:nModels2Test,'UniformOutput',0);
                    elseif strcmp(Metric,'R2TimePoint')
                        [hp,MeanMetric,STDMetric]=arrayfun(@(x) obj.FigParams.PlotMeanStd(x,ModelComp.R2DiffTimePoint{IndLamb}(:,x),[],'Models','R2 Model',ThisModels2Test.BarColor(x),2,'model comparision'),1:nModels2Test,'UniformOutput',0);
                    end
                    arrayfun(@(x) set(hp{x},'linestyle',':','LineWidth',5),unique(ThisModels2Test.Ref));
                    %       sigstar( arrayfun(@(x) [x ThisModels2Test.Ref(x)], 1:nModels2Test,'UniformOutput',0),ModelComp.StatTest.(Metric){IndLamb})
                    
                    MeanMetric=cell2mat(MeanMetric);STDMetric=cell2mat(STDMetric);
                    xticks(1:nModels2Test)
                    xticklabels(strrep(Models2Test,'_',''))
                    xtickangle(45)
                    YlimVal=[min(MeanMetric)-2*max(STDMetric) max(MeanMetric)+4*max(STDMetric)];
                    if YlimVal(1)==YlimVal(2)
                        ylim auto
                    else
                        ylim(YlimVal);
                    end
                    PvalStar=arrayfun(@(x) pvalueStar(ModelComp.StatTest.(Metric){IndLamb}(x),ThisModels2Test.Alpha(x)),1:nModels2Test,'UniformOutput',0);
                    arrayfun(@(x) text(x-0.2,MeanMetric(x)+2*STDMetric(x),PvalStar{x},'Color','red','FontSize',14),1:nModels2Test);
                    % title([Models2TestName ' Lam' num2str(ModelComp.GLMLamdaVals(IndLamb))])
                    
                case 'line' % use this to look at all the lambda values togther in one plot without significance level
                    if strcmp(Metric,'MSE')
                        [MeanMetric]=arrayfun(@(y) arrayfun(@(x) mean(ModelComp.MSEDiffs{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                        [STDMetric] =arrayfun(@(y) arrayfun(@(x) std(ModelComp.MSEDiffs{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                    elseif strcmp(Metric,'R2')
                        [MeanMetric]=arrayfun(@(y) arrayfun(@(x) mean(ModelComp.R2Diffs{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                        [STDMetric] =arrayfun(@(y) arrayfun(@(x) std(ModelComp.R2Diffs{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                    elseif strcmp(Metric,'R2TimePoint')
                        [MeanMetric]=arrayfun(@(y) arrayfun(@(x) mean(ModelComp.R2DiffTimePoint{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                        [STDMetric] =arrayfun(@(y) arrayfun(@(x) std(ModelComp.R2DiffTimePoint{x}(:,y)),IndLamb,'UniformOutput',1),1:nModels2Test,'UniformOutput',0);
                    end
                    % now plot all of the models together
                    MdlCol=distinguishable_colors(nModels2Test);
                    [leg]=arrayfun(@(x) obj.FigParams.PlotMeanStd(IndLamb,MeanMetric{x},STDMetric{x},'Lambda values',[Metric],ThisModels2Test.BarColor(x),3,[Metric ' values x lambda']),1:nModels2Test,'UniformOutput',1);
                    %    legend(leg,ThisModels2Test.Models)
                    xticklabels(arrayfun(@num2str ,ModelComp.GLMLamdaVals,'UniformOutput',0))
                    xtickangle(45)
            end
        end
        function SummeryGLMfit=InferFactorSignificance(obj,FullMdlName,varargin)   % infer significance of each factor in the main model
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % define options for cluster correction
            opts.dependent_samples=AnalysisOpts.GLM_dependent_samples; % usually we have independent samples for shuffles
            opts.p_threshold=AnalysisOpts.GLM_p_threshold;
            opts.num_permutations=AnalysisOpts.GLM_num_permutations;
            opts.two_sided=AnalysisOpts.GLM_two_sided;
            opts.num_clusters =AnalysisOpts.GLM_num_clusters;
            
            obj=obj.DetermineGLMFullMdlType('GLMmdl',FullMdlName); %determine type of full model we are using
            [GLMModelSet,FullModelFactors,nFullModelFactors]=obj.DefineGLMmodelSet(FullMdlName);
            if ~AnalysisOpts.GLM_SkipSingleCellCharctristics % are we skipping single cell charactristics?
                %% p values for single cells
                for Neu=AnalysisOpts.nCh_2look

                    % load the main GLM files
                    [GLMfit,~,~,GLMFileName]=obj.LoadGLMfitfile(Neu,FullMdlName,'GLMfit');
                    CPD=GLMfit.CPD;%obj.CalCoefPartialDet(GLMfit,FullModelFactors,FullMdlName);

                    % now load shuffle data and calculate CPD for each shuffle data
                    [GLMfitsh,FileExist]=obj.LoadGLMfitfile(Neu,FullMdlName,'GLMfitShConcat');
                    CPDsh=obj.CatFactorizedFata([GLMfitsh.CPD],1,0);
                    % perform statistical test now
                    StatTestMethod='clust';
                    switch StatTestMethod
                        case 'pval' % calculate p-value and then we will use bonferroni correction for this
                            CPDpval=arrayfun(@(lam) cellfun(@(x) obj.ManData.CalpValShuffle(CPDsh(lam).(x),CPD.(x)(lam,:)),FullModelFactors,'UniformOutput',0),1:length(CPDsh),'UniformOutput',0); % calculate pval
                            CPDpval=cellfun(@(x) obj.ManData.CopyCell2Struct(x,FullModelFactors),CPDpval,'UniformOutput',0);
                            CPDcluster=[];
                        case 'clust' % use clusterMass statistical test for this
                            SmoothData4StatTest=1;
                            % perform clusted-corrected t-test
                            [clusters, p_values,t_sums, permutation_distribution,statsummery]=...
                                arrayfun(@(lam) cellfun(@(x) obj.PerformClusterCorrected_tTest(permute(CPD.(x)(lam,:),[1 3 2]),... % replicate CPD for 100 times
                                permute(CPDsh(lam).(x),[1 3 2]), opts.dependent_samples,opts.p_threshold,opts.num_permutations,...
                                opts.two_sided,opts.num_clusters,SmoothData4StatTest),FullModelFactors,'UniformOutput',0),...
                                1:length(CPDsh),'UniformOutput',0);
                            CPDpval=cellfun(@(x) obj.ManData.CopyCell2Struct(x,FullModelFactors),statsummery,'UniformOutput',0);
                            CPDcluster=cellfun(@(x) obj.ManData.CopyCell2Struct(x,FullModelFactors),clusters,'UniformOutput',0);
                    end

                    %% save these calculations to the the summery file
                    SummeryGLMfit.(FullMdlName)=GLMfit.(FullMdlName);
                    SummeryGLMfit.NullMdl      =GLMfit.NullMdl;
                    SummeryGLMfit.X            =GLMfit.X;
                    SummeryGLMfit.Y            =GLMfit.Y;
                    SummeryGLMfit.RunTimeTot   =GLMfit.RunTimeTot;
                    SummeryGLMfit.CPDpval      =CPDpval;
                    SummeryGLMfit.CPD          =CPD;
                    SummeryGLMfit.CPDshMean    =arrayfun(@(y) structfun(@(x) mean(x,1),CPDsh(y),'UniformOutput',0),1:length(CPDsh));
                    SummeryGLMfit.CPDsh        =CPDsh;
                    SummeryGLMfit.CPDcluster   =CPDcluster;


                    [ExtraStr,ExtraStrVar]=obj.GetExtraStr4Cond('SummeryFile');
                    try
                        obj.ManData.SaveVar('GLM',SummeryGLMfit,['GLMfit' ExtraStrVar '_' FullMdlName],ExtraStr,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                    catch me
                        disp(me.message)
                        obj.ManData.DeleteFile('GLM',ExtraStr,1,'WantedCh',AnalysisOpts.CurrentCh_ChNum);   % first delete existing file
                        obj.ManData.SaveVar('GLM',SummeryGLMfit,['GLMfit' ExtraStrVar '_' FullMdlName],ExtraStr,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                    end
                end
            end
            %% save values for the population
            if length(AnalysisOpts.nCh_2look)>1 & ~AnalysisOpts.GLM_SkipPopulationCharctristics
                [GLMfit,CPD,CPDzscore,CPDsh,CPDshMean,CPDpval,CPDcluster,GLMFileExist,CPDpure,CPDclusterPop,CPDpvalPop,...
                    IndNeuSigFactor,CPDpurepval,BestLambda,CPDFieldNames,SigFactorAllLambda]=obj.GetGLMfitdata4Neu([],[]);

                % if we are looking at each area then save  our metricesfor each area
                [ExtraTxt,VarExtraStr]=obj.GetExtraStr4Cond('GLMareaSummery');
                GLMmdlName=obj.GLMmdl;
                %  VarNames={'CPD','CPDzscore','CPDsh','CPDshMean','CPDpval','CPDcluster','GLMFileExist',...
                %      'CPDpure','CPDclusterPop','CPDpvalPop','IndNeuSigFactor','CPDpurepval','BestLambda','CPDFieldNames'};
                VarNames={'CPD','CPDzscore','CPDshMean','CPDpval','CPDcluster','GLMFileExist',...
                    'CPDclusterPop','CPDpvalPop','IndNeuSigFactor','CPDpurepval','BestLambda','CPDFieldNames','SigFactorAllLambda'};

                for Var=VarNames
                    eval(['temp=' Var{1} ';']);
                    obj.ManData.SaveVar('GLM',temp,[Var{1} VarExtraStr '_' GLMmdlName ],ExtraTxt,'WantedCh','ALL');
                end
            end
        end
        function FactorStatTest=GetMdlComparisionResultsSummery(obj,Models2TestName,varargin) % gets summery of statistics for model comparison
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % infer significance of each factor in the main model
            GLMModelSet=obj.DefineGLMmodelSet;
            Models2TestSet=obj.DefineModels2Test; % get the set of GLM models to compare
            ThisModels2Test=Models2TestSet(arrayfun(@(x) strcmp(Models2TestSet(x).Name,Models2TestName),1:length(Models2TestSet)));
            FullModelFactors=GLMModelSet.(ThisModels2Test.FullMdlName); % to be changed
            nFullModelFactors=length(FullModelFactors);
            if length(obj.GLMLambda)>1;warning('Target GLM Lambda has >1 values, taking the first val...');end
            
            for Neu=AnalysisOpts.nCh_2look
                obj.TrialFunc.UpdateCurrentCh(Neu);
                [ThisMdlComp,FileExist(Neu)]=obj.ManData.LoadVar('GLM',['ModelComp_' Models2TestName],['MdlComp' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_Results'],0);
                if ~isempty(ThisMdlComp) & isfield(ThisMdlComp,'MSEDiffs')
                    if sum(contains(ThisMdlComp.ThisModels2Test.Name,Models2TestName))
                        MdlCompResults(Neu)=ThisMdlComp;
                        nModels2test=length(MdlCompResults(Neu).ThisModels2Test.Models);
                        % get the results for the GLM lambda we care about
                        LambdaInd=find(MdlCompResults(Neu).GLMLamdaVals==obj.GLMLambda(1));
                        FactorStatTest.p(Neu,:)=MdlCompResults(Neu).StatTest.R2{LambdaInd};
                        FactorStatTest.a(Neu,:)=MdlCompResults(Neu).StatTest.R2{LambdaInd}<=MdlCompResults(Neu).ThisModels2Test.Alpha;
                        % get mean R2 for this lambda as well
                        FactorStatTest.R2(Neu,:)=mean(MdlCompResults(Neu).R2Diffs{LambdaInd},1);
                    end
                else
                    FactorStatTest.p(Neu,1:nModels2test)=nan;
                    FactorStatTest.a(Neu,1:nModels2test)=false;
                    FactorStatTest.R2(Neu,1:nModels2test)=nan;
                    FileExist(Neu)=0;
                end
            end
            FactorStatTest.FullModelFactors=FullModelFactors;
            FactorStatTest.FullMdlName=ThisModels2Test.FullMdlName;
            FactorStatTest.nFullModelFactors=nFullModelFactors;
            FactorStatTest.ThisModels2Test=ThisModels2Test;
            %  FactorStatTest.SignSummery=obj.ManData.ReshapeStruct2Mat(FactorStatTest,'a',1); % tile the data for future use
            % update so that only channels that have existing file will be
            % included in the future analysis
            obj.TrialFunc.UpdateCh_2look(FileExist);
            FactorStatTest.a=FactorStatTest.a(FileExist,:);
            FactorStatTest.p=FactorStatTest.p(FileExist,:);
            FactorStatTest.R2=FactorStatTest.R2(FileExist,:);
        end
        function [X_train,Y_train,X_test,Y_test,TrainSetInd,TestSetInd]=SplitTrainTest(obj,X,Y,FactorNames,KeepRuleRatio,varargin) % splits data into train and test
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            nTrls=size(Y,1);
            
            switch KeepRuleRatio
                case 0 % we are splitting trials in a random manner and don't care about the rule ratio
                    nTrain=floor(nTrls*obj.GLMTrainTestRatio);
                    TrainSetInd=randsample(nTrls,nTrain);
                    TestSetInd=setdiff(1:nTrls,TrainSetInd);
                case 1 % we are splitting so that each rule has the same proportion of trials so we don't bias the model
                    RuleInd=strcmp(FactorNames,'Rule');
                    RuleTrls=arrayfun(@(x) find(X(:,RuleInd)==x)',1:3,'UniformOutput',false);
                    nRuleTrls=cellfun(@length,RuleTrls);
                    nTrainRule=floor(nRuleTrls.*obj.GLMTrainTestRatio);
                    TrainSetInd=cell2mat(arrayfun(@(x) randsample(RuleTrls{x},nTrainRule(x)),1:3,'UniformOutput',0));
                    TestSetInd=setdiff(1:nTrls,TrainSetInd);
            end
            % get the train and test data
            X_train=X(TrainSetInd,:);
            Y_train=Y(TrainSetInd,:);
            X_test=X(TestSetInd,:);
            Y_test=Y(TestSetInd,:);
        end
        function [AngleFit,resid,R2,AngleFit2,GLM_weights]=EstimateTuningAngle(obj,X,Y,varargin)% estimates tuning angle of the cell
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            options = optimoptions('lsqcurvefit','display','off');
            xdata=(obj.ManData.CategorizeData(X(:,1))-1)*2*pi/8;
            Y=Y/max(Y(:));% nomralize Y
            %% build the model now
            %   fun=@(x,xdata) x(1).*xdata(:,1)+x(2).*xdata(:,2)+x(3).*xdata(:,3)+x(4).*xdata(:,4)+x(5).*xdata(:,5)+x(6).*xdata(:,6)+x(7).*xdata(:,7)+x(8);
            fun=@(x,xdata) x(1).*cos(xdata(:,1)-x(2))+x(3);
            fun2=@(x,xdata) x(1).*cos(xdata(:,1))+x(2).*sin(xdata(:,1))+x(3);
            xdataglm=[cos(xdata) sin(xdata)];
            Nvars=3;Nshuffle=100;
            %% fit this for 100 times and find the one with significant R2
            for i=1:Nshuffle
                x0=[rand 2*pi*rand randn];
                AngleFit(i,:) = lsqcurvefit(fun,x0,xdata,Y,[],[],options);
                Yhat=fun(AngleFit(i,:),xdata);
                R2(i)=obj.ManData.CalR2(Y,Yhat);
                %% fit angle in a different way
                x02=[rand rand randn];
                AngleFit2(i,:) = lsqcurvefit(fun2,x02,xdata,Y,[],[],options);
                Yhat2=fun(AngleFit2(i,:),xdata);
                R2_2(i)=obj.ManData.CalR2(Y,Yhat2);
            end
            %% now what is the best fit among all of this that gives the best R2
            [R2,indbest1]=max(R2);
            [R2_2,indbest2]=max(R2_2);
            AngleFit=AngleFit(indbest1(1),:);
            AngleFit2=AngleFit2(indbest2(1),:);
            resid=Y-fun(AngleFit,xdata);
            
            %% fit with glm as well
            GLM_mdl=fitglm(xdataglm,Y);
            GLM_weights = GLM_mdl.Coefficients.Estimate';
            GLM_Yhat=predict(GLM_mdl,xdataglm);
            GLM_R2=obj.ManData.CalR2(Y,GLM_Yhat);
        end
        function [GLMfit,CPD,CPDzscore,CPDsh,CPDshMean,CPDpval,CPDcluster,GLMFileExist,CPDpure,CPDclusterPop,CPDpvalPop,...
                IndNeuSigFactor,CPDpurepval,BestLambda,CPDFieldNames,IndNeuSigFactorAllLambda]=GetGLMfitdata4Neu(obj,GLMfit,GLMFileExist,varargin) % retrieves CPD values and GLM model fit for neurons
            % output synopsis
            % GLMfit GLM fit per neuron
            % CPD neuron concatinated CPD with obj.GLMmainLambdaInd lambda
            % CPDzscore neuron concatinated zscored CPD with obj.GLMmainLambdaInd lambda
            % CPDsh all of the shuffled CPD data for obj.GLMmainLambdaInd lambda
            % CPDpval for obj.GLMmainLambdaInd lambda
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % get the values of CPD shuffle so we use them to do zscore for each cell
            % get the values of Lambda we care about
            % reorganize structures(each structure is a lambda) and concatinated
            % based on the neuorns instead of lambda
            if isempty(GLMfit) | isempty(GLMFileExist)
                [GLMfit,GLMFileExist]=obj.LoadGLMfitfile(AnalysisOpts.nCh_2look,obj.GLMmdl,'SummeryFile'); % load summery file
            end
            % update so that only channels that exist are included
            obj.TrialFunc.UpdateCh_2look(GLMFileExist );

            [~,AnalysisOpts.Time]=obj.ManData.GenerateTimeAxis(obj.PSTHTimRef); % generate time axis for these neurons
          
            %% Get model comparision results to find the best Lambda
            nLambdaGLM=length(GLMfit(1).(obj.GLMmdl).Lambda);
            if AnalysisOpts.GLM_UseR2forBestLambda % USE MSE to find the best lambda
                ModelCompName=AnalysisOpts.SingCellAna.GLMMdlComp2Test{1};
                [GLMModelComp,GLMModelCompFileExist]=obj.LoadGLMfitfile(AnalysisOpts.nCh_2look,ModelCompName,'ModelComp'); % load model comparision summery file
              % [obj.GLMmainLambdaInd,IndLambdaR2,IndLambdaR2TimePoint]=arrayfun(@(x) obj.FindBestGLMlambda(GLMModelComp(x),obj.GLMmdl),1:length(GLMModelComp));
                [~,obj.GLMmainLambdaInd,IndLambdaR2TimePoint]=arrayfun(@(x) obj.FindBestGLMlambda(GLMModelComp(x),obj.GLMmdl),1:length(GLMModelComp));
              
              IndNeuSigFactorAllLambda=[]; 
            else
                % get the best lambda through counting the max number of significant factors for a neuron
                [SigColAllLambda,IndNeuSigFactorAllLambda,obj.GLMmainLambdaInd]=obj.CountSigGLMFactor4Neurons(GLMfit);
            end
            BestLambda=obj.GLMmainLambdaInd;
             %% reorganize the data
            % get full repertiotions of shuffle CPD data
            CPDsh=arrayfun(@(x) [GLMfit(x).CPDsh(obj.GLMmainLambdaInd(x))],1:length(GLMfit)); % organize shuffle data with specific lambda
            % get mean shuffle CPD data
            CPDshMean=arrayfun(@(x) [GLMfit(x).CPDshMean(obj.GLMmainLambdaInd(x))],1:length(GLMfit)); % organize shuffle data with specific lambda
            CPDshMean=obj.CatFactorizedFata(CPDshMean,1,0); % get CPD shuffle mean values
            % get observed CPD data
            CPDFieldNames=fieldnames(GLMfit(1).CPD);NTargFactors=length(CPDFieldNames);
            for Neu=1:length(GLMfit)
                for f=CPDFieldNames'
                    CPD.(f{1})(Neu,:)=GLMfit(Neu).CPD.(f{1})(obj.GLMmainLambdaInd(Neu),:);
                end
            end
           
            %% calculate zscore for each factor per neuron
            for Neu=AnalysisOpts.nCh_2look % r
                for field=CPDFieldNames'
                    field=field{1};
                    temp=zscore([CPD.(field)(Neu,:) ;CPDsh(Neu).(field)]);
                    CPDzscore.(field)(Neu,:)=temp(1,:);
                end
            end
            %% get pvalues for CPD
            CPDpval=arrayfun(@(x) [GLMfit(x).CPDpval{obj.GLMmainLambdaInd(x)}],1:length(GLMfit));
            if ~isempty(GLMfit(1).CPDcluster)
                CPDcluster=arrayfun(@(x) [GLMfit(x).CPDcluster{obj.GLMmainLambdaInd(x)}],1:length(GLMfit));
            else
                CPDcluster=[];
            end
            %% calculate p value for each of the factors for the population
            for field=CPDFieldNames'
                field=field{1};
                CPDshField=obj.ManData.ReshapeStruct2Mat(CPDsh,field,62);
             %  zCPDField=CPDzscore.(field);
                CPDField=CPD.(field);
                % smooth the data before feeding it 
                [CPDField,CPDshField]=obj.SmoothData4ClusterStatTest(CPDField,CPDshField,2);
                [CPDclusterPop.(field),~,~,~, CPDpvalPop.(field)]=obj.ManData.CalPvalPopulation(CPDshField,CPDField,AnalysisOpts.GLM_p_threshold_pop);            
            end
            
            %% calculate p-val for each neuron 
            % count the number of significant points for each factor for each neuron
            for Neu=AnalysisOpts.nCh_2look
                for cf=1:NTargFactors
                    if strcmp(CPDFieldNames{cf},'Rule') % if it is rule take all of the trial
                        StrTim=-2;EndTim=2;
                    elseif contains(CPDFieldNames{cf},'Color') | contains(CPDFieldNames{cf},'Shape') 
                        StrTim=-0.3;EndTim=AnalysisOpts.GLM_Time4SigStimInfo; % if not take after stimulus onset
                    else
                        StrTim=0;EndTim=2; % if not take after stimulus onset
                    end
                    SigCol(cf,Neu)=obj.ManData.GetPvalClusterTime(AnalysisOpts.Time,CPDcluster(Neu).(CPDFieldNames{cf}),CPDpval(Neu).(CPDFieldNames{cf}),AnalysisOpts.GLM_p_threshold,StrTim,EndTim);                
                end
            end

            % count the number of significant points if they are more than AnalysisOpts.GLM_npoints4indNeuSig
            SigCol(SigCol<AnalysisOpts.GLM_npoints4indNeuSig)=0;
            SigCol(SigCol>=AnalysisOpts.GLM_npoints4indNeuSig)=1;
            IndNeuSigFactor=SigCol>0;
          
            %% cal significance for average beta for the significant neurons only
            % first subtract the mean shuffle for each neuron
            for cf=1:NTargFactors
                CPDpure.(CPDFieldNames{cf})=CPD.(CPDFieldNames{cf})-CPDshMean.(CPDFieldNames{cf});
                [CPDpure.(CPDFieldNames{cf})]=obj.SmoothData4ClusterStatTest(CPDpure.(CPDFieldNames{cf}),CPDpure.(CPDFieldNames{cf}),2);
                % perform t-test for the pure CPD 
                [~,  CPDpurepval.(CPDFieldNames{cf})] = ttest(CPDpure.(CPDFieldNames{cf}), 0, 'Alpha', AnalysisOpts.GLM_p_threshold);
            end
            
        end
        function [SigColAllLambda,IndNeuSigFactorAllLambda,IndBestLambdaAll]=CountSigGLMFactor4Neurons(obj,GLMfit) % counts the significant number of GLM factors for neurons 
            global AnalysisOpts
            
            CPDFieldNames=fieldnames(GLMfit(1).CPD);
            NTargFactors=length(CPDFieldNames);
            nLambdaGLM=length(GLMfit(1).(obj.GLMmdl).Lambda);


            CPDpvalAllLabmda=arrayfun(@(lam) arrayfun(@(x) [GLMfit(x).CPDpval{lam}],1:length(GLMfit),'UniformOutput',1),1:nLambdaGLM,'UniformOutput',0);
            CPDclusterAllLambda=arrayfun(@(lam) arrayfun(@(x) [GLMfit(x).CPDcluster{lam}],1:length(GLMfit)),1:nLambdaGLM,'UniformOutput',0);
            
            for Neu=AnalysisOpts.nCh_2look
                for cf=1:NTargFactors
                    if strcmp(CPDFieldNames{cf},'Rule') % if it is rule take all of the trial
                        StrTim=-2;EndTim=2;
                    elseif contains(CPDFieldNames{cf},'Color') | contains(CPDFieldNames{cf},'Shape')
                        StrTim=0;EndTim=AnalysisOpts.GLM_Time4SigStimInfo; % if not take after stimulus onset
                    else
                        StrTim=0;EndTim=2; % if not take after stimulus onset
                    end

                    for lam=1:nLambdaGLM
                        SigColAllLambda(cf,Neu,lam)=obj.ManData.GetPvalClusterTime(AnalysisOpts.Time,CPDclusterAllLambda{lam}(Neu).(CPDFieldNames{cf}),CPDpvalAllLabmda{lam}(Neu).(CPDFieldNames{cf}),AnalysisOpts.GLM_p_threshold,StrTim,EndTim);
                    end
                end
            end
             
            % count the number of significant points for all lambdas if they are more than AnalysisOpts.GLM_npoints4indNeuSig            
            SigColAllLambda(SigColAllLambda<AnalysisOpts.GLM_npoints4indNeuSig)=0;
            SigColAllLambda(SigColAllLambda>=AnalysisOpts.GLM_npoints4indNeuSig)=1;
            IndNeuSigFactorAllLambda=SigColAllLambda>0;
            
            % find best lambda for each neuron
            SumIndNeuSigFactorAllLambda=squeeze(sum(IndNeuSigFactorAllLambda,1));
            [BestLambdaAll]=max(SumIndNeuSigFactorAllLambda,[],2);
            % find the lambda that is bigger and has the most significant factors
            IndBestLambdaAll=arrayfun(@(x) find(SumIndNeuSigFactorAllLambda(x,:)==BestLambdaAll(x),1,'last'),AnalysisOpts.nCh_2look);
        end
        function [IndLambdaMSE,IndLambdaR2,IndLambdaR2TimePoint]=FindBestGLMlambda(obj,GLMModelComp,GLMmodelName,varargin) % find the best GLM lambda for this model based on the model comparision results 
            global AnalysisOpts
            obj=obj.ParseParams(varargin); %%Process optional inputs
           
            % find the index of this model in the model comparision 
            GLMModelInd=strcmp(GLMModelComp.ThisModels2Test.Models,GLMmodelName);
            MSEDiffs=cell2mat(cellfun(@(x) mean(x,1)',GLMModelComp.MSEDiffs,'UniformOutput',0));
            [~,IndLambdaMSE]=max(MSEDiffs(GLMModelInd,:));
            R2Diffs=cell2mat(cellfun(@(x) mean(x,1)',GLMModelComp.R2Diffs,'UniformOutput',0));
            [~,IndLambdaR2]=max(R2Diffs(GLMModelInd,:));
            R2DiffTimePoint=cell2mat(cellfun(@(x) mean(x,1)',GLMModelComp.R2DiffTimePoint,'UniformOutput',0));
            [~,IndLambdaR2TimePoint]=max(R2DiffTimePoint(GLMModelInd,:));
            IndLambdaMSE=IndLambdaMSE(1);R2Diffs=R2Diffs(1);R2DiffTimePoint=R2DiffTimePoint(1);
        end
        function GLMfitModlCompResultsArea(obj,varargin) % loads and preprocesses model comparision results for each area
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ModelCompName=AnalysisOpts.SingCellAna.GLMMdlComp2Test{1};
            %% now get model comparison data if we have them
            [GLMModelComp,GLMModelCompFileExist]=obj.LoadGLMfitfile(AnalysisOpts.nCh_2look,...
                ModelCompName,'ModelComp'); % load summery file
            % get statistical test values of models
            for Metric={'MSE','R2'}
                Metric=Metric{1};
                ModelCompStatSummery.(Metric)=cell2mat(arrayfun(@(neu) GLMModelComp(neu).StatTest.(Metric){GLMModelComp(neu).LambdaIndMaxR2}',...
                    1:length(GLMModelComp),'UniformOutput',0));
                ModelCompStatSummery.(Metric)(isnan(ModelCompStatSummery.(Metric)) | (ModelCompStatSummery.(Metric))>0.05/4)=-1;
                ModelCompStatSummery.(Metric)(ModelCompStatSummery.(Metric)<=0.05/4 & ModelCompStatSummery.(Metric)>=0)=1;
            end
            ModelCompStatSummery.TotNNeu=length(GLMModelComp);
            ModelCompStatSummery.StimRespNeurons=sum(ModelCompStatSummery.R2(2,:)==1);
            ModelCompStatSummery.CatStimResp=sum(ModelCompStatSummery.R2(3,:)==1);
            ModelCompStatSummery.ObjStimResp=sum(ModelCompStatSummery.R2(4,:)==1);
            %  hist([GLMModelComp.GLMCategoryTuningIndex])
            % save this data now
            ExtraTxt=obj.GetExtraStr4Cond('GLMareaSummery');
            obj.ManData.SaveVar('GLM',GLMModelComp,['GLMModelComp_' ModelCompName ],ExtraTxt,'WantedCh','ALL');
            obj.ManData.SaveVar('GLM',ModelCompStatSummery,['ModelCompStatSummery_' ModelCompName ],ExtraTxt,'WantedCh','ALL');
        end
        function PlotGLMmodelCompAreaSummery(obj,varargin) % plots area summery for
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ModelCompName=AnalysisOpts.SingCellAna.GLMMdlComp2Test{1};
            % plot histogram for each area
            
            for Ar=[1 3]
                AnalysisOpts.CurrentCh_AreaName=AnalysisOpts.AreaNames{Ar};
                ExtraTxt=obj.GetExtraStr4Cond('GLMareaSummery');
                GLMModelComp=obj.ManData.LoadVar('GLM',['GLMModelComp_' ModelCompName ],ExtraTxt,0,'WantedCh','ALL');
                ModelCompStatSummery=obj.ManData.LoadVar('GLM',['ModelCompStatSummery_' ModelCompName ],ExtraTxt,0,'WantedCh','ALL');
                X{Ar}=[GLMModelComp.GLMCategoryTuningIndex];
                hp=obj.FigParams.HistogramPlot(X{Ar},[],Ar,'Color Tuning Index','Proportion',...
                    ['Dist Color Tuning Index ' AnalysisOpts.CurrentCh_AreaName],'ThisSubplot',[2 2 Ar]);
                subplot(2, 2, Ar+1)
                bar([ModelCompStatSummery.TotNNeu ModelCompStatSummery.StimRespNeurons ModelCompStatSummery.CatStimResp ModelCompStatSummery.ObjStimResp]/ModelCompStatSummery.TotNNeu,'stacked')
                title(['Prop significat factor for ' AnalysisOpts.CurrentCh_AreaName])
                xticklabels({'Tot','StimResp','CatResp','ObjResp'});xtickangle(45)
            end
            [a,p]=ttest2(X{1},X{3},'tail','right')
        end
        function [varargout]=ClusterNeuronswithSelectivity(obj,CPD,CPDpval,CPDcluster,GLMFileExist,SigCol,varargin) % clusters neurons based on their selectivty to different features
            % inputs are the same as outputs of obj.GetGLMfitdata4Neu
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % Models2Test={'HybridbhvMdlFull','InferAFbhvMdlFull'};
            
            % find if any of these neurons is responding to any of the factors
            %Sig=structfun(@(x) sum(obj.ManData.ComparePval(x,0.001,[]),2),CPDpval,'UniformOutput',0); % this is for cluster correction
%            Sig=structfun(@(x) sum(obj.ManData.ComparePval(x,0.001,length(AnalysisOpts.Time)),2),CPDpval,'UniformOutput',0); % this is for bonferroni correction
%            SigCol=cell2mat(struct2cell(Sig)');

            CPDfactors=fieldnames(CPD)';   
            NTargFactors=length(CPDfactors);
           
            
            [h1]=obj.FigParams.RenderFigure(1,[]);
            TargetFactorInds=ones(1,NTargFactors);Col=distinguishable_colors(NTargFactors);
            [~,Sp1]=obj.FigParams.RenderSubplots([],[],h1{1},NTargFactors);
            
            arrayfun(@(x) obj.PlotFactorizedData(CPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),CPDfactors{x},...
                [ CPDfactors{x}  ],AnalysisOpts.Xlabel,'CPD',h1,Sp1(x),'Neu2Use',...
                SigCol(x,:),'NormalizebyMax',0),1:length(TargetFactorInds),'UniformOutput',1);
            
            [h2]=obj.FigParams.RenderFigure(1,[]);
            subplot(221)
            SumArea=[];
            Area=AnalysisOpts.Ch_2look_AreaNum;
            for i=1:5; SumArea(i,:)=sum(SigCol(:,Area==i),2)/sum(Area==i);end
            bar(SumArea','stacked')
            legend(AnalysisOpts.AreaNames)
            xticklabels(fieldnames(CPD))
            xtickangle(45)
            obj.ManData.PhenoClusterPlot(SigCol,AnalysisOpts.Ch_2look_AreaNum);
            varargout=[h1 h2];
        end
        function varargout=PlotGLMfitbyFactor(obj,FactorizedData,TargetFactor,varargin)% plots PSTH based on the factor we care about
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            hPop=cell(1,2);
            % retrive GLM data and also process CPD values
            [GLMfit,CPD,CPDzscore,CPDsh,CPDshMean,CPDpval,CPDcluster,GLMFileExist,CPDpure,CPDclusterPop,CPDpvalPop,...
                IndNeuSigFactor,CPDpurepval,BestLambda,CPDFieldNames]=obj.GetGLMfitdata4Neu([],[]);
            %% plot PEV and group neurons based on their selectivity
            if length(AnalysisOpts.nCh_2look)>1 % then compare neurons as well
                [hPop{:}]=obj.ClusterNeuronswithSelectivity(CPDzscore,CPDpval,CPDcluster,GLMFileExist,IndNeuSigFactor);
            end
            
            if ~isempty(obj.GLMstatTestData)
                obj.GLMstatTestData.a=obj.GLMstatTestData.a(GLMFileExist,:);
                obj.GLMstatTestData.p=obj.GLMstatTestData.p(GLMFileExist,:);
            end
            
            if ~obj.PlotResults;varargout=cell(1,2);return;end
            %% prepare variables
            GLMfittemp=GLMfit; % save a copy of GLM data
            FullMdlName=obj.GLMmdl;
            GLMfit=rmfield(GLMfit,{'X','Y','RunTimeTot'});
            [GLMModelSet,GLMfactorsnames]=obj.DefineGLMmodelSet(FullMdlName);
            GLMfactorsnamesDetailed=GLMfit(1).(FullMdlName).GLMfactorsnames;
            NNeu=length(GLMfit);
            if sum(obj.TargetArea)==0 | isnan(obj.TargetArea) | isempty(obj.TargetArea);obj.TargetArea=nan;end
            if isempty(TargetFactor);TargetFactor=GLMfit(1).GLMfactorsnames;end
            nLambda=1;LambdaLvls=1;
            Lambda=BestLambda; % index of the best lambda
            nTargArea=length(obj.TargetArea);
            AreaCol=obj.FigParams.getColorPalet(nTargArea);
            % Remove Time from the factors
            TargetFactor=TargetFactor(~strcmp(TargetFactor,'Time'));
            
            % if there is model comparision data, plot the summery
            % statistics as well per area
            if ~isempty(obj.GLMstatTestData);ShowMdlCompStats=1;else; ShowMdlCompStats=0;end
            
            %% Plot the data
            h1=cell(1,nTargArea); % plot individual beta weights
            h2=cell(1,nTargArea); % plot all beta weights in one plot with different Lambda values
            h3=h2;h4=h2; %inistialize
            [h1(1:nTargArea)]=obj.FigParams.RenderFigure(nTargArea,[]);
            [h2(1:nTargArea)]=obj.FigParams.RenderFigure(nTargArea,[]);
            [h3(1:nTargArea)]=obj.FigParams.RenderFigure(nTargArea,[]);
            if ShowMdlCompStats
                [h4]=obj.FigParams.RenderFigure(1,[]);
                [h4,Sp4]=obj.FigParams.RenderSubplots([],[],h4{1},nTargArea);
            else
                h4=cell(1);
            end
            
            nAr=1;nSph2=6; 
            for AreaNum=obj.TargetArea
                [h2{nAr},Sp2]=obj.FigParams.RenderSubplots([],[],h2{nAr},nSph2*length(LambdaLvls));
                [h3{nAr},Sp3]=obj.FigParams.RenderSubplots([],[],h3{nAr},3);

                %clear GLMfitFullMdl

                GLMfit=GLMfittemp; % reload the original GLMfit and write on it

                for Neu=1:NNeu % get Beta values per neuron
                    GLMfit(Neu).(FullMdlName).GLM_weights=squeeze(GLMfit(Neu).(FullMdlName).GLM_weights_full(:,Lambda(Neu),:));
                end

                % are we limiting the area?
                [ChNumArea,AreaNames]=obj.TrialFunc.GrabNeuronswithArea(AreaNum);
                if isempty(ChNumArea);continue;end % if we don't have any cell skip this area
                if ~isnan(AreaNum);GLMfit=GLMfit(ChNumArea);end

                % we calculate the selectivity only based on the full model data.
                % claculate color angle and information for each neuron
                for ThisTargetFactor=TargetFactor
                    GLMfit=obj.CalSelectivityGLMweights(GLMfit,FullMdlName,GLMfactorsnamesDetailed,ThisTargetFactor{1});
                end

                % concatinate all of the information across neurons now
                [GLMfitCat]=obj.CatFactorizedFata([GLMfit.(FullMdlName)],1,0);

                % determine the factors we want to plot
                if strcmp(obj.GLMmdl,'RuleMdlFull')
                    TargetFactor_weights={'Rule1','Rule2','Rule3','RespLoc1','RespLoc2','RespLoc3','RespLoc4'};
                elseif strcmp(obj.GLMmdl,'HybridbhvMdlFull')
                    TargetFactor_weights={};%{'Time','Reward','Hybrid_Q1','Hybrid_Q2','Hybrid_Q3','Hybrid_Q4','Hybrid_Baxes'};
                elseif strcmp(obj.GLMmdl,'InferAFbhvMdlFull')
                    TargetFactor_weights={};%{'Time','Reward','InferAF_Q1','InferAF_Q2','InferAF_Q3','InferAF_Q4','InferAF_Baxes','InferAF_Bfeature'};
                elseif strcmp(obj.GLMmdl,'SensoryMotorMdl')
                    TargetFactor_weights={};
                elseif strcmp(obj.GLMmdl,'InferRulebhvMdlFull')
                    TargetFactor_weights={};
                elseif strcmp(obj.GLMmdl,'FullMdl')
                    TargetFactor_weights={'Rule1','Rule2','Rule3','RespLoc1','RespLoc2','RespLoc3','RespLoc4','Reward','Time'};
                elseif strcmp(obj.GLMmdl,'SensoryMotorInteractMdl')
                    TargetFactor_weights={};
                else
                    TargetFactor_weights={};
                end

                GLMFactors=TargetFactor;
                TargetFactorInds_weights=cell2mat(cellfun(@(x) find(strcmp(GLMfitCat(1).GLMfactorsnames(1,:),x)),TargetFactor_weights,'UniformOutput',false));
                DataFieldNames=[arrayfun(@(x) 'GLM_weights',TargetFactorInds_weights,'UniformOutput',0),GLMFactors];
                TargetFactorInds=[TargetFactorInds_weights, ones(1,length(GLMFactors))];
                FactorNames=[arrayfun(@(x) GLMfitCat(1).GLMfactorsnames{1,x},TargetFactorInds_weights,'UniformOutput',0) GLMFactors];
                NTargFactors=length(TargetFactorInds);
                Col=obj.FigParams.getColorPalet(NTargFactors);

                %concatinate all of the desired factors in a single matrix
                %  GLMWeights=cell2mat(arrayfun(@(x) GLMfitCat(TargetFactorInds(x)).(DataFieldNames{x})',1:length(TargetFactorInds),'UniformOutput',false));
                % plot individual GLM weights only for the first lambda
                [h1{nAr},Sp1]=obj.FigParams.RenderSubplots([],[],h1{nAr},NTargFactors);
                arrayfun(@(x) obj.PlotFactorizedData(CPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [ DataFieldNames{x} ' L ' num2str(nLambda)],AnalysisOpts.Xlabel,'CPD',h1(nAr),Sp1(x),'Neu2Use',...
                    '','NormalizebyMax',0),1:length(TargetFactorInds),'UniformOutput',1);
                % if we only have one neuron
                if length(AnalysisOpts.nCh_2look)==1 % add significance star
                    arrayfun(@(x) obj.FigParams.plot_significance_level(CPDcluster.(FactorNames{x}),...
                        CPDpval.(FactorNames{x}),AnalysisOpts.Time,'auto','r',[],[],'Sp',Sp1(x),...,
                        'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod),1:length(TargetFactorInds));
                else % plot significance for the population 
                    arrayfun(@(x) obj.FigParams.plot_significance_level(CPDclusterPop.(FactorNames{x}),...
                        CPDpvalPop.(FactorNames{x}),AnalysisOpts.Time,'auto','r',[],[],'Sp',Sp1(x),...,
                        'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod),1:length(TargetFactorInds));
                end
                % plot mean CPD shuffle as well
                arrayfun(@(x) obj.PlotFactorizedData(CPDshMean,AnalysisOpts.Time,TargetFactorInds(x),[0.5 0.5 0.5],DataFieldNames{x},...
                    [ DataFieldNames{x} ' L ' num2str(nLambda)],AnalysisOpts.Xlabel,'CPD',h1(nAr),Sp1(x),'Neu2Use',...
                    '','NormalizebyMax',0,'ThisLineStyle','--'),1:length(TargetFactorInds),'UniformOutput',1);


                %% Plot GLM weights together but seperate out the
                %% sensory terms (no interaction term)
                SensoryMotorFactors={{'ColorML'}    {'ShapeML'}    {'ColorCat'}    {'ShapeCat'}   };
                SensoryMotorFactorsInds=cell2mat(cellfun(@(x) find(contains(DataFieldNames,x) & ~contains(DataFieldNames,'x')), SensoryMotorFactors,'UniformOutput',0));

                arrayfun(@(x) obj.PlotFactorizedData(GLMfitCat,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['B for ' obj.GLMmdl]} ;{[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'Beta',h2(nAr),Sp2(1+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',0,'ThisLegendTxt',DataFieldNames{x}),SensoryMotorFactorsInds,'UniformOutput',1);

                %% add interaction terms here
                InteractionFactors={{'ColorML'}  {'ShapeML'}  };
                InteractionFactorsInds=cell2mat(cellfun(@(x) find(contains(DataFieldNames,x) & contains(DataFieldNames,'x')), InteractionFactors,'UniformOutput',0));

                arrayfun(@(x) obj.PlotFactorizedData(GLMfitCat,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['B for ' obj.GLMmdl]} ;{[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'Beta',h2(nAr),Sp2(2+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',0,'ThisLegendTxt',DataFieldNames{x}),InteractionFactorsInds,'UniformOutput',1);

                %% add rest of the factors now
                BhvModelFactorsInds=setdiff(1:length(TargetFactorInds),[SensoryMotorFactorsInds InteractionFactorsInds]);
                arrayfun(@(x) obj.PlotFactorizedData(GLMfitCat,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['B for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'Beta',h2(nAr),Sp2(3+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',0,'ThisLegendTxt',DataFieldNames{x}),BhvModelFactorsInds,'UniformOutput',1);

                %% Plot CPD as well
                % sensory
                arrayfun(@(x) obj.PlotFactorizedData(CPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h2(nAr),Sp2(4+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',0),SensoryMotorFactorsInds,'UniformOutput',1);

                %CPD for Interaction terms
                arrayfun(@(x) obj.PlotFactorizedData(CPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h2(nAr),Sp2(5+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',0),InteractionFactorsInds,'UniformOutput',1);

                % non-sensory factors
                BhvModelFactorsInds=setdiff(1:length(TargetFactorInds),[SensoryMotorFactorsInds InteractionFactorsInds]);
                [~,Legs]= arrayfun(@(x) obj.PlotFactorizedData(CPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h2(nAr),Sp2(6+nSph2*(nLambda-1)),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',obj.NormalizebyMax),BhvModelFactorsInds,'UniformOutput',1);

                if isempty(BhvModelFactorsInds);subplot(Sp2(2+4*(nLambda-1)));axis off;subplot(Sp2(4+6*(nLambda-1)));axis off;end

                %% plot sensory and motor factors together to justfy timing
                if length(AnalysisOpts.nCh_2look)>1; ThisCPD=CPDzscore;else;ThisCPD=CPD;end
                SensoryMotorInds=setdiff(1:length(TargetFactorInds),[InteractionFactorsInds]);
                arrayfun(@(x) obj.PlotFactorizedData(ThisCPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h3(nAr),Sp3(1),'Neu2Use',...
                    '','MeanStdPlotType',1,'NormalizebyMax',0,'ThisLegendTxt',DataFieldNames{x}),SensoryMotorInds,'UniformOutput',1);

                arrayfun(@(x) obj.PlotFactorizedData(ThisCPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['Timing of CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h3(nAr),Sp3(2),'Neu2Use',...
                    '','MeanStdPlotType',3,'NormalizebyMax',1,'SubtractBaseLine',1),SensoryMotorInds,'UniformOutput',1);
                % plot
                arrayfun(@(x) obj.PlotFactorizedData(ThisCPD,AnalysisOpts.Time,TargetFactorInds(x),Col(x,:),DataFieldNames{x},...
                    [{['CPD for ' obj.GLMmdl]}; {[' L ' num2str(nLambda) ' ' AreaNames{1}]}],AnalysisOpts.Xlabel,'CPD',h3(nAr),Sp3(3),'Neu2Use',...
                    '','MeanStdPlotType',1,'NormalizebyMax',1,'SubtractBaseLine',0,'ThisLegendTxt',DataFieldNames{x}),[SensoryMotorInds],'UniformOutput',1);


                %% if we have model comparision results add them here the
                if ShowMdlCompStats
                    % if we need to show summery stats then plot it here
                    figure(h4)
                    subplot(Sp4(nAr))
                    obj.FigParams.PlotMeanStd(1:4,obj.GLMstatTestData.R2(ChNumArea,:),[],'Models','R2',AreaCol(nAr,:),2,['MdlComp Stats ' AreaNames{1}] ) ;
                    xticklabels(obj.GLMstatTestData.ThisModels2Test.Models)
                end
                nAr=nAr+1;
            end

            
            
            %             %% plot residuals
            %             FactorNames={'Rule1','Rule2','Rule3','Color','Shape','R^2'};
            %             Col=obj.FigParams.getColorPalet(NTargFactors+1);
            %             [h2,Sp]=obj.FigParams.RenderSubplots([],[],[],1);
            %             [~,Legs]=arrayfun(@(x) obj.PlotFactorizedData(GLMfit,Time,x,Col(x,:),'resid','Residuals',AnalysisOpts.Xlabel,'Y-Yhat',h2,Sp),1:5);
            %             legend(Legs,FactorNames)
            %
            %
            %             %% plot R2
            %             Col=obj.FigParams.getColorPalet(NTargFactors+1);
            %             [h2,Sp]=obj.FigParams.RenderSubplots([],[],[],1);
            %             [~,Legs]=arrayfun(@(x) obj.PlotFactorizedData(GLMfit,Time,x,Col(x,:),'resid',FactorNames{x},AnalysisOpts.Xlabel,'Model Performance',h2,Sp),6);
            %             legend(Legs,'R^2')
            if ShowMdlCompStats
                varargout=[h1 h2 h3 h4 hPop];
            else
                varargout=[h1 h2 h3 hPop];
            end
            
        end
        function varargout=PlotSignificantGLMfactors(obj,Models2TestName,ModelName,varargin) % plots significant factors only for
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if ~isempty(ModelName) % then we are testing a specific model without caring about significance
                [GLMmodelSet,FullModelFactors,nModelFactors]=obj.DefineGLMmodelSet(ModelName);
                FullMdlName=ModelName;
                %    obj.GLMstatTestData=obj.InferFactorSignificance(ModelName); % infers if factors are significant
            elseif ~isempty(Models2TestName)
                [Models2TestSet,ThisModels2Test,FullModelFactors,FullMdlName]=obj.DefineModels2Test(Models2TestName); % get the set of GLM models to compare
                %% load the model comparison resutls for each neuron
                obj.GLMstatTestData=obj.GetMdlComparisionResultsSummery(Models2TestName);
            end
            % go through each factor and plot it for us now for all of the
            % neurons
            varargout=cell(1,AnalysisOpts.np);
            [varargout{:}]=obj.PlotGLMfitbyFactor([],FullModelFactors,'UseSavedData',1,'GLMmdl',FullMdlName);
        end
        
        function CreateNeuronSummeryFile(obj,varargin) % creates a summery of the GLM analysis that are performed on the neuron so loading and plotting is faster
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ModelNames=AnalysisOpts.SingCellAna.GLMMdlName2Test;%{'HybridbhvMdlFull','InferAFbhvMdlFull'};
            % load GLM data and add significance value for each model and
            % save them in the summery file
            cellfun(@(x) obj.InferFactorSignificance(x,'GLMmdl',x),ModelNames,'UniformOutput',0);
        end
        function varargout=PlotCompareGLMfitArea(obj,AreaNum,GLMmdlName,varargin) % compares encoding of variables across areas
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs

            AnalysisOpts.ColorCatColors=obj.FigParams.getOthercolormap(AnalysisOpts.ColorCatColors_ColorName,5,1);%Purple AnalysisOpts.ColorMLColors([3 1 6],:);
            AnalysisOpts.ShapeCatColors=obj.FigParams.getOthercolormap(AnalysisOpts.ShapeCatColors_ColorName,5,1);%Green  AnalysisOpts.ShapeMLColors([3 1 6],:);
            AnalysisOpts.ResponseLocColors=obj.FigParams.getOthercolormap(AnalysisOpts.ResponseLocColors_ColorName,5,1);%AnalysisOpts.ColorPalett1([1 2 5 6],:);
            AnalysisOpts.RewardColors=AnalysisOpts.ColorPalett3([1 6],:);
            AnalysisOpts.RTColors=AnalysisOpts.ColorPalett3;

            if contains(GLMmdlName,'CatSing')
               DataFieldNames=[{'ColorMLSing'}    {'ShapeMLSing'}  {'ColorCat'}  {'ShapeCat'}  {'Rule'}    {'ResponseLoc'} {'Reward'}];
               DataFieldNamesNoRule=[{'ColorMLSing'}    {'ShapeMLSing'}   {'ColorCat'}  {'ShapeCat'}  {'ResponseLoc'} {'Reward'}];
               
            elseif contains(GLMmdlName,'Sing')
                DataFieldNames=[{'ColorMLSing'}    {'ShapeMLSing'}    {'Rule'}    {'ResponseLoc'} {'Reward'}];
                DataFieldNamesNoRule=[{'ColorMLSing'}    {'ShapeMLSing'}   {'ResponseLoc'} {'Reward'}];
            else
              %  DataFieldNames=[{'ColorML'}    {'ShapeML'}    {'Rule'}    {'ResponseLoc'} {'Reward'}];
              %  DataFieldNamesNoRule=[{'ColorML'}    {'ShapeML'}   {'ResponseLoc'} {'Reward'}];
              DataFieldNames=[  {'ColorCat'}  {'ShapeCat'}  {'Rule'}    {'ResponseLoc'} {'Reward'}];
              DataFieldNamesNoRule=[  {'ColorCat'}  {'ShapeCat'}  {'ResponseLoc'} {'Reward'}];
            end
            GetFieldInd=@(x) find(strcmp(x,DataFieldNames));
            NTargFactors=length(DataFieldNames);
            Col=AnalysisOpts.AreaColors;%obj.FigParams.getColorPalet(5); % colors for areas
            MarkerFactors=obj.FigParams.getMarkerPalet(NTargFactors);% AnalysisOpts.ColorPalett3;
            %ColFactors= AnalysisOpts.ColorPalett6;
            [~,ColFactors]=cellfun(@(x) obj.GetColorPalet4Factor(x,1),DataFieldNames,'UniformOutput',0);
            ColFactors=obj.ManData.ReshapeCell2Mat(ColFactors,2);
            
            % load varibles for intrest for each area
            VarNames={'CPD','CPDshMean','CPDpval','CPDcluster','GLMFileExist','CPDzscore',...
                        'CPDclusterPop','CPDpvalPop','IndNeuSigFactor','CPDpurepval','BestLambda','CPDFieldNames'};%,'CPDsh','CPDpval','CPDcluster','GLMFileExist'};
            k=1;
            for Ar=AreaNum
                AnalysisOpts.CurrentCh_AreaName=AnalysisOpts.AreaNames{Ar};
                [ExtraTxt,VarExtraStr]=obj.GetExtraStr4Cond('GLMareaSummery');
                for Var=VarNames
                    temp=obj.ManData.LoadVar('GLM',[Var{1} VarExtraStr '_' GLMmdlName ],ExtraTxt,0,'WantedCh','ALL');
                    eval([Var{1} '{' num2str(k) '}=temp;']);
                end
                FieldNames=fieldnames(CPD{1});
                for f=FieldNames'
                    CPDsubsh{k}.(f{1})=CPD{k}.(f{1})-CPDshMean{k}.(f{1});%
                end
                k=k+1;
            end
           
            %% concatinate data from all areas into one matrix
            CPDsubshAll=obj.ManData.ReshapeCellStruct2Mat(CPDsubsh,1);
            ModelCPDFieldNames=fieldnames(CPD{1}); % what is field names used for saveing the data 
            IndMatchCPDFieldNames=cellfun(@(x) find(strcmp(ModelCPDFieldNames,x)),DataFieldNames); % match the field names we have 
            % plot comparisions for each factor
            [h1]=obj.FigParams.RenderFigure(6,[]);
            [h1{1},Sp1]=obj.FigParams.RenderSubplots([],[],h1{1},NTargFactors);
            [h1{2},Sp2]=obj.FigParams.RenderSubplots([],[],h1{2},length(AreaNum));
            [h1{3},Sp3]=obj.FigParams.RenderSubplots([],[],h1{3},2);
            [h1{4},Sp4]=obj.FigParams.RenderSubplots([],[],h1{4},length(AreaNum));
            k=1;
             for Ar=AreaNum
                % plot each factor in a sperate subplot with its significance for all neurons
                arrayfun(@(x) obj.PlotFactorizedData(CPDsubsh{k},AnalysisOpts.Time,1,Col(Ar,:),DataFieldNames{x},...
                    [DataFieldNames{x} ' information'],AnalysisOpts.Xlabel,'CPD',h1(1),Sp1(x),'Neu2Use',...
                    [],'MeanStdPlotType',3,'SubtractBaseLine',0,'ThisMarker','none',...
                    'NormalizebyMax',0,'ThisLegendTxt',[AnalysisOpts.AreaNames{Ar}],'n_movavg',obj.WidthSmoothing),1:NTargFactors,'UniformOutput',1);%IndNeuSigFactor{Ar}(IndMatchCPDFieldNames(x),:)
                
%                 % significance
%                 arrayfun(@(x) obj.FigParams.plot_significance_level(CPDclusterPop{k}.(DataFieldNames{x}),...
%                     CPDpvalPop{k}.(DataFieldNames{x}),AnalysisOpts.Time,'auto',Col(Ar,:),[],[],'Sp',Sp1(x),...,
%                     'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod),1:length(DataFieldNames));

                % plot each factor for each area
                arrayfun(@(x) obj.PlotFactorizedData(CPDsubsh{k},AnalysisOpts.Time,1,ColFactors(GetFieldInd(DataFieldNamesNoRule{x}),:),DataFieldNamesNoRule{x},...
                    ['Time course of task information for ' AnalysisOpts.AreaNames{Ar}],AnalysisOpts.Xlabel,'CPD',h1(2),Sp2(k),'Neu2Use',...
                    '','MeanStdPlotType',3,'SubtractBaseLine',1,'NPnts_SubtractBaseLine','auto',...
                    'NormalizebyMax',1,'NormalizebyMean',0,'ThisLegendTxt',[DataFieldNamesNoRule{x}],'n_movavg',obj.WidthSmoothing,...
                    'ThisMarker','none'),1:length(DataFieldNamesNoRule),'UniformOutput',1);
                              
                % plot all factors for each area
                 arrayfun(@(x) obj.PlotFactorizedData(CPDsubsh{k},AnalysisOpts.Time,1,ColFactors(GetFieldInd(DataFieldNamesNoRule{x}),:),DataFieldNamesNoRule{x},...
                    ['Time course of task information for ' AnalysisOpts.AreaNames{Ar}],AnalysisOpts.Xlabel,'CPD',h1(4),Sp4(k),'Neu2Use',...
                    '','MeanStdPlotType',3,'SubtractBaseLine',0,'NPnts_SubtractBaseLine','auto',...
                    'NormalizebyMax',0,'NormalizebyMean',0,'ThisLegendTxt',[DataFieldNamesNoRule{x}],'n_movavg',obj.WidthSmoothing,...
                    'ThisMarker','none'),1:length(DataFieldNamesNoRule),'UniformOutput',1);

                   % significance
%                 arrayfun(@(x) obj.FigParams.plot_significance_level(CPDclusterPop{k}.(DataFieldNamesNoRule{x}),...
%                     CPDpvalPop{k}.(DataFieldNamesNoRule{x}),AnalysisOpts.Time,'auto',ColFactors(GetFieldInd(DataFieldNamesNoRule{x}),:),[],[],'Sp',Sp4(k),...,
%                     'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod),1:length(DataFieldNamesNoRule));
                  k=k+1;
            end
            % plot timing for each factor averaged across all areas
            arrayfun(@(x) obj.PlotFactorizedData(CPDsubshAll,AnalysisOpts.Time,1,ColFactors(GetFieldInd(DataFieldNamesNoRule{x}),:),DataFieldNamesNoRule{x},...
                ['Time course of task information for all areas'],AnalysisOpts.Xlabel,'CPD',h1(3),Sp3(1),'Neu2Use',...
                '','MeanStdPlotType',1,'SubtractBaseLine',1,'NPnts_SubtractBaseLine','auto',...
                'NormalizebyMax',1,'NormalizebyMean',0,'ThisLegendTxt',[DataFieldNamesNoRule{x}],'n_movavg',obj.WidthSmoothing,...
                'ThisMarker','none'),1:length(DataFieldNamesNoRule),'UniformOutput',1);
            % plot rule information on its own
            arrayfun(@(x) obj.PlotFactorizedData(CPDsubshAll,AnalysisOpts.Time,1,ColFactors(GetFieldInd('Rule'),:),'Rule',...
                ['Time course of task information for all areas'],AnalysisOpts.Xlabel,'CPD',h1(3),Sp3(2),'Neu2Use',...
                '','MeanStdPlotType',1,'SubtractBaseLine',0,'NPnts_SubtractBaseLine',5,...
                'NormalizebyMax',1,'NormalizebyMean',0,'ThisLegendTxt',['Rule'],'n_movavg',obj.WidthSmoothing,...
                'ThisMarker','none'),1,'UniformOutput',1);
            ylim([0 1.2])

            % plot the proportion of siginificant neurons per area
            figure(h1{5});
            SigCol=obj.ManData.ReshapeCell2Mat(IndNeuSigFactor,64);
            SumArea=[];
            Area=cell2mat(arrayfun(@(x) x*ones(1,size(IndNeuSigFactor{x},2)),1:length(IndNeuSigFactor),'uniformoutput',0));
            for i=1:length(IndNeuSigFactor)
                SumSig=sum(SigCol(:,Area==i),2);
                SumTot=sum(Area==i);
                SumArea(i,:)=SumSig/SumTot;
                % run binomial test for each factor as well
                SigArea(i,:)=arrayfun(@(x) obj.ManData.BinomialTest(SumTot,SumSig(x),AnalysisOpts.GLM_pval_binomial_AreaCell),1:size(SigCol,1));
            end
            bar(SumArea')
            legend(AnalysisOpts.AreaNames)
            xticklabels(CPDFieldNames{1})
            xtickangle(45)
            %  obj.ManData.PhenoClusterPlot(SigCol,SumArea);
            figure(h1{6});hold on
            bar(SigArea)
            legend(AnalysisOpts.AreaNames)
            xticklabels(CPDFieldNames{1})
            xtickangle(45)
            v=axis;
            plot([v(1) v(2)],[0.05 0.05],'--','color',[0.5 0.5 0.5])
            
            varargout=h1;
        end
        function GLMfit=DecomposeCircularDataGLM(obj,GLMfit,FullMdlName,GLMfactorsnames,FactorType,varargin) % gets the color and shape information on a circular space
            % FactorType can be 'color' or 'shape'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(GLMfit);
            % check if this factor type contains other factors such as
            % rule in addition to ColorML or ShapeMl
            if length(FactorType)>8;InterActFactor=['x' FactorType(9:end)];else;InterActFactor='';end
            ML1ind=contains(GLMfactorsnames,[FactorType(1:5) 'ML1' InterActFactor],'IgnoreCase',0);
            ML2ind=contains(GLMfactorsnames,[FactorType(1:5) 'ML2' InterActFactor],'IgnoreCase',0);
            if sum(ML1ind)
                for Neu=1:NNeu
                    GLMfit(Neu).(FullMdlName).([FactorType]) =sqrt(GLMfit(Neu).(FullMdlName).GLM_weights(ML1ind,:).^2+GLMfit(Neu).(FullMdlName).GLM_weights(ML2ind,:).^2);
                    GLMfit(Neu).(FullMdlName).(['Theta' FactorType])=wrapTo360(atand(GLMfit(Neu).(FullMdlName).GLM_weights(ML1ind,:)./GLMfit(Neu).(FullMdlName).GLM_weights(ML2ind,:)));
                    MaxBeta=max(GLMfit(Neu).(FullMdlName).(FactorType));
                    GLMfit(Neu).(FullMdlName).(['ThetaTH' FactorType])=GLMfit(Neu).(FullMdlName).(['Theta' FactorType]).*(GLMfit(Neu).(FullMdlName).(FactorType)>=0.3*MaxBeta);
                end
            end
        end
        function GLMfit=CalSelectivityGLMweights(obj,GLMfit,FullMdlName,GLMfactorsnames,FactorType,varargin) % calculates selectivity for GLM weights
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % check if it is color or shape so we use a differnt metric
            if (contains(FactorType,'colorml','IgnoreCase',1) | contains(FactorType,'shapeml','IgnoreCase',1)) & ~contains(FactorType,'sing','IgnoreCase',1)
                GLMfit=obj.DecomposeCircularDataGLM(GLMfit,FullMdlName,GLMfactorsnames,FactorType);
                return
            end
            
            NNeu=length(GLMfit);
            FactorInd=contains(lower(GLMfactorsnames),lower(FactorType));
            Nfacts=sum(FactorInd);
            NTim=size(GLMfit(1).(FullMdlName).GLM_weights,2);
            if Nfacts==0;return;end
            for Neu=1:NNeu
                GLMfit(Neu).(FullMdlName).(FactorType) =arrayfun(@(t) obj.ManData.SelectivityIndex(1:Nfacts,GLMfit(Neu).(FullMdlName).GLM_weights(FactorInd,t)),1:NTim);
            end
        end
        % calclulate coefficient of partial determination
        function CPD=CalCoefPartialDet(obj,GLMfit,GLMfactorsnames,FullMdlName,varargin) % calculates CPD based on different models
            % GLM fit contains all fits from all of the models
            % AllMdlsName: Name of all of the models
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(GLMfit);
            NTim=size(GLMfit(1).Y,2);
            GLMModelSet=obj.DefineGLMmodelSet;
            for Neu=1:NNeu
                NLambda=length(GLMfit(Neu).(FullMdlName).Lambda);
                for LambdaInd=1:NLambda % loop on different lambda values
                    % get Y and Yfull first
                    Y=GLMfit(Neu).Y;
                    GLM_weights=squeeze(GLMfit(Neu).(FullMdlName).GLM_weights_full(:,LambdaInd,:)); % we look at the main LambdaInd
                    [~,Xdata_test]=obj.(['GLM_' obj.GLMfullMdlType])(GLMfit(Neu).X,[],AnalysisOpts.factornames,GLMfactorsnames,1);
                    Yfull=cell2mat(arrayfun(@(x) glmval(GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                    
                    for ThisFactorName=GLMfactorsnames % calculate CPD for each factor based on reduced model
                        ThisMdlName=sprintf('%s_No_%s',FullMdlName,ThisFactorName{1});
                        ModelDef=GLMModelSet.(ThisMdlName);
                        ThisMdl_GLM_weights=squeeze(GLMfit(Neu).(ThisMdlName).GLM_weights_full(:,LambdaInd,:)); % we look at the main LambdaInd
                        [~,Xdata_test]=obj.(['GLM_' obj.GLMfullMdlType])(GLMfit(Neu).X,[],AnalysisOpts.factornames,ModelDef,1);
                        Yred=cell2mat(arrayfun(@(x) glmval(ThisMdl_GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                        CPD(Neu).(ThisFactorName{1})(LambdaInd,:)=obj.ManData.CallCPD(Y,Yfull,Yred);
                    end
                end
            end
        end
        
        function CPD=CalCoefPartialDetSingFactShuff(obj,GLMfit,GLMfitSh,GLMfactorsnames,FullMdlName,varargin) % calculates CPD based on different models
            % this is to calculate the CPD for single factor shuffle condition
            % GLM fit contains all fits from all of the models
            % AllMdlsName: Name of all of the models
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(GLMfit);
            NTim=size(GLMfit(1).Y,2);
            GLMModelSet=obj.DefineGLMmodelSet;
            for Neu=1:NNeu
                NLambda=length(GLMfit(Neu).(FullMdlName).Lambda);
                for LambdaInd=1:NLambda % loop on different lambda values
                    % get Y and Yfull first
                    Y=GLMfit(Neu).Y;
                    for ThisFactorName=GLMfactorsnames % calculate CPD for each factor based on reduced model

                        % get CPD for full model with shuffled factor
                        GLM_weights=squeeze(GLMfitSh(Neu).([FullMdlName '_Shuff' ThisFactorName{1}]).GLM_weights_full(:,LambdaInd,:)); % we look at the main LambdaInd
                        [~,Xdata_test_sh]=obj.(['GLM_' obj.GLMfullMdlType])(GLMfitSh(Neu).(['XShuff_' ThisFactorName{1}]),[],AnalysisOpts.factornames,GLMfactorsnames,1);
                      %  [~,Xdata_test_sh]=obj.(['GLM_' obj.GLMfullMdlType])(GLMfit(Neu).X,[],AnalysisOpts.factornames,GLMfactorsnames,1);                      
                        Yfull=cell2mat(arrayfun(@(x) glmval(GLM_weights(:,x),Xdata_test_sh,'identity'),1:NTim,'UniformOutput',0));

                        % get CPD for reduced model ( this model doens't have the shuffled factors)
                        ThisMdlName=sprintf('%s_No_%s',FullMdlName,ThisFactorName{1});
                        ModelDef=GLMModelSet.(ThisMdlName);
                        ThisMdl_GLM_weights=squeeze(GLMfit(Neu).(ThisMdlName).GLM_weights_full(:,LambdaInd,:)); % we look at the main LambdaInd
                        [~,Xdata_test]=obj.(['GLM_' obj.GLMfullMdlType])(GLMfit(Neu).X,[],AnalysisOpts.factornames,ModelDef,1);
                        Yred=cell2mat(arrayfun(@(x) glmval(ThisMdl_GLM_weights(:,x),Xdata_test,'identity'),1:NTim,'UniformOutput',0));
                        CPD(Neu).(ThisFactorName{1})(LambdaInd,:)=obj.ManData.CallCPD(Y,Yfull,Yred);
                    end
                end
            end
        end
        
        function GLMHierarchicalClustering(obj,GLMWeights,FactorNames)
            Y=pdist(GLMWeights','correlation');
            Z=linkage(Y);
            subplot(121)
            dendrogram(Z,'Labels',FactorNames)
            
            Y=pdist(GLMWeights');
            Z=linkage(Y);
            subplot(122)
            dendrogram(Z,'Labels',FactorNames)
        end
        %% generate fake neurons with factors
        function PSTHRaster=FakeNeuronRespWithFactors(obj,FactorizedData,SensitiveFactors,varargin) % generate a fake neuron with the sensitivity to factors we want and get its response
            % sensitive factors are the list of factors we want this neuron
            % to respond to
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            [TrialSpikeData]=obj.ArtSimFunc.GenerateFakeNeuronWithFactors(FactorizedData,SensitiveFactors);
            %  load playdata.mat
            [PSTHRaster.PSTH,PSTHRaster.Raster,PSTHRaster.SpkCount,PSTHRaster.SpkCountTim,PSTHRaster.RasterTim]=...
                obj.ProcessSpikeCounting(TrialSpikeData,FactorizedData.TimingTaskData,AnalysisOpts.SpkCntStartFieldName);
            
        end
        function Factors=GenFakeNeuronFactorSet(obj,Neu,varargin) % generate factor set for simulated neurons
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            FactorSet(1).Factors={'ColorML'};
            FactorSet(2).Factors={'ColorCat'};
            FactorSet(3).Factors={'ResponseLoc'};
            FactorSet(4).Factors={'Rule'};
            FactorSet(5).Factors={'ColorML','Rule'};
            FactorSet(6).Factors={'ColorML','ColorCat','Rule'};
            FactorSet(7).Factors={'ColorML','ColorCat','Rule','ResponseLoc'};
            FactorSet(8).Factors={'ColorML','ColorCat','ShapeML','ShapeCat','Rule','ResponseLoc'};
            
            Factors=FactorSet(Neu).Factors;
        end
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%NEURAL POPULATION ANALYSIS FUNCTIONS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        function [FactorizedData,FactorizedData_Raster,obj]=GetFactorizedData(obj,data,TimingStimData,FactorizeRasterData,varargin) % gets factorized data for each neuron
            %@data PSTH data
            %@TimingStimData timing and stimulus specs data
            % FactorizeRasterData  do we want to factorize the raster data as well?
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if ~exist('FactorizeRasterData','var');FactorizeRasterData=0;end
            FactorizedData=[];FactorizedData_Raster=[];
            if obj.MeanSubtractByRule==1 % we are zero meaning the data for each neuron for each rule
                fprintf(2,'\n Warning: we are zero meaning the data for each rule ...');
            end
            for Neu=1:AnalysisOpts.NNeu
                % get factorized
                [FactorizedData(Neu).data,FactorizedData(Neu).factors,FactorizedData(Neu).factornames,....
                    FactorizedData(Neu).TimingTaskData,FactorizedData(Neu).StimInfoData,FactorizedData(Neu).SpkCntbyFactor,obj]=obj.GetFactorDataForThisNeuron(data(Neu),TimingStimData(Neu),'PSTH');
                if FactorizeRasterData
                    [FactorizedData_Raster(Neu).data,FactorizedData_Raster(Neu).factors,FactorizedData_Raster(Neu).factornames,~,~,~,obj]=obj.GetFactorDataForThisNeuron(data(Neu),TimingStimData(Neu),'Raster');
                end
                
                if obj.UseFakeNeurons % if we are using fake neurons then generate fake data and replace it with what we have
                    Factors=obj.GenFakeNeuronFactorSet(AnalysisOpts.nCh_2look(Neu));
                    if FactorizeRasterData
                        [PSTHRaster]=obj.FakeNeuronRespWithFactors(FactorizedData,Factors);
                        FactorizedData_Raster(Neu).data=PSTHRaster.Raster;
                    end
                    % replace the factorized data with simulated neuron data
                    FactorizedData(Neu).data=PSTHRaster.PSTH;
                end
            end
        end
        function data=LimitSpikingDataTimeAxis(obj,data,TimeInd,varargin)% limits the time on the data axis 
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isempty(data);return;end
            NNeu=length(data);
            for Neu=1:NNeu
                data(Neu).PSTH=cellfun(@(x) x(:,TimeInd),data(Neu).PSTH,'uniformoutput',0);
            end
        end
        function varargout=GetFactorizedData4ThisArea(obj,data,TimingStimData,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %@data is usually the PSTH
            %@TimingStimData is timing and stimulus information
            
            %  Prepare variables
            AnalysisOpts.Xlabel=['Time(s) from ' strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ')];
            Time=data(1).SpkCountTim{1}-AnalysisOpts.SpkParams.BaselineDelay;%obj.ManData.GenerateTimeAxis;
            NNeu=length(data);
            if obj.UseFakeNeurons;AnalysisOpts.ExtraStr='Sim';end
            RasterTime=data(1).RasterTim{1}-AnalysisOpts.SpkParams.BaselineDelay;
            NTim=length(Time);
            obj.ManData.CopyVars2AnalysisOpts('Time',Time,'RasterTime',RasterTime,'NTim',NTim,'NNeu',NNeu);
            
            [varargout{1}]=obj.GetFactorizedData(data,TimingStimData,'MeanSubtractByRule',0); % get factorized data
        end
        function varargout=SetupNeuralAnalysis(obj,data,TimingStimData,SpkCountTim,RasterTim,varargin) % set up the analysis pipeline for population
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %@data is usually the PSTH
            %@TimingStimData is timing and stimulus information
            
            %%  Prepare variables
            AnalysisOpts.Xlabel=['Time, relative to ' lower(strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ')) ' (s)'];
            if obj.UsePCA4AxB;AnalysisOpts.ExtaStrAnalysis='PCAxB';end
            if obj.UseFakeNeurons;AnalysisOpts.ExtraStr='Sim';end
            
            if isempty(data)                 
                [~,Time]=obj.ManData.GenerateTimeAxis(obj.PSTHTimRef);
                RasterTime=0;
            else
                Time=SpkCountTim-AnalysisOpts.SpkParams.BaselineDelay;%obj.ManData.GenerateTimeAxis;
                RasterTime=RasterTim-AnalysisOpts.SpkParams.BaselineDelay;
            end
           
            NNeu=length(data);
            % Limit Time axis and data to save computing time
            [TimeInd]=obj.FigParams.LimitTimeAxis(Time,'Time');
            Time=Time(TimeInd);
            NTim=length(Time);
            %    limits the data PSTH data into time period for the paper
            data=obj.LimitSpikingDataTimeAxis(data,TimeInd);
            obj.ManData.CopyVars2AnalysisOpts('Time',Time,'RasterTime',RasterTime,'NTim',NTim,'NNeu',NNeu);
            
            varargout=cell(1,AnalysisOpts.NfigProcesStep(AnalysisOpts.ProcessingStep));
            %% deviding this function into processing steps so that we can
            %% run it in different modes
            switch AnalysisOpts.ProcessingStep
                %% Calculate angle between Shape and Color subspaces for each rule pair in time
                case 1
                    obj.SubspaceAnalysis_Learning(data,TimingStimData)
                    %% Plot subspace analysis results
                case 2
                    [SubspaceAnaResults,SubspaceAnaOpts]=obj.LoadSubspaceAnaResults(obj.SubspaceAna_TaskName,'CalShuff',0);
                    % load permutation results as well
                    [obj.SubspaceAna_Shuff]=obj.LoadSubspaceAnaResults(obj.SubspaceAna_TaskName,'CalShuff',1);
                    %plot results from this condition
                    Conds=1:length(SubspaceAnaOpts.TestCond); % total number of conditions
                    h=arrayfun(@(x) obj.PlotSubspaceAnalysisResults(SubspaceAnaResults,SubspaceAnaOpts,SubspaceAnaOpts.Name,x),Conds,'UniformOutput',0);
                    % save off the figures
                    [~,~,SubspaceAnaFigFileName]=obj.ManData.GetFileName(['Subspace'],['_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],SubspaceAnaFigFileName,[h{1}],'SaveEachFrame',1);
                    %make movie of different conditions as well
                    % to make movie you need to have compelete matrixes so put AnalysisOpts.GetFullAxBdata=1
                    %  obj.MakeMovieAxBAnalysisResults(SubspaceAnaResults,SubspaceAnaOpts)
                    if contains(SubspaceAnaOpts.Name,'Learning');return;end
                    hComp=obj.PlotCompositionalityAnalysisResutls(SubspaceAnaResults,SubspaceAnaOpts);
                    [~,~,SubspaceAnaFigFileName]=obj.ManData.GetFileName(['Subspace'],['_AxBCompositionality_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],SubspaceAnaFigFileName,[hComp],'SaveEachFrame',1);
                    %% Perfom classifier analysis
                case 3
                    obj.TrialFunc.RevertCh_2look; 
                    if contains(obj.Classifier_TaskName,'2D') ||  contains(obj.Classifier_TaskName,'Learning') || contains(obj.Classifier_TaskName,'3D')
                        % obj.CrossTemporalClassfierAnalysis2D(data,TimingStimData);
                        obj.CrossTemporalClassfierAnalysis_Learning(data,TimingStimData)
                    else
                        obj.CrossTemporalClassfierAnalysis(data,TimingStimData);
                    end
                    %% Plot classifier Analysis results
                case 4                    
                    [ClassifierResults,ClassifierOpts]=obj.LoadClassiferResults(obj.Classifier_TaskName,'CalShuff',0);
                    % load permutation results as well
                    [obj.ClassifierResults_Observed,ClassifierOpts_Shuff,~,obj.ClassifierResults_Shuff]=obj.LoadClassiferResults(obj.Classifier_TaskName,'CalShuff',1);
                    % if we don't have the results throw an error
                    if isempty(ClassifierResults);error('\ClassifierResults is empty');end
                    % update time axis
                  %  [~,AnalysisOpts.Time]=obj.ManData.GenerateTimeAxis(obj.PSTHTimRef,ClassifierOpts.AnalysisOpts);
%                     if isempty(ClassifierOpts_Shuff)
%                     else
%                         AnalysisOpts.Time=ClassifierOpts_Shuff.AnalysisOpts.Time;                        
%                     end
                    AnalysisOpts.Time=ClassifierOpts.AnalysisOpts.Time;
                    % because our timing when we created the PSTH was centered and we are changing to leading 
                    % we need to subtract half of the bin length from the timing 
                    if strcmp(obj.PSTHTimRef,'leading')
                        AnalysisOpts.Time=AnalysisOpts.Time-AnalysisOpts.PopulationAna.PSTHbin*0.001/2;
                        warning('We have subtracted half of the PSTH bin from time vector')
                    end

                    % copy data from ClassifierOpts
                    obj.ManData.CopyVars2AnalysisOpts('RasterTime',ClassifierOpts.AnalysisOpts.RasterTime,'NTim',ClassifierOpts.AnalysisOpts.NTim,'NNeu',ClassifierOpts.AnalysisOpts.NNeu);
                    %plot results from this condition
                    Conds=1:length(ClassifierOpts.TestCond); % total number of conditions
                    if contains(ClassifierOpts.Name,'2D')
                        h=arrayfun(@(x) obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CondDetail',x),Conds,'UniformOutput',0);
                    elseif contains(ClassifierOpts.Name,'Learning') & ~contains(ClassifierOpts.Name,'3D')                        
                        h=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                    elseif contains(ClassifierOpts.Name,'Learning') & contains(ClassifierOpts.Name,'3D')
                        h=obj.QuantifySharedSubspaces_Learning3D(ClassifierResults,ClassifierOpts);
                   elseif ~contains(ClassifierOpts.Name,'Learning') & contains(ClassifierOpts.Name,'3D')     
                        h=obj.PlotXTemporalClassifierResults3D(ClassifierResults,ClassifierOpts,'',[]);
                    else
                        % plot perfromance in all of the conditions
                        h1=obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'XTempPerf',[]);
                        % plot each individual condition
                        h2=arrayfun(@(x) obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CondDetail',x),Conds,'UniformOutput',0);
                        h=[{h1} h2];
                    end
                    % save off the figures
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h],'SaveEachFrame',AnalysisOpts.SaveEachFrame,'SaveEachSubplots',AnalysisOpts.SaveEachSubplots);
                    %% plot different conditions of classifier analysis and compare them
                case 5
                    Task2CompareName=AnalysisOpts.PopulationAna.Classifier_ComparisionNameSet{AnalysisOpts.PairNum};
                    fprintf(2,'\nPlotting Classfier Comparision on task:%s\n',Task2CompareName)
                    Tasks2Compare=obj.ClassifierComparisionOpts(Task2CompareName);
                    % plot classifier analysis we have and compare them
                    for TskCompId=1:Tasks2Compare.NComparisons
                        if ~isempty(obj.ClassifierResults_Loaded)
                            ClassifierResults=obj.ClassifierResults_Loaded;
                            ClassifierOpts=obj.ClassifierOpts_Loaded;
                            break;
                        end % if we have already loaded 
                        Ind=strcmp(AnalysisOpts.PopulationAna.Classifier_TaskNameSet,Tasks2Compare.TaskInd{TskCompId});
                        ClassifierOptsTemp=obj.DefineClassifierTestOptions(AnalysisOpts.PopulationAna.Classifier_TaskNameSet{Ind});
                        FileNameSyntax=['_' ClassifierOptsTemp.Name '_' Tasks2Compare.Area{TskCompId} '_' Tasks2Compare.SpkCntStartFieldName{TskCompId} '_' Tasks2Compare.TrlSpkTimeFieldName{TskCompId} '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                        ClassifierResults{TskCompId}=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        ClassifierOpts{TskCompId}=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
                    end
                    % copy data from ClassifierOpts
                    obj.ManData.CopyVars2AnalysisOpts('Time',ClassifierOpts{1}.AnalysisOpts.Time,'RasterTime',ClassifierOpts{1}.AnalysisOpts.RasterTime,'NTim',ClassifierOpts{1}.AnalysisOpts.NTim,'NNeu',ClassifierOpts{1}.AnalysisOpts.NNeu);
                   % correct for timing
                    if strcmp(obj.PSTHTimRef,'leading')
                        AnalysisOpts.Time=AnalysisOpts.Time-AnalysisOpts.PopulationAna.PSTHbin*0.001/2;
                        warning('We have subtracted half of the PSTH bin from time vector')
                    end
                    
                    if contains(Task2CompareName,'2D')
                        h1=obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CompareConds',Tasks2Compare.Cond,Tasks2Compare);
                    elseif contains(Task2CompareName,'3D')
                        h1=obj.PlotXTemporalClassifierResults3D(ClassifierResults,ClassifierOpts,'ComparisionSummery',Tasks2Compare);                    
                    else
                        h1=obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CompareConds',Tasks2Compare.Cond,Tasks2Compare);
                    end
                    % save off the figures
                    % if this comparison is for all of the areas
                    if sum(cellfun(@(x) sum(contains(AnalysisOpts.AreaNames,x)),unique(Tasks2Compare.Area)))==5;SaveArea='ALL';else;SaveArea=AnalysisOpts.Area2look{1};end
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName('Classifier',['_' Task2CompareName '_Compare_' SaveArea '_' Tasks2Compare.SpkCntStartFieldName{1} '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h1],'SaveEachFrame',1);
                    %% estimation of intrinsic dimensionality of representation in time and conditions
                case 6
                    TargetFactors= {'AllObjects','Rule'};
                    Rule=[1 2 3];
                    [FactorData,CatFactorData,FactorLevelComb,FactorLevels]=...
                        obj.PrepareData4PCAnalysis(FactorizedData,TargetFactors,{[AnalysisOpts.StimulusMorphLevels],[Rule]});
                    PCA=obj.DoPCAanalysisSingTrialTime(FactorData,FactorLevelComb,TargetFactors);
                    %% charactrize subspace contents
                case 7
                    % SubspaceTasks{1}={'2D_Cat_Color_Shape','2D_Cat_Color_Resp_Xgen','2D_Cat_Color_Color_Xgen','Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Shape_Rule_Xgen_AltRule50NMS'};
                    SubspaceTasks{1}={'2D_Cat_Color_Shape','2D_Cat_Color_Resp_Xgen','2D_Cat_Color_Color_Xgen','Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule','Learning_Cat_Shape_Rule_Xgen_AltRule_HiPerf'};
                    SubspaceTasks{2}={'2D_Cat_Color_Shape_BalRespDir','2D_Cat_Color_Resp_Xgen_BalRespDir','2D_Cat_Color_Color_Xgen'};
                    
                    SubspaceTasks{3}={'Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Shape_Color_Xgen_SameRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule_HiPerf'};
                    
                    SubspaceTasks=SubspaceTasks{AnalysisOpts.PairNum};
                    %% plot classfier weights in color and shape in PCA space
                    %                     fprintf(2,'\nCharactrizing subspace contents')
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{1});
                    %                     h1=obj.CharactrizeSubspaces(ClassifierResults,ClassifierOpts);
                    %                     h1=num2cell(h1);
                    %
                    %                     % plot classifier weights in 1D and 2D in differrentCondtions
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{2});
                    %                     h2=obj.CharactrizeSharedSubspaces(ClassifierResults,ClassifierOpts);
                    %
                    %                     %% Quantify shared variances in color and response dimensions
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{3});
                    %                     h3=obj.QuantifySharedSubspaces(ClassifierResults,ClassifierOpts);
                    %
                    %% Quantify shared variances in during learning
                    obj.WidthSmoothing=10;    % what is width of our smooting
                    obj.WidthSmoothingDim2=2; % what is width of our smooting Dim2
                    h=[];
                    AnalysisOpts.CurrentCh_Animal='ALL'; % we are looking at one recording for this
                    for S=1:length(SubspaceTasks)
                        [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{S});
                        h1=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                        h=[h h1];
                    end
                    ExtraTxt='Full';
                    %% quantify subspaces and relate them to behavioral model
                    %                     AnalysisOpts.CurrentCh_Animal='Silas'; % we are looking at one recording for this
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{6});
                    %                     h7=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                    %
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{6});
                    %                     h8=obj.QuantifySubSpaceBhvCorr_Learning(ClassifierResults,ClassifierOpts);
                    % save off the figures
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['_SubSpaceAna' ExtraTxt num2str(AnalysisOpts.PairNum) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h],'SaveEachFrame',1);
                    %% concatinate classifer files together
                case 8
                    obj.ConcatinateClassifierFiles(obj.Classifier_TaskName)
                    %% concatinate subspace files together
                case 9
                    obj.ConcatinateSubspaceFiles(obj.SubspaceAna_TaskName)

%%  %%%%%%%%%%%%%%%%%%%%% <<<<<single cell analysis processing steps>>>>> %%%%%%%%%%%%%%%%%%%%%%%%%%%%
                case 10 %% generate a summery plot for population or single cells
                    % concatinate GLM fit data
                    cellfun(@(x) obj.ConcatinateGLMfitdata(x),AnalysisOpts.SingCellAna.GLMMdlName2Test);
                    
                    % create summery file and concatinate shuffle files everything
                    obj.CreateNeuronSummeryFile;
                    
                    % generate a report for this neuron
                    [FactorizedData,FactorizedData_Raster]=obj.GetFactorizedData(data,TimingStimData,1); % get factorized data
                    [FactorizedData_SACCADE_START]=obj.GetFactorizedData(obj.ExtraPSTHRaster,TimingStimData,0); % get factorized data for SaccadeStart
                    
                    % plot basic charactristics of the neuron
                    [varargout{1}]=obj.PlotResponseLatencies(FactorizedData,FactorizedData_SACCADE_START);
                    [varargout{2}]=obj.PlotPSTHbyFactor(FactorizedData,Time,FactorizedData.factornames(1:9));
                    [varargout{3:4}]=obj.PlotTuningCurvesbyFactor(FactorizedData_Raster,RasterTime,{'ColorML','ShapeML'});
                    
                    nar=length(obj.TargetArea);
                    np=3*nar;AnalysisOpts.np=np;
                    Models2Test=AnalysisOpts.SingCellAna.GLMMdlName2Test{1}; % we are only looking at one model at the moment
                    [varargout{(4+1:4+np)}]=obj.PlotSignificantGLMfactors([],Models2Test,'PlotResults',1);
                    % save the generated figures
                    ExtraTxt=obj.GetExtraStr4Cond('GLMfit');
                    if length(AnalysisOpts.nCh_2look)>1;AnalysisOpts.CurrentCh_ChNum='ALL';end
                    [~,~,GLMFigFileName]=obj.ManData.GetFileName('GLM',ExtraTxt,'SaveInResults',1,'WantedDate','ALL','WantedCh',AnalysisOpts.CurrentCh_ChNum);
                    obj.FigParams.SaveFigSeries([],GLMFigFileName,varargout,'SaveEachFrame',1);
                   
                case 11  %% Fit GLM models
                    obj.Remove50MLFactor=1;
                    [FactorizedData]=obj.GetFactorizedData(data,TimingStimData,0); % get factorized data
                    Models2Test=AnalysisOpts.SingCellAna.GLMMdlName2Test;% Models2Test={'HybridbhvMdlFull','InferAFbhvMdlFull'};
                    % <<<check if we are shuffleing the data>>>
                    obj.GLMshuffleFlag=AnalysisOpts.CalShuffleGLM;
                    cellfun(@(mdl) obj.FitGLMmdls2data(FactorizedData,'GLMmdl',mdl,'UseSavedData',0,'PlotResults',0,...
                        'GLMfitMethod','FactorOmit'),Models2Test,'UniformOutput',0);
                   if AnalysisOpts.SingCellAna.GLM_UseSingFactorShuff;return;end
                    % add shuffle runs here for now as well << to be% corrected
                    if AnalysisOpts.SingCellAna.GLMShuffleRuns<=1000 % if we have low number then run them all here
                        obj.GLMshuffleFlag=1;AnalysisOpts.ReWriteGLMData=1;
                        for CalShuffleGLM_Cond=1:AnalysisOpts.SingCellAna.GLMShuffleRuns
                            AnalysisOpts.CalShuffleGLM_Cond=CalShuffleGLM_Cond;
                            cellfun(@(mdl) obj.FitGLMmdls2data(FactorizedData,'GLMmdl',mdl,'UseSavedData',0,'PlotResults',0,...
                                'GLMfitMethod','FactorOmit','GLMshuffleFlag',obj.GLMshuffleFlag),Models2Test,'UniformOutput',0);
                        end
                        AnalysisOpts.ShuffleStr='';
                        cellfun(@(x) obj.ConcatinateGLMfitdata(x),AnalysisOpts.SingCellAna.GLMMdlName2Test);
                    end
                    % delete shuffle files 
                    AnalysisOpts.ReWriteGLMData=0;
                    cellfun(@(x) obj.ConcatinateGLMfitdata(x),AnalysisOpts.SingCellAna.GLMMdlName2Test(1));
                    %% run model comparision here as well
                    obj.GLMnMdlCompRuns=1:AnalysisOpts.SingCellAna.GLMnMdlCompRuns;
                    obj.GLMmodelComparision_Hierarchical(FactorizedData,AnalysisOpts.SingCellAna.GLMMdlComp2Test)
                    obj.TrialFunc.UpdateCurrentCh(AnalysisOpts.nCh_2look);
                    obj.PlotGLMmodelComparision_Hierarchical(AnalysisOpts.SingCellAna.GLMMdlComp2Test{1},0);% 'CompareBhvModels','HybridbhvMdlFullReduce' 'InferAFbhvMdlFullReduce'
                    %%
                    obj.CreateNeuronSummeryFile;
                       
                case 12%% GLM model comparision(run on cluster)
                    obj.Remove50MLFactor=1;
                    [FactorizedData]=obj.GetFactorizedData(data,TimingStimData,0); % get factorized data
                    obj.GLMmodelComparision_Hierarchical(FactorizedData,AnalysisOpts.SingCellAna.GLMMdlComp2Test)
              
                case 13 %% plot GLM model comparision results
                    np=3;
                    for Neu=AnalysisOpts.nCh_2look
                        close all
                        obj.TrialFunc.UpdateCurrentCh(Neu);
                        [varargout{1:np}]=obj.PlotGLMmodelComparision_Hierarchical(AnalysisOpts.SingCellAna.GLMMdlComp2Test{1},1);% 'CompareBhvModels','HybridbhvMdlFullReduce' 'InferAFbhvMdlFullReduce'
                        % save figures( add to existing file for each neuron)
                        ExtraTxt=obj.GetExtraStr4Cond('GLMfit');
                        [~,~,GLMFigFileName]=obj.ManData.GetFileName('GLM',ExtraTxt,'SaveInResults',1,'WantedDate','ALL','WantedCh',AnalysisOpts.CurrentCh_ChNum);
                        obj.FigParams.SaveFigSeries([],GLMFigFileName,varargout,'SaveEachFrame',0);
                    end
                    % process model comparision resutls for each area
                    %obj.GLMfitModlCompResultsArea
                    %obj.PlotGLMmodelCompAreaSummery()
                   
                case 14 %% generate a summery file for an area
                    AnalysisOpts.GLM_SkipSingleCellCharctristics=1;
                    AnalysisOpts.GLM_SkipPopulationCharctristics=0;
                    obj.CreateNeuronSummeryFile;
                
                case 15 %% concatinate GLM fit data and create a summery file                   
             %       cellfun(@(x) obj.ConcatinateGLMfitdata(x),AnalysisOpts.SingCellAna.GLMMdlName2Test);
                     % if we have GLM_UseSingFactorShuff then do it for all of the cells of the areas first 
                     AnalysisOpts.GLM_SkipSingleCellCharctristics=0;
                     AnalysisOpts.GLM_SkipPopulationCharctristics=1;
                     obj.CreateNeuronSummeryFile;
                     
                case 16 %% plot GLM results for area
%                     nar=length(obj.TargetArea);
%                     Models2Test=AnalysisOpts.SingCellAna.GLMMdlName2Test;nMdl=length(Models2Test);
%                     np=5*nar*nMdl;AnalysisOpts.np=np;GLMfigs=cell(1,np);
%                     for m=1:nMdl
%                         [GLMfigs{1+(5*nar*(m-1)):5*nar*m}]=obj.PlotSignificantGLMfactors([],Models2Test{m},'PlotResults',1);
%                     end
%                     ExtraTxt=obj.GetExtraStr4Cond('GLMfit');
%                     [~,~,GLMFigFileName]=obj.ManData.GetFileName('GLM',ExtraTxt,'SaveInResults',1,'WantedDate','ALL','WantedCh','ALL');
%                     obj.FigParams.SaveFigSeries([],GLMFigFileName,[GLMfigs],'SaveEachFrame',1);                    
             
                    % run step 14 first so that we get the data for the population first 

                    % Compare GLM encoding between areas
                    [GLMAreaComp{(1:5)}]=cellfun(@(GLMmdlName) obj.PlotCompareGLMfitArea([1:5],GLMmdlName),AnalysisOpts.SingCellAna.GLMMdlName2Test);
                    % save the generated figures
                    AnalysisOpts.CurrentCh_AreaName='ALL';ExtraTxt=obj.GetExtraStr4Cond('GLMfit');
                    [~,~,GLMFigFileName]=obj.ManData.GetFileName('GLM',ExtraTxt,'SaveInResults',1,'WantedDate','ALL','WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],GLMFigFileName,[GLMAreaComp],'SaveEachFrame',1);
            end
        end
        
        function varargout=SetupNeuralAnalysisOld(obj,data,TimingStimData,varargin) % OLD copy set up the analysis pipeline for population
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            %@data is usually the PSTH
            %@TimingStimData is timing and stimulus information
            
            %  Prepare variables
            AnalysisOpts.Xlabel=['Time(s) from ' strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ')];
            if obj.UsePCA4AxB
                AnalysisOpts.ExtaStrAnalysis='PCAxB';
            end
            if obj.UseFakeNeurons;AnalysisOpts.ExtraStr='Sim';end
            if ~isempty(data)
                Time=data(1).SpkCountTim{1}-AnalysisOpts.SpkParams.BaselineDelay;%obj.ManData.GenerateTimeAxis;
                NNeu=length(data);
                RasterTime=data(1).RasterTim{1}-AnalysisOpts.SpkParams.BaselineDelay;
                NTim=length(Time);
                obj.ManData.CopyVars2AnalysisOpts('Time',Time,'RasterTime',RasterTime,'NTim',NTim,'NNeu',NNeu);
            end
            %% deviding this function into processing steps so that we can
            %% run it in different modes
            varargout=cell(1,AnalysisOpts.NfigProcesStep(AnalysisOpts.ProcessingStep));
            switch AnalysisOpts.ProcessingStep
                case 1 % Calculate angle between Shape and Color subspaces for each rule pair in time
                    obj.SubspaceAnalysis_Learning(data,TimingStimData)
                    %
                    %                     [FactorizedData]=obj.GetFactorizedData(data,TimingStimData); % get factorized data
                    %                     obj.PCAonlyCorrTrls=1;
                    %                     TargetFactors= {'PrototypeObject','Rule'};%PrototypeObject
                    %                     [~,CatFactorData,FactorLevelComb,FactorLevels]=...
                    %                         obj.PrepareData4PCAnalysis(FactorizedData,TargetFactors,[]);
                    %                     PCA=obj.DoPCAanalysisMeanTrialTime(CatFactorData,FactorLevelComb,TargetFactors);
                    %
                    %                     % calculate angle of subspace planes
                    %                     [PairAngled,PairAngler,CosTheta,Pairs]=...
                    %                         arrayfun(@(x) obj.CalculateAnglesBetConds(PCA.score{x},FactorLevelComb,TargetFactors),1:NTim,'UniformOutput',0);
                    %                     PairAngled=cell2mat(cellfun(@transpose,PairAngled,'UniformOutput',0));
                    %                     PairAngler=cell2mat(cellfun(@transpose,PairAngler,'UniformOutput',0));
                    %                     CosTheta=cell2mat(cellfun(@transpose,CosTheta,'UniformOutput',0));
                    %
                    %                     % plot angle of subspace planes
                    %                     [smothCosTheta,TimeInd]=obj.ManData.SmoothData(CosTheta,10,'SmoothingMethod','movmean');
                    %                     figure;plot(Time(TimeInd),smothCosTheta,'LineWidth',3)
                    %                     legend({'R1-R2','R1-R3','R2-R3'});
                    %                     title(['Cos angle bet planes' TargetFactors ])
                    %                     xlabel(AnalysisOpts.Xlabel);
                    %                     ylabel('Cos(theta)')
                    %
                    %                     % show planes in PC space and generate a movie
                    %                     for i=1:NTim
                    %                         cla
                    %                         obj.PlotPCAanalysis(PCA.score{i},FactorLevelComb,TargetFactors);
                    %                         title([TargetFactors{1} ' ' AnalysisOpts.Xlabel '=' num2str(AnalysisOpts.Time(i)*1000) 'ms'])
                    %                         pause(0.1)
                    %                         mvFrame(i)=getframe(gcf);
                    %                         xlabel('PC1');ylabel('PC2');zlabel('PC3')
                    %                         grid on
                    %                     end
                    %                     MakeMovieFromFrames(mvFrame,0.75,[TargetFactors{1} '_planePCATrlTime'])
                    %% plot evolution of Color and Shape subspace in time
                    % [FactorizedData]=obj.GetFactorizedData(data,TimingStimData); % get factorized data
                    %                     TargetFactors= {'AllObjects','Rule'};
                    %                     Rule=[1 3];
                    %                     [FactorData,CatFactorData,FactorLevelComb,FactorLevels,ObjComb]=...
                    %                         obj.PrepareData4PCAnalysis(FactorizedData,TargetFactors,{[AnalysisOpts.StimulusMorphLevels],[Rule]});
                    %
                    %                     PCA=obj.DoPCAanalysisMeanTrialTime(CatFactorData,FactorLevelComb,TargetFactors);
                    %                     obj.PlotSubspaceinTime(PCA,FactorLevelComb,TargetFactors,ObjComb)
                    %                     title([TargetFactors ' PCA Time Trial'])
                    %
                    %                     figure
                    %                     PCA=obj.DoPCAanalysisTimeCollapse(CatFactorData,FactorLevelComb,TargetFactors);
                    %                     obj.PlotSubspaceinTime(PCA,FactorLevelComb,TargetFactors,ObjComb)
                    %                     title([TargetFactors ' PCA Avg Time'])
                    %
                    %                     figure
                    %                     UmapProj=obj.DoUMAPanalysisTimeTrial(CatFactorData,FactorLevelComb,TargetFactors);
                    %                     obj.PlotSubspaceinTime(UmapProj,FactorLevelComb,TargetFactors,ObjComb)
                    %                     title([TargetFactors ' UMAP dim reduction'])
                    
                    %% plot subspace analysis results
                case 2
                    [SubspaceAnaResults,SubspaceAnaOpts]=obj.LoadSubspaceAnaResults(obj.SubspaceAna_TaskName,'CalShuff',0);
                    % load permutation results as well
                    [obj.SubspaceAna_Shuff]=obj.LoadSubspaceAnaResults(obj.SubspaceAna_TaskName,'CalShuff',1);
                    
                    %plot results from this condition
                    Conds=1:length(SubspaceAnaOpts.TestCond); % total number of conditions
                    h=arrayfun(@(x) obj.PlotSubspaceAnalysisResults(SubspaceAnaResults,SubspaceAnaOpts,SubspaceAnaOpts.Name,x),Conds,'UniformOutput',0);
                    
                    % save off the figures
                    [~,~,SubspaceAnaFigFileName]=obj.ManData.GetFileName(['Subspace'],['_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],SubspaceAnaFigFileName,[h{1}],'SaveEachFrame',1);
                    
                    %make movie of different conditions as well
                    % to make movie you need to have compelete matrixes so put AnalysisOpts.GetFullAxBdata=1
                    %  obj.MakeMovieAxBAnalysisResults(SubspaceAnaResults,SubspaceAnaOpts)
                    
                    if contains(SubspaceAnaOpts.Name,'Learning');return;end
                    
                    hComp=obj.PlotCompositionalityAnalysisResutls(SubspaceAnaResults,SubspaceAnaOpts);
                    
                    [~,~,SubspaceAnaFigFileName]=obj.ManData.GetFileName(['Subspace'],['_AxBCompositionality_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],SubspaceAnaFigFileName,[hComp],'SaveEachFrame',1);
                    
                    %% do classifier analysis
                case 3
                    if contains(obj.Classifier_TaskName,'2D') ||  contains(obj.Classifier_TaskName,'Learning')
                        % obj.CrossTemporalClassfierAnalysis2D(data,TimingStimData);
                        obj.CrossTemporalClassfierAnalysis2D_Learning(data,TimingStimData)
                    else
                        obj.CrossTemporalClassfierAnalysis(data,TimingStimData);
                    end
                    
                    %% plot classifier Analysis
                case 4
                    [ClassifierResults,ClassifierOpts]=obj.LoadClassiferResults(obj.Classifier_TaskName,'CalShuff',0);
                    % load permutation results as well
                    % [obj.ClassifierResults_Shuff]=obj.LoadClassiferResults(obj.Classifier_TaskName,'CalShuff',1);
                    % copy data from ClassifierOpts
                    obj.ManData.CopyVars2AnalysisOpts('Time',ClassifierOpts.AnalysisOpts.Time,'RasterTime',ClassifierOpts.AnalysisOpts.RasterTime,'NTim',ClassifierOpts.AnalysisOpts.NTim,'NNeu',ClassifierOpts.AnalysisOpts.NNeu);
                    
                    %plot results from this condition
                    Conds=1:length(ClassifierOpts.TestCond); % total number of conditions
                    if contains(obj.Classifier_TaskName,'2D')
                        h=arrayfun(@(x) obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CondDetail',x),Conds,'UniformOutput',0);
                    elseif contains(obj.Classifier_TaskName,'Learning')
                        h=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                        %h=arrayfun(@(x) obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'Learning',x),Conds,'UniformOutput',0);
                    else
                        % plot perfromance in all of the conditions
                        h1=obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'XTempPerf',[]);
                        % plot each individual condition
                        h2=arrayfun(@(x) obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CondDetail',x),Conds,'UniformOutput',0);
                        h=[{h1} h2];
                    end
                    % save off the figures
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h],'SaveEachFrame',1);
                    %% plot different conditions of classifier analysis and compare them
                case 5
                    Task2CompareName=AnalysisOpts.PopulationAna.Classifier_ComparisionNameSet{AnalysisOpts.PairNum};
                    fprintf(2,'\nPlotting Classfier Comparision on task:%s\n',Task2CompareName)
                    Tasks2Compare=obj.ClassifierComparisionOpts(Task2CompareName);
                    
                    % plot classifier analysis we have and compare them
                    for TskCompId=1:Tasks2Compare.NComparisons
                        Ind=strcmp(AnalysisOpts.PopulationAna.Classifier_TaskNameSet,Tasks2Compare.TaskInd{TskCompId});
                        ClassifierOptsTemp=obj.DefineClassifierTestOptions(AnalysisOpts.PopulationAna.Classifier_TaskNameSet{Ind});
                        FileNameSyntax=['_' ClassifierOptsTemp.Name '_' Tasks2Compare.Area{TskCompId} '_' Tasks2Compare.SpkCntStartFieldName{TskCompId} '_' Tasks2Compare.TrlSpkTimeFieldName{TskCompId} '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                        ClassifierResults{TskCompId}=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        ClassifierOpts{TskCompId}=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
                    end
                    % copy data from ClassifierOpts
                    obj.ManData.CopyVars2AnalysisOpts('Time',ClassifierOpts{1}.AnalysisOpts.Time,'RasterTime',ClassifierOpts{1}.AnalysisOpts.RasterTime,'NTim',ClassifierOpts{1}.AnalysisOpts.NTim,'NNeu',ClassifierOpts{1}.AnalysisOpts.NNeu);
                    
                    if contains(Task2CompareName,'2D')
                        h1=obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CompareConds',Tasks2Compare.Cond,Tasks2Compare);
                    else
                        h1=obj.PlotXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CompareConds',Tasks2Compare.Cond,Tasks2Compare);
                    end
                    % save off the figures
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName('Classifier',['_' Task2CompareName '_Compare_' AnalysisOpts.Area2look{1} '_' Tasks2Compare.SpkCntStartFieldName{1} '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h1],'SaveEachFrame',1);
                    %% estimation of intrinsic dimensionality of representation in time and conditions
                case 6
                    TargetFactors= {'AllObjects','Rule'};
                    Rule=[1 2 3];
                    [FactorData,CatFactorData,FactorLevelComb,FactorLevels]=...
                        obj.PrepareData4PCAnalysis(FactorizedData,TargetFactors,{[AnalysisOpts.StimulusMorphLevels],[Rule]});
                    PCA=obj.DoPCAanalysisSingTrialTime(FactorData,FactorLevelComb,TargetFactors);
                    %% charactrize subspace contents
                case 7
                    % SubspaceTasks{1}={'2D_Cat_Color_Shape','2D_Cat_Color_Resp_Xgen','2D_Cat_Color_Color_Xgen','Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Shape_Rule_Xgen_AltRule50NMS'};
                    SubspaceTasks{1}={'2D_Cat_Color_Shape','2D_Cat_Color_Resp_Xgen','2D_Cat_Color_Color_Xgen','Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule','Learning_Cat_Shape_Rule_Xgen_AltRule_HiPerf'};
                    SubspaceTasks{2}={'2D_Cat_Color_Shape_BalRespDir','2D_Cat_Color_Resp_Xgen_BalRespDir','2D_Cat_Color_Color_Xgen'};
                    
                    SubspaceTasks{3}={'Learning_Cat_Shape_Color_Xgen_AltRule','Learning_Cat_Shape_Color_Xgen_SameRule','Learning_Cat_Color_Color_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule','Learning_Cat_Color_Rule_Xgen_AltRule_HiPerf'};
                    
                    SubspaceTasks=SubspaceTasks{AnalysisOpts.PairNum};
                    %% plot classfier weights in color and shape in PCA space
                    %                     fprintf(2,'\nCharactrizing subspace contents')
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{1});
                    %                     h1=obj.CharactrizeSubspaces(ClassifierResults,ClassifierOpts);
                    %                     h1=num2cell(h1);
                    %
                    %                     % plot classifier weights in 1D and 2D in differrentCondtions
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{2});
                    %                     h2=obj.CharactrizeSharedSubspaces(ClassifierResults,ClassifierOpts);
                    %
                    %                     %% Quantify shared variances in color and response dimensions
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{3});
                    %                     h3=obj.QuantifySharedSubspaces(ClassifierResults,ClassifierOpts);
                    %
                    %% Quantify shared variances in during learning
                    obj.WidthSmoothing=10;    % what is width of our smooting
                    obj.WidthSmoothingDim2=2; % what is width of our smooting Dim2
                    h=[];
                    
                    AnalysisOpts.CurrentCh_Animal='ALL'; % we are looking at one recording for this
                    for S=1:length(SubspaceTasks)
                        [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{S});
                        h1=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                        h=[h h1];
                    end
                    ExtraTxt='Full';
                    %% quantify subspaces and relate them to behavioral model
                    %                     AnalysisOpts.CurrentCh_Animal='Silas'; % we are looking at one recording for this
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{6});
                    %                     h7=obj.QuantifySharedSubspaces_Learning(ClassifierResults,ClassifierOpts);
                    %
                    %                     [ClassifierResults,ClassifierOpts]= obj.LoadClassiferResults(SubspaceTasks{6});
                    %                     h8=obj.QuantifySubSpaceBhvCorr_Learning(ClassifierResults,ClassifierOpts);
                    
                    % save off the figures
                    [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['_SubSpaceAna' ExtraTxt num2str(AnalysisOpts.PairNum) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'SaveInResults',1,'WantedDate','ALL');
                    obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h],'SaveEachFrame',1);
                    %% concatinate classifer files together
                case 8
                    obj.ConcatinateClassifierFiles(obj.Classifier_TaskName)
                    %% concatinate subspace files together
                case 9
                    obj.ConcatinateSubspaceFiles(obj.SubspaceAna_TaskName)
                    %% single cell analysis functions
                    
                    %% Fit GLM models
                case 10
                    
                    Models2Test={'HybridbhvMdlFull','InferAFbhvMdlFull'};
                    
                    % <<<check if we are shuffleing the data>>>
                    obj.GLMshuffleFlag=AnalysisOpts.CalShuffleGLM;
                    cellfun(@(mdl) obj.FitGLMmdls2data(FactorizedData,'GLMmdl',mdl,'UseSavedData',0,'PlotResults',0,...
                        'GLMfitMethod','FactorOmit'),Models2Test,'UniformOutput',0);
                    
                    %% GLM model comparision(run on cluster)
                case 11
                    obj.GLMmodelComparision_Hierarchical(FactorizedData)
                    
                    %% plot GLM model comparision results
                case 12
                    np=3;
                    for Neu=AnalysisOpts.nCh_2look
                        close all
                        obj.TrialFunc.UpdateCurrentCh(Neu);
                        
                        %  [varargout{1:np}]       =obj.PlotGLMmodelComparision_Hierarchical('HybridbhvMdlFullReduce');
                        %  [varargout{np+1:2*np}]  =obj.PlotGLMmodelComparision_Hierarchical('InferAFbhvMdlFullReduce');
                        [varargout{1:np}]=obj.PlotGLMmodelComparision_Hierarchical('CompareBhvModels');
                        
                        [~,~,SingCellAnaFigsFileName]=obj.ManData.GetFileName([],...
                            ['SingCellAna' AnalysisOpts.ExtraStr '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName 'Prstp' num2str(AnalysisOpts.ProcessingStep)],...
                            'SaveInResults',1,'WantedDate',AnalysisOpts.CurrentCh_RecDate);
                        obj.FigParams.SaveFigSeries([],SingCellAnaFigsFileName,[varargout],'SaveEachFrame',0)
                    end
                    
                    %% generate a summery file for population or single cells
                case 13
                    nar=length(obj.TargetArea);
                    np=2*nar;AnalysisOpts.np=np;
                    
                    obj.CreateNeuronSummeryFile;
                    
                    %[varargout{(1:np)}]       =obj.PlotSignificantGLMfactors([],'HybridbhvMdlFull','PlotResults',1);
                    %                     [varargout{(1:np)}]       =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                     obj.TrialFunc.RevertCh_2look;
                    %                     [varargout{(np+1:2*np)}]  =obj.PlotSignificantGLMfactors([],'SensoryMotorMdl','PlotResults',1);
                    %                     obj.TrialFunc.RevertCh_2look;
                    %                     [varargout{(2*np+1:3*np+1)}]=obj.PlotSignificantGLMfactors('CompareBhvModels','','PlotResults',1);
                    
                    % now plot model comparision results
                    %   obj.TrialFunc.RevertCh_2look;
                    %      [varargout{(1:np)}]       =obj.PlotSignificantGLMfactors('CompareBhvModels','','PlotResults',1);
                    
                    %% generate a summery plot for population or single cells
                case 14
                    
                    % Plot Information by Area
                    %   obj.PlotInformaitonByArea(Time,factornames,'')
                    % [varargout{2:3}]=obj.PlotwPEVbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames);
                    % [varargout{5:6}]=obj.PlotInformationbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames);
                    
                    % plot basic charactristics of the neuron
                    %                     [varargout{1}]=obj.PlotResponseLatencies(FactorizedData,Time);
                    %                     [varargout{2}]=obj.PlotPSTHbyFactor(FactorizedData,Time,FactorizedData(Neu).factornames(1:9));
                    %                     [varargout{3:4}]=obj.PlotTuningCurvesbyFactor(FactorizedData_Raster,RasterTime,{'ColorML','ShapeML'});
                    
                    % plot GLM models
                    base=4;
                    nar=length(obj.TargetArea);
                    np=2*nar;AnalysisOpts.np=np;
                    [varargout{base+(1:np)}]       =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                   obj.TrialFunc.RevertCh_2look;
                    %                   [varargout{base+(np+1:2*np)}]  =obj.PlotSignificantGLMfactors([],'InferAFbhvMdlFull','PlotResults',1);
                    %                   obj.TrialFunc.RevertCh_2look;
                    %                   [varargout{base+(2*np+1:3*np)}]=obj.PlotSignificantGLMfactors([],'SensoryMotorMdl','PlotResults',1);
                    %
                    %                   % plot GLM model comparison results
                    %                   [varargout{base+3*np+(1:3)}]=obj.PlotGLMmodelComparision_Hierarchical('CompareBhvModels');
                    
            end
        end
        
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Low Dimensional Subspace Analysis METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        function [SubspaceAnaOpts,obj]=DefineSubspaceAnaTestOptions(obj,TestName,varargin) % prepare options for each type of low dimensional subspacetest we want to run
            %@TestName name of the test we want to do e.g. 'XTemp_Rule' 'XTemp_Cat_Color' 'XTemp_Cat_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isscalar(TestName);TestName=AnalysisOpts.PopulationAna.SubspaceAna_TaskNameSet{TestName};end
            
            SubspaceAnaOpts.Nrep=100;
            SubspaceAnaOpts.NrepShuf=100;
            SubspaceAnaOpts.MeanSubtractByRule=0; % are we zero meaning each rule before doing analysis
            % get indices for future use
            SubspaceAnaOpts.Congruency.Ind   =strcmp(AnalysisOpts.factornames,'Congruency');
            SubspaceAnaOpts.Reward.Ind       =strcmp(AnalysisOpts.factornames,'Reward');
            SubspaceAnaOpts.ResponseLoc.Ind  =strcmp(AnalysisOpts.factornames,'ResponseLoc');
            SubspaceAnaOpts.ColorML.Ind      =strcmp(AnalysisOpts.factornames,'ColorML');
            SubspaceAnaOpts.ShapeML.Ind      =strcmp(AnalysisOpts.factornames,'ShapeML');
            SubspaceAnaOpts.ColorCat.Ind     =strcmp(AnalysisOpts.factornames,'ColorCat');
            SubspaceAnaOpts.ShapeCat.Ind     =strcmp(AnalysisOpts.factornames,'ShapeCat');
            SubspaceAnaOpts.Rule.Ind         =strcmp(AnalysisOpts.factornames,'Rule');
            SubspaceAnaOpts.SeqHist.Ind      =strcmp(AnalysisOpts.factornames,'SeqHist');
            % define values for each factor
            SubspaceAnaOpts.Congruency.Val   =[0 1];
            SubspaceAnaOpts.Reward.Val       =[0 1];
            SubspaceAnaOpts.ResponseLoc.Val  =[1 2 3 4];
            SubspaceAnaOpts.ResponseLoc.ValRule={[1 2],[3 4],[1 2]};
            SubspaceAnaOpts.ColorML.Val      =AnalysisOpts.StimulusMorphLevels;
            SubspaceAnaOpts.ShapeML.Val      =AnalysisOpts.StimulusMorphLevels;
            SubspaceAnaOpts.ColorCat.Val     =[1 2];
            SubspaceAnaOpts.ShapeCat.Val     =[1 2];
            SubspaceAnaOpts.Rule.Val         =[1 2 3];
            SubspaceAnaOpts.SeqHist.Val      =[0 1];
            % all of the combinations of train and test
            SubspaceAnaOpts.TrainAllCombs={[1],[2],[3],[2],[3],[1]};
            SubspaceAnaOpts.TestAllCombs ={[2],[3],[1],[1],[2],[3]};
            SubspaceAnaOpts.AllCombPlotPair={[1 4],[2 5],[3 6]}; %pairs of conditions to be plotted together
            SubspaceAnaOpts.ColorOnRule=1; %color results based on their rule
            SubspaceAnaOpts.NTrlStpLearning=5; % steps for learning
            
            switch TestName
                case 'Learning_Cat_Shape_Color_Xgen_AltRule'  % Train and test of category of color simoultanously for two rules
                    SubspaceAnaOpts.Name='Learning_Shape_Color Category AltRule';
                    SubspaceAnaOpts.Rule=[1 2 3];
                    SubspaceAnaOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    SubspaceAnaOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    SubspaceAnaOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
                    SubspaceAnaOpts.Levels={[1 2],[SubspaceAnaOpts.Rule]};
                    SubspaceAnaOpts.Levels_2ndD={[1 2],[SubspaceAnaOpts.Rule]}; % second dimension levels
                    SubspaceAnaOpts.type={'DoubleCrossCond'};
                    SubspaceAnaOpts.TrainCond ={[1]};
                    SubspaceAnaOpts.TrainCond2={[2]};
                    SubspaceAnaOpts.TestCond  ={[3]};
                    SubspaceAnaOpts.TestCond2 ={[3]};
                    SubspaceAnaOpts.ntrlPerCond=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.ntrlPerCondTest=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.StimCongruency=10; % balance congruency and seqhist
                    SubspaceAnaOpts.TrialType=1; % correct trials
                    SubspaceAnaOpts.caxis_limits=[0.3 1];
                    SubspaceAnaOpts.TrainTrlNumRange={[-1 -75 75 0]};
                    SubspaceAnaOpts.TestTrlNumRange ={[1 125 75 SubspaceAnaOpts.NTrlStpLearning]};
                    SubspaceAnaOpts.ParamMdlRDM_type={'OrthogonalShapeColor','ParallelColor'}; % type of model RDM
                    SubspaceAnaOpts.RSAAnalysisType='Learning';
                    SubspaceAnaOpts.MeanSubtractByRule=0;
                    SubspaceAnaOpts.fmincon_N_ITERS=100; % number for itrations for fmincon fits
                    SubspaceAnaOpts.LimitFromSwitchPerf={[nan 0.6]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    SubspaceAnaOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    SubspaceAnaOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    if  strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START')
                        TimeRng=(-400:20:400)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON')
                        TimeRng=(-200:20:600)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    end
                case 'Learning_Cat_Color_Color_Xgen_AltRule'  % Train and test of category of color simoultanously for two rules
                    SubspaceAnaOpts.Name='Learning_Color_Color Category AltRule';
                    SubspaceAnaOpts.Rule=[1 2 3];
                    SubspaceAnaOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    SubspaceAnaOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    SubspaceAnaOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
                    SubspaceAnaOpts.Levels={[1 2],[SubspaceAnaOpts.Rule]};
                    SubspaceAnaOpts.Levels_2ndD={[1 2],[SubspaceAnaOpts.Rule]}; % second dimension levels
                    SubspaceAnaOpts.type={'DoubleCrossCond'};
                    SubspaceAnaOpts.TrainCond ={[3]};
                    SubspaceAnaOpts.TrainCond2={[2]};
                    SubspaceAnaOpts.TestCond  ={[3]};
                    SubspaceAnaOpts.TestCond2 ={[3]};
                    SubspaceAnaOpts.ntrlPerCond=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.ntrlPerCondTest=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.StimCongruency=10; % balance congruency and seqhist
                    SubspaceAnaOpts.TrialType=1; % correct trials
                    SubspaceAnaOpts.caxis_limits=[0.3 1];
                    SubspaceAnaOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    SubspaceAnaOpts.TestTrlNumRange ={[1 125 50 SubspaceAnaOpts.NTrlStpLearning]};
                    SubspaceAnaOpts.ParamMdlRDM_type={'ParallelColor','ParallelColor'}; % type of model RDM
                    SubspaceAnaOpts.RSAAnalysisType='Learning';
                    SubspaceAnaOpts.MeanSubtractByRule=0;
                    SubspaceAnaOpts.Nrep=100;
                    SubspaceAnaOpts.fmincon_N_ITERS=100; % number for itrations for fmincon fits
                    SubspaceAnaOpts.LimitFromSwitchPerf={[nan 0.6]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    SubspaceAnaOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    SubspaceAnaOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    if  strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START')
                        TimeRng=(-400:20:400)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON')
                        TimeRng=(-200:20:600)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    end
                case 'Sensory_Motor_Transformation'  % Train and test of category of color simoultanously for two rules
                    SubspaceAnaOpts.Name='Sensory Motor Transformation';
                    SubspaceAnaOpts.Rule=[1 2 3];
                    SubspaceAnaOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    SubspaceAnaOpts.TargetFactors_2ndD={'ColorML','Rule'}; % target factor for the second dimension
                    SubspaceAnaOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
                    SubspaceAnaOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[SubspaceAnaOpts.Rule]};
                    SubspaceAnaOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevels],[SubspaceAnaOpts.Rule]}; % second dimension levels
                    SubspaceAnaOpts.type={'DoubleCrossCond'};
                    SubspaceAnaOpts.TrainCond ={[1]};
                    SubspaceAnaOpts.TrainCond2={[3]};
                    SubspaceAnaOpts.TestCond  ={[2]};
                    SubspaceAnaOpts.TestCond2 ={[2]};
                    SubspaceAnaOpts.ntrlPerCond=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.ntrlPerCondTest=[5 5];   % number of trials per condition of congruency
                    SubspaceAnaOpts.StimCongruency=4; % balance congruency only
                    SubspaceAnaOpts.TrialType=1; % correct trials
                    SubspaceAnaOpts.caxis_limits=[0.3 1];
                    %  SubspaceAnaOpts.TrainTrlNumRange={[1 500 500 0]}; % take all of the trials <<Try to take last 50 trials>>
                    SubspaceAnaOpts.TrainTrlNumRange={[-1 -100 100 0]}; % take all of the trials <<Try to take last 50 trials>>
                    SubspaceAnaOpts.TestTrlNumRange ={[1 500 500 0]}; % take all of the trials
                    SubspaceAnaOpts.ParamMdlRDM_type={'OrthogonalShapeColor','ParallelColor'}; % type of model RDM
                    SubspaceAnaOpts.RSAAnalysisType='SensoryMotorTransform';
                    SubspaceAnaOpts.MeanSubtractByRule=0;
                    %  SubspaceAnaOpts.Nrep=3;
                    SubspaceAnaOpts.fmincon_N_ITERS=100; % number for itrations for fmincon fits
                    SubspaceAnaOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    SubspaceAnaOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    SubspaceAnaOpts.SeqHistCond={[nan]}; % Seqhist value for this condition
                    if  strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START')
                        TimeRng=(-400:20:400)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON')
                        TimeRng=(-200:20:600)*0.001;
                        SubspaceAnaOpts.SpkCountPeriod=[TimeRng' TimeRng'+obj.PSTH_Bin]; % spike count time period for sensory and response
                    end
            end
            nConds=length(SubspaceAnaOpts.TrainCond);
            % fill some missing variables
            if sum(SubspaceAnaOpts.ntrlPerCond)~=(SubspaceAnaOpts.ntrlPerCond(1)*length(SubspaceAnaOpts.ntrlPerCond))
                error('number of trials/condition must be equal')
            end
            if ~isfield(SubspaceAnaOpts,'TrainTrlNumRange')
                SubspaceAnaOpts.TrainTrlNumRange=repmat({[0 0 0 0]},[1 nConds]); % include all trails
                SubspaceAnaOpts.TestTrlNumRange =repmat({[0 0 0 0]},[1 nConds]); % include all trails
            end
            SubspaceAnaOpts.RunCrossTemporalClassifer=obj.RunCrossTemporalClassifer;
            NConds=length(SubspaceAnaOpts.TrainCond);
            if ~isfield(SubspaceAnaOpts,'ntrlPerCondTest');SubspaceAnaOpts.ntrlPerCondTest=ceil(SubspaceAnaOpts.ntrlPerCond/2);end
            % update obj.SpkCountPeriod if we have values in SubspaceAnaOpts.SpkCountPeriod
            if ~isfield(SubspaceAnaOpts,'SpkCountPeriod');SubspaceAnaOpts.SpkCountPeriod=[];end
            % update one-class response label for both dimensions
            if ~isfield(SubspaceAnaOpts,'One_Class_ResponseLbl');SubspaceAnaOpts.One_Class_ResponseLbl=cell(1,NConds);end
            if ~isfield(SubspaceAnaOpts,'One_Class_ResponseLbl2');SubspaceAnaOpts.One_Class_ResponseLbl2=cell(1,NConds);end
            % if we are running cross temporal then change file name
            if obj.RunCrossTemporalClassifer==1;SubspaceAnaOpts.Nrep=50;SubspaceAnaOpts.Name=[SubspaceAnaOpts.Name '_XTMP'];end
            % if we have mean subtracted each rule then show it
            if SubspaceAnaOpts.MeanSubtractByRule==1;SubspaceAnaOpts.Name=[SubspaceAnaOpts.Name '_MS'];end
            % if we have zscore and detrend the data then add it to the name
            if obj.ZscoreFactorData==1;SubspaceAnaOpts.Name=[SubspaceAnaOpts.Name '_ZS'];end
            % if we have detrended the data then add it to the name
            if obj.DetrendFactorData==1;SubspaceAnaOpts.Name=[SubspaceAnaOpts.Name '_DT'];end
            
            SubspaceAnaOpts.AnaType='AxB';
        end
        function SubspaceAnalysis_Learning(obj,data,TimingStimData,varargin) % run 2D subspace analysis during learning
            %@data PSTH data
            %@TimingStimData Timing data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            fprintf(2,'\nRunning Subspace Analysis on task:%s\n',obj.SubspaceAna_TaskName)
            % define what type of test we want to do
            SubspaceAnaOpts=obj.DefineSubspaceAnaTestOptions(obj.SubspaceAna_TaskName);
            [FactorizedData]=obj.GetFactorizedData(data,TimingStimData,0,'MeanSubtractByRule',SubspaceAnaOpts.MeanSubtractByRule,'SpkCountPeriod',SubspaceAnaOpts.SpkCountPeriod); % get factorized data
            
            % grab all of the relevant data for this test and also add the raster data
            [FactorData,~,FactorLevelComb,~]=obj.PrepareData4ClassifierAnalysis(FactorizedData,SubspaceAnaOpts);
            
            % run cross temporal classifer analysis
            [SubspaceAnaResults,SubspaceAnaOpts]=obj.RunSubspaceAnalysis_Learning(FactorData,FactorLevelComb,SubspaceAnaOpts);
            
        end
        function [SubspaceAnaResults,SubspaceAnaOpts]=RunSubspaceAnalysis_Learning(obj,FactorData,FactorLevelComb,SubspaceAnaOpts,varargin) % runs subspace analysis during learning
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % if this is a calculation of shuffled distribution then
            % prepare the data
            if AnalysisOpts.CalShuffleSubspace | AnalysisOpts.CalShuffleAxB
                ShuffTxt=sprintf('Shuf_C%i_',AnalysisOpts.CalShuffleSubspace_Cond);
                rng(AnalysisOpts.CalShuffleSubspace_Cond);
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.CalShuffleSubspace_TrlRng(x),1:length(SubspaceAnaOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.CalShuffleSubspace_TrlRng(x)),1:length(SubspaceAnaOpts.TrainCond),'UniformOutput',0));
                nCondsTot=length(CondInds);
                % find which condition we are looking at
                ThisCondLoc=mod(AnalysisOpts.CalShuffleSubspace_Cond,nCondsTot);%
                ThisCondLoc(ThisCondLoc==0)=nCondsTot;
                CondSet  =CondInds(ThisCondLoc);  % condition
                TrlRngSet=TrlRngInds(ThisCondLoc); % trial range
                RepSet=ceil(AnalysisOpts.CalShuffleSubspace_Cond/nCondsTot); % AnalysisOpts.DividSpockSubspace_Cond repetition
                
            elseif AnalysisOpts.DividSpockSubspace
                ShuffTxt=sprintf('C%i_',AnalysisOpts.DividSpockSubspace_Cond);
                rng(AnalysisOpts.DividSpockSubspace_Cond);
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockSubspace_TrlRng(x),1:length(SubspaceAnaOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockSubspace_TrlRng(x)),1:length(SubspaceAnaOpts.TrainCond),'UniformOutput',0));
                nCondsTot=length(CondInds);
                % find which condition we are looking at
                ThisCondLoc=mod(AnalysisOpts.DividSpockSubspace_Cond,nCondsTot);%
                ThisCondLoc(ThisCondLoc==0)=nCondsTot;
                CondSet  =CondInds(ThisCondLoc);  % condition
                TrlRngSet=TrlRngInds(ThisCondLoc); % trial range
                RepSet=ceil(AnalysisOpts.DividSpockSubspace_Cond/nCondsTot); % AnalysisOpts.DividSpockSubspace_Cond repetition
            else
                ShuffTxt='';
                CondSet=1:length(SubspaceAnaOpts.TrainCond);
                RepSet=1:SubspaceAnaOpts.Nrep;
            end
            
            % now create a mesh of time points and run classifier train and test repectively
            [SubspaceAnaOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(SubspaceAnaOpts);
            
            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,SubspaceAnaOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,SubspaceAnaOpts,FactorLevelComb);
            
            SubspaceAnaOpts.typebuff=SubspaceAnaOpts.type; % take a copy of t
            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                % if there is SeqHist you should consider them first
                if SubspaceAnaOpts.StimCongruency==9 || SubspaceAnaOpts.StimCongruency==10; obj.SeqHistCond=SubspaceAnaOpts.SeqHistCond{Cond};end
                if iscell(SubspaceAnaOpts.type);type=SubspaceAnaOpts.type{Cond};else;type=SubspaceAnaOpts.type;end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=obj.GetTrialRangeforThisCond(SubspaceAnaOpts,Cond);
                
                if ~(AnalysisOpts.DividSpockSubspace | AnalysisOpts.CalShuffleSubspace) ;TrlRngSet=1:nXTrlPnt;end
                
                for nTrlRng=1:length(TrlRngSet)
                    TrlRng=TrlRngSet(nTrlRng);
                    
                    ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                    
                    % now limit factor data trials to these trial range we want
                    % generate factor data for training
                    FactorData    =obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                    
                    % if we are limitign based on block performance then
                    if isfield(SubspaceAnaOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',SubspaceAnaOpts.LimitFromSwitchPerf{Cond}(1),SubspaceAnaOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',SubspaceAnaOpts.LimitFromSwitchPerf{Cond}(2),SubspaceAnaOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                    
                    for nrep=1:length(RepSet)        % loop on repetition per condition
                        tic
                        rep=RepSet(nrep);
                        %    waitbar(rep/ClassifierOpts.Nrep,f,sprintf('repetition:%i',rep))
                        fprintf('\nRunning Subspace Analysis on Condition Train1:%s Test1:%s | Train2:%s Test2:%s TrlRng:%i Rep:%i',obj.ManData.ConvMat2Char(SubspaceAnaOpts.TrainCond{Cond}),...
                            obj.ManData.ConvMat2Char(SubspaceAnaOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(SubspaceAnaOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(SubspaceAnaOpts.TestCond2{Cond}),TrlRng,rep);
                        isok=0;
                        while isok==0 % make sure we have enough trials for both categories in both dimensions
                            % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                            if ~strcmp(type,'SameCond')
                                % grab random set of data
                                [predictors ,response , TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,SubspaceAnaOpts,SubspaceAnaOpts.TrainCond{Cond},...
                                    SubspaceAnaOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange);
                                
                                [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,~,~,predictors2SpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,SubspaceAnaOpts,SubspaceAnaOpts.TrainCond2{Cond},...
                                    SubspaceAnaOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',1);
                                
                                % if we are using the same dataset for training in both dimensions then match the trials
                                if SubspaceAnaOpts.TrainCond2{Cond}==SubspaceAnaOpts.TrainCond{Cond}
                                    if sum(SubspaceAnaOpts.TestCond{Cond}==SubspaceAnaOpts.TrainCond{Cond})
                                        predictors2{1}=predictors{1};
                                        response2{1}=response{1};
                                        Train2DataAllFactors=TrainDataAllFactors;
                                        if ~isempty(SubspaceAnaOpts.SpkCountPeriod)
                                            predictors2SpkCnt{1}=predictorsSpkCnt{1};
                                        end
                                    else
                                        predictors{1}=predictors2{1};
                                        response{1}=response2{1};
                                        TrainDataAllFactors=Train2DataAllFactors;
                                        if ~isempty(SubspaceAnaOpts.SpkCountPeriod)
                                            predictorsSpkCnt{1}=predictors2SpkCnt{1};
                                        end
                                    end
                                end
                                
                                if SubspaceAnaOpts.TestCond2{Cond}==SubspaceAnaOpts.TestCond{Cond}
                                    if sum(SubspaceAnaOpts.TestCond{Cond}==SubspaceAnaOpts.TrainCond2{Cond}) % if we have a condition in which train=3/2 and test=2/2 then we make sure we use different sets for train and test
                                        predictors{2}=predictors2{2};
                                        response{2}=response2{2};
                                        TestDataAllFactors=Test2DataAllFactors;
                                        if ~isempty(SubspaceAnaOpts.SpkCountPeriod)
                                            predictorsSpkCnt{2}=predictors2SpkCnt{2};
                                        end
                                    else
                                        predictors2{2}=predictors{2};
                                        response2{2}=response{2};
                                        Test2DataAllFactors=TestDataAllFactors;
                                        if ~isempty(SubspaceAnaOpts.SpkCountPeriod)
                                            predictors2SpkCnt{2}=predictorsSpkCnt{2};
                                        end
                                    end
                                end
                            elseif strcmp(type,'SameCond') % if we are testing the same condition then take data from the same condition
                                % grab random set of data
                                [predictors,response, TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,SubspaceAnaOpts,SubspaceAnaOpts.TrainCond{Cond},SubspaceAnaOpts.TestCond{Cond},FactorLevelComb,Cond,FactorData,ThisTrainTrialRange,ThisTestTrialRange);
                                
                                predictors2=predictors;
                                response2=response;
                                Train2DataAllFactors=TrainDataAllFactors;
                                Test2DataAllFactors=TestDataAllFactors;
                                if ~isempty(SubspaceAnaOpts.SpkCountPeriod)
                                    predictors2SpkCnt=predictorsSpkCnt;
                                end
                            end
                            
                            %                             if ~obj.CalShuff
                            %                                 % save the factor data
                            %                                 FactorInds2Keep=1:2; % just keep ColorML and ShapeML data
                            %                                 SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).TrainDataAllFactors =TrainDataAllFactors(:,FactorInds2Keep);
                            %                                 SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).TestDataAllFactors  =TestDataAllFactors(:,FactorInds2Keep);
                            %                                 SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Train2DataAllFactors=Train2DataAllFactors(:,FactorInds2Keep);
                            %                                 SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Test2DataAllFactors =Test2DataAllFactors(:,FactorInds2Keep);
                            %                             end
                            
                            % now get train/test data on the second factor as well
                            TargetFactors_2ndDInd=obj.GetFactornameInd(SubspaceAnaOpts.TargetFactors_2ndD{1});
                            DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
                            if isempty(SubspaceAnaOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                                DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
                            else
                                DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
                            end
                            
                            if contains(SubspaceAnaOpts.Name,'Category') & sum(strcmp(SubspaceAnaOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(SubspaceAnaOpts.TargetFactors_2ndD{1},'ColorML'))
                                DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                                DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                            end
                            response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                            
                            % check so that the labels are the same as what we have specificed for the second dimension
                            if iscell(SubspaceAnaOpts.Levels_2ndD{1})
                                Levels_2ndD_Train=SubspaceAnaOpts.Levels_2ndD{1}{SubspaceAnaOpts.TrainCond2{Cond}==SubspaceAnaOpts.Levels_2ndD{2}};
                                Levels_2ndD_Test =SubspaceAnaOpts.Levels_2ndD{1}{SubspaceAnaOpts.TestCond2{Cond}==SubspaceAnaOpts.Levels_2ndD{2}};
                            elseif contains(SubspaceAnaOpts.Name,'Category') & sum(strcmp(SubspaceAnaOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(SubspaceAnaOpts.TargetFactors_2ndD{1},'ColorML'))
                                Levels_2ndD_Train=[1 2];
                                Levels_2ndD_Test =[1 2];
                            else
                                Levels_2ndD_Train=SubspaceAnaOpts.Levels_2ndD{1};
                                Levels_2ndD_Test =SubspaceAnaOpts.Levels_2ndD{1};
                            end
                            
                            if (length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |...
                                    ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                    ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                    isnan(SubspaceAnaOpts.One_Class_ResponseLbl2{Cond})
                                isok=0;
                            else
                                isok=1;
                            end
                        end
                        
                        if AnalysisOpts.CalShuffleSubspace % shuffle training data
                            response{1}=response{1}(randperm(numel(response{1})));
                            response_2ndD{1}=response_2ndD{1}(randperm(numel(response_2ndD{1})));
                        end
                        
                        SubspaceAnaOpts.ConcatinateMethod='SepTimePoint';
                        % Run subspace analysis on different time points   % do combined analysis of the subspaces
                        [Subspace1,FactorLvLInds1,FactorLvLData1,FactorLevels1] =obj.DiscoverSubspaces(cat(1,predictors{1},predictors{2}),SubspaceAnaOpts,[TrainDataAllFactors;TestDataAllFactors],[ones(1,size(predictors{1},1)) 2*ones(1,size(predictors{2},1))]);
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PairAngled,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).CosTheta]        =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace1.CondScore{1}{x} Subspace1.CondScore{2}{x}},[]),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad3DAngled,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad3DCosTheta]=arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace1.CondScore{1}{x} Subspace1.CondScore{2}{x}},{'Shape','Color'},3),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad2DAngled,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad2DCosTheta]=arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace1.CondScore{1}{x} Subspace1.CondScore{2}{x}},{'Shape','Color'},2),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).SubspaceCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(Subspace1.CondScore{1}(x)),1:AnalysisOpts.NTim);  % Calculates compression for each subspace
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).SubspaceCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(Subspace1.CondScore{2}(x)),1:AnalysisOpts.NTim);  % Calculates compression for each subspace
                        
                        % Run subspace analysis on different time points on the second dimension
                        [Subspace2,FactorLvLInds2,FactorLvLData2,FactorLevels2] =obj.DiscoverSubspaces(cat(1,predictors2{1},predictors2{2}),SubspaceAnaOpts,[Train2DataAllFactors;Test2DataAllFactors],[ones(1,size(predictors2{1},1)) 2*ones(1,size(predictors2{2},1))]);
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PairAngled2,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).CosTheta2]        =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace2.CondScore{1}{x} Subspace2.CondScore{2}{x}},[]),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad3DAngled2,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad3DCosTheta2]=arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace2.CondScore{1}{x} Subspace2.CondScore{2}{x}},{'Color','Color'},3),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad2DAngled2,~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Quad2DCosTheta2]=arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace2.CondScore{1}{x} Subspace2.CondScore{2}{x}},{'Color','Color'},2),1:AnalysisOpts.NTim); % calculates angles between the planes that are fit to each condition
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Subspace2Compression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(Subspace2.CondScore{1}(x)),1:AnalysisOpts.NTim);  % Calculates compression for each subspace
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).Subspace2Compression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(Subspace2.CondScore{2}(x)),1:AnalysisOpts.NTim);  % Calculates compression for each subspace
                        
                        % if we have any spike count classification that we need to do then do that
                        for SpkCnt=1:size(SubspaceAnaOpts.SpkCountPeriod,1)
                            % do combined analysis of the subspaces
                            [Subspace1SpkCnt{SpkCnt},FactorLvLInds1SpkCnt{SpkCnt},FactorLvLData1SpkCnt{SpkCnt},FactorLevels1SpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,predictorsSpkCnt{1}{SpkCnt},predictorsSpkCnt{2}{SpkCnt}),SubspaceAnaOpts,[TrainDataAllFactors;TestDataAllFactors],[ones(1,size(predictors{1},1)) 2*ones(1,size(predictors{2},1))]);
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['PairAngled_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['CosTheta_SpkCntPrd' num2str(SpkCnt)])]=obj.CalculateAnglesBetSubspaces({Subspace1SpkCnt{SpkCnt}.CondScore{1}{1} Subspace1SpkCnt{SpkCnt}.CondScore{2}{1}},[]); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad3DAngled_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad3DCosTheta_SpkCntPrd' num2str(SpkCnt)])]  =obj.CalculateAnglesBetSubspaces({Subspace1SpkCnt{SpkCnt}.CondScore{1}{1} Subspace1SpkCnt{SpkCnt}.CondScore{2}{1}},{'Shape','Color'},3); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad2DAngled_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad2DCosTheta_SpkCntPrd' num2str(SpkCnt)])]  =obj.CalculateAnglesBetSubspaces({Subspace1SpkCnt{SpkCnt}.CondScore{1}{1} Subspace1SpkCnt{SpkCnt}.CondScore{2}{1}},{'Shape','Color'},2); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['SubspaceCompression1_SpkCntPrd' num2str(SpkCnt)])]= obj.CalculateCompressionBetSubspaces(Subspace1SpkCnt{SpkCnt}.CondScore{1}(1));  % Calculates compression for each subspace
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['SubspaceCompression2_SpkCntPrd' num2str(SpkCnt)])]= obj.CalculateCompressionBetSubspaces(Subspace1SpkCnt{SpkCnt}.CondScore{2}(1));  % Calculates compression for each subspace
                            
                            % run geometry analysis for the second dimension
                            [Subspace2SpkCnt{SpkCnt},FactorLvLInds2SpkCnt{SpkCnt},FactorLvLData2SpkCnt{SpkCnt},FactorLevels2SpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,predictors2SpkCnt{1}{SpkCnt},predictors2SpkCnt{2}{SpkCnt}),SubspaceAnaOpts,[TrainDataAllFactors;TestDataAllFactors],[ones(1,size(predictors{1},1)) 2*ones(1,size(predictors{2},1))]);
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['PairAngled2_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['CosTheta2_SpkCntPrd' num2str(SpkCnt)])] =obj.CalculateAnglesBetSubspaces({Subspace2SpkCnt{SpkCnt}.CondScore{1}{1} Subspace2SpkCnt{SpkCnt}.CondScore{2}{1}},[]); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad3DAngled2_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad3DCosTheta2_SpkCntPrd' num2str(SpkCnt)])]   =obj.CalculateAnglesBetSubspaces({Subspace2SpkCnt{SpkCnt}.CondScore{1}{1} Subspace2SpkCnt{SpkCnt}.CondScore{2}{1}},{'Shape','Color'},3); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad2DAngled2_SpkCntPrd' num2str(SpkCnt)]),~,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Quad2DCosTheta2_SpkCntPrd' num2str(SpkCnt)])]   =obj.CalculateAnglesBetSubspaces({Subspace2SpkCnt{SpkCnt}.CondScore{1}{1} Subspace2SpkCnt{SpkCnt}.CondScore{2}{1}},{'Shape','Color'},2); % calculates angles between the planes that are fit to each condition
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Subspace2Compression1_SpkCntPrd' num2str(SpkCnt)])]= obj.CalculateCompressionBetSubspaces(Subspace2SpkCnt{SpkCnt}.CondScore{1}(1));  % Calculates compression for each subspace
                            [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).(['Subspace2Compression2_SpkCntPrd' num2str(SpkCnt)])]= obj.CalculateCompressionBetSubspaces(Subspace2SpkCnt{SpkCnt}.CondScore{2}(1));  % Calculates compression for each subspace
                        end
                        
                        %% perfrom AxB analysis on both dimensions
                        [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis1,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis2,...
                            SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis3,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis4,...
                            SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis5,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_Analysis6,SubspaceAnaResults(Cond).AxBAnalysisTitles]=...
                            obj.RunMultipleAxBanalysisonSubspace(FactorLvLData1SpkCnt,FactorLvLData2SpkCnt,FactorLvLInds1SpkCnt,FactorLevels1SpkCnt,SubspaceAnaOpts,SubspaceAnaOpts.RSAAnalysisType,Cond);
                        
                        if ~(AnalysisOpts.CalShuffleSubspace | AnalysisOpts.CalShuffleAxB) && ~contains(SubspaceAnaOpts.Name,'Learning')
                            SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).AxBresults_CompAnalysis=obj.RunAxBCompositionalityAnalysis(FactorLvLData1SpkCnt,FactorLvLData2SpkCnt,FactorLvLInds1SpkCnt,FactorLevels1SpkCnt,SubspaceAnaOpts,SubspaceAnaOpts.RSAAnalysisType,Cond);
                        end
                        %% Perform PCA analysis on both dimensions
                        % on first dimension
                        %                         [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults1_Analysis1,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults1_Analysis2,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults1_Analysis3]=...
                        %                             obj.RunMultiplePCAanalysisonSubspace(Subspace1SpkCnt,FactorLvLInds1SpkCnt,FactorLvLData1SpkCnt,FactorLevels1SpkCnt,SubspaceAnaOpts);
                        %
                        %                        % on second dimension
                        %                         [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults2_Analysis1,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults2_Analysis2,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).PCAresults2_Analysis3]=...
                        %                             obj.RunMultiplePCAanalysisonSubspace(Subspace2SpkCnt,FactorLvLInds2SpkCnt,FactorLvLData2SpkCnt,FactorLevels2SpkCnt,SubspaceAnaOpts);
                        
                        
                        %                       %% do RSA analysis on both dimensions
                        %                         % on first dimension
                        %                         [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults1_Analysis1,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults1_Analysis2,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults1_Analysis3]=...
                        %                             obj.RunMultipleRSAanalysisonSubspace(Subspace1SpkCnt,FactorLvLInds1SpkCnt,FactorLvLData1SpkCnt,FactorLevels1SpkCnt,SubspaceAnaOpts,SubspaceAnaOpts.ParamMdlRDM_type{1},SubspaceAnaOpts.RSAAnalysisType);
                        %
                        %                         % on second dimension
                        %                         [SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults2_Analysis1,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults2_Analysis2,SubspaceAnaResults(nCond).TrialRange(nTrlRng).Rep(nrep).RSAresults2_Analysis3]=...
                        %                             obj.RunMultipleRSAanalysisonSubspace(Subspace2SpkCnt,FactorLvLInds2SpkCnt,FactorLvLData2SpkCnt,FactorLevels2SpkCnt,SubspaceAnaOpts,SubspaceAnaOpts.ParamMdlRDM_type{2},SubspaceAnaOpts.RSAAnalysisType);
                        toc
                    end
                end
            end
            
            SubspaceAnaOpts.AnalysisOpts=AnalysisOpts;
            % save off the variables
            obj.ManData.SaveVar('Subspace',SubspaceAnaResults,'SubspaceAnaResults',...
                [SubspaceAnaOpts.AnaType '_' ShuffTxt SubspaceAnaOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedCh','ALL');
            obj.ManData.SaveVar('Subspace',SubspaceAnaOpts,'SubspaceAnaOpts',...
                [SubspaceAnaOpts.AnaType '_' ShuffTxt SubspaceAnaOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedCh','ALL');
        end
        function SubspaceAnaResults=PreprocessSubspaceResults(obj,SubspaceAnaResults,SubspaceAnaOpts,Dim2ndFlag,ShuffFlag,varargin) % spits out the metrics after subspace analysis
            %@ClassifierResults results after training the classifier
            %@Dim2ndFlag 1 is we are processing 2nd dimension data
            %@ShuffFlag are we processing shuffled data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
                        
            if Dim2ndFlag==1 || Dim2ndFlag==2
                DimNumTxt='2';RSADimNumTxt='2';
            elseif Dim2ndFlag==3  
                DimNumTxt='3';RSADimNumTxt='3';
            else
                DimNumTxt='';RSADimNumTxt='1';
            end
            if ~isfield(SubspaceAnaResults(1).TrialRange(1).Rep(1),['Subspace' DimNumTxt 'Compression1'])
                warning('No subspace information in SubspaceAnaResults matrix...')
                return;
            end
            TrialRange=isfield(SubspaceAnaResults,'TrialRange'); % do we have trial range data?
            switch TrialRange
                case 1 % we are looking during learning thus we have a trial range
                    for Cond=1:length(SubspaceAnaResults)
                        nTrialRange=length(SubspaceAnaResults(Cond).TrialRange);
                        for TrlRng=1:nTrialRange
                            Nrep=length(SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep);
                            % get angle in degree
                            SubspaceAnaResults(Cond).TrialRange(TrlRng).(['PairAngled' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['PairAngled' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                            % get Cos Theta
                            SubspaceAnaResults(Cond).TrialRange(TrlRng).(['CosTheta' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['CosTheta' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                            % if we have quadrant angles 
                            if isfield(SubspaceAnaResults(Cond).TrialRange(TrlRng),['Quad3DAngled' DimNumTxt])
                                % load quadrant angles
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad3DAngled' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad3DAngled' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad2DAngled' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad2DAngled' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad3DCosTheta' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad3DAngled' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad2DCosTheta' DimNumTxt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad2DAngled' DimNumTxt]),1:Nrep,'UniformOutput',0),2);
                            end
                            % load PCA compression
                            SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Subspace' DimNumTxt 'Compression1'])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Subspace' DimNumTxt 'Compression1']),1:Nrep,'UniformOutput',0),2);
                            SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Subspace' DimNumTxt 'Compression2'])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Subspace' DimNumTxt 'Compression2']),1:Nrep,'UniformOutput',0),2);
                            
                            %% RSA analysis
                            if isfield(SubspaceAnaOpts,'AnaType') % if we are running thison classifier skip this
                                if sum(strcmp(SubspaceAnaOpts.AnaType,'RSA')) % check if we want to do it
                                    RSAfieldNames={'minlossAll','BrainRDM','rdms','betas_hat'};
                                    RSAfieldDim=[1 3 3 1];
                                    nTimRSA=size(SubspaceAnaOpts.SpkCountPeriod,1);
                                    for RSAtype=SubspaceAnaOpts.RSAanalysisSubType % loop on the subtypes of analysis
                                        RSAtype=['_' RSAtype{1}];
                                        for nFieldName=1:length(RSAfieldNames)
                                            FieldName=RSAfieldNames{nFieldName};
                                            for rep=1:Nrep
                                                % process meaningful data from this analysis
                                                Temp1=cellfun(@(x) obj.RSAFunc.GetCorrectRSAresults4Loss(x,'CorrectRSAresults4Loss',1),SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(rep).(['RSAresults' RSADimNumTxt RSAtype]),'UniformOutput',0);
                                                
                                                Temp2{rep}=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) Temp1{x}.(FieldName),...
                                                    1:nTimRSA,'UniformOutput',0),RSAfieldDim(nFieldName));
                                                if strcmp(FieldName,'minlossAll')
                                                    % process freeze conds as well
                                                    TempFreez1=arrayfun(@(x) obj.RSAFunc.GetCorrectRSAresults4Loss(SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(rep).(['RSAresults' RSADimNumTxt RSAtype]){x}.freezeConds{1}), 1:nTimRSA,'UniformOutput',0);
                                                    
                                                    TempFreez2{rep}=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) TempFreez1{x}.(FieldName),...
                                                        1:nTimRSA,'UniformOutput',0),RSAfieldDim(nFieldName));
                                                end
                                            end
                                            SubspaceAnaResults(Cond).TrialRange(TrlRng).(['RSAresults' RSADimNumTxt RSAtype '_' FieldName])=...
                                                obj.ManData.ReshapeCell2Mat(Temp2,4);
                                            % get the infor for freeze cond
                                            if strcmp(FieldName,'minlossAll')
                                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['RSAresults' RSADimNumTxt RSAtype 'Freeze_' FieldName])=...
                                                    obj.ManData.ReshapeCell2Mat(TempFreez2,4);
                                            end
                                        end
                                    end
                                end
                            end
                            %% if we have any spike count data then retrieve those data as well
                            for spkcnt=1:size(SubspaceAnaOpts.SpkCountPeriod,1)
                                Txt=sprintf('_SpkCntPrd%i',spkcnt);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['PairAngled' DimNumTxt Txt])    =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['PairAngled' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['CosTheta' DimNumTxt Txt])      =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['CosTheta' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                               
                                if isfield(SubspaceAnaResults(Cond).TrialRange(TrlRng),['Quad3DAngled' DimNumTxt])
                                    SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad3DAngled' DimNumTxt Txt])  =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad3DAngled' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                                    SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad2DAngled' DimNumTxt Txt])  =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad2DAngled' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                                    SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad3DCosTheta' DimNumTxt Txt])  =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad3DAngled' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                                    SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Quad2DCosTheta' DimNumTxt Txt])  =arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Quad2DAngled' DimNumTxt Txt]),1:Nrep,'UniformOutput',1);
                                end
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Subspace' DimNumTxt 'Compression1' Txt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Subspace' DimNumTxt 'Compression1' Txt]),1:Nrep,'UniformOutput',0),2);
                                SubspaceAnaResults(Cond).TrialRange(TrlRng).(['Subspace' DimNumTxt 'Compression2' Txt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(x).(['Subspace' DimNumTxt 'Compression2' Txt]),1:Nrep,'UniformOutput',0),2);
                            end
                        end
                    end
            end
        end
        function h=PlotSubspaceAnalysisResults(obj,SubspaceAnaResults,SubspaceAnaOpts,PlotMode,Conds,ComparisionOpts,varargin) % plots the results from classifer analysis
            %@SubspaceAnaResults SubspaceAnaOpts: if you are comparing(CompareConds) conditions then put each condition in a cell
            %@PlotMode dictates which type of plots we want
            %@Conds (Cell or double) index of the conditions you want be plotted. If this a 'CompareConds' then each cell has to have one value
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare variables
            NConds=length(SubspaceAnaResults);
            SubspaceAnaOpts.AxBanalysisSubType=arrayfun(@(x) sprintf('Analysis%i',x),1:6,'uniformoutput',0);
            MeanStdPlotTypeRot_sh=3; % only plot the mean
            MeanStdPlotTypeRot=1;
            AxBTime=mean(SubspaceAnaOpts.SpkCountPeriod,2)';
            %{'Sensory','Response','SensoryToResponse'};
            obj.ManData.CopyVars2AnalysisOpts('Time',SubspaceAnaOpts.AnalysisOpts.Time,'RasterTime',SubspaceAnaOpts.AnalysisOpts.RasterTime,'NTim',SubspaceAnaOpts.AnalysisOpts.NTim,'NNeu',SubspaceAnaOpts.AnalysisOpts.NNeu);
            
            obj.RSAFunc=RSA_AnalysisFuncs;
            if ~strcmp(PlotMode,'CompareConds')% preprocess classifier results to have them in an easier shape
                SubspaceAnaResults_1ndD=obj.PreprocessSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,0,0); % process first Dimension
                SubspaceAnaResults_2ndD=obj.PreprocessSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,1,0); % process second Dimension
            else
                SubspaceAnaResults_1ndD=arrayfun(@(x) obj.PreprocessSubspaceResults(SubspaceAnaResults{x},SubspaceAnaOpts{x},0,0),1:NConds,'UniformOutput',0);
                SubspaceAnaResults_2ndD=arrayfun(@(x) obj.PreprocessSubspaceResults(SubspaceAnaResults{x},SubspaceAnaOpts{x},1,0),1:NConds,'UniformOutput',0);
            end
            %             if ~isempty(obj.SubspaceAna_Shuff)
            %                     obj.SubspaceAna_Shuff=obj.PreprocessSubspaceResults(obj.SubspaceAna_Shuff,ClassifierOpts,0,1);
            %                     obj.StatTest=obj.PerformStatTest(SubspaceAnaResults_1ndD,obj.SubspaceAna_Shuff,[],Conds);
            %             end
            
            if ~contains(PlotMode,'Learning')
                
                % plot first dimension results
                h=[];nSP=5;
                for nAxBAnaType=1:length(SubspaceAnaOpts.AxBanalysisSubType)
                    for Plot4D=[0 1]
                        h1=obj.FigParams.RenderFigure(1,[]);
                        [h1,Sp]=obj.FigParams.RenderSubplots(2,nSP,h1{1},[]);
                        obj.PutSGtitle4Figure(SubspaceAnaOpts)
                        
                        AxBAnaType=SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType};
                        AnaTitle=SubspaceAnaResults(Conds).AxBAnalysisTitles{nAxBAnaType};%SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType};%
                        
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',AxBAnaType,Sp(1),Conds,1,1,[],AnaTitle,2,0,[],'MeanStdPlotType',1);
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression','Analysis5',Sp(1),Conds,1,1,[],AnaTitle,2,0,[],'MeanStdPlotType',1);
                        
                        %% plot total rotation
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationTot',AxBAnaType,Sp(2),Conds,1,1,[],AnaTitle,Plot4D,0,[],'MeanStdPlotType',MeanStdPlotTypeRot);
                        
                        %% shuffle for total rotation
                        obj.PlotAxBMetric_Learning(obj.SubspaceAna_Shuff,SubspaceAnaOpts,'rotationTot',AxBAnaType,Sp(2),Conds,1,1,[],AnaTitle,Plot4D,1,[],'MeanStdPlotType',MeanStdPlotTypeRot_sh);
                        
                        %% plot total in plane and out of plane rotations
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX_In',AxBAnaType,Sp(3),Conds,1,1,[],AnaTitle,Plot4D,0,[],'MeanStdPlotType',MeanStdPlotTypeRot);
                        % add shuffle for in plane
                        obj.PlotAxBMetric_Learning(obj.SubspaceAna_Shuff,SubspaceAnaOpts,'rotationX_In',AxBAnaType,Sp(3),Conds,1,1,[],AnaTitle,Plot4D,1,[],'MeanStdPlotType',MeanStdPlotTypeRot_sh);
                        
                        %% out of plane
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX_Out',AxBAnaType,Sp(4),Conds,1,1,[],AnaTitle,Plot4D,0,[],'MeanStdPlotType',MeanStdPlotTypeRot);
                        % add shuffle for out plane
                        obj.PlotAxBMetric_Learning(obj.SubspaceAna_Shuff,SubspaceAnaOpts,'rotationX_Out',AxBAnaType,Sp(4),Conds,1,1,[],AnaTitle,Plot4D,1,[],'MeanStdPlotType',MeanStdPlotTypeRot_sh);
                        
                        % plot generalization Err
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'GeneralizationErr',AxBAnaType,Sp(5),Conds,1,1,[],AnaTitle,Plot4D,0,[],'MeanStdPlotType',MeanStdPlotTypeRot);
                        obj.PlotAxBMetric_Learning(obj.SubspaceAna_Shuff,SubspaceAnaOpts,'GeneralizationErr',AxBAnaType,Sp(5),Conds,1,1,[],AnaTitle,Plot4D,1,[],'MeanStdPlotType',MeanStdPlotTypeRot_sh);
                        
                        %% plot rotations for individual objects
                        arrayfun(@(x) obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX',AxBAnaType,Sp(x+nSP),Conds,1,1,x,AnaTitle,Plot4D,0,[],'MeanStdPlotType',MeanStdPlotTypeRot),1:4,'UniformOutput',0);
                        % add shuffles for individual objects
                        arrayfun(@(x) obj.PlotAxBMetric_Learning(obj.SubspaceAna_Shuff,SubspaceAnaOpts,'rotationX',AxBAnaType,Sp(x+nSP),Conds,1,1,x,AnaTitle,Plot4D,1,[],'MeanStdPlotType',MeanStdPlotTypeRot_sh),1:4,'UniformOutput',0);
                        
                        h=[h h1];
                    end
                end
                
            elseif contains(PlotMode,'Learning')
                h=[];nSP=5;
                for nAxBAnaType=1:length(SubspaceAnaOpts.AxBanalysisSubType)
                    for Plot4D=[0]
                        h1=obj.FigParams.RenderFigure(1,[]);
                        [h1,Sp]=obj.FigParams.RenderSubplots(3,nSP,h1{1},[]);
                        obj.PutSGtitle4Figure(SubspaceAnaOpts)
                        
                        AxBAnaType=SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType};
                        AnaTitle=SubspaceAnaResults(Conds).AxBAnalysisTitles{nAxBAnaType};
                        
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',AxBAnaType,Sp(1),Conds,1,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',1);
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',AxBAnaType,Sp(2),Conds,1,1,[],AnaTitle,Plot4D,0,2,'MeanStdPlotType',1);
                        %   obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',AxBAnaType,Sp(3),Conds,1,1,[],AnaTitle,Plot4D,0,3,'MeanStdPlotType',1);
                        Time2Look=AxBTime>=0.2 & AxBTime<=0.4; % average compression for thos times
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',AxBAnaType,Sp(3),Conds,Time2Look,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',1);
                        % SubspaceAnaResults,SubspaceAnaOpts,Metric,AxBAnaType,Sp,Cond,TimeInd,TrnTstNum,ObjNum,AnalysisTitle,Plot4D,ShuffFlag,MatNum
                        %% plot total rotation
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationTot',AxBAnaType,Sp(4),Conds,1,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',MeanStdPlotTypeRot);
                        
                        %% plot PCA rotation
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'RotPCA',AxBAnaType,Sp(5),Conds,1,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',MeanStdPlotTypeRot);
                        
                        %% plot total in plane and out of plane rotations
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX_In',AxBAnaType,Sp(6),Conds,1,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',MeanStdPlotTypeRot);
                        
                        %% out of plane
                        obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX_Out',AxBAnaType,Sp(7),Conds,1,1,[],AnaTitle,Plot4D,0,1,'MeanStdPlotType',MeanStdPlotTypeRot);
                        
                        %% plot rotations for individual objects
                        %in plane
                        arrayfun(@(x) obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX',AxBAnaType,Sp(x+7),Conds,1,1,x,AnaTitle,Plot4D,0,1,'MeanStdPlotType',MeanStdPlotTypeRot),1:4,'UniformOutput',0);
                        % out plane
                        arrayfun(@(x) obj.PlotAxBMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotationX',AxBAnaType,Sp(x+11),Conds,1,1,x,AnaTitle,Plot4D,0,2,'MeanStdPlotType',MeanStdPlotTypeRot),1:4,'UniformOutput',0);
                        
                    end
                    h=[h h1];
                end
            end
            
            
            %                     h=obj.FigParams.RenderFigure(1,[]);
            %                     [h,Sp]=obj.FigParams.RenderSubplots(2,5,h{1},[]);
            %                     obj.PutSGtitle4Figure(SubspaceAnaOpts)
            %                     Metric='CosTheta';
            %                     nSpkCnt=size(SubspaceAnaOpts.SpkCountPeriod,1);
            %                     % plot metric in time during learning for first dimension
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,Metric,Sp(1),Conds,[],1);
            %                     arrayfun(@(x) obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,Metric,Sp(1+x),Conds,x,1),1:nSpkCnt);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'Quad2DCosTheta',Sp(2+nSpkCnt),Conds,[],1);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'SubspaceCompression1',Sp(3+nSpkCnt),Conds,[],1);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(4+nSpkCnt),Conds,[],1);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(5+nSpkCnt),Conds,1,1);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(6+nSpkCnt),Conds,2,1);
            %
            %                     h1=obj.FigParams.RenderFigure(1,[]);
            %                     [h1,Sp]=obj.FigParams.RenderSubplots(2,5,h1{1},[]);
            %                     obj.PutSGtitle4Figure(SubspaceAnaOpts)
            %                     % plot metric in time during learning for second dimension
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,Metric,Sp(1),Conds,[],2);
            %                     arrayfun(@(x) obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,Metric,Sp(1+x),Conds,x,2),1:nSpkCnt);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'Quad2DCosTheta',Sp(2+nSpkCnt),Conds,[],2);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'SubspaceCompression1',Sp(3+nSpkCnt),Conds,[],2);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(4+nSpkCnt),Conds,[],2);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(5+nSpkCnt),Conds,1,2);
            %                     obj.PlotSubspaceMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'SubspaceCompression2',Sp(6+nSpkCnt),Conds,2,2);
            %
            % plot metric in time during learning for RSA results
            % RSA results for the second dimension
            %                      h3=obj.FigParams.RenderFigure(1,[]);
            %                     [h3,Sp]=obj.FigParams.RenderSubplots(2,4,h3{1},[]);
            %                     obj.PutSGtitle4Figure(SubspaceAnaOpts)
            %                     for nRSAAnaType=1:length(SubspaceAnaOpts.RSAanalysisSubType)
            %                         RSAAnaType=SubspaceAnaOpts.RSAanalysisSubType{nRSAAnaType};
            %                         nSP=4*(nRSAAnaType-1);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'compression',RSAAnaType,Sp(1+nSP),Conds,1,2);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'rotation',RSAAnaType,Sp(2+nSP),Conds,1,2);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'ctxbias',RSAAnaType,Sp(3+nSP),Conds,1,2);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_2ndD,SubspaceAnaOpts,'RotFreezLoss',RSAAnaType,Sp(4+nSP),Conds,1,2);
            %                     end
            %                     for nRSAAnaType=1:length(SubspaceAnaOpts.RSAanalysisSubType)
            %                         RSAAnaType=SubspaceAnaOpts.RSAanalysisSubType{nRSAAnaType};
            %                         nSP=4*(nRSAAnaType-1);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'compression',RSAAnaType,Sp(1+nSP),Conds,1,1);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'rotation',RSAAnaType,Sp(2+nSP),Conds,1,1);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'ctxbias',RSAAnaType,Sp(3+nSP),Conds,1,1);
            %                         obj.PlotRSAMetric_Learning(SubspaceAnaResults_1ndD,SubspaceAnaOpts,'RotFreezLoss',RSAAnaType,Sp(4+nSP),Conds,1,1);
            %                     end
            %
            
            % make a movie of the RDM for this analysis
            %obj.ShowRSAanaMDS(SubspaceAnaResults_1ndD,SubspaceAnaOpts,SubspaceAnaOpts.RSAanalysisSubType{1},1,1)
            
        end
        function h=PlotSubspaceMetric_Learning(obj,SubspaceAnaResults,SubspaceAnaOpts,Metric,Sp,Cond,TimeInd,TrnTstNum,varargin) % plots subspace metric during learning
            %@SubspaceAnaResults SubspaceAnaOpts  cell structure of output of the classifer projection of validation data
            %@Metric can be 'PairAngled' 'CosTheta'
            %@TimeInd: Indices we want to to average and look at in a line plot
            %@TrnTstNum is it train and test condition 1 or 2
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare varibables
            nTrialRange=length(SubspaceAnaResults(Cond).TrialRange);
            if TrnTstNum==1
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors{1};
                TrainCondTxt=sprintf('TrainCond');
                TestCondTxt=sprintf('TestCond');
            elseif TrnTstNum==2
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors_2ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);
                if contains(Metric,'SubspaceCompression')
                    Metric=sprintf('Subspace%iCompression%s',TrnTstNum,Metric(end));
                else
                    Metric=sprintf('%s%i',Metric,TrnTstNum);
                end
            end
            
            %TrialRangeSet=max([ClassifierOpts.TrainTrlNumRange{Cond}(2:4);ClassifierOpts.TestTrlNumRange{Cond}(2:4)],[],1);
            TrialRangeSet=SubspaceAnaOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            Title=[   Metric;...
                {[TargetFactorTxt ' Trn ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TrainCondTxt){Cond}),...
                ' Tst ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TestCondTxt){Cond})]}];
            
            % get data for this metric first
            MetricVals=obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,Metric,4);
            
            % now take average across repetitions and squeeze
            if isempty(TimeInd) % image plot
                MetricVals=squeeze(mean(MetricVals,1))';
                % do gaussian smoothing of 2D data
                % MetricVals=imgaussfilt(MetricVals,'FilterSize',obj.WidthSmoothing);
                MetricVals=smoothdata(smoothdata(MetricVals,2,'movmean',obj.WidthSmoothing),1,'movmean',obj.WidthSmoothingDim2);
                
                % plot accuracy as image
                obj.FigParams.Image(AnalysisOpts.Time,TrialRange,MetricVals,...
                    AnalysisOpts.Xlabel,...
                    ['Trial Set ' num2str(TrialRangeSet(2))],...
                    'Perf',Title,Sp,'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'OriginLine',2);
                yticks(TrialRange);
            elseif islogical(TimeInd) % line plot
                MetricVals=squeeze(mean(MetricVals(:,TimeInd,:,:),2));
                Col=obj.FigParams.getSingleColor(obj.ThisColor);
                Ylbl =[TargetFactorTxt ' ' PerfMetric];
                h=obj.FigParams.PlotMeanStd(TrialRange,MetricVals,[],'Trials',Ylbl,Col,obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax);
                yticks(TrialRange);
            else % we are rading the values for spikecount periods
                Txt=sprintf('_SpkCntPrd%i',TimeInd);
                MetricVals=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[Metric Txt],3));
                Col=obj.FigParams.getSingleColor(obj.ThisColor);
                Ylbl =[TargetFactorTxt ' ' Metric];
                Title=[Title; [num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,1)) '-' num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,2)) 'sec']];
                h=obj.FigParams.PlotMeanStd(TrialRange,MetricVals,[],'Trials',Ylbl,Col,obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax);
                xticks(TrialRange);
            end
            
            % plot the data now
            subtitle(obj.ThisSubtitle)
        end
        function MakeMovieAxBAnalysisResults(obj,SubspaceAnaResults,SubspaceAnaOpts,varargin)  % makes a movie from results of subspace analysis
            %@SubspaceAnaResults SubspaceAnaOpts resutls from subspace analysis
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            %% get X and Y data and take average from all of them
            
            SubspaceAnaOpts.AxBanalysisSubType=arrayfun(@(x) sprintf('Analysis%i',x),1:6,'uniformoutput',0);
            
            h=[];nSP=3;
            SpNum=[1 2 3 6 9];
            
            for nAxBAnaType= 1:length(SubspaceAnaOpts.AxBanalysisSubType)
                
                X=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,'Xproj2plane',['AxBresults_' SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType}]);
                Y=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,'Yproj2plane',['AxBresults_' SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType}]);
                Xproj=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,'RotX',['AxBresults_' SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType}]);
                % take mean of X and Y across time
                X=mean(X,3);Y=mean(Y,3);Xproj=mean(Xproj,3);
                NTim=size(X,1);
                
                h1=obj.FigParams.RenderFigure(1,[]);
                [h1,Sp]=obj.FigParams.RenderSubplots(3,nSP,h1{1},[]);
                obj.PutSGtitle4Figure(SubspaceAnaOpts)
                
                AxBAnaType=SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType};
                AnaTitle=SubspaceAnaResults.AxBAnalysisTitles{nAxBAnaType};%SubspaceAnaOpts.AxBanalysisSubType{nAxBAnaType};%
                
                obj.PlotAxBMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'compression',AxBAnaType,Sp(SpNum(1)),1,1,1,[],AnaTitle,0,0,'MeanStdPlotType',3);
                
                %% plot rotations for individual objects
                arrayfun(@(x) obj.PlotAxBMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'rotationX',AxBAnaType,Sp(SpNum(x+1)),1,1,1,x,AnaTitle,0,0,'MeanStdPlotType',3),1:4,'UniformOutput',0);
                AxBTime=mean(SubspaceAnaOpts.SpkCountPeriod,2)';
                
                %% add the planes of X and Y as they are changing in Time
                for Tim=1:5:NTim
                    subplot(3,nSP,[4 5 7 8])
                    cla
                    RespVect=[reshape(Y(Tim,:),[3 4]) reshape(X(Tim,:),[3 4]) ]';
                    XprojTim=reshape(Xproj(Tim,:),[3 4])';
                    obj.AxBFunc.PlotAxBXYplanes(RespVect,XprojTim,AnaTitle)
                    title(sprintf('Time:%0.2f-%0.2fms from %s', SubspaceAnaOpts.SpkCountPeriod(Tim,1)*1000,...
                        SubspaceAnaOpts.SpkCountPeriod(Tim,2)*1000),AnalysisOpts.SpkCntStartFieldName);
                    
                    hp=arrayfun(@(x) obj.FigParams.PlotVerticalLine(AxBTime(Tim),Sp(SpNum(x)),'r'),1:5,'UniformOutput',0); % plot vertical lines
                    drawnow
                    mvFrame(Tim) = getframe(gcf);
                    
                    %                    % same every frame in .fig
                    %                    % save off the figures
                    [~,~,SubspaceAnaFigFileName]=obj.ManData.GetFileName(['Subspace'],...
                        [AxBAnaType '_' AnalysisOpts.SpkCntStartFieldName  't' num2str(floor(AxBTime(Tim)*1000))],'SaveInResults',1,'WantedCh','ALL');
                    obj.FigParams.SaveFigSeries([],SubspaceAnaFigFileName,[gcf],'SaveEachFrame',1,'SaveEachFrameFrmt','fig','CreateFolder4Fig',0);
                    
                    cellfun(@delete,hp); % delete all of the lines
                end
                
                ExtraStr=[ '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                [~,~,AxBMovieFileName]=obj.ManData.GetFileName('Subspace',['_AxB_' AxBAnaType ExtraStr],'SaveInResults',1);
                obj.FigParams.MakeMovieFromFrames(mvFrame,1,AxBMovieFileName)
            end
            
        end
        function h=PlotCompositionalityAnalysisResutls(obj,SubspaceAnaResults,SubspaceAnaOpts,varargin)
            %@SubspaceAnaResults SubspaceAnaOpts resutls from subspace analysis
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            VarType='_NSFM';%Can be '_Sac' pr '' or '_NSFM'
            RemoveDash=@(Str) strrep(Str,'_',' ');
            ComAnalysisTitles={'Ycomp3_R1C2','Ycomp3_TR1C2','Ycomp3_R2C1',...
                'Ycomp3_R1','Ycomp3_R2','Ycomp3_R3','Ycomp3_TR1',...
                'Ycomp3_C1','Ycomp3_C2','Ycomp3_C3',...
                'Ycomp3_R1C1','Ycomp3_R2C2',...
                'Ycomp3_S2A1','Ycomp3_S2A2','Ycomp3_S2A3','Ycomp3_S1A1'};
            MainCondsTitle={'Rot3*Comp3','Rot3shuf*Comp3shuf'};
            
            NCondsComAna=length(ComAnalysisTitles);
            
            GeneralizationErr=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['GeneralizationErr' VarType],['AxBresults_CompAnalysis']);
            CompositionErr=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['CompositionErr' VarType],['AxBresults_CompAnalysis']);
            GeneralizationErr_Sh=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['GeneralizationErr_Sh' VarType],['AxBresults_CompAnalysis']);
            
            GeneralizationCorr=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['GeneralizationCorr' VarType],['AxBresults_CompAnalysis']);
            CompositionCorr=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['CompositionCorr' VarType],['AxBresults_CompAnalysis']);
            GeneralizationCorr_Sh=GetValFromSubspaceResults(SubspaceAnaResults,SubspaceAnaOpts,['GeneralizationCorr_Sh' VarType],['AxBresults_CompAnalysis']);
            
            
            AxBTime=SubspaceAnaOpts.SpkCountPeriod(:,1);
            NtimBase=1%sum(SubspaceAnaOpts.SpkCountPeriod(:,2)<=0); % number of point on baseline
            NTim=length(AxBTime);
            NTimRun=size(CompositionCorr,1);
            if NTimRun==NTim
                ReshapeComMat=@(x,NTim) reshape(x,[1 NTim size(x,2) size(x,3) size(x,4)]); % reshape matrixes
            elseif NTim^2==NTimRun
                ReshapeComMat=@(x,NTim) reshape(x,[NTim NTim size(x,2) size(x,3) size(x,4)]); % reshape matrixes
            end
            Results.GeneralizationErr=ReshapeComMat(GeneralizationErr,NTim);Results.GeneralizationCorr=ReshapeComMat(GeneralizationCorr,NTim);
            Results.GeneralizationErr_Sh=ReshapeComMat(GeneralizationErr_Sh,NTim);Results.GeneralizationCorr_Sh=ReshapeComMat(GeneralizationCorr_Sh,NTim);
            Results.CompositionErr=ReshapeComMat(CompositionErr,NTim);Results.CompositionCorr =ReshapeComMat(CompositionCorr,NTim);
            
            
            Cols=distinguishable_colors(NCondsComAna);
            CondColl={[1 2 3],[4 5 6 7],[8 7 10],[11 12],[13 14 15 16]}; % divide conditions in three groups
            %CondColl={[11 12 13 14]}; % divide conditions in three groups
            
            h1=obj.FigParams.RenderFigure(1,[]);
            [h1,Sp]=obj.FigParams.RenderSubplots(2,length(CondColl),h1{1},[]);
            obj.PutSGtitle4Figure(SubspaceAnaOpts)
            
            FieldSuffix={'Err','Corr'};
            SmoothingWidth=1;
            %YLims={[-0.5 1.2],[-.1 0.1]};
            YLims={'auto','auto'};
            for ii=1:2
                Txt=FieldSuffix{ii};
                for i=1:length(CondColl)
                    subplot(Sp(i+length(CondColl)*(ii-1)))
                    arrayfun(@(x) obj.FigParams.PlotMeanStd(AxBTime,obj.ManData.Diag3D(squeeze(Results.(['Composition' Txt])(:,:,x,:))),[],AnalysisOpts.Xlabel ,Txt,Cols(x,:),3,'Compositionality Analysis',...
                        'LegendTxt',RemoveDash(ComAnalysisTitles{x}),'WidthSmoothing',SmoothingWidth,'SmoothingMethod','movmean','SubtractBaseLine',1,'NPnts_SubtractBaseLine',NtimBase,'p_line_width',1.5,'STD_method','bootstrap'),CondColl{i},'uniformoutput',0);
                    
                    obj.FigParams.PlotMeanStd(AxBTime,obj.ManData.Diag3D(squeeze(Results.(['Generalization' Txt])(:,:,3,:))),[],AnalysisOpts.Xlabel,Txt,Cols(11,:),3,'Compositionality Analysis','LegendTxt',...
                        RemoveDash(MainCondsTitle{1}) ,'WidthSmoothing',SmoothingWidth,'SmoothingMethod','movmean','SubtractBaseLine',1,'NPnts_SubtractBaseLine',NtimBase,'p_line_width',3,'p_line_style',':','STD_method','bootstrap');
                    
                    obj.FigParams.PlotMeanStd(AxBTime,obj.ManData.Diag3D(squeeze(Results.(['Generalization' Txt '_Sh'])(:,:,3,:))),[],AnalysisOpts.Xlabel,Txt,Cols(12,:),3,'Compositionality Analysis','LegendTxt',...
                        RemoveDash(MainCondsTitle{2}),'WidthSmoothing',SmoothingWidth,'SmoothingMethod','movmean','SubtractBaseLine',1,'NPnts_SubtractBaseLine',NtimBase,'p_line_width',3,'p_line_style',':','STD_method','bootstrap');
                    ylim(YLims{ii})
                end
            end
            if NTimRun==NTim;h=h1;return;end
            %% add a bar plot for compositionality analysis
            h3=obj.FigParams.RenderFigure(1,[]);
            [h3,Sp]=obj.FigParams.RenderSubplots(1,1,h3{1},[]);
            obj.PutSGtitle4Figure(SubspaceAnaOpts)
            Cols=distinguishable_colors(20);
            Conds2Look=[12 13 14 11];
            
            GetDiag=@(Mat) arrayfun(@(x) obj.ManData.Diag3D(squeeze(Mat(:,:,x,:))),1:size(Mat,3),'uniformoutput',0);
            SubtractMean=@(Mat,NtimBase) cellfun(@(x) x-mean(mean(x(:,1:NtimBase),1)),Mat,'UniformOutput',0);
            MeanCol=@(Mat,Inds) cellfun(@(x) mean(x(:,Inds),2),Mat,'UniformOutput',0);
            
            TimeInds=AxBTime>-0.2 & AxBTime<=0;
            CompositionErr_Comp=MeanCol(SubtractMean(GetDiag(Results.CompositionCorr),NtimBase),TimeInds);
            GeneralizationErr_Comp=MeanCol(SubtractMean(GetDiag(Results.GeneralizationCorr),NtimBase),TimeInds);
            GeneralizationErr_Sh_Comp=MeanCol(SubtractMean(GetDiag(Results.GeneralizationCorr_Sh),NtimBase),TimeInds);
            % do ttest on the data
            [~,psig,groups]=obj.ManData.DoTtestonCell([ GeneralizationErr_Comp(3) GeneralizationErr_Sh_Comp(3) CompositionErr_Comp(Conds2Look)],0);
            
            subplot(Sp(1))
            L1=arrayfun(@(x) obj.FigParams.PlotMeanStd(find(Conds2Look==x)+2,CompositionErr_Comp{x},[],AnalysisOpts.Xlabel ,'Err',Cols(x,:),2,'Compositionality Analysis',...
                'LegendTxt',ComAnalysisTitles{x},'WidthSmoothing',3,'SmoothingMethod','','SubtractBaseLine',0,'p_line_width',1.5,'STD_method','bootstrap'),[Conds2Look],'uniformoutput',1);
            
            L2=obj.FigParams.PlotMeanStd(1,GeneralizationErr_Comp{3},[],AnalysisOpts.Xlabel,'Err',Cols(19,:),2,'Compositionality Analysis','LegendTxt',...
                MainCondsTitle{1} ,'WidthSmoothing',3,'SmoothingMethod','','SubtractBaseLine',0,'p_line_width',3,'p_line_style',':','STD_method','bootstrap');
            
            L3=obj.FigParams.PlotMeanStd(2,GeneralizationErr_Sh_Comp{3},[],AnalysisOpts.Xlabel,'Err',Cols(20,:),2,'Compositionality Analysis','LegendTxt',...
                MainCondsTitle{2},'WidthSmoothing',3,'SmoothingMethod','','SubtractBaseLine',0,'p_line_width',3,'p_line_style',':','STD_method','bootstrap');
            
            sigstar(groups,psig*length(psig))
            legend([L1 L2 L3],[arrayfun(@(x) ComAnalysisTitles{x},Conds2Look,'UniformOutput',0 ) MainCondsTitle{1} MainCondsTitle{2}])
            %% plot everything in an image
            h2=obj.FigParams.RenderFigure(1,[]);
            [h2,Sp]=obj.FigParams.RenderSubplots(2,6,h2{1},[]);
            obj.PutSGtitle4Figure(SubspaceAnaOpts)
            Clim=[3 5];
            
            arrayfun(@(x) obj.FigParams.Image(AxBTime,AxBTime,mean(Results.CompositionErr(:,:,x,:),4),'Time ty','Time tx','Err',['R3(ty)=' ComAnalysisTitles{x} '*R3(tx)'],Sp(x),'caxis_limits',Clim),1:10,'uniformoutput',0);
            obj.FigParams.Image(AxBTime,AxBTime,mean(Results.GeneralizationErr(:,:,3,:),4),'Time ty','Time tx','Err',['R3(ty)=' ComAnalysisTitles{11} '*R3(tx)'],Sp(11),'caxis_limits',Clim);
            obj.FigParams.Image(AxBTime,AxBTime,mean(Results.GeneralizationErr_Sh(:,:,3,:),4),'Time ty','Time tx','Err',['R3(ty)=' ComAnalysisTitles{12} '*R3(tx)'],Sp(12),'caxis_limits',Clim);
            h=[h1 h2 h3];
        end
        function VarVal=GetValFromSubspaceResults(obj,SubspaceAnaResults,SubspaceAnaOpts,VarName,AxBfieldName) % gets specified value from subspace analysis results matrix
            
            nTrialRange=length(SubspaceAnaResults.TrialRange);
            % get X and Y X projdata
            for nTrlRng=1:nTrialRange
                for rep=1:SubspaceAnaOpts.Nrep
                    VarVal(:,:,rep,nTrlRng)=cell2mat(cellfun(@(x)  x.(VarName),SubspaceAnaResults.TrialRange(nTrlRng).Rep(rep).([AxBfieldName])','UniformOutput',0))';
                end
            end
        end
        function [PCAresults_Analysis1,PCAresults_Analysis2,PCAresults_Analysis3]=RunMultiplePCAanalysisonSubspace(obj,SubspaceSpkCnt,FactorLvLInds,FactorLvLData,FactorLevels,SubspaceAnaOpts,varargin) % runs a bunch of PCA analysis on the data
            %@ AnalysisType can be 'Learning' or 'SensoryMotorTransform'
            
            % in the case of Learning there are three analysis
            %1) Charactrize geometry of sensory representation during
            %learning
            %2) Charactrize geometry of response representation during
            %learning
            %3) Charactrize geometry of sensory to response transformation
            
            % in the case of SensoryMotorTransform there are two analysis
            % 1) Charactrize geometry of sensory to response in the same
            % rule
            % 2) Charactrize geometry of sensory in one rule to response in
            % another rule
            % 3) Charactrize geometry of all time points in one rule to
            % another rule
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            AnalysisType='SensoryMotorTransform';
            switch AnalysisType
                case {'SensoryMotorTransform','Learning'}
                    % find the timeing where there has been a response
                    if strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON');RespTim=0.25;elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START');RespTim=0;end
                    IndResp=find(SubspaceAnaOpts.SpkCountPeriod(:,1)==RespTim,1,'first');
                    nTim=size(SubspaceAnaOpts.SpkCountPeriod,1);
                    fprintf('\nRunning RSA analysis')
                    tic
                    for Tim=1:nTim
                        
                        %% run analysis 1 (SensoryToResponse_SameRule)
                        %% tranformation of sensory to response in the same rule
                        %     FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        [PCAresults_Analysis1.PairAngled(Tim),~,PCAresults_Analysis1.CosTheta(Tim)] =obj.CalculateAnglesBetSubspaces({SubspaceSpkCnt{IndResp}.CondScore{2}{1} SubspaceSpkCnt{Tim}.CondScore{2}{1}},[]); % calculates angles between the planes that are fit to each condition
                        [PCAresults_Analysis1.SubspaceCompression1(Tim)]                             =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{IndResp}.CondScore{1}(1));  % Calculates compression for each subspace
                        [PCAresults_Analysis1.SubspaceCompression2(Tim)]                   =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{Tim}.CondScore{2}(1));      % Calculates compression for each subspace
                        
                        %% run analysis 2 (SensoryToResponse_DiffRule)
                        %% tranformation of sensory in one rule to response in another rule
                        %      FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        [PCAresults_Analysis2.PairAngled(Tim),~,PCAresults_Analysis2.CosTheta(Tim)] =obj.CalculateAnglesBetSubspaces({SubspaceSpkCnt{IndResp}.CondScore{1}{1} SubspaceSpkCnt{Tim}.CondScore{2}{1}},[]); % calculates angles between the planes that are fit to each condition
                        [PCAresults_Analysis2.SubspaceCompression1(Tim)]                             =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{IndResp}.CondScore{1}(1));  % Calculates compression for each subspace
                        [PCAresults_Analysis2.SubspaceCompression2(Tim)]                   =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{Tim}.CondScore{2}(1));      % Calculates compression for each subspace
                        
                        %% run analysis 3 (AlltoAll_DiffRule)
                        %% tranformation of sensory in one rule to response in another rule
                        [PCAresults_Analysis3.PairAngled(Tim),~,PCAresults_Analysis3.CosTheta(Tim)] =obj.CalculateAnglesBetSubspaces({SubspaceSpkCnt{Tim}.CondScore{1}{1} SubspaceSpkCnt{Tim}.CondScore{2}{1}},[]); % calculates angles between the planes that are fit to each condition
                        [PCAresults_Analysis3.SubspaceCompression1(Tim)]                             =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{Tim}.CondScore{1}(1));  % Calculates compression for each subspace
                        [PCAresults_Analysis3.SubspaceCompression2(Tim)]                   =obj.CalculateCompressionBetSubspaces(SubspaceSpkCnt{Tim}.CondScore{2}(1));      % Calculates compression for each subspace
                    end
                    ElapsedTime=toc;
                    fprintf('\nAnalysing PCA  for Time point %i/%i ElapsedTime:%0.2f',Tim,nTim,ElapsedTime);
            end
        end
        function [Subspace,IndConds,FactorData,FactorLevels,FactorDataTiled]=DiscoverSubspaces(obj,Data,SubspaceAnaOpts,DataAllFactors,IndConds,varargin)% performs subspace discovery analyis on data
            % IndCodns is the indice of the the conditions that need to be
            % combined
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            SubspaceAnaOpts.DimReductionMethod='PCA';
            SubspaceAnaOpts.ConcatinateMethod='SepTimePoint'; % 'TimeCollapse' 'MeanTimeTrial' 'MeanAllTrlTime' 'SepTimePoint'
            TargetFactor=SubspaceAnaOpts.MainTargetFactor; FactorLevels=[];
            NTim=size(Data,3);
            if isempty(IndConds);IndConds=ones(1,size(DataAllFactors,1));end
            
            % tile trials based on our desired factor
            [FactorDataInd,FactorLevels]=obj.TileTrialsbasedonFactor(DataAllFactors,TargetFactor,FactorLevels);
            FactorDataIndTot=[];
            for Cond=unique(IndConds)
                FactorDataIndTot=cat(2,FactorDataIndTot,cellfun(@(x) x(IndConds(x)==Cond),FactorDataInd,'UniformOutput',0));
            end
            FactorData=cellfun(@(x) Data(x,:,:),FactorDataIndTot,'UniformOutput',0);
            AllFactors=cellfun(@(x) DataAllFactors(x,:,:),FactorDataIndTot,'UniformOutput',0);
            
            Subspace=obj.PerformSubspacePCAAnalysis(FactorData,SubspaceAnaOpts);
            IndConds=cell2mat(arrayfun(@(x) x*ones(1,length(FactorLevels)),unique(IndConds),'UniformOutput',0));
            
            % if we have different conditions then differentiate between
            % their scores
            FactorDataTiled=cell(1,2); % this is the varibale that takes the full data for each condition
            for Cond=unique(IndConds)
                Subspace.CondScore{Cond}=cellfun(@(x) x(IndConds==Cond,:),Subspace.score,'UniformOutput',0);
                FactorDataTiled{Cond}=arrayfun(@(Tim) obj.ManData.ReshapeCell2Mat(cellfun(@(x) mean(x(:,:,Tim),1),...
                    FactorData(IndConds==Cond),'UniformOutput',0),2),1:NTim,'UniformOutput',0);
            end
            
        end
        function Subspace=PerformSubspacePCAAnalysis(obj,FactorData,SubspaceAnaOpts,varargin)
            % @FactorData if it is matrix then it is (Factor*Neu*Time)
            % @FactorData if it is a cell array then each cell includes
            % trial by neuron and cells are time
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            
            if iscell(FactorData)
                % take the mean of each factor and concatinate them
                MeanFactorData=obj.ManData.ReshapeCell2Mat(cellfun(@(x) mean(x,1),FactorData,'UniformOutput',0),62);
            else
                MeanFactorData=FactorData;
            end
            
            % runsubspace analysis
            switch SubspaceAnaOpts.ConcatinateMethod
                case 'SepTimePoint'% do PCA  analysis for each time point
                    NTim=size(FactorData{1},3);
                    nFactorLevel=size(FactorData,2);
                    rMean=squeeze(mean(MeanFactorData,1)); % take the mean across factor values
                    % take PCA per each time point now
                    [Subspace.coeff,Subspace.score,Subspace.latent,Subspace.tsquared,Subspace.explained,Subspace.mu]=...
                        arrayfun(@(x) pca(MeanFactorData(:,:,x)-repmat(rMean(:,x)',[nFactorLevel 1])),1:NTim,'uniformoutput',0);
                case 'MeanAllTrlTime'
                    MeanFactorData=permute(MeanFactorData,[1 3 2]);
                    % do this analysis for each time point
                    NTim=size(MeanFactorData,2);
                    nLevelComb=size(MeanFactorData,1);
                    NNeu=size(MeanFactorData,3);
                    % reorganize data into 2D
                    CatFactorData2D=reshape(MeanFactorData,[NTim*nLevelComb NNeu]);
                    rMean=mean(CatFactorData2D,1); % take the mean across factor values and time
                    % take PCA for the mean data over all time
                    [Subspace.coeff,Subspace.score,Subspace.latent,Subspace.tsquared,Subspace.explained,Subspace.mu]=pca(CatFactorData2D-repmat(rMean,[NTim*nLevelComb 1]));
                    Subspace.score= reshape(Subspace.score,size(MeanFactorData));
                    Subspace.score= arrayfun(@(x) squeeze(Subspace.score(:,x,:)),1:NTim,'UniformOutput',0);
                case 'TimeCollapse'
                    MeanFactorData=permute(MeanFactorData,[1 3 2]);
                    % do this analysis for each time point
                    NTim=size(MeanFactorData,2);
                    nLevelComb=size(MeanFactorData,1);
                    rMean=squeeze(mean(mean(MeanFactorData,2),1))'; % take the mean across factor values
                    % take PCA for the mean data over all time
                    [Subspace.coeff,Subspace.score,Subspace.latent,Subspace.tsquared,Subspace.explained,Subspace.mu]=pca(squeeze(mean(MeanFactorData,2))-repmat(rMean,[nLevelComb 1]));
                    % project each time point into the mean subspace
                    Subspace.score=arrayfun(@(x) (squeeze(MeanFactorData(:,x,:))-repmat(rMean,[nLevelComb 1]))*Subspace.coeff,1:NTim,'uniformoutput',0);
            end
        end
        function PCA=DoPCAanalysis(obj,CatFactorData,FactorLevelComb,TargetFactors,varargin) % does PCA analysis per time point
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % do this analysis for each time point
            NTim=size(CatFactorData,1);
            nLevelComb=size(CatFactorData,2);
            rMean=squeeze(mean(CatFactorData,2)); % take the mean across factor values
            % take PCA per each time point now
            [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=...
                arrayfun(@(x) pca(squeeze(CatFactorData(x,:,:))-repmat(rMean(x,:),[nLevelComb 1])),1:NTim,'uniformoutput',0);
            %   PCA.Projection=arrayfun(@(x) (squeeze(CatFactorData(x,:,:))-repmat(rMean(x,:),[nLevelComb 1]))*PCA.coeff{x},1:NTim,'uniformoutput',0);
        end
        function PCA=DoPCAanalysisTimeCollapse(obj,CatFactorData,FactorLevelComb,TargetFactors,varargin) % calculates PCA but collapses time and then projects back each time point in that space
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % do this analysis for each time point
            NTim=size(CatFactorData,1);
            nLevelComb=size(CatFactorData,2);
            rMean=squeeze(mean(mean(CatFactorData,1),2))'; % take the mean across factor values
            % take PCA for the mean data over all time
            [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=pca(squeeze(mean(CatFactorData,1))-repmat(rMean,[nLevelComb 1]));
            % take PCA per each time point now
            %            [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=...
            %                arrayfun(@(x) pca(squeeze(CatFactorData(x,:,:))-repmat(rMean(x,:),[nLevelComb 1])),1:NTim,'uniformoutput',0);
            % project each time point into the mean subspace
            PCA.score=arrayfun(@(x) (squeeze(CatFactorData(x,:,:))-repmat(rMean,[nLevelComb 1]))*PCA.coeff,1:NTim,'uniformoutput',0);
        end
        function PCA=DoPCAanalysisMeanTrialTime(obj,CatFactorData,FactorLevelComb,TargetFactors,varargin) % calculates PCA for time and trial(takes mean per condition)  and then projects back each time point in that space
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % do this analysis for each time point
            NTim=size(CatFactorData,1);
            nLevelComb=size(CatFactorData,2);
            NNeu=size(CatFactorData,3);
            % reorganize data into 2D
            CatFactorData2D=reshape(CatFactorData,[NTim*nLevelComb NNeu]);
            rMean=mean(CatFactorData2D,1); % take the mean across factor values and time
            % take PCA for the mean data over all time
            [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=pca(CatFactorData2D-repmat(rMean,[NTim*nLevelComb 1]));
            
            PCA.score= reshape(PCA.score,size(CatFactorData));
            PCA.score=arrayfun(@(x) squeeze(PCA.score(x,:,:)),1:NTim,'UniformOutput',0);
        end
        function UMAPout=DoUMAPanalysisTimeTrial(obj,CatFactorData,FactorLevelComb,TargetFactors,varargin) % calculates PCA for time and trial  and then projects back each time point in that space
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % do this analysis for each time point
            NTim=size(CatFactorData,1);
            nLevelComb=size(CatFactorData,2);
            NNeu=size(CatFactorData,3);
            % reorganize data into 2D
            CatFactorData2D=reshape(CatFactorData,[NTim*nLevelComb NNeu]);
            % rMean=mean(CatFactorData2D,1); % take the mean across factor values and time
            % take PCA for the mean data over all time
            % [umapProj]=run_umap(CatFactorData2D-repmat(rMean,[NTim*nLevelComb 1]),'n_components',3);
            [umapProj]=run_umap(zscore(CatFactorData2D,0,1),'n_components',3);
            
            UMAPout.score= reshape(umapProj,[size(CatFactorData,1) size(CatFactorData,2) 3]);
            UMAPout.score=arrayfun(@(x) squeeze(UMAPout.score(x,:,:)),1:NTim,'UniformOutput',0);
        end
        function PlotSubspaces(obj,Score,FactorLevels,nTim,varargin) % plots results from subspace analysis
            %@Score is a cell array of subspace scores as output of
            %DiscoverSubspaces function
            %nTim timepoint we want to look at
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            opts.MarkerSize=20;
            
            NSubspace=length(Score);
            if isempty(nTim);nTim=1;end
            
            % generate color for each factor level
            nFactorLevels=length(FactorLevels);
            
            FactorCol=AnalysisOpts.MorphlevelsColRGB;%obj.FigParams.getColorPalet(nFactorLevels(1));
            FactorMarker=obj.FigParams.getMarkerPalet(NSubspace);
            
            % plot PCA score with 3d plot
            for S=1:NSubspace
                hold on
                leg{S}=arrayfun(@(x) plot3(Score{S}{nTim}(x,1),Score{S}{nTim}(x,2),Score{S}{nTim}(x,3),'Color',FactorCol(x,:),...
                    'Marker',FactorMarker{S},'MarkerSize',opts.MarkerSize),1:nFactorLevels);
                % fit a plane to data per second condition now
                obj.PlotFittedPlane(Score{S}{nTim}(:,1:3));
            end
            legend(arrayfun(@(x) leg{x}(1),1:NSubspace),arrayfun(@(x) sprintf('Subspace%i',x),1:NSubspace,'UniformOutput',0));
            view(30,30);
            subtitle(obj.ThisSubtitle)
        end
        function PlotPCAanalysis(obj,PCAscore,FactorLevelComb,TargetFactors,varargin) % plots PCA planes in a 3D plot
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            opts.MarkerSize=20;
            % generate color for each factor level
            FactorLevels=arrayfun(@(x) unique(FactorLevelComb(:,x)),1:size(FactorLevelComb,2),'UniformOutput',0);
            nFactorLevels=cellfun(@length,FactorLevels);
            nPoints=size(FactorLevelComb,1);
            
            FactorCol=AnalysisOpts.MorphlevelsColRGB;%obj.FigParams.getColorPalet(nFactorLevels(1));
            FactorMarker=obj.FigParams.getMarkerPalet(nFactorLevels(2));
            
            % plot PCA score with 3d plot
            hold on
            leg=arrayfun(@(x) plot3(PCAscore(x,1),PCAscore(x,2),PCAscore(x,3),'Color',FactorCol(FactorLevelComb(x,1)==FactorLevels{1},:),...
                'Marker',FactorMarker{FactorLevelComb(x,2)==FactorLevels{2}},'MarkerSize',opts.MarkerSize),1:nPoints);
            % fit a plane to data per second condition now
            arrayfun(@(x) obj.PlotFittedPlane(PCAscore(FactorLevelComb(:,2)==x,1:3)), FactorLevels{2}','UniformOutput',0);
            legend('Rule1','Rule2','Rule3')
            view(30,30);
            
        end
        function [PCA,PCAcoeff,OriginPlane,FittedPlane,PlaneEq]=FitPlane2Data(obj,data,varargin) % finds the best 2D plane that fits the data using PCA
            %@ data points where we want to find the best plane fitting them
            %@ PCAcoeff vectors specifying the plane
            %@ OriginPlane: plane that passes through origin
            %@ FittedPlane: plane that is shifted to the mean of the points
            %@ PlaneEq: equation of the plane using
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            rMean=squeeze(mean(data,1)); % take the mean across factor values
            
            % take PCA per each time point now
            [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=...
                pca(data-repmat(rMean,[size(data,1) 1]));
            % now the plane is the two principal component vectors , orogin and their sum
            PCAcoeff=PCA.coeff(:,1:2)';
            sumPCAvectors=sum(PCAcoeff,1);
            
            OriginPlane=[0 0 0;PCAcoeff(1,:);sumPCAvectors;PCAcoeff(2,:)];
            
            % add mean to origin palce to get the fitted plane
            FittedPlane=rMean+OriginPlane;
            
            % get the equation for this plane as well
            % calculate orthogonal vector
            OrthoVector=cross(PCAcoeff(1,:),PCAcoeff(2,:));
            
            PlaneEq=@(x,y) (OrthoVector(1)*(rMean(1)-x)+OrthoVector(2)*(rMean(2)-y))./OrthoVector(3) + rMean(3);
        end
        function [PlaneEq]=PlotFittedPlane(obj,data,varargin) % fits a plane to the data and plots it
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            opts.PlaneColor(1,1,:)=[ 1   1   1 ];
            
            [~,~,~,~,PlaneEq]=obj.FitPlane2Data(data);
            % build a meshgrid with min and max of the data in x and y then estimate the z based on the euqation
            Mindata=min(data,[],1);
            Maxdata=max(data,[],1);
            range=(Maxdata-Mindata)/1000;
            X=Mindata(1):range(1):Maxdata(1);
            Y=Mindata(2):range(2):Maxdata(2);
            [x,y]=meshgrid(X,Y);
            z=PlaneEq(x,y);
            surface(x,y,z,repmat(opts.PlaneColor,[size(z,1),size(z,2),1]),'FaceColor',[1 1 1],'FaceAlpha',0.3);
            
        end
        function [PairAngled,PairAngler,CosTheta,Pairs]=CalculateAnglesBetSubspaces(obj,PCAscores,Factors,nD,varargin) % calculates angles between the planes that are fit to each condition
            %@PCAscores is a cell with scores of different conditions we want to compare
            %@Factors cellarray of factors if we are using quadrants then we collapse based on
            %Shape or Color and calculate angle between lines
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NConds=1:length(PCAscores);
            if isempty(Factors)
                % fit a plane to data per second condition now
                [PCA,PCAcoeff,OriginPlane,FittedPlane,PlaneEq]=arrayfun(@(x) obj.FitPlane2Data(PCAscores{x}(:,1:3)), NConds,'UniformOutput',0);
                
                % calculate perpenducular vector
                PerpendVec=cellfun(@(x) cross(x(1,:),x(2,:)),PCAcoeff,'UniformOutput',0);
                
                % calculate angle between pairs of conditions
                PairsInd=nchoosek(NConds,2);
                [PairAngled,PairAngler,CosTheta]=arrayfun(@(x) obj.ManData.GetAngleBetVectors(PerpendVec{PairsInd(x,1)},PerpendVec{PairsInd(x,2)}),1:size(PairsInd,1));
                Pairs=NConds(PairsInd);
            else % we are using a line to fit to average of the quadrants
                % calculate avegrage Quadrants for each one
                AverageQuadrants=arrayfun(@(x) obj.AverageQuadrants(PCAscores{x},Factors{x}),1:length(PCAscores),'UniformOutput',0);
                
                % calculate angle between Average Quadrants in 2D and 3D
                [PairAngled,PairAngler,CosTheta]=obj.ManData.GetAngleBetVectors(AverageQuadrants{1}(1,1:nD)-AverageQuadrants{1}(2,1:nD),AverageQuadrants{2}(1,1:nD)-AverageQuadrants{2}(2,1:nD));
                Pairs=[];
            end
        end
        function AvgPC=AverageQuadrants(obj,PCAscores,Factor,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if contains(Factor,'Color')
                AvgPC=[mean([PCAscores(1,:);PCAscores(4,:)],1);mean([PCAscores(2,:);PCAscores(3,:)],1)];
            elseif contains(Factor,'Shape')
                AvgPC=[mean([PCAscores(1,:);PCAscores(3,:)],1);mean([PCAscores(2,:);PCAscores(4,:)],1)];
            end
        end
        function SubspaceCompression=CalculateCompressionBetSubspaces(obj,PCAscores,varargin) % calculates compression in the quadrants
            % calculates compression if the input is PCs for Quadrants the
            % distance is euclidean distance between mean([Dist(GB-GT)
            % Dist(RB-RT)]/mean([GB-RB]-[RT-GT]
            %@PCAscores is a cell with scores of different conditions we want to compare
            %  correspond to [Shape Color] category [1 1],[2 2],
                % [1 2],[2 1] %[red bunny, green tee, green bunny, red tee]
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            SubspaceCompression=cellfun(@(x) obj.CalQuadrantCompression(x),PCAscores);
        end
        function Compression=CalQuadrantCompression(obj,PC,varargin)%calculates compression for Quadrants
            % @PC principal components of the quadrants
            % calculates compression if the input is PCs for Quadrants the
            % distance is euclidean distance between mean([Dist(GB-GT)
            % Dist(RB-RT)]/mean([GB-RB]-[RT-GT)
            %[1 1][2 2][1 2][2 1]->[RB,GT,GB,RT]
            %  correspond to [Shape Color] category [1 1],[2 2], [1 2],[2 1] %[red bunny, green tee, green bunny, red tee]
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            nPC=1:size(PC,2);
            Dist= @(x,y) sqrt(sum((x(:) - y(:)).^2)); %Euclidean Distance
            A1=PC(1,nPC);%RB
            A2=PC(2,nPC);%GT
            A3=PC(3,nPC);%GB
            A4=PC(4,nPC);%RT
            
            Compression=mean([Dist(A2,A3) Dist(A1,A4)])/mean([Dist(A3,A1) Dist(A4,A2)]);
        end
        function [CompressionEncoding,EncodingDist,EncodingVars,CompIndexVars]=CalQuadrantCompressionEncodingAxis(obj,ShapeAxisTime,ColorAxisTime,varargin)%calculates compression for Quadrants based on shape and color encoding axis
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % compression index is calculated by dividing distance in the
            % encoding axis along color divided by shape
            % objects are [1 1][2 2][1 2][2 1]->[RB,GT,GB,RT]-> O1 O2 O3 O4
            %CompressionIndex=mean([Dist(GB-RB),Dist(RT-GT)])/mean([Dist(GB-GT) Dist(RB-RT)])/% trial based
            % ColorDist=mean(Dist(O1,O3) Dist(O2,O4))
            % ShapeDist=mean(Dist(O2,O3) Dist(O1,O4)) ->
            % CimpressionIndex=ColorDist/ShapeDist
            EncodingVars={'ShapeDist','ShapeDistRed','ShapeDistGreen','ShapeDistCong','ShapeDistInCong',...
                'ColorDist','ColorDistBunny','ColorDistTee','ColorDistCong','ColorDistInCong'}; % list of distances for encoding varables
            CompIndexVars={'All','Cong','InCong'};
            if isempty(ShapeAxisTime);CompressionEncoding=[];EncodingDist=[];return;end
            nTrlRng=length(ColorAxisTime);
            NTrl=size(ShapeAxisTime{1}{1},1);
            MeanRS=@(x) mean(obj.ManData.ReshapeCell2Mat(x,2),1);
            
            for i=1:nTrlRng
                ShapeEncodeAxis=ShapeAxisTime{i};
                ColorEncodeAxis=ColorAxisTime{i};
                %% prepare encoding trial seperately               
                ShapeDist=arrayfun(@(trl) mean([abs(ShapeEncodeAxis{2}(trl,:)-ShapeEncodeAxis{3}(trl,:));abs(ShapeEncodeAxis{1}(trl,:)-ShapeEncodeAxis{4}(trl,:))],1),1:NTrl,'UniformOutput',0);
                ColorDist=arrayfun(@(trl) mean([abs(ColorEncodeAxis{1}(trl,:)-ColorEncodeAxis{3}(trl,:));abs(ColorEncodeAxis{2}(trl,:)-ColorEncodeAxis{4}(trl,:))],1),1:NTrl,'UniformOutput',0);
               % distance between same color but different shape on shape axis          
                ShapeDistRed=arrayfun(@(trl) mean([abs(ShapeEncodeAxis{1}(trl,:)-ShapeEncodeAxis{4}(trl,:))],1),1:NTrl,'UniformOutput',0);
                ShapeDistGreen=arrayfun(@(trl) mean([abs(ShapeEncodeAxis{2}(trl,:)-ShapeEncodeAxis{3}(trl,:))],1),1:NTrl,'UniformOutput',0);
               % distance between same shape but different color on color axis
                ColorDistBunny=arrayfun(@(trl) mean([abs(ColorEncodeAxis{1}(trl,:)-ColorEncodeAxis{3}(trl,:))],1),1:NTrl,'UniformOutput',0);
                ColorDistTee=arrayfun(@(trl) mean([abs(ColorEncodeAxis{2}(trl,:)-ColorEncodeAxis{4}(trl,:))],1),1:NTrl,'UniformOutput',0);
            
                %% prepare encoding for congruent and incongruent objects
                % congruent objects
                ShapeDistCong=arrayfun(@(trl) abs(ShapeEncodeAxis{3}(trl,:)-ShapeEncodeAxis{4}(trl,:)),1:NTrl,'UniformOutput',0);
                ColorDistCong=arrayfun(@(trl) abs(ColorEncodeAxis{3}(trl,:)-ColorEncodeAxis{4}(trl,:)),1:NTrl,'UniformOutput',0);
                % incongruent objects
                ShapeDistInCong=arrayfun(@(trl) abs(ShapeEncodeAxis{1}(trl,:)-ShapeEncodeAxis{2}(trl,:)),1:NTrl,'UniformOutput',0);
                ColorDistInCong=arrayfun(@(trl) abs(ColorEncodeAxis{1}(trl,:)-ColorEncodeAxis{2}(trl,:)),1:NTrl,'UniformOutput',0);
                %% calculate compression index on a trial by trial bases i.e for each trial we have one compression index
                CompressionEncoding.Trl.All(i,:)=mean(cell2mat(arrayfun(@(trl) [ColorDist{trl}./ShapeDist{trl}]',1:NTrl,'UniformOutput',0)),2);
                CompressionEncoding.Trl.Full{i}=cell2mat(arrayfun(@(trl) [ColorDist{trl}./ShapeDist{trl}]',1:NTrl,'UniformOutput',0));
                CompressionEncoding.Trl.Cong(i,:)=mean(cell2mat(arrayfun(@(trl) [ColorDistCong{trl}./ShapeDistCong{trl}]',1:NTrl,'UniformOutput',0)),2);
                CompressionEncoding.Trl.InCong(i,:)=mean(cell2mat(arrayfun(@(trl) [ColorDistInCong{trl}./ShapeDistInCong{trl}]',1:NTrl,'UniformOutput',0)),2);

                %% Compression index using average of encoing across trials i.e take average of encoding across trls before cal compression index
                for v=1:length(EncodingVars)
                    EncodingDist.([EncodingVars{v} 'Avg'])(i,:) =eval(['MeanRS(' EncodingVars{v} ')']);                    
                end
                % calculate compression index
                CompressionEncoding.TrlAvg.All(i,:)   =EncodingDist.ColorDistAvg(i,:)./EncodingDist.ShapeDistAvg(i,:);
                CompressionEncoding.TrlAvg.Cong(i,:)  =EncodingDist.ColorDistCongAvg(i,:)./EncodingDist.ShapeDistCongAvg(i,:);
                CompressionEncoding.TrlAvg.InCong(i,:)=EncodingDist.ColorDistInCongAvg(i,:)./EncodingDist.ShapeDistInCongAvg(i,:);                                                                 
            end
                %                 CompressionEncoding(i,:)=ShapeDist./ColorDist;
                %
                %                 % (Avg(GT,RT)-Avg(RB,GB))/(Avg(RB,RT)-Avg(GT,GB)) Averageof dimensions based
                %                 ShapeDist2=abs(mean([ShapeEncodeAxis(2,:);ShapeEncodeAxis(4,:)])-mean([ShapeEncodeAxis(1,:);ShapeEncodeAxis(3,:)]));
                %                 ColorDist2=abs(mean([ColorEncodeAxis(1,:);ColorEncodeAxis(4,:)])-mean([ColorEncodeAxis(2,:);ColorEncodeAxis(3,:)]));
                %                 CompressionEncoding2(i,:)=ShapeDist2./ColorDist2;
   
        end
        function [PairAngled,PairAngler,CosTheta,Pairs]=CalculateAnglesBetConds(obj,PCAscore,FactorLevelComb,TargetFactors,varargin) % calculates angles between the planes that are fit to each condition
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare variables
            FactorLevels=arrayfun(@(x) unique(FactorLevelComb(:,x)),1:size(FactorLevelComb,2),'UniformOutput',0);
            nFactorLevels=cellfun(@length,FactorLevels);
            nPoints=size(FactorLevelComb,1);
            
            % fit a plane to data per second condition now
            [PCA,PCAcoeff,OriginPlane,FittedPlane,PlaneEq]=arrayfun(@(x) obj.FitPlane2Data(PCAscore(FactorLevelComb(:,2)==x,1:3)), FactorLevels{2}','UniformOutput',0);
            
            % calculate perpenducular vector
            PerpendVec=cellfun(@(x) cross(x(1,:),x(2,:)),PCAcoeff,'UniformOutput',0);
            
            % calculate angle between pairs of conditions
            PairsInd=nchoosek(1:nFactorLevels(2),2);
            [PairAngled,PairAngler,CosTheta]=arrayfun(@(x) obj.ManData.GetAngleBetVectors(PerpendVec{PairsInd(x,1)},PerpendVec{PairsInd(x,2)}),...
                1:nFactorLevels(2));
            Pairs=FactorLevels{2}(PairsInd);
        end
        function [FactorData,CatFactorData,FactorLevelComb,FactorLevels,ObjComb]=PrepareData4PCAnalysis(obj,FactorizedData,TargetFactor,WantedFactorLevels,varargin) % prepares population data using factors
            %@FactorizedData factorized data based on different defined factors
            %@TargetFactor factors used to organize the input data
            %@
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            
            for Neu=1:length(FactorizedData) % loop on the neurons
                % find the data for this factor
                [FactorData(Neu).data,FactorData(Neu).dataMean,FactorLevelComb,FactorLevels,~,FactorData(Neu).nTrlFactorData,ObjComb]=...
                    obj.GrabFactorDatabyLevel(FactorizedData(Neu),TargetFactor,WantedFactorLevels);
            end
            % concatinate mean data for factors
            CatFactorData=obj.ManData.ReshapeStruct2Mat(FactorData,'dataMean',3);
        end
        function [FactorData,MeanFactorData,FactorLevelComb,FactorLevels,AllFactors,nTrlFactorData,ObjComb,FactorData_SpkCnt]=GrabFactorDatabyLevel(obj,FactorizedData,TargetFactor,WantedFactorLevels,varargin) % grabs conjunction of factor data based on their levels
            %  IntegTimeEpoch is the time epoch that we want to sum the
            %  number of spikes ; leave empty if you don't want it
            %  Target factor can be Rule, ColorML, ColorCat, ShapeML, ShapeCat, PrototypeObject, AllObjects, AllObjectsInc50
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare variables
            factornames=AnalysisOpts.factornames;
            CorrIncorrInd=cellfun(@(x) find(strcmp(factornames,x)),{'Reward'});
            ShapeMLInd=find(strcmp(factornames,'ShapeML'));
            ColorMLInd=find(strcmp(factornames,'ColorML'));
            ResponseLocInd=find(strcmp(factornames,'ResponseLoc'));
            RuleResponseLoc=[1 2;3 4;1 2]; % what are the response locations of each rule
            
            nFactors=length(TargetFactor);
            ThisTargetFactor=TargetFactor;
            % if one of the target factors is "PrototypeObject" Then only take Shape color [0 0;100 100;100 0;0 100]
            if strcmp(ThisTargetFactor{1},'PrototypeObject') | strcmp(ThisTargetFactor{1},'AllObjects')
                TargetFactor=[{'ShapeML'} TargetFactor{2}];
            end
            
            % determine factor levels
            TargetFactorInds=cellfun(@(x) find(strcmp(factornames,x)),TargetFactor);
            if isempty(WantedFactorLevels)
                FactorLevels=arrayfun(@(x) unique(FactorizedData.factors{x}),TargetFactorInds,'UniformOutput',0);
            else
                FactorLevels=WantedFactorLevels;
            end
            
            if obj.PCAremove50ML% remove 50% morphlevels
                FactorLevels=cellfun(@(x) obj.ManData.RemoveEntryFromVec(x,[50 150]),FactorLevels,'UniformOutput',0);
            end
            
            % change factor levels if we are using PrototypeObject or AllObjects
            if strcmp(ThisTargetFactor{1},'PrototypeObject')
                FactorLevels={[1 2 3 4],FactorLevels{2}}; % we have 4 objects ([0 0],[100 100],[0 100],[100 0])
                ObjComb=[0 0;100 100;0 100;100 0];%[red bunny, green tee, green bunny, red tee]
            elseif strcmp(ThisTargetFactor{1},'AllObjects')
                StimulusMorphLevels=obj.ManData.RemoveEntryFromVec(AnalysisOpts.StimulusMorphLevels,[50 150]);
                % generate a matrix with all of the objects other than ambigous (50 150) objects
                ObjComb=[sort(repmat(StimulusMorphLevels',[length(StimulusMorphLevels) 1])) repmat(StimulusMorphLevels',[length(StimulusMorphLevels) 1])];
                FactorLevels={[1:size(ObjComb,1)],FactorLevels{2}};
            else
                ObjComb=[];
            end
            
            % get ind all of the combinations of factor levels
            % FactorLevelComb=cell2mat(arrayfun(@(x) sort(repmat(FactorLevels{x}',...
            % [length(FactorLevels{setdiff(1:nFactors,x)}) 1])),1:nFactors,'UniformOutput',0));
            
            % find conjuction of data for all of the factor levels
            CorrIncorrFactorVals=obj.GrabFactorVals4thisFactor(FactorizedData,CorrIncorrInd);
            
            if nFactors==1
                if ~iscell(FactorLevels{1});FactorLevelComb=FactorLevels{1};else;FactorLevelComb=cell2mat(FactorLevels{1});end
                FactorVals1=obj.GrabFactorVals4thisFactor(FactorizedData,TargetFactorInds(1));
                
                if obj.PCAonlyCorrTrls==1
                    FactorDataInd=arrayfun(@(x)  FactorVals1==FactorLevelComb(x,1) & CorrIncorrFactorVals==1 ,1:size(FactorLevelComb,1),'UniformOutput',false);
                elseif obj.PCAonlyCorrTrls==2 % incorrect
                    FactorDataInd=arrayfun(@(x)  FactorVals1==FactorLevelComb(x,1) & CorrIncorrFactorVals==0 ,1:size(FactorLevelComb,1),'UniformOutput',false);
                elseif obj.PCAonlyCorrTrls==3 % all
                    FactorDataInd=arrayfun(@(x)  FactorVals1==FactorLevelComb(x,1) ,1:size(FactorLevelComb,1),'UniformOutput',false);
                end
            elseif nFactors==2
                if ~iscell(FactorLevels{1}) % check if second target factor needs to be matched with a specific value in the first target factor
                    FactorLevelComb=[sort(repmat(FactorLevels{1}',[length(FactorLevels{2}) 1])) repmat(FactorLevels{2}',[length(FactorLevels{1}) 1])];
                else
                    FactorLevelComb=transpose(cell2mat(arrayfun(@(x) [sort(repmat(FactorLevels{1}{x}',[length(FactorLevels{2}(x)) 1])) repmat(FactorLevels{2}(x)',[length(FactorLevels{1}{x}) 1])]',1:length(FactorLevels{1}),'UniformOutput',0)));
                end
                
                if strcmp(ThisTargetFactor{1},'PrototypeObject') | strcmp(ThisTargetFactor{1},'AllObjects')
                    ShapeFactorVals=obj.GrabFactorVals4thisFactor(FactorizedData,ShapeMLInd);
                    ColorFactorVals=obj.GrabFactorVals4thisFactor(FactorizedData,ColorMLInd);
                    FactorVals2=obj.GrabFactorVals4thisFactor(FactorizedData,TargetFactorInds(2));
                    
                    if obj.PCAonlyCorrTrls==1 % correct
                        FactorDataInd=arrayfun(@(x)  ShapeFactorVals==ObjComb(FactorLevelComb(x,1),1) &  ColorFactorVals==ObjComb(FactorLevelComb(x,1),2) & FactorVals2==FactorLevelComb(x,2)  & CorrIncorrFactorVals==1 ,1:size(FactorLevelComb,1),'UniformOutput',false);
                    elseif obj.PCAonlyCorrTrls==2 % incorrect
                        FactorDataInd=arrayfun(@(x)  ShapeFactorVals==ObjComb(FactorLevelComb(x,1),1) &  ColorFactorVals==ObjComb(FactorLevelComb(x,1),2) & FactorVals2==FactorLevelComb(x,2)  & CorrIncorrFactorVals==0 ,1:size(FactorLevelComb,1),'UniformOutput',false);
                    elseif obj.PCAonlyCorrTrls==3 % all
                        FactorDataInd=arrayfun(@(x)  ShapeFactorVals==ObjComb(FactorLevelComb(x,1),1) &  ColorFactorVals==ObjComb(FactorLevelComb(x,1),2) & FactorVals2==FactorLevelComb(x,2) ,1:size(FactorLevelComb,1),'UniformOutput',false);
                    end
                else
                    FactorVals1=obj.GrabFactorVals4thisFactor(FactorizedData,TargetFactorInds(1));
                    FactorVals2=obj.GrabFactorVals4thisFactor(FactorizedData,TargetFactorInds(2));
                    
                    if obj.PCAonlyCorrTrls==1 % correct
                        FactorDataInd=arrayfun(@(x) FactorVals1==FactorLevelComb(x,1) & FactorVals2==FactorLevelComb(x,2)  & CorrIncorrFactorVals==1,1:size(FactorLevelComb,1),'UniformOutput',false);
                    elseif obj.PCAonlyCorrTrls==2 % incorrect
                        FactorDataInd=arrayfun(@(x) FactorVals1==FactorLevelComb(x,1) & FactorVals2==FactorLevelComb(x,2)  & CorrIncorrFactorVals==0,1:size(FactorLevelComb,1),'UniformOutput',false);
                    elseif obj.PCAonlyCorrTrls==3 % all
                        FactorDataInd=arrayfun(@(x) FactorVals1==FactorLevelComb(x,1) & FactorVals2==FactorLevelComb(x,2),1:size(FactorLevelComb,1),'UniformOutput',false);
                    end
                end
            end
            % remove off axis response if we need to
            if strcmp(ThisTargetFactor{2},'Rule')
                ResponseLocVals=obj.GrabFactorVals4thisFactor(FactorizedData,ResponseLocInd);
                ResponseLocDataInd=arrayfun(@(x) ResponseLocVals==RuleResponseLoc(FactorLevelComb(x,2),1) | ResponseLocVals==RuleResponseLoc(FactorLevelComb(x,2),2) ,1:size(FactorLevelComb,1),'UniformOutput',false);
                FactorDataInd=arrayfun(@(x) ResponseLocDataInd{x} & FactorDataInd{x},1:size(FactorLevelComb,1),'UniformOutput',false);
            else
                warning('\Off axis responses are not removed because the second target factor is not Rule');
            end
            % if sum(strcmp(TargetFactor,'Rule'))==2 % if we are looking at Rule conditions
            if ~strcmp(ThisTargetFactor{1},'AllObjects')
                % remove conditions where there is no data
                NonEmptyConds=logical(cellfun(@sum,FactorDataInd));
                FactorDataInd=FactorDataInd(NonEmptyConds);
                FactorLevelComb=FactorLevelComb(NonEmptyConds,:);
            end
            % end
            
            % get spiking data for data type we are looking for
            FactorData=cellfun(@(x) FactorizedData.data(x,:),FactorDataInd,'UniformOutput',0);
            
            % if there is any SpkCountData then get those as well
            if ~isempty(FactorizedData.SpkCntbyFactor)
                FactorData_SpkCnt=cellfun(@(y) cellfun(@(x) y(x),FactorDataInd,'UniformOutput',0),FactorizedData.SpkCntbyFactor,'UniformOutput',0);
            else
                FactorData_SpkCnt=[];
            end
            nTrlFactorData=cellfun(@(x) size(x,1),FactorData);
            
            % if you want to plot and see the distribution
            %bar(nTrlFactorData)
            %arrayfun(@(x) text(x,40,{num2str(ObjComb(FactorLevelComb(x,1),1));num2str(ObjComb(FactorLevelComb(x,1),2));num2str(FactorLevelComb(x,2))},'FontSize',6),1:108)
            
            % take mean of the value spiking data
            MeanFactorData=cell2mat(cellfun(@(x) mean(x,1)',FactorData,'UniformOutput',0));
            % get all of the factors for these trials they might be use later in the any analysis
            AllFactors=cellfun(@(y) cell2mat(cellfun(@(x) double(x(:,y))',FactorizedData.factors,'UniformOutput',0)),...
                FactorDataInd,'UniformOutput',0);
        end
        function FactorVals=GrabFactorVals4thisFactor(~,FactorizeData,FactorInd)
            global AnalysisOpts
            if ischar(FactorInd);FactorInd=find(strcmp(FactorizeData(1).factornames,FactorInd));end
            ind1=AnalysisOpts.factorindex(1,FactorInd);
            ind2=AnalysisOpts.factorindex(2,FactorInd);
            FactorVals=FactorizeData.factors{ind1}(ind2,:);
        end
        function no_dims=CalculateIntrinsicDimensionality(obj,data,method,varargin) % calculates intrinsic dimensionality of the data
            % @data can be a 2D matrix. If it is 3D or it a cell array, the Dim3 or the each cell array will be considered a time point
            % @method can be defined based on my own developed method or using Dimensionality reduction Toolbox. developed by Laurens van der Maaten(should be added to the path)
            %Possible values for method are 'CorrDim'(based on correlation dimension), 'NearNbDim' (based on nearest neighbor
            % dimension), 'GMST' (based on the analysis of the geodesic minimum spanning tree), 'PackingNumbers' (based on the analysis of data packing numbers),
            % 'EigValue' (based on analysis of PCA eigenvalues), and 'MLE' (maximum likelihood estimator). The default method is 'MLE'. All methods are
            % parameterless.
            % @method can be 'PCAExpVar' where the number of principal components that are needed to explain 95% of variance are reported using PCA function
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % prepare data points by putting data for each time point in a cell
            if ~iscell(data);data=arrayfun(@(x) data(:,:,x),1:size(data,3),'UniformOutput',0);end
            NTim=length(data);
            try
                if strcmp(method,'PCAExpVar')
                    % take pca
                    [PCA.coeff,PCA.score,PCA.latent,PCA.tsquared,PCA.explained,PCA.mu]=...
                        arrayfun(@(x) pca(data{x}-repmat(mean(data{x},1),[size(data{x},1) 1])),1:NTim,'uniformoutput',0);
                    % find the number of PCs necessary to explain 95% of varaince
                    no_dims=cellfun(@(x) find(cumsum(x)>=70,1,'first'),PCA.explained);
                else
                    no_dims=cellfun(@(x) intrinsic_dim(x,method),data);
                end
            catch
                no_dims=nan*ones(1,NTim);
            end
            
        end
        function PlotSubspaceinTime(obj,PCA,FactorLevelComb,TargetFactors,ObjComb,varargin) % plots Subspace Evolution in Time
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            opts.MarkerSize=20;
            FactorLevels=arrayfun(@(x) unique(FactorLevelComb(:,x)),1:size(FactorLevelComb,2),'UniformOutput',0);
            nFactorLevels=cellfun(@length,FactorLevels);
            nPoints=size(FactorLevelComb,1);
            NTim=length(PCA.score); % number of time points
            if strcmp(TargetFactors{1},'AllObjects')
                MorphlevelsCol=unique(ObjComb(:,1))';
                FactorCol=transpose(cell2mat(arrayfun(@(x) AnalysisOpts.MorphlevelsColRGB(MorphlevelsCol==ObjComb(x,2),:)',1:nFactorLevels(1),'UniformOutput',0)));    % generate color for each factor level
            elseif strcmp(TargetFactors{1},'ProtoypeObject')
                FactorCol=AnalysisOpts.ProtoypeImgRGB;%MorphlevelsColRGB;
            end
            FactorMarker=obj.FigParams.getMarkerPalet(nFactorLevels(2));
            FactorLineStype={'-','--','-.',':'};
            
            Projection=obj.ManData.ReshapeCell2Mat(PCA.score,3);
            hold on
            % colormap(jet(255));
            TimeInd=AnalysisOpts.Time>0;
            for p=1:nPoints
                
                ThisCondProj=squeeze(Projection(p,:,:));
                %   plot3(ThisCondProj(1,:),ThisCondProj(2,:),ThisCondProj(3,:),'Color',FactorCol(FactorLevelComb(p,1)==FactorLevels{1},:));%,...
                %   'Marker',FactorMarker{FactorLevelComb(x,2)==FactorLevels{2}},'MarkerSize',opts.MarkerSize)
                x=ThisCondProj(1,TimeInd);y=ThisCondProj(2,TimeInd);z=ThisCondProj(3,TimeInd);
                ThisCondInd=find(FactorLevels{1}==FactorLevelComb(p,1));
                col_ind=1:length(x);
                ThisCol=cell2mat(arrayfun(@(y) FactorCol(ThisCondInd,:)'*y,col_ind,'uniformoutput',0));
                col=zeros(size(z,1),size(z,2),3);col(1,:,:)=ThisCol'/max(ThisCol(:));
                surface([x;x],[y;y],[z;z],[col;col],...%[col;col],...
                    'facecol','no',...
                    'edgecol','interp',...
                    'linew',(obj.ManData.CategorizeMorphlevel(ObjComb(ThisCondInd,1)))*2.5,...
                    'LineStyle',FactorLineStype{FactorLevelComb(p,2)});
            end
            view(30,30);
            % add legend
            h=cellfun(@(x) plot([0:10],[0:10],'r','LineStyle',x, 'visible', 'off'),FactorLineStype(1:nFactorLevels(2)),'UniformOutput',1);
            legs=arrayfun(@(x) [TargetFactors{2} num2str(x)],FactorLevels{2},'UniformOutput',0);
            legend(h,legs{:});
            
            xlabel('PC1');ylabel('PC2');zlabel('PC3')
            
            % plot PCA score with 3d plot
            %             hold on
            %             for t=1:NTim
            %                 leg=arrayfun(@(x) plot3(PCA.score{t}(x,1),PCA.score{t}(x,2),PCA.score{t}(x,3),'Color',FactorCol(FactorLevelComb(x,1)==FactorLevels{1},:),...
            %                     'Marker',FactorMarker{FactorLevelComb(x,2)==FactorLevels{2}},'MarkerSize',opts.MarkerSize),1:nPoints);
            %             end
            %             % fit a plane to data per second condition now
            %             arrayfun(@(x) obj.PlotFittedPlane(PCAscore(FactorLevelComb(:,2)==x,1:3)), FactorLevels{2}','UniformOutput',0);
            %             legend('Rule1','Rule2','Rule3')
            
            
        end
        function varargout=PlotPCADatainTime(obj,DimRedData,CondInds,TimeAxis,CondNames,PCNums,DimRedMethod,varargin) % plots PCA(or tsne) data type in time
            %@PCA is the pca of the data
            %@Inds is the index per data point that shows which category it
            %@DimRedMethod is PCA or tsne
            %belongs to
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            switch DimRedMethod
                case 'pca'
                    Data=DimRedData.score;
                    sgtitletxt=sprintf('%s Analysis: Sum Ex Var for PC%i,%i,%i=%0.1f Percent',DimRedMethod,PCNums(1),PCNums(2),PCNums(3),sum(DimRedData.explained(PCNums)));
                case 'tsne'
                    Data=DimRedData.score;
                    sgtitletxt=sprintf('%s Analysis:Loss %0.1f ',DimRedMethod,DimRedData.loss);
            end
            Conds=unique(CondInds);nConds=length(Conds);
            NTim=sum(CondInds==Conds(1)); % number of time points
            FactorMarker=obj.FigParams.getMarkerPalet(nConds);
            FactorCol=obj.FigParams.getColorPalet(nConds);
            FactorLineStype={'-',':','--','-.'};
            % get timings
            TimeTxt=[0 0.05 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8];
            TimeTxtInd=arrayfun(@(x) find(TimeAxis>=x,1,'first'),TimeTxt);
            TimeTxtChar=arrayfun(@(x) num2str(x),TimeTxt,'UniformOutput',0);
            varargout=obj.FigParams.RenderFigure(1,[]);
            hold on
            % colormap(jet(255));
            for p=Conds
                ThisCondProj=Data(CondInds==p,:); % limit to this condition
                % ThisCondProj=ThisCondProj; % limit to these timepoints
                x=ThisCondProj(:,PCNums(1))';y=ThisCondProj(:,PCNums(2))';z=ThisCondProj(:,PCNums(3))';
                col_ind=1:length(x);
                ThisCol=cell2mat(arrayfun(@(y) FactorCol(p,:)'*y,col_ind,'uniformoutput',0));
                col=zeros(size(z,1),size(z,2),3);col(1,:,:)=ThisCol'/max(ThisCol(:));
                surface([x;x],[y;y],[z;z],[col;col],...%[col;col],...
                    'facecol','no',...
                    'edgecol','interp',...
                    'linew', 2.5,...
                    'LineStyle',FactorLineStype{p});
                % show time for each point
                text(x(TimeTxtInd),y(TimeTxtInd),z(TimeTxtInd),TimeTxtChar)
            end
            view(30,30);
            % add legend
            h=arrayfun(@(x) plot([0:10],[0:10],'color',FactorCol(x,:),'LineStyle',FactorLineStype{x}, 'visible', 'off'),(1:nConds),'UniformOutput',1);
            legs=CondNames;%arrayfun(@(x) ['Cond:' num2str(x)],1:nConds,'UniformOutput',0);
            legend(h,legs{:});
            
            xlabel([DimRedMethod num2str(PCNums(1))]);ylabel([DimRedMethod num2str(PCNums(2))]);zlabel([DimRedMethod num2str(PCNums(3))])
            sgtitle(sgtitletxt)
            obj.FigParams.FormatAxes(gca)
        end
        function h=PlotXcorrInTime(obj,Data,CondInds,TimeAxis,CondNames,varargin) % plots Xcorr of conditions in time
            % Data Matrix of values that Xcorr needs to be calculated for
            % CondInds Index of each condition in Time
            % TimeAxis value of time per time point
            % CondNames: name of each condition based on the index
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            Xcorr=corr(Data,Data); % calculate cross correlation
            
            % now plot this
            % build the time axis labels
            nConds=length(unique(CondInds));
            nTim=length(TimeAxis);
            FullTimeAxis=repmat(TimeAxis,[1 nConds]);nTimFull=length(FullTimeAxis);
            TimeTxt=[0  0.2  0.4  0.6  ];
            TimeTxtInd=arrayfun(@(x) find(FullTimeAxis>=x,1,'first'),TimeTxt,'UniformOutput',1);
            TimeTxtInd=cell2mat(arrayfun(@(x) TimeTxtInd+nTim*(x-1),1:nConds,'UniformOutput',0));
            TimeTxtChar=repmat(arrayfun(@(x) num2str(x),TimeTxt,'UniformOutput',0),[1 nConds]);
            
            h=obj.FigParams.RenderFigure(1,[]);
            [h,Sp]=obj.FigParams.RenderSubplots(1,1,h{1},1);
            AxisLabelCond={strjoin(CondNames,repmat(' ',[1 30]))};
            obj.FigParams.Image(1:nTimFull,1:nTimFull,Xcorr,['Time(s)';AxisLabelCond],['Time(s)';AxisLabelCond],'Corr',['Xcorr between ' ;CondNames'],Sp,...
                'Xticks',TimeTxtInd,'XticksLabels',TimeTxtChar,'Yticks',TimeTxtInd,'YticksLabels',TimeTxtChar)
        end
        %% AxB  ANALYSIS RELATED FUNCTIONS
        function [AxBresults_Analysis1,AxBresults_Analysis2,AxBresults_Analysis3,AxBresults_Analysis4]=RunMultipleAxBanalysisonSubspaceOld(obj,SubspaceSpkCnt,FactorLvLInds,FactorLvLData,FactorLevels,SubspaceAnaOpts,ParamMdlRDM_type,AnalysisType,varargin) % runs a bunch of AxB analysis on the data
            %@ AnalysisType can be 'Learning' or 'SensoryMotorTransform'
            
            % in the case of Learning there are three analysis
            %1) Charactrize geometry of sensory representation during
            %learning
            %2) Charactrize geometry of response representation during
            %learning
            %3) Charactrize geometry of sensory to response transformation
            
            % in the case of SensoryMotorTransform there are two analysis
            % 1) Charactrize geometry of sensory to response in the same
            % rule
            % 2) Charactrize geometry of sensory in one rule to response in
            % another rule
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            SubspaceAnaOpts.ConcatinateMethod='MeanAllTrlTime';
            opts.DoPCAonAllTimePoints=1; % are we doing PCA before hand on all timepoints
            switch AnalysisType
                case {'SensoryMotorTransform','Learning'}
                    % find the timeing where there has been a response
                    if strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON');RespTim=0.4;elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START');RespTim=0;end
                    IndResp=find(SubspaceAnaOpts.SpkCountPeriod(:,1)==RespTim,1,'first');
                    nTim=size(SubspaceAnaOpts.SpkCountPeriod,1);
                    fprintf('\nRunning AxB analysis')
                    
                    %%
                    %% test to visualize the process of transformation
                    for t=SubspaceAnaOpts.SpkCountPeriod(:,1)'%-0.6:0.02:0.4
                        IndPreResp=find(floor(SubspaceAnaOpts.SpkCountPeriod(:,1)*1000)==floor(t*1000),1,'first');
                        FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData{IndPreResp}(FactorLvLInds{IndPreResp}==2)];
                        AxBresults_AnalysisTest=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{IndPreResp},...
                            FactorLvLDataSR,FactorLevels{IndPreResp},SubspaceAnaOpts,t,...
                            'PlotAxBDetails',1,'PlotAxBCircSubspace',0);
                        pause
                    end
                    
                    % take PCA of the data in all time points before feeding it into the anaysis.
                    % In this case we put all data points in a similar reference point
                    MeanFactorData=obj.ManData.ReshapeCell2Mat(cellfun(@(y) cell2mat(cellfun(@(x) mean(x,1)',y,'UniformOutput',0))',FactorLvLData,'UniformOutput',0),3);
                    tic
                    % if opts.DoPCAonAllTimePoints
                    % subtract the mean
                    MeanFactorData(1:4,:,:)=MeanFactorData(1:4,:,:)-mean(MeanFactorData(1:4,:,:),1);
                    MeanFactorData(5:8,:,:)=MeanFactorData(5:8,:,:)-mean(MeanFactorData(5:8,:,:),1);
                    
                    % for each analysis we project the data with its own
                    % related conditions
                    Analysis1_FactorData=MeanFactorData(1:4,:,:);
                    Analysis1_Subspace=obj.PerformSubspacePCAAnalysis(Analysis1_FactorData,SubspaceAnaOpts);
                    
                    Analysis2_FactorData=MeanFactorData(1:8,:,:);
                    Analysis2_Subspace=obj.PerformSubspacePCAAnalysis(Analysis2_FactorData,SubspaceAnaOpts);
                    
                    
                    
                    for Tim=1:nTim
                        FactorLvLDataSR=[Analysis1_Subspace.score{IndResp}; Analysis1_Subspace.score{Tim}];
                        AxBresults_Analysis1{Tim}=obj.AxBFunc.RunAxBanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts);
                        
                        FactorLvLDataSR=[Analysis2_Subspace.score{IndResp}(FactorLvLInds{IndResp}==1,:); Analysis2_Subspace.score{Tim}(FactorLvLInds{Tim}==2,:)];
                        AxBresults_Analysis2{Tim}=obj.AxBFunc.RunAxBanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts);
                        
                        %% find the angle with PCA analsis as well
                        [AxBresults_Analysis1{Tim}.PairAngled,~,AxBresults_Analysis1{Tim}.CosTheta] =obj.CalculateAnglesBetSubspaces({Analysis1_Subspace.score{IndResp} Analysis1_Subspace.score{Tim}},[]); % calculates angles between the planes that are fit to each condition
                        [AxBresults_Analysis1{Tim}.SubspaceCompression1]  =obj.CalculateCompressionBetSubspaces(Analysis1_Subspace.score(IndResp));  % Calculates compression for each subspace
                        [AxBresults_Analysis1{Tim}.SubspaceCompression2]  =obj.CalculateCompressionBetSubspaces(Analysis1_Subspace.score(Tim));      % Calculates compression for each subspace
                        
                    end
                    
                    %%
                    %   else
                    for Tim=1:nTim
                        %% run analysis 1 (SensoryToResponse_SameRule)
                        %% tranformation of sensory to response in the same rule
                        FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis3{Tim}=obj.AxBFunc.RunAxBanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts);
                        
                        %% run analysis 2 (SensoryToResponse_DiffRule)
                        %% tranformation of sensory in one rule to response in another rule
                        FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis4{Tim}=obj.AxBFunc.RunAxBanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts);
                    end
                    %    end
                    ElapsedTime=toc;
                    fprintf('\nAnalysing AxB  for Time point %i/%i ElapsedTime:%0.2f',Tim,nTim,ElapsedTime);
                    
            end
        end
        function AxBresults_CompAnalysis=RunAxBCompositionalityAnalysis(obj,FactorLvLData1,FactorLvLData2,FactorLvLInds,FactorLevels,SubspaceAnaOpts,AnalysisType,Cond,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            opts.XtempCompositionlityAna=0; % are we running an cross temporal compositionality analysis
            opts.UsePCCompositionalityAna=0; % are we taking PC before feeding the data into analysis
            SubspaceAnaOpts.ConcatinateMethod='MeanAllTrlTime';
            
            if ~strcmp(SubspaceAnaOpts.Name,'Sensory Motor Transformation');error('this analysis works only for Sensory Motor Transformation...');end
            % find the timeing where there has been a response
            if strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON');RespTim=0.3;elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START');RespTim=0;end
            IndResp=find(SubspaceAnaOpts.SpkCountPeriod(:,1)==RespTim,1,'first');
            nTim=size(SubspaceAnaOpts.SpkCountPeriod,1);
            
            %% do compoistionality analysis % this is supposing that we are running Processing Step 3
            fprintf('\nRunning AxB compositionality analysis')
            
            % build a PCA space for this analysis
            % [FactorLvLData1{x} FactorLvLData2{x}(1:4)] if we are in the sensory motor
            % trasnformation this will give us the trials from rule 1 2 3
            Ntrl=size(FactorLvLData1{1}{1},1);
            if opts.UsePCCompositionalityAna % we are taking PC before feeding into
                TrlPCData=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) obj.ManData.ReshapeCell2Mat([FactorLvLData1{x} FactorLvLData2{x}(1:4)],62),1:nTim,'uniformoutput',0),3);
                TrlPCSubspace=obj.PerformSubspacePCAAnalysis(TrlPCData,SubspaceAnaOpts);
                TrlPC=cellfun(@(x) arrayfun(@(y) x((y-1)*Ntrl+1:(y)*Ntrl,:),1:12,'uniformoutput',0),TrlPCSubspace.score,'uniformoutput',0);
            else
                TrlPC=arrayfun(@(x) [FactorLvLData1{x} FactorLvLData2{x}(1:4)],1:nTim,'UniformOutput',0);
            end
            AxBresults_CompAnalysis.GeneralizationErr=[];AxBresults_CompAnalysis.CompositionErr=[];AxBresults_CompAnalysis.GeneralizationErr_Sh=[];
            % determine timing
            if opts.XtempCompositionlityAna
                TimeMatrixSize=[nTim nTim];
                [XTimInd,YTimInd]=ind2sub(TimeMatrixSize,1:nTim^2);
                nXtimePnt=nTim^2;
            else
                nXtimePnt=nTim;
            end
            
            for Tim=1:nXtimePnt
                tic
                % FactorLvLData_Compositionality{1}=[FactorLvLData1{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData1{Tim}(FactorLvLInds{Tim}==1)]; %R1
                % FactorLvLData_Compositionality{2}=[FactorLvLData1{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData1{Tim}(FactorLvLInds{Tim}==2)]; %R2
                % FactorLvLData_Compositionality{3}=[FactorLvLData2{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData2{Tim}(FactorLvLInds{Tim}==1)]; %R2
                if opts.XtempCompositionlityAna
                    FactorLvLData_Compositionality{1}=[TrlPC{YTimInd(Tim)}(1:4) TrlPC{XTimInd(Tim)}(1:4)];   %R1
                    FactorLvLData_Compositionality{2}=[TrlPC{YTimInd(Tim)}(5:8) TrlPC{XTimInd(Tim)}(5:8)];   %R2
                    FactorLvLData_Compositionality{3}=[TrlPC{YTimInd(Tim)}(9:12) TrlPC{XTimInd(Tim)}(9:12)]; %R3
                else
                    % measure moment to moment
                    FactorLvLData_Compositionality{1}=[TrlPC{Tim}(1:4) TrlPC{Tim}(1:4)];   %R1
                    FactorLvLData_Compositionality{2}=[TrlPC{Tim}(5:8) TrlPC{Tim}(5:8)];   %R2
                    FactorLvLData_Compositionality{3}=[TrlPC{Tim}(9:12) TrlPC{Tim}(9:12)]; %R3
                    
                    % measure with respect to saccade onset
                    FactorLvLData_Compositionality_Sac{1}=[TrlPC{IndResp}(1:4) TrlPC{Tim}(1:4)];   %R1
                    FactorLvLData_Compositionality_Sac{2}=[TrlPC{IndResp}(5:8) TrlPC{Tim}(5:8)];   %R2
                    FactorLvLData_Compositionality_Sac{3}=[TrlPC{IndResp}(9:12) TrlPC{Tim}(9:12)]; %R3
                end
                % do analysis for moment to moment
                [AxBresults_CompAnalysis.GeneralizationErr(Tim,:),AxBresults_CompAnalysis.CompositionErr(Tim,:),AxBresults_CompAnalysis.GeneralizationErr_Sh(Tim,:),...
                    AxBresults_CompAnalysis.GeneralizationCorr(Tim,:),AxBresults_CompAnalysis.CompositionCorr(Tim,:),AxBresults_CompAnalysis.GeneralizationCorr_Sh(Tim,:)]=...
                    obj.AxBFunc.TestAxBCompositionality(FactorLvLInds{1},FactorLvLData_Compositionality,SubspaceAnaOpts,'UsePCA4AxB',1);
                
                % do anlayis for locked to saccade
                [AxBresults_CompAnalysis.GeneralizationErr_Sac(Tim,:),AxBresults_CompAnalysis.CompositionErr_Sac(Tim,:),AxBresults_CompAnalysis.GeneralizationErr_Sh_Sac(Tim,:),...
                    AxBresults_CompAnalysis.GeneralizationCorr_Sac(Tim,:),AxBresults_CompAnalysis.CompositionCorr_Sac(Tim,:),AxBresults_CompAnalysis.GeneralizationCorr_Sh_Sac(Tim,:)]=...
                    obj.AxBFunc.TestAxBCompositionality(FactorLvLInds{1},FactorLvLData_Compositionality_Sac,SubspaceAnaOpts,'UsePCA4AxB',1);
                
                
                % do the same anlaysis but now don't subtract factor mean   _NSFM (Not Subtract Factor Mean)
                % do analysis for moment to moment
                [AxBresults_CompAnalysis.GeneralizationErr_NSFM(Tim,:),AxBresults_CompAnalysis.CompositionErr_NSFM(Tim,:),AxBresults_CompAnalysis.GeneralizationErr_Sh_NSFM(Tim,:),...
                    AxBresults_CompAnalysis.GeneralizationCorr_NSFM(Tim,:),AxBresults_CompAnalysis.CompositionCorr_NSFM(Tim,:),AxBresults_CompAnalysis.GeneralizationCorr_Sh_NSFM(Tim,:)]=...
                    obj.AxBFunc.TestAxBCompositionality(FactorLvLInds{1},FactorLvLData_Compositionality,SubspaceAnaOpts,'UsePCA4AxB',1,'SubtractFactorMean',0);
                
                fprintf('\nRunning Compositionality Analysis on time point %i Elapsed time:%0.4f',Tim,toc);
            end
            
        end
        function [AxBresults_Analysis1,AxBresults_Analysis2,AxBresults_Analysis3,AxBresults_Analysis4,AxBresults_Analysis5,AxBresults_Analysis6,AnalysisTitles]=RunMultipleAxBanalysisonSubspace(obj,FactorLvLData1,FactorLvLData2,FactorLvLInds,FactorLevels,SubspaceAnaOpts,AnalysisType,Cond,varargin) % runs a bunch of AxB analysis on the data
            %@ AnalysisType can be 'Learning' or 'SensoryMotorTransform'
            %@ FactorLvLData1 and FactorLvLData2   are the data from two subspaces
            % in the case of SensoryMotorTransform there are two analysis
            % 1) Charactrize geometry of sensory to response in the same
            % rule
            % 2) Charactrize geometry of sensory in one rule to response in
            % another rule
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            SubspaceAnaOpts.ConcatinateMethod='MeanAllTrlTime';
            MakeMovie=0;% are we making a movie
            Ana2Plot=0; % which analysis are we ploting
            PlotCircDet=0;
            switch AnalysisType
                case {'SensoryMotorTransform','Learning'}
                    % find the timeing where there has been a response
                    if strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON');RespTim=0.4;elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START');RespTim=0;end
                    IndResp=find(SubspaceAnaOpts.SpkCountPeriod(:,1)==RespTim,1,'first');
                    nTim=size(SubspaceAnaOpts.SpkCountPeriod,1);
                    fprintf('\nRunning AxB analysis')
                    tic
                    warning off
                    % if we are taking PCA before feeding into
                    if obj.UsePCA4AxB
                        MeanFactorData1=obj.ManData.ReshapeCell2Mat(cellfun(@(y) cell2mat(cellfun(@(x) mean(x,1)',y,'UniformOutput',0))',FactorLvLData1,'UniformOutput',0),3);
                        % for each analysis we project the data with its own
                        % related conditions
                        Subspace1=obj.PerformSubspacePCAAnalysis(MeanFactorData1,SubspaceAnaOpts);
                        FactorLvLData1=cellfun(@(x) arrayfun(@(y) x(y,:),1:8,'uniformoutput',0),Subspace1.score,'UniformOutput',0);
                        
                        MeanFactorData2=obj.ManData.ReshapeCell2Mat(cellfun(@(y) cell2mat(cellfun(@(x) mean(x,1)',y,'UniformOutput',0))',FactorLvLData2,'UniformOutput',0),3);
                        % for each analysis we project the data with its own
                        % related conditions
                        Subspace2=obj.PerformSubspacePCAAnalysis(MeanFactorData2,SubspaceAnaOpts);
                        FactorLvLData2=cellfun(@(x) arrayfun(@(y) x(y,:),1:8,'uniformoutput',0),Subspace2.score,'UniformOutput',0);
                    end
                    
                    %% do decomposition analysis
                    for Tim=1:nTim
                        
                        %% run analysis 1 (SensoryToResponse_SameRule)
                        %% tranformation of sensory to response in the same rule
                        AnalysisTitles{1}=sprintf('S2R:R%i->R%i',SubspaceAnaOpts.TestCond{Cond},SubspaceAnaOpts.TestCond{Cond});
                        FactorLvLDataSR=[FactorLvLData1{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData1{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis1{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{1},...
                            'PlotAxBDetails',Ana2Plot==1,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        %% run analysis 2 (SensoryToResponse_DiffRule in subspace1)
                        %% tranformation of sensory in one rule to response in another rule
                        AnalysisTitles{2}=sprintf('S2R:R%i->R%i',SubspaceAnaOpts.TestCond{Cond},SubspaceAnaOpts.TrainCond{Cond});
                        FactorLvLDataSR=[FactorLvLData1{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData1{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis2{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{2},...
                            'PlotAxBDetails',Ana2Plot==2,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        %% run analysis 3 (SensoryToResponse_DiffRule in subspace2)
                        %% tranformation of sensory to response in the same rule
                        AnalysisTitles{3}=sprintf('S2R:R%i->R%i',SubspaceAnaOpts.TestCond2{Cond},SubspaceAnaOpts.TrainCond2{Cond});
                        FactorLvLDataSR=[FactorLvLData2{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData2{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis3{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{3},...
                            'PlotAxBDetails',Ana2Plot==3,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        %% run analysis 4 (Moment2Moment_DiffRule in subspace1)
                        %% tranformation of sensory in one rule to response in another rule
                        AnalysisTitles{4}=sprintf('M2M:R%i->R%i',SubspaceAnaOpts.TestCond{Cond},SubspaceAnaOpts.TrainCond{Cond});
                        FactorLvLDataSR=[FactorLvLData1{Tim}(FactorLvLInds{Tim}==1) FactorLvLData1{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis4{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{4},...
                            'PlotAxBDetails',Ana2Plot==4,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        %% run analysis 5 (Moment2Moment_DiffRule in subspace2)
                        %% tranformation of sensory to response in the same rule
                        AnalysisTitles{5}=sprintf('M2M:R%i->R%i',SubspaceAnaOpts.TestCond2{Cond},SubspaceAnaOpts.TrainCond2{Cond});
                        FactorLvLDataSR=[FactorLvLData2{Tim}(FactorLvLInds{Tim}==1) FactorLvLData2{Tim}(FactorLvLInds{Tim}==2)];
                        AxBresults_Analysis5{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{5},...
                            'PlotAxBDetails',Ana2Plot==5,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        %% run analysis 6 (Moment2Moment_DiffRule subspace1 in subspace2)
                        %% tranformation of sensory to response in the same rule
                        AnalysisTitles{6}=sprintf('M2M:R%i->R%i',SubspaceAnaOpts.TrainCond2{Cond},SubspaceAnaOpts.TrainCond{Cond});
                        FactorLvLDataSR=[FactorLvLData1{Tim}(FactorLvLInds{Tim}==1) FactorLvLData2{Tim}(FactorLvLInds{Tim}==1)];
                        AxBresults_Analysis6{Tim}=obj.AxBFunc.NeuralDataAxBanaDemo(FactorLvLInds{Tim},...
                            FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,SubspaceAnaOpts.SpkCountPeriod(Tim,1),AnalysisTitles{6},...
                            'PlotAxBDetails',Ana2Plot==6,'PlotAxBCircSubspace',PlotCircDet,'UsePCA4AxB',obj.UsePCA4AxB);
                        
                        if MakeMovie
                            mvFrame(Tim) = getframe(gcf);
                            pause
                            close all
                        end
                    end
                    if MakeMovie
                        [~,~,AxBFigFileName]=obj.ManData.GetFileName('Subspace',['_NeuralDemo_AxB_Ana' num2str(Ana2Plot)],'SaveInResults',1);
                        obj.FigParams.MakeMovieFromFrames(mvFrame,1,AxBFigFileName)
                    end
                    ElapsedTime=toc;
                    fprintf('\nAnalysing AxB  for Time point %i/%i ElapsedTime:%0.2f',Tim,nTim,ElapsedTime);
            end
        end
        
        function [h,AxBTime]=PlotAxBMetric_Learning(obj,SubspaceAnaResults,SubspaceAnaOpts,Metric,AxBAnaType,Sp,Cond,TimeInd,TrnTstNum,ObjNum,AnalysisTitle,Plot4D,ShuffFlag,MatNum,varargin) % plots RSA metric during learning
            %@SubspaceAnaResults SubspaceAnaOpts  cell structure of output of the classifer projection of validation data
            %@Metric can be 'compression' 'rotation'
            %@TimeInd: Indices we want to to average and look at in a line plot
            %@TrnTstNum is it train and test condition 1 or 2
            %@RSAAnaType type of RSA analysis we want to plot. can be 'Sensory','Response','SensoryToResponse'
            %@Plot4D plots 4D data
            %@MatNum is the number of the matrix we are intrested to plot now
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isempty(SubspaceAnaResults);h=[];AxBTime=[];return;end
            UseCos=1; % are we using cos for angles
            % prepare varibables
            nTrialRange=length(SubspaceAnaResults(Cond).TrialRange);
            Nrep=length(SubspaceAnaResults(Cond).TrialRange(1).Rep);
            if TrnTstNum==1
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors{1};
                TrainCondTxt=sprintf('TrainCond');
                TestCondTxt=sprintf('TestCond');
                SpCompNum=''; % subspace compression index
            elseif TrnTstNum==2
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors_2ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);
                SpCompNum=2; % subspace compression index
            end
            AxBfieldName=['AxBresults_' AxBAnaType];
            
            TrialRangeSet=SubspaceAnaOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            Title=[{Metric};{AnalysisTitle}];
            
            AxBTime=mean(SubspaceAnaOpts.SpkCountPeriod,2)';
            NTim=length(AxBTime);
            LineStyle='-';
            if Plot4D==1
                txt4D='4D';
                LineStyle='-';
            elseif Plot4D==0
                txt4D='';
            elseif Plot4D==2
                txt4D='Full';
            end
            if ShuffFlag
                LineStyle='--';
            end
            % get data for this metric first
            if strcmp(Metric,'compression')
                txt4D='Full'; % take the full dimensions for compression
                for nTrlRng=1:nTrialRange      % compression using AxB
                    for rep=1:Nrep
                        CompressionCtx1(rep,:,nTrlRng)=cell2mat(cellfun(@(x)  x.(['Compression_X' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([ AxBfieldName])','UniformOutput',0))';
                        CompressionCtx2(rep,:,nTrlRng)=cell2mat(cellfun(@(x)  x.(['Compression_XCompressed' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([ AxBfieldName])','UniformOutput',0))';
                    end
                    % compression using PC data
                    %                     CompressionCtx1(:,:,nTrlRng)=cell2mat(arrayfun(@(x)  SubspaceAnaResults(Cond).TrialRange(nTrlRng).(['Subspace' num2str(SpCompNum) 'Compression1_SpkCntPrd' num2str(x)]),...
                    %                         1:NTim,'UniformOutput',0));
                    %                      CompressionCtx2(:,:,nTrlRng)=cell2mat(arrayfun(@(x)  SubspaceAnaResults(Cond).TrialRange(nTrlRng).(['Subspace' num2str(SpCompNum) 'Compression2_SpkCntPrd' num2str(x)]),...
                    %                         1:NTim,'UniformOutput',0));
                end
                %     PercChngCompresstion=obj.ManData.CalPercentChange(CompressionCtx1,CompressionCtx2);
                %     MetricVals=[ {CompressionCtx1} {CompressionCtx2} {PercChngCompresstion}];
                %     MetricLeg={'CompCtx1','CompCtx2','PCComp'};
                MetricVals=[ {log(1./CompressionCtx1)} {log(1./CompressionCtx2)}];
                MetricLeg={'CompCtx1','CompCtx2'};
                CircularData=0;UseCos=0;YLim='auto';
            elseif strcmp(Metric,'GeneralizationErr')
                for nTrlRng=1:nTrialRange      % compression using AxB
                    for rep=1:Nrep
                        GeneralizationErr(rep,:,nTrlRng)=cell2mat(cellfun(@(x)  x.(['GeneralizationErr' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([ AxBfieldName])','UniformOutput',0))';
                    end
                end
                MetricVals=[ {GeneralizationErr}  ];
                MetricLeg={'GenErr'};
                CircularData=0;UseCos=0; YLim='auto';
            elseif contains(Metric,'rotationX') % rotation per object
                ObjectNames={'RedBun_InCon','RedTee_Con','GrenBun_Con','GrenTee_InCon'};
                
                for nTrlRng=1:nTrialRange
                    for rep=1:Nrep
                        RotInplane_X(:,:,rep,nTrlRng)=cell2mat(cellfun(@(x)  x.(['RotInplane_X' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([ AxBfieldName])','UniformOutput',0))';
                        RotOutplane_X(:,:,rep,nTrlRng)=cell2mat(cellfun(@(x)  x.(['RotOutplane_X' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([ AxBfieldName])','UniformOutput',0))';
                    end
                end
                if isempty(ObjNum)
                    ObjNum=1:size(RotInplane_X,1);
                else
                    Title=[Title;ObjectNames(ObjNum)];
                end
                % take circular mean across objects
                if ~UseCos
                    RotInplane_X =squeeze((circ_mean(deg2rad(RotInplane_X(ObjNum,:,:,:,:)),[],1)));
                    RotOutplane_X=squeeze((circ_mean(deg2rad(RotOutplane_X(ObjNum,:,:,:,:)),[],1)));
                    CircularData=1;
                else
                    RotInplane_X =squeeze(mean(cosd(RotInplane_X(ObjNum,:,:,:,:)),1)) ;
                    RotOutplane_X=squeeze(mean(cosd(RotOutplane_X(ObjNum,:,:,:,:)),1));
                    CircularData=0;
                end
                %
                RotInplane_X=permute(RotInplane_X,[2 1 3]);
                RotOutplane_X=permute(RotOutplane_X,[2 1 3]);
                % take circular mean of the
                if contains(Metric,'In')
                    MetricVals=[{RotInplane_X}];
                    MetricLeg={'RotIn'};
                elseif contains(Metric,'Out')
                    MetricVals=[{RotOutplane_X}];
                    MetricLeg={'RotOut'};
                else
                    MetricVals=[{RotInplane_X} {RotOutplane_X}];
                    MetricLeg={'RotIn','RotOut'};
                end
                YLim=[10 150];
            elseif strcmp(Metric,'rotationTot')
                RotTot=[];RotTotEig=[];RotAngPCA=[];
                for nTrlRng=1:nTrialRange
                    for rep=1:Nrep
                        RotTot(:,rep,nTrlRng)=(cell2mat(cellfun(@(x)  x.(['RotTot']),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([AxBfieldName]),'UniformOutput',0))');
                        RotTotEig(:,rep,nTrlRng)=(cell2mat(cellfun(@(x)  x.(['RotTotEig' txt4D]),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([AxBfieldName]),'UniformOutput',0))');
                        RotAngPCA(:,rep,nTrlRng)=(cell2mat(cellfun(@(x)  x.(['RotAngPCA']),SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([AxBfieldName]),'UniformOutput',0))');
                    end
                end
                if ~UseCos
                    RotTot=deg2rad(permute(RotTot,[2 1 3]));CircularData=1;
                    RotTotEig=deg2rad(permute(RotTotEig,[2 1 3]));
                    RotAngPCA=deg2rad(permute(RotAngPCA,[2 1 3]));
                else
                    RotTot=cosd(permute(RotTot,[2 1 3]));CircularData=0;
                    RotTotEig=cosd(permute(RotTotEig,[2 1 3]));
                    RotAngPCA=cosd(permute(RotAngPCA,[2 1 3]));
                end
                MetricVals=[{RotTot},{(RotTotEig)},{RotAngPCA}];
                MetricLeg={'RotTot','RotTotEig','RotAngPCA'};
                YLim='auto';%[0 180];
            elseif strcmp(Metric,'RotPCA')
                for nTrlRng=1:nTrialRange
                    for rep=1:Nrep
                        Rot_PCA(:,:,rep,nTrlRng)=cell2mat(cellfun(@(x)  x.RotAngPCA,SubspaceAnaResults(Cond).TrialRange(nTrlRng).Rep(rep).([AxBfieldName]),'UniformOutput',0))';
                    end
                end
                if ~UseCos
                    Rot_PCA=deg2rad(permute(squeeze(Rot_PCA),[2 1 3]));CircularData=1;
                else
                    Rot_PCA=cosd(permute(squeeze(Rot_PCA),[2 1 3]));CircularData=0;
                end
                MetricVals=[{Rot_PCA}];
                MetricLeg={'Rot_PCA'};
                YLim=[0 180];
            end
            if exist('MatNum','var')
                if ~isempty(MatNum)
                    MetricVals=MetricVals(MatNum);
                    Title=[Title;MetricLeg(MatNum)]; % add metric legend to the title
                end
            end % take the metric we are intrested in
            if size(MetricVals{1},3)>1 & ~islogical(TimeInd); TimeInd=[];end % if we have trials and time then use image plot
            
            % now take average across repetitions and squeeze
            if isempty(TimeInd) % image plot
                if CircularData
                    MetricVals=squeeze(circ_mean(MetricVals{1},[],1))'; % for now we are only taking the second metric
                elseif UseCos
                    MetricVals=acosd(squeeze(mean(MetricVals{1},1))'); % for now we are only taking the second metric
                else
                    MetricVals=squeeze(mean(MetricVals{1},1))'; % for now we are only taking the second metric
                end
                if ~isreal(MetricVals);MetricVals=real(MetricVals);warning('This Metric vals has imaginary values, only plotting real values');end
                % do gaussian smoothing of 2D data
                % MetricVals=imgaussfilt(MetricVals,'FilterSize',obj.WidthSmoothing);
                MetricVals=smoothdata(smoothdata(MetricVals,2,'movmean',obj.WidthSmoothing),1,'movmean',obj.WidthSmoothingDim2);
                
                % plot accuracy as image
                h=obj.FigParams.Image(AxBTime,TrialRange,MetricVals,...
                    AnalysisOpts.Xlabel,...
                    ['Trial Set ' num2str(TrialRangeSet(2))],...
                    'Perf',Title,Sp,'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'OriginLine',2);
                yticks(TrialRange);
            elseif islogical(TimeInd) % Plot in time
                Ylbl =[Metric];
                Title=[Title];%; [num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,1)) '-' num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,2)) 'sec']];
                h=arrayfun(@(x) obj.FigParams.PlotMeanStd(TrialRange,squeeze(mean(MetricVals{x}(:,TimeInd,:),2)),[],'Time',Ylbl,x,obj.MeanStdPlotType,Title,...
                    'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,'LegendTxt',[MetricLeg{x} txt4D],...
                    'SmoothingMethod','movmean','WidthSmoothing',obj.WidthSmoothing,'LegendLoc','northwest',...
                    'CircularData',CircularData,'UseCos',UseCos,'STD_method','bootstrap','p_line_style',LineStyle),1:length(MetricVals));
                xticks(TrialRange);
                axis tight
                ylim(YLim)
            else % we are rading the values for spikecount periods
                Ylbl =[Metric];
                Title=[Title];%; [num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,1)) '-' num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,2)) 'sec']];
                h=arrayfun(@(x) obj.FigParams.PlotMeanStd(AxBTime,MetricVals{x},[],'Time',Ylbl,x,obj.MeanStdPlotType,Title,...
                    'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,'LegendTxt',MetricLeg{x},...
                    'SmoothingMethod','movmean','WidthSmoothing',obj.WidthSmoothing,'LegendLoc','northwest',...
                    'CircularData',CircularData,'UseCos',UseCos,'STD_method','bootstrap','p_line_style',LineStyle),1:length(MetricLeg));
                %  xticks(TrialRange);
                axis tight
                ylim(YLim)
            end
            
            % plot the data now
            subtitle(obj.ThisSubtitle)
        end
        
        
        %% RSA ANALYSIS RELATED FUNCTIONS
        function h=PlotRSAMetric_Learning(obj,SubspaceAnaResults,SubspaceAnaOpts,Metric,RSAAnaType,Sp,Cond,TimeInd,TrnTstNum,varargin) % plots RSA metric during learning
            %@SubspaceAnaResults SubspaceAnaOpts  cell structure of output of the classifer projection of validation data
            %@Metric can be 'compression' 'rotation'
            %@TimeInd: Indices we want to to average and look at in a line plot
            %@TrnTstNum is it train and test condition 1 or 2
            %@RSAAnaType type of RSA analysis we want to plot. can be 'Sensory','Response','SensoryToResponse'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare varibables
            nTrialRange=length(SubspaceAnaResults(Cond).TrialRange);
            if TrnTstNum==1
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors{1};
                TrainCondTxt=sprintf('TrainCond');
                TestCondTxt=sprintf('TestCond');
            elseif TrnTstNum==2
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors_2ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);
            end
            RSAfieldName=['RSAresults' num2str(TrnTstNum) '_' RSAAnaType];
            
            TrialRangeSet=SubspaceAnaOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            Title=[   RSAAnaType ' ' Metric;{[TargetFactorTxt ' Trn ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TrainCondTxt){Cond}),...
                ' Tst ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TestCondTxt){Cond})]}];
            
            RSATime=SubspaceAnaOpts.SpkCountPeriod(:,1)';
            % get data for this metric first
            if strcmp(Metric,'compression')
                betas_hat=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[RSAfieldName '_betas_hat'],4));
                CompressionCtx1=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) squeeze(log(betas_hat(1,:,:,x)./betas_hat(3,:,:,x)))',1:nTrialRange,'UniformOutput',0),3);
                CompressionCtx2=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) squeeze(log(betas_hat(2,:,:,x)./betas_hat(4,:,:,x)))',1:nTrialRange,'UniformOutput',0),3);
                MetricVals=[ {CompressionCtx2} {CompressionCtx1}];
                MetricLeg={'Comp Ctx2','Comp Ctx1'};
            elseif strcmp(Metric,'rotation')
                betas_hat=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[RSAfieldName '_betas_hat'],4));
                rotationabs=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) abs(squeeze(betas_hat(5,:,:,x)))',1:nTrialRange,'UniformOutput',0),3);
                rotationraw=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) (squeeze(betas_hat(5,:,:,x)))',1:nTrialRange,'UniformOutput',0),3);
                MetricVals=[{rotationabs} {rotationraw}];
                MetricLeg={'Rotabs','RotRaw',};
            elseif strcmp(Metric,'ctxbias')
                betas_hat=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[RSAfieldName '_betas_hat'],4));
                ctxbias=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) squeeze(betas_hat(6,:,:,x))',1:nTrialRange,'UniformOutput',0),3);
                MetricVals=[{ctxbias}];
                MetricLeg={'Ctx Bias'};
            elseif strcmp(Metric,'RotFreezLoss') % look at the loss with fixed rotation condition
                if nTrialRange>1;h=[];return;end % we loos at this only in sensory motor transformation
                loss=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[RSAfieldName '_minlossAll'],4))';
                freezloss=squeeze(obj.ManData.ReshapeStruct2Mat(SubspaceAnaResults(Cond).TrialRange,[RSAfieldName 'Freeze_minlossAll'],4))';
                MetricVals=[{loss},{freezloss}];
                MetricLeg={'Loss','RotFreezLoss'};
            end
            if size(MetricVals{1},3)>1; TimeInd=[];end % if we have trials and time then use image plot
            
            % now take average across repetitions and squeeze
            if isempty(TimeInd) % image plot
                MetricVals=squeeze(mean(MetricVals{1},1))'; % for now we are only taking the second metric
                % do gaussian smoothing of 2D data
                % MetricVals=imgaussfilt(MetricVals,'FilterSize',obj.WidthSmoothing);
                MetricVals=smoothdata(smoothdata(MetricVals,2,'movmean',obj.WidthSmoothing),1,'movmean',obj.WidthSmoothingDim2);
                
                % plot accuracy as image
                h=obj.FigParams.Image(RSATime,TrialRange,MetricVals,...
                    AnalysisOpts.Xlabel,...
                    ['Trial Set ' num2str(TrialRangeSet(2))],...
                    'Perf',Title,Sp,'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'OriginLine',2);
                yticks(TrialRange);
            elseif islogical(TimeInd) % Plot in time
                Ylbl =[Metric];
                Title=[Title];%; [num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,1)) '-' num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,2)) 'sec']];
                h=arrayfun(@(x) obj.FigParams.PlotMeanStd(TrialRange,MetricVals{x},[],'Time',Ylbl,x,obj.MeanStdPlotType,Title,...
                    'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,'LegendTxt',MetricLeg{x},...
                    'SmoothingMethod','movmean','WidthSmoothing',obj.WidthSmoothing,'LegendLoc','bestoutside'),1:length(MetricLeg));
                xticks(TrialRange);
                axis tight
            else % we are rading the values for spikecount periods
                Ylbl =[Metric];
                Title=[Title];%; [num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,1)) '-' num2str(SubspaceAnaOpts.SpkCountPeriod(TimeInd,2)) 'sec']];
                h=arrayfun(@(x) obj.FigParams.PlotMeanStd(RSATime,MetricVals{x},[],'Time',Ylbl,x,obj.MeanStdPlotType,Title,...
                    'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,'LegendTxt',MetricLeg{x},...
                    'SmoothingMethod','movmean','WidthSmoothing',obj.WidthSmoothing,'LegendLoc','bestoutside'),1:length(MetricLeg));
                %  xticks(TrialRange);
                axis tight
            end
            
            % plot the data now
            subtitle(obj.ThisSubtitle)
        end
        function [RSAresults_Analysis1,RSAresults_Analysis2,RSAresults_Analysis3]=RunMultipleRSAanalysisonSubspace(obj,SubspaceSpkCnt,FactorLvLInds,FactorLvLData,FactorLevels,SubspaceAnaOpts,ParamMdlRDM_type,AnalysisType,varargin) % runs a bunch of RSA analysis on the data
            %@ AnalysisType can be 'Learning' or 'SensoryMotorTransform'
            
            % in the case of Learning there are three analysis
            %1) Charactrize geometry of sensory representation during
            %learning
            %2) Charactrize geometry of response representation during
            %learning
            %3) Charactrize geometry of sensory to response transformation
            % in the case of SensoryMotorTransform there are two analysis
            
            % 1) Charactrize geometry of sensory to response in the same
            % rule
            % 2) Charactrize geometry of sensory in one rule to response in
            % another rule
            
            % sensory info is in SpkCnt=1 Response is in SpkCnt=2
            % @ParamMdlRDM_type defines the type of the model that should be
            % fit it depends on the rules that data are coming from
            % "OrthogonalShapeColor"->rule 1 to 3 or 3
            % "ParallelColor"-> Rule 2 or 3->rule 2 or 3
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            switch AnalysisType
                case 'OldAnalysis'
                    %% run analysis 1(Sensory)
                    RSAresults_Analysis1=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{1},FactorLvLData{1},FactorLevels{1},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type',ParamMdlRDM_type);
                    RSAresults_Analysis1=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{1},FactorLvLData{1},FactorLevels{1},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type',ParamMdlRDM_type);
                    
                    %% run analysis 2(Response)
                    RSAresults_Analysis2=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{2},FactorLvLData{2},FactorLevels{2},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type',ParamMdlRDM_type);
                    
                    %% run analysis 3(SensoryToResponse)
                    % take response from first context and sensory from second context and look at the transoformation
                    FactorLvLDataSR=[FactorLvLData{2}(FactorLvLInds{2}==1) FactorLvLData{1}(FactorLvLInds{1}==2)];
                    RSAresults_Analysis3=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{2},FactorLvLDataSR,FactorLevels{2},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type',ParamMdlRDM_type);
                case {'SensoryMotorTransform','Learning'}
                    % find the timeing where there has been a response
                    if strcmp(AnalysisOpts.SpkCntStartFieldName,'SAMPLE_ON');RespTim=0.25;elseif strcmp(AnalysisOpts.SpkCntStartFieldName,'SACCADE_START');RespTim=0;end
                    IndResp=find(SubspaceAnaOpts.SpkCountPeriod(:,1)==RespTim,1,'first');
                    nTim=size(SubspaceAnaOpts.SpkCountPeriod,1);
                    fprintf('\nRunning RSA analysis')
                    for Tim=1:nTim
                        tic
                        %% run analysis 1 (SensoryToResponse_SameRule)
                        %% tranformation of sensory to response in the same rule
                        FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==2) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        RSAresults_Analysis1{Tim}=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type','ParallelColor','ParamMdlRDM_TestFreezMdl',1);
                        
                        %% run analysis 2 (SensoryToResponse_DiffRule)
                        %% tranformation of sensory in one rule to response in another rule
                        FactorLvLDataSR=[FactorLvLData{IndResp}(FactorLvLInds{IndResp}==1) FactorLvLData{Tim}(FactorLvLInds{Tim}==2)];
                        RSAresults_Analysis2{Tim}=obj.RSAFunc.RunRSAanalysisNeuralData(FactorLvLInds{Tim},FactorLvLDataSR,FactorLevels{Tim},SubspaceAnaOpts,'fmincon_N_ITERS',SubspaceAnaOpts.fmincon_N_ITERS,'ParamMdlRDM_type',ParamMdlRDM_type,'ParamMdlRDM_TestFreezMdl',1);
                        
                        RSAresults_Analysis3{Tim}=[];
                        ElapsedTime=toc;
                        fprintf('\nAnalysing RSA for Time point %i/%i ElapsedTime:%0.2f',Tim,nTim,ElapsedTime);
                    end
            end
        end
        function ShowRSAanaMDS(obj,SubspaceAnaResults,SubspaceAnaOpts,RSAAnaType,TrnTstNum,Cond,varargin)% shows MDS plot from RSA resutls and saves them as a movie
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            RSAfieldName=['RSAresults' num2str(TrnTstNum) '_' RSAAnaType];
            nTrialRange=length(SubspaceAnaResults(Cond).TrialRange);
            if TrnTstNum==1
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors{1};
                TrainCondTxt=sprintf('TrainCond');
                TestCondTxt=sprintf('TestCond');
            elseif TrnTstNum==2
                TargetFactorTxt=SubspaceAnaOpts.TargetFactors_2ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);
            end
            TrialRangeSet=SubspaceAnaOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            Title=[   RSAAnaType ' RDM' ;{[TargetFactorTxt ' Trn ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TrainCondTxt){Cond}),...
                ' Tst ' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TestCondTxt){Cond})]}];
            CtxLegTxt={['R' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TrainCondTxt){Cond})],['R' obj.ManData.ConvMat2Char(SubspaceAnaOpts.(TestCondTxt){Cond})]};
            % get data for this metric first
            RSAresults.BrainRDM=squeeze(mean(SubspaceAnaResults(Cond).TrialRange.([RSAfieldName '_BrainRDM']),4));
            RSAresults.ModelRDM=squeeze(mean(SubspaceAnaResults(Cond).TrialRange.([RSAfieldName '_rdms']),4));
            
            nTrialRange=size(RSAresults.ModelRDM,3);
            h=obj.FigParams.RenderFigure(1,[]);
            [h,Sp]=obj.FigParams.RenderSubplots(2,4,h{1},[]);
            RSAtime=SubspaceAnaOpts.SpkCountPeriod(:,1);
            for ntrlrng=1:nTrialRange
                % show brain RDM
                obj.RSAFunc.ShowMDS(RSAresults.BrainRDM(:,:,ntrlrng),3,Sp(1),CtxLegTxt);
                xlim([-6 6]);ylim([-3 3]);zlim([-2 2]);
                title('Brain RDM')
                obj.RSAFunc.ShowMDS(RSAresults.BrainRDM(:,:,ntrlrng),3,Sp(2),CtxLegTxt,'MDSview',[0 90]);
                xlim([-6 6]);ylim([-3 3]);zlim([-2 2]);
                obj.RSAFunc.ShowMDS(RSAresults.BrainRDM(:,:,ntrlrng),3,Sp(3),CtxLegTxt,'MDSview',[90 0]);
                xlim([-6 6]);ylim([-3 3]);zlim([-2 2]);
                %   obj.RSAFunc.ShowMDS(RSAresults.BrainRDM(:,:,ntrlrng),3,Sp(4),CtxLegTxt,'MDSview',[0 0]);
                % show model RDM
                obj.RSAFunc.ShowMDS(RSAresults.ModelRDM(:,:,ntrlrng),3,Sp(5),CtxLegTxt);%xlim([-1.2 1.2]);ylim([-0.5 0.5]);zlim([-0.5 0.5]);
                title('Model RDM')
                obj.RSAFunc.ShowMDS(RSAresults.ModelRDM(:,:,ntrlrng),3,Sp(6),CtxLegTxt,'MDSview',[0 90]);%xlim([-1.2 1.2]);ylim([-0.5 0.5]);zlim([-0.5 0.5]);
                obj.RSAFunc.ShowMDS(RSAresults.ModelRDM(:,:,ntrlrng),3,Sp(7),CtxLegTxt,'MDSview',[90 0]);%xlim([-1.2 1.2]);ylim([-0.5 0.5]);zlim([-0.5 0.5]);
                %  obj.RSAFunc.ShowMDS(RSAresults.ModelRDM(:,:,ntrlrng),3,Sp(8),CtxLegTxt,'MDSview',[0 0]);
                
                % add data from
                subplot(Sp(4));cla
                obj.PlotRSAMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'compression',RSAAnaType,Sp(4),1,1,1);legend off
                v=axis;plot([RSAtime(ntrlrng) RSAtime(ntrlrng)],[v(3) v(4)],'r')
                
                subplot(Sp(8));cla
                obj.PlotRSAMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'rotation',RSAAnaType,Sp(8),1,1,1);legend off
                v=axis;plot([RSAtime(ntrlrng) RSAtime(ntrlrng)],[v(3) v(4)],'r')
                
                %    obj.PlotRSAMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'ctxbias',RSAAnaType,Sp(3+nSP),Conds,1,1);
                %    obj.PlotRSAMetric_Learning(SubspaceAnaResults,SubspaceAnaOpts,'RotFreezLoss',RSAAnaType,Sp(4+nSP),Conds,1,1);
                
                obj.PutSGtitle4Figure(SubspaceAnaOpts,{['Time to:' AnalysisOpts.SpkCntStartFieldName ':' num2str(RSAtime(ntrlrng))]})
                mvFrame(ntrlrng) = getframe(gcf);
            end
            [~,~,MDSFigFileName]=obj.ManData.GetFileName(['Subspace'],['_' RSAAnaType '_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'SaveInResults',1,'WantedDate','ALL');
            
            obj.FigParams.MakeMovieFromFrames(mvFrame,1,MDSFigFileName)
        end
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%       %Classifier Analysis METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        % steps to the cross temporal classfier analysis based on Meyers et all
        % 1- Choose a random population of N neurons in each area in this way the number of neurons per area is equalized
        % 2- for each neuron randomly select the firing rate from ntrl trials for eash of S stimuli
        % 3- Concatinate firing rate of N neurons from each ntrl trials to create ntrl*S data points in a R(N) space.
        % 4- Zscore fring rate values for each neuron.ensuring high firing rate neurons don't run the classifier(check without normalization)
        % 5- Train the classfier using F fold cross validation.
        % 6- Test classifier on the test data and measure performance and distance from hyperplane
        % 7- Repeate the whole procisure of 1-6 Nrep times to get a smooth bootstrap-like estimate of the classification accuracy
        % note suggested binning of firing rate is 150ms bins sampled at 50ms intervals with data from each time bin classified independently
        function CrossTemporalClassfierAnalysis(obj,data,TimingStimData,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            fprintf(2,'\nRunning Classfier Analysis on task:%s\n',obj.Classifier_TaskName)
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(obj.Classifier_TaskName);
            [FactorizedData]=obj.GetFactorizedData(data,TimingStimData,0,'MeanSubtractByRule',ClassifierOpts.MeanSubtractByRule); % get factorized data
            
            % grab all of the relevant data for this test
            [FactorData,~,FactorLevelComb,~]=obj.PrepareData4ClassifierAnalysis(FactorizedData,ClassifierOpts);
            
            % run cross temporal classifer analysis
            [ClassifierResults,ClassifierOpts]=obj.RunCrossTemporalClassiferAnalysis(FactorData,FactorLevelComb,ClassifierOpts);
        end
        function CrossTemporalClassfierAnalysis2D(obj,data,TimingStimData,varargin) % run 2D cross temporal analysis
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            fprintf(2,'\nRunning Classfier Analysis on task:%s\n',obj.Classifier_TaskName)
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(obj.Classifier_TaskName);
            [FactorizedData]=obj.GetFactorizedData(data,TimingStimData,'MeanSubtractByRule',ClassifierOpts.MeanSubtractByRule); % get factorized data
            
            % grab all of the relevant data for this test
            [FactorData,~,FactorLevelComb,~]=obj.PrepareData4ClassifierAnalysis(FactorizedData,ClassifierOpts);
            
            % run cross temporal classifer analysis
            %             if strcmp(ClassifierOpts.type,'DoubleCrossCond') % if we are doing double cross cond
            %                 [ClassifierResults,ClassifierOpts]=obj.Run2DCrossTemporalClassiferAnalysis_DoubleCrossCond(FactorData,FactorLevelComb,ClassifierOpts);
            %             else
            %                 [ClassifierResults,ClassifierOpts]=obj.Run2DCrossTemporalClassiferAnalysis(FactorData,FactorLevelComb,ClassifierOpts);
            %             end
            
            [ClassifierResults,ClassifierOpts]=obj.Run2DCrossTemporalClassiferAnalysis_DoubleCrossCond_Learning(FactorData,FactorLevelComb,ClassifierOpts);
            
            % plot results from this condition
            Conds=1:length(ClassifierOpts.TestCond); % total number of conditions
            h2=arrayfun(@(x) obj.Plot2DXTemporalClassifierResults(ClassifierResults,ClassifierOpts,'CondDetail',x),Conds,'UniformOutput',0);
            
            % save off the figures
            [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'SaveInResults',1,'WantedDate','ALL');
            obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h2],'SaveEachFrame',1);
        end
        function CrossTemporalClassfierAnalysis_Learning(obj,data,TimingStimData,varargin) % run 2D cross temporal analysis during learning
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            fprintf(2,'\nRunning Classfier Analysis on task:%s\n',obj.Classifier_TaskName)
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(obj.Classifier_TaskName);
            
            [FactorizedData,~,obj]=obj.GetFactorizedData(data,TimingStimData,0,'MeanSubtractByRule',ClassifierOpts.MeanSubtractByRule,'SpkCountPeriod',ClassifierOpts.SpkCountPeriod); % get factorized data
            
            % grab all of the relevant data for this test and also add the raster data
            [FactorData,~,FactorLevelComb,~]=obj.PrepareData4ClassifierAnalysis(FactorizedData,ClassifierOpts);
            
            if AnalysisOpts.SweepClassifierConds
                obj.SweepClassifierConditions(FactorData,ClassifierOpts,FactorLevelComb);
            elseif contains(ClassifierOpts.Name,'3D') % 3 dimentional test
                if obj.CalShuffTrlOrder
                    [ClassifierResults,ClassifierOpts]=obj.Run3DClassiferAnalysis_TripleCrossCond_LearningCVShuffTrlOrder(FactorData,FactorLevelComb,ClassifierOpts);
                else
                    [ClassifierResults,ClassifierOpts]=obj.Run3DClassiferAnalysis_TripleCrossCond_LearningCVCorrectShuffV2(FactorData,FactorLevelComb,ClassifierOpts);
                end
            else% two dimensional test
                [ClassifierResults,ClassifierOpts]=obj.Run2DCrossTemporalClassiferAnalysis_DoubleCrossCond_Learning(FactorData,FactorLevelComb,ClassifierOpts);
            end
        end
        function ClassifierOpts=SetClassifierSetLearningParameters(obj,ClassifierOpts,varargin) % adjusts learning parameters 
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
           
            Vars2look=AnalysisOpts.ClassifierLearningParamsFields;
            for i=1:length(Vars2look)
                if ~isnan(AnalysisOpts.(Vars2look{i}))
                    if length(AnalysisOpts.(Vars2look{i}))>1
                        ClassifierOpts.(Vars2look{i})=AnalysisOpts.(Vars2look{i});
                    else
                        ClassifierOpts.(Vars2look{i})=repmat(AnalysisOpts.(Vars2look{i}),1,5);
                    end
                end
            end
             ClassifierOpts.ntrlPerCond_Learning=@(x) repmat({[ClassifierOpts.ntrlPerCondArea(ClassifierOpts.AreaNum) ClassifierOpts.ntrlPerCondArea(ClassifierOpts.AreaNum)]},1,3);
            ClassifierOpts.TrainTrlNumRange_Learning=@(x) repmat({[sign(ClassifierOpts.NTrlRngTrainLearningArea(ClassifierOpts.AreaNum))*1 ClassifierOpts.NTrlRngTrainLearningArea(ClassifierOpts.AreaNum) abs(ClassifierOpts.NTrlRngTrainLearningArea(ClassifierOpts.AreaNum)) 0]},1,x);
            ClassifierOpts.TestTrlNumRange_Learning =@(x) repmat({[sign(ClassifierOpts.NTrlRngTestLearningArea(ClassifierOpts.AreaNum))*1 sign(ClassifierOpts.NTrlRngTestLearningArea(ClassifierOpts.AreaNum))*ClassifierOpts.MaxTrlTestLearning abs(ClassifierOpts.NTrlRngTestLearningArea(ClassifierOpts.AreaNum)) ClassifierOpts.NTrlStpLearning(ClassifierOpts.AreaNum)]},1,x);
            ClassifierOpts.LimitFromSwitchPerf_Learning=@(x) repmat({[nan ClassifierOpts.LimitFromSwitchPerfArea(ClassifierOpts.AreaNum) ]},1,x);        
            ClassifierOpts.NTrlStpLearning_Learning=@(x) repmat({[nan ClassifierOpts.NTrlStpLearningArea(ClassifierOpts.AreaNum) ]},1,x);

        end
        function [ClassifierOpts,obj]=DefineClassifierTestOptions(obj,TestName,varargin) % prepare options for each type of test we want to run
            %@TestName name of the test we want to do 'XTemp_Rule' 'XTemp_Cat_Color' 'XTemp_Cat_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            %% Define Parameters
            if isscalar(TestName);TestName=AnalysisOpts.PopulationAna.Classifier_TaskNameSet{TestName};end
            ClassifierOpts.AreaNum=AnalysisOpts.AreaNum;
            ClassifierOpts.Nrep=250; % how many resampling of train and test
            ClassifierOpts.NrepShuf=30; % how many shuffle we have we resmapling of train and test
            ClassifierOpts.NrepShufperFold=1000; % how many shuffles per folds we have
            ClassifierOpts.holdout_frac=0.1;
            ClassifierOpts.RunCrossTemporalClassifer=0; % run these tests in cross temporal
            ClassifierOpts.MeanSubtractByRule=0; % are we zero meaning each rule before doing analysis
            ClassifierOpts.IncludeAllClassifierInfo=0; % are we including the bias and beta 
            % get indices for future use
            ClassifierOpts.Congruency.Ind   =strcmp(AnalysisOpts.factornames,'Congruency');
            ClassifierOpts.Reward.Ind       =strcmp(AnalysisOpts.factornames,'Reward');
            ClassifierOpts.ResponseLoc.Ind  =strcmp(AnalysisOpts.factornames,'ResponseLoc');
            ClassifierOpts.ColorML.Ind      =strcmp(AnalysisOpts.factornames,'ColorML');
            ClassifierOpts.ShapeML.Ind      =strcmp(AnalysisOpts.factornames,'ShapeML');
            ClassifierOpts.ColorCat.Ind     =strcmp(AnalysisOpts.factornames,'ColorCat');
            ClassifierOpts.ShapeCat.Ind     =strcmp(AnalysisOpts.factornames,'ShapeCat');
            ClassifierOpts.RuleInfo.Ind     =strcmp(AnalysisOpts.factornames,'Rule');
            ClassifierOpts.SeqHist.Ind      =strcmp(AnalysisOpts.factornames,'SeqHist');
            BhvFields={'BhvPerfShape50','BhvPerfColor50','BhvPerfShape10','BhvPerfColor10'};
            for BhvField=BhvFields
                ClassifierOpts.(BhvField{1}).Ind      =strcmp(AnalysisOpts.factornames,BhvField{1});
                ClassifierOpts.(BhvField{1}).Val      =[];                
            end
            ClassifierOpts.none.Ind         =[];
            % define values for each factor
            ClassifierOpts.Congruency.Val   =[0 1];
            ClassifierOpts.Reward.Val       =[0 1];
            ClassifierOpts.ResponseLoc.Val  =[1 2 3 4];
            ClassifierOpts.ResponseLoc.ValRule={[1 2],[3 4],[1 2]};
            ClassifierOpts.ColorML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ShapeML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ColorCat.Val     =[1 2];
            ClassifierOpts.ShapeCat.Val     =[1 2];
            ClassifierOpts.RuleInfo.Val     =[1 2 3];
            ClassifierOpts.SeqHist.Val      =[0 1];
            ClassifierOpts.none.Val         =1;
            
            % all of the combinations of train and test
            ClassifierOpts.TrainAllCombs={[1],[2],[3],[2],[3],[1]};
            ClassifierOpts.TestAllCombs ={[2],[3],[1],[1],[2],[3]};
            ClassifierOpts.AllCombPlotPair={[1 4],[2 5],[3 6]}; %pairs of conditions to be plotted together
            ClassifierOpts.TriplePlots={[1 1;1 2;1 3],[2 1;2 2],[2 3;3 2],[3 1;3 3]}; % Dim/Cond
            ClassifierOpts.TrainTriple1={[1],[2],[3]};ClassifierOpts.TestTriple1={[1],[2],[3]};
            ClassifierOpts.TrainTriple2={[1],[2],[3]};ClassifierOpts.TestTriple2={[2],[1],[2]};
            ClassifierOpts.TrainTriple3={[1],[2],[3]};ClassifierOpts.TestTriple3={[3],[3],[1]}; 

            ClassifierOpts.TrainTriple1Reduced={[1],[2]};ClassifierOpts.TestTriple1Reduced={[1],[2]};
            ClassifierOpts.TrainTriple2Reduced={[1],[3]};ClassifierOpts.TestTriple2Reduced={[2],[2]};
            ClassifierOpts.TrainTriple3Reduced={[2],[3]};ClassifierOpts.TestTriple3Reduced={[3],[3]}; 
            ClassifierOpts.TriplePlotsReduced={[1 1;1 2;3 2],[2 1],[3 1;2 2]};

            % no rule 2 conditions for training( to save the number of neurons)
            ClassifierOpts.TrainTriple1NoTrR2={[1],[3]};ClassifierOpts.TestTriple1NoTrR2={[1],[3]};
            ClassifierOpts.TrainTriple2NoTrR2={[1],[3]};ClassifierOpts.TestTriple2NoTrR2={[3],[1]};
            ClassifierOpts.TrainTriple3NoTrR2={[1],[3]};ClassifierOpts.TestTriple3NoTrR2={[2],[2]};
            ClassifierOpts.caxis_limits_XTemp='auto';%[0.45 0.70];
            ClassifierOpts.enforceAxisLimits=0; % are we enforcing axis limits
            if ClassifierOpts.AreaNum==1
                ClassifierOpts.caxis_limits_Learning=[0.45 0.7;0.45 0.7;0.4 0.8];
            else
                ClassifierOpts.caxis_limits_Learning='auto';%[0.4 0.6;0.4 0.6;0.4 0.6];
            end
            ClassifierOpts.caxis_limits_SCR={[0.4 1],[0.4 0.7],[0.4 0.7],[0.4 1],[0.4 1]};% axis limits for shape-color-response
            ClassifierOpts.ColorOnRule=1; %color results based on their rule
            ClassifierOpts.ThPerfLow=0.5; % threshold for learning perfromance low
            ClassifierOpts.ThPerfHigh=0.6;% threshold for learning perfromance high
            ClassifierOpts.AllTrials={[-1 -800 800 0]}; % take all of the trials of the block
            ClassifierOpts.AllTrialsTriple=repmat( ClassifierOpts.AllTrials,[1 3]);
            ClassifierOpts.AllTrialsDouble=repmat( ClassifierOpts.AllTrials,[1 2]);
            ClassifierOpts.LimitFromSwitchPerfTriple=repmat({[nan nan]},[1 3]);
            ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple=repmat({[{nan},{nan}]},[1 3]);
            ClassifierOpts.SpkCountPeriod_LearningShapeColor=[0.1 0.3;0.1 0.3;-0.4 0];
            ClassifierOpts.SpkCountPeriod_LearningColorResp=[0.2 0.4;0.2 0.4;-0.4 0];
            if ~isnan(AnalysisOpts.NTrlStpLearningArea)
                ClassifierOpts.NTrlStpLearning=AnalysisOpts.NTrlStpLearningArea*ones(1,5);
            else
                ClassifierOpts.NTrlStpLearning=5*ones(1,5); % number of steps for trial shifts in learning
            end
            ClassifierOpts.NTrlRngTrainLearning=-75*ones(1,5); % default number of trials to take from end of the block for training
            ClassifierOpts.NTrlRngTestLearning=sign(AnalysisOpts.ClassifierLearningTrlSweepDir)*50*ones(1,5); % default number of trials shift for Test
            ClassifierOpts.MaxTrlTestLearning=125;
            ClassifierOpts.TriplePlotsFunc=@(ClassifierOpts) arrayfun(@(x) [[1:3]' x*ones(3,1)],...
                1:length(ClassifierOpts.TrainCond),'UniformOutput',0);
            ClassifierOpts.EqualizeTrialsXConds=1; % equalize trials across conditions
            ClassifierOpts.UseCV=1; % use cross validation always
            ClassifierOpts.nCVfoldNoIdentical=10; % if two conditions are not identical, how many samples of CV are we getting for test
            ClassifierOpts.RunPrelimSubspace=0; % are we running a preliminary subspace analysis
            ClassifierOpts.SkipSeqHistTrain=0; % are we taking all trials for training data(no not for all conditions)
            ClassifierOpts.DividSpockClassifier=AnalysisOpts.DividSpockClassifier; % divide classifier conditions based on repetitions on spock
            ClassifierOpts.ExchangeableCalShuffClassifier=AnalysisOpts.ExchangeableCalShuffClassifier; % we are doing shuffling at the same time 
            % for equalizing trials over conditions

            ZeroMat=zeros(1,10);
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=ZeroMat;% skip copying the traintest data(in DupTrainTest Condition)
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=ZeroMat; % skip copying the train data(in DupTrainTest Condition)
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=ZeroMat;% skip copying the test data(in DupTrainTest Condition)
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainOnly=ZeroMat; % skip copying the train data(in non DupTrainTest Condition)
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTestOnly=ZeroMat; % skip copying the test data(in non DupTrainTest Condition)
            ClassifierOpts.EqualizeTrials4Conds.DupTrainTestOrder='first'; % are we taking the first or the last matching dimension to copy
            ClassifierOpts.EqualizeTrials4Conds.DupTestOrder='first'; % are we taking the first or the last matching dimension to copy
            % determine the SpkCntStartFieldName
            IndStrFieldName=AnalysisOpts.GetIndStrFieldName(AnalysisOpts.SpkCntStartFieldName);
            ClassifierOpts.PlotFunction=[];
            ClassifierOpts.TestName=TestName;
            
            % for statistical tests 
            ClassifierOpts.ClustStatTst_p_threshold=AnalysisOpts.pvalClassifierAnalysis_ClusterCorrect;
            ClassifierOpts.UseBalancedShuffling=1; % are we balancing factos when we do shuffling
            %% define tests
            switch TestName
                %% 3D conditions without learning 
                case '3D_Color_Cat_Xgen'  % train and test color category for correct trials on all rule combinations
                    ClassifierOpts.Name='3D Color Category Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
%                     ClassifierOpts.TargetFactors     = {'ColorML','Rule'};
%                     ClassifierOpts.TargetFactors_2ndD= {'ColorML','Rule'};
%                     ClassifierOpts.TargetFactors_3ndD= {'ColorML','Rule'};
%                     ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
%                     ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
%                     ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                   
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1Reduced;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2Reduced;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3Reduced;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1Reduced;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2Reduced;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3Reduced;
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; %Balance Congruency
                    ClassifierOpts.TrialType=1; % Correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.EqualizeTrialsXConds=0;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};%  we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsReduced;
                case '3D_Shape_Cat_Xgen' % train and test shape category for correct trials on all rule combinations
                    ClassifierOpts.Name='3D Shape Category Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    %                     ClassifierOpts.TargetFactors     = {'ShapeML','Rule'};
                    %                     ClassifierOpts.TargetFactors_2ndD= {'ShapeML','Rule'};
                    %                     ClassifierOpts.TargetFactors_3ndD= {'ShapeML','Rule'};
                    %                     ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    %                     ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    %                     ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.TargetFactors     = {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};%ClassifierOpts.TrainTriple1Reduced;
                    ClassifierOpts.TrainCond2={[2]};%ClassifierOpts.TrainTriple2Reduced;
                    ClassifierOpts.TrainCond3={[3]};%ClassifierOpts.TrainTriple3Reduced;
                    ClassifierOpts.TestCond  ={[1]};%ClassifierOpts.TestTriple1Reduced;
                    ClassifierOpts.TestCond2 ={[2]};%ClassifierOpts.TestTriple2Reduced;
                    ClassifierOpts.TestCond3 ={[3]};%ClassifierOpts.TestTriple3Reduced;
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.EqualizeTrialsXConds=0;                    
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl ={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]};%ClassifierOpts.TriplePlotsReduced;
                case '3D_Color_Cat_Xgen_BalRespDir'  % train and test color category for correct trials on all rule combinations balance response direction
                    ClassifierOpts.Name='3D Color Category Discrimination Xgen BalRespDir';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % Balance response direction for rule
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                case '3D_Shape_Cat_Xgen_BalRespDir' % train and test shape category for correct trials on all rule combinations balance response direction
                    ClassifierOpts.Name='3D Shape Category Discrimination Xgen BalRespDir';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response dir for rule
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                case '3D_Color_Cat_Xgen_BalRespDirNoTrR2' % NoTrR2 train and test color category for correct trials on all rule combinations balance response direction
                    ClassifierOpts.Name='3D Color Category Discrimination Xgen BalRespDirNoTrR2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1NoTrR2;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2NoTrR2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3NoTrR2;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1NoTrR2;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2NoTrR2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3NoTrR2;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % Balance response direction for rule
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                case '3D_Shape_Cat_Xgen_BalRespDirNoTrR2' % NoTrR2 train and test shape category for correct trials on all rule combinations balance response direction
                    ClassifierOpts.Name='3D Shape Category Discrimination Xgen BalRespDirNoTrR2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1NoTrR2;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2NoTrR2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3NoTrR2;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1NoTrR2;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2NoTrR2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3NoTrR2;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response dir for rule
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                
                case '3D_Response_Xgen_BalCorr'  % ResonseLoc balanced reward
                    ClassifierOpts.Name='3D Response Xgen BalCorr';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=7; %7: Balance Reward
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                case '3D_Response_Xgen_BalCong'   % ResonseLoc balanced congruency and reward
                    ClassifierOpts.Name='3D Response Xgen BalCong';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]} ;
                    ClassifierOpts.TrainCond2={[3]} ;
                    ClassifierOpts.TrainCond3={[3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[1]} ;
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of congruency and response
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1];
                    ClassifierOpts.StimCongruency=6; % Balance Congruency and Reward
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};%  we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond
                case '3D_Response_Xgen_BalInCong'   %ResonseLoc Balance Incongruent and Reward
                    ClassifierOpts.Name='3D Response Xgen BalInCong';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};%ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2={[2]};%ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3={[2]};%ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  ={[2]};%ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 ={[3]};%ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 ={[1]};%ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[3 3];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=12; % Balance Incongruent and Reward
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.enforceAxisLimits=1;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.EqualizeTrialsXConds=0;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]};
                case '3D_Color_Response_Xgen'             %train on D1:response, D2:color(correct), D3:color(all),
                    ClassifierOpts.Name='3D Color Category Response Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[7 7 4];   % 7: Balance Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits='auto';
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;                                        
                case '3D_Color_Response_XgenNMS'          %train on D1:response, D2:color(correct), D3:color(all), no mean subtract
                    ClassifierOpts.Name='3D Color Category Response Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[7 7 4];   % 7: Balance Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits='auto';
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;                                  
                case '3D_Color_Response_XgenBalCong'      %train on D1:response, D2:color(correct), D3:color(all), balance congruency
                    ClassifierOpts.Name='3D Color Category Response Discrimination XgenBalCong';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'}; 
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'}; 
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[1]};
                    ClassifierOpts.TrainCond2={[1],[1]};
                    ClassifierOpts.TrainCond3={[1],[1]};
                    ClassifierOpts.TestCond  ={[1],[2]};
                    ClassifierOpts.TestCond2 ={[1],[2]};
                    ClassifierOpts.TestCond3 ={[1],[2]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond={[1 1 1 1],[1 1 1 1],[2 2]};
                    ClassifierOpts.ntrlPerCondTest={[1 1 1 1],[1 1 1 1],[2 2]};
                    ClassifierOpts.StimCongruency=[6 6 4];   % 6: Balance congruency and Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits='auto';
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;                                  
                case '3D_Color_Response_XgenBalInCong'    %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCong';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1]};                  
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 7: Balance Incongruency and Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.TriplePlots={[1 6;3 5],[1 5;3 5],[1 1;1 2],[2 5;3 5],[1 4;1 6],...
                        [1 3;1 5]}; % Dim/Cond
                case '3D_Color_Response_XgenBalInCongV2'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongV2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    %                     ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3],[1]};
                    %                     ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3],[3]};
                    %                     ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3],[2]};
                    %                     ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1],[3]};
                    %                     ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1],[3]};
                    %                     ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1],[3]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[3],[3],[1]};
                    ClassifierOpts.TrainCond2={[3],[3],[1],[3],[3],[3]};
                    ClassifierOpts.TrainCond3={[3],[3],[1],[3],[3],[2]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[2],[1],[3]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[2],[1],[3]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[2],[1],[3]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 12: Balance Incongruency and Reward 7: Blanace Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.TriplePlots={[1 1;1 2],[1 5;1 6],[1 1;1 2],[2 3;3 3],[3 4;3 6],[2 2;3 2],[1 3;1 4]}; % Dim/Cond
                    ClassifierOpts.LimFactorTrialVal=repmat({[2]},[1 nconds]);% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest'; 
                case '3D_Color_Response_XgenBalInCongV4'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongV4';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};                
%                   ClassifierOpts.TrainCond ={[1],[3],[3],[3],[1]};
%                   ClassifierOpts.TrainCond2={[1],[3],[1],[3],[3]};
%                   ClassifierOpts.TrainCond3={[2],[3],[1],[3],[2]};
%                   ClassifierOpts.TestCond  ={[1],[3],[1],[2],[3]};
%                   ClassifierOpts.TestCond2 ={[3],[3],[2],[2],[1]};
%                   ClassifierOpts.TestCond3 ={[2],[3],[2],[2],[3]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[3],[3],[1]};
                    ClassifierOpts.TrainCond2={[3],[3],[1],[3],[1],[3]};
                    ClassifierOpts.TrainCond3={[2],[3],[1],[3],[1],[2]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[2],[1],[3]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[2],[3],[3]};
                    ClassifierOpts.TestCond3 ={[2],[3],[2],[2],[1],[3]};

                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 12: Balance Incongruency and Reward 7: Blanace Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.TriplePlots={[1 1;1 2],[1 3;1 5],[1 1;1 2],[2 3;3 3],[3 4;3 6],[2 2;3 2],[1 3;1 4]}; % Dim/Cond
                    ClassifierOpts.LimFactorTrialVal=repmat({[2]},[1 nconds]);% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest'; 
                    if ClassifierOpts.AreaNum==1;ClassifierOpts.NrepShuf=50;end

                case '3D_Color_Response_XgenBalInCongV5'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongV5';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};                
%                   ClassifierOpts.TrainCond ={[1],[3],[3],[3],[1]};
%                   ClassifierOpts.TrainCond2={[1],[3],[1],[3],[3]};
%                   ClassifierOpts.TrainCond3={[2],[3],[1],[3],[2]};
%                   ClassifierOpts.TestCond  ={[1],[3],[1],[2],[3]};
%                   ClassifierOpts.TestCond2 ={[3],[3],[2],[2],[1]};
%                   ClassifierOpts.TestCond3 ={[2],[3],[2],[2],[3]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[3],[3],[1],[3]};
                    ClassifierOpts.TrainCond2={[3],[3],[1],[3],[1],[1],[3]};
                    ClassifierOpts.TrainCond3={[2],[3],[1],[3],[1],[2],[3]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[2],[1],[3],[2]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[2],[3],[1],[1]};
                    ClassifierOpts.TestCond3 ={[2],[3],[3],[2],[1],[3],[1]};
                    ClassifierOpts.TriplePlots={[1 1;1 2],[3 1;3 2;3 5],[1 5;1 6],[2 3],[2 5;2 7],[3 4;3 6],...
                        [2 2],[1 4],[3 7;3 3],[2 4]}; % Dim/Cond shared resp, all correcet color,resp 1/3, col D2 1/2
                    %Col D2 1/3 3/1 , sahred D3 color 1/3, col D2 D3 R3, resp 1/3, col D3 1/3 3/1
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 12: Balance Incongruency and Reward 7: Blanace Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.LimFactorTrialVal=repmat({[2]},[1 nconds]);% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest'; 
                    if ClassifierOpts.AreaNum==1;ClassifierOpts.NrepShuf=50;end
                    ClassifierOpts.IncludeAllClassifierInfo=1;

                case '3D_Color_Response_XgenBalInCongV2Test'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongV2Test';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 7: Balance Incongruency and Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond
                    ClassifierOpts.UseCV=1; % use cross validation always

                case '3D_Color_Response_XgenBalInCongV3'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response Take last 75 trials of the block
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongV3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3],[1]};
                    ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3],[2]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1],[3]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1],[3]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1],[3]};                  
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[5 5];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 7 4];   % 7: Balance Incongruency and Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_SCR{ClassifierOpts.AreaNum};
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -75 75 0]},[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -75 75 0]},[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;   
                    ClassifierOpts.TriplePlots={[1 6;3 5],[1 5;3 5],[1 1;1 2],[2 5;3 5],[1 4;1 6],...
                        [1 3;1 5],[1 7;2 7;3 7]}; % Dim/Cond
                                  
                case '3D_Color_Response_XgenBalInCongPrototype'  %train on D1:response, D2:color(correct), D3:color(all), Balance incongruent for response
                    ClassifierOpts.Name='3D Color Category Response Xgen BalInCongPrototype';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'PrototypeObject','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'PrototypeObject','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1:4],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1:4],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[2],[2],[1]};
                    ClassifierOpts.TestCond2 ={[2],[2],[1]};
                    ClassifierOpts.TestCond3 ={[2],[2],[1]};                  
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[5 5];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[12 12 12];   % 7: Balance Incongruency and Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 3];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits='auto';
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;                                        
                                  
                case '3D_Shape_Response_Xgen'  %train on D1:response, D2:Shape(correct), D3:Shape(all),
                    ClassifierOpts.Name='3D Shape Category Response Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ShapeCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[1],[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond2 ={[1],[3],[2],[3],[2],[1]};
                    ClassifierOpts.TestCond3 ={[1],[3],[2],[3],[2],[1]};
                    nconds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1,nconds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[7 7 4];   % 7: Balance Reward %4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1];  % 3:All Trials 1: Correct Trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,nconds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat(ClassifierOpts.LimitFromSwitchPerfTriple(1),[1,nconds]); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat(ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1),[1,nconds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl =repmat({[]},[1,nconds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1,nconds]);% we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.EqualizeTrialsXConds=0;
               
                    %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                    %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Main learning conditions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
                    %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%                   
                    %% Look at color shpae and rule representation during learning                
               
                case 'Learning3D_Color_Shape_Rule_Xgen_AltRule'  % Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen AltRule';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 3 3 3 3];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.3;0.1 0.3;-0.5 0];
                    ClassifierOpts.RunPrelimSubspace=1;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                case 'Learning3D_Color_Shape_Rule_Xgen_AltRule_HiTh' % Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule Hi performance Threshold
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen AltRule_HiTh'; 
                     ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                   ClassifierOpts.ntrlPerCondArea=[4 2 2 2 2]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.6 0.6 0.6 0.6 0.6];
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.3;0.1 0.3;-0.5 0];
                    ClassifierOpts.RunPrelimSubspace=1;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};               
                case 'Learning3D_Color_Shape_Rule_Xgen_SameRule' % Train D1:ColorCat D2:ShapeCat D3:Rule with Same Rule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen SameRule';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[3 2 2 2 2]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.5 0.5 0.5 0.5]; 
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};               
                case 'Learning3D_Color_Color_Rule_Xgen_AltRuleR1'  % Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule for Rule 1
                    ClassifierOpts.Name='Learning3D_Color_Color_Rule Xgen AltRuleR1';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 2 2 2 2]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.4 0.4 0.4 0.4 0.4];  
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.3;0.1 0.3;-0.5 0];
                    ClassifierOpts.RunPrelimSubspace=1;
                    ClassifierOpts.PlotFunction={'MainPerformance'};%,'Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};               
                case 'Learning3D_Color_Shape_Rule_Xgen_AltRule_SameRule'  % Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule AltRule_SameRule';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 2 2 2 2];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.5 0.5 0.5 0.5];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[2]};
                    ClassifierOpts.TrainCond2={[1],[1]};
                    ClassifierOpts.TrainCond3={[1,3],[1,3]};
                    ClassifierOpts.TestCond  ={[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3]};
                    ClassifierOpts.TestCond3 ={[3],[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(2);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(2);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=[ClassifierOpts.LimitFromSwitchPerf_Learning(1) {[nan nan]}];%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'},{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[0]}; % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3],[3]};%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.3;0.1 0.3;-0.5 0];
                    ClassifierOpts.RunPrelimSubspace=1;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};               
               
                 % this is for the compression analysis 
                
                 %% do reward balanced learning   
                  case 'Learning3D_Color_Response_Rule_Xgen_AltRule' 
                    ClassifierOpts.Name='Learning3D_Color_Response_Rule Xgen AltRule';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 2 2 2 2];
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.5 0.5 0.5 0.5];
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);                
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();% number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=13; % balance correctincorrect and seqhist
                    ClassifierOpts.TrialType=3; % all trials                   
                    ClassifierOpts.caxis_limits= [ 0.45000    0.8;0.45000    0.8;0.45000    0.8000];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch                   
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningColorResp;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=0;  
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','CorrBeliefMotorRep'};
                case 'Learning3D_Color_Response_Rule_Xgen_SameRule' 
                    ClassifierOpts.Name='Learning3D_Color_Response_Rule Xgen SameRule';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 3 3 3 3];
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.5 0.5 0.5 0.5];
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);                
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();% number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=13; % balance correctincorrect and seqhist
                    ClassifierOpts.TrialType=3; % all trials                   
                    ClassifierOpts.caxis_limits= [ 0.45000    0.8;0.45000    0.8;0.45000    0.8000];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningColorResp;
                    ClassifierOpts.PlotFunction={'MainPerformance'};

                case 'Learning3D_Shape_Color_Rule_Xgen_AltRule_RB'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen AltRuleV2_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 3 3 3 3];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning; 
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1; 
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    ClassifierOpts.SkipSeqHistTrain=1; % are we taking all trials for training data
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                  % ClassifierOpts.NrepShufperFold=20; % for now only
                  % ClassifierOpts.IncludeAllClassifierInfo=1;
                case 'Learning3D_Shape_Color_Rule_Xgen_AltRule_RB_Step'  % with 1 step only Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen AltRule_RB_Step';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 3 3 3 3];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning; 
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                    ClassifierOpts.NrepShuf=15; % how many shuffle we have we resmapling of train and test
                case 'Learning3D_Shape_Color_Rule_Xgen_AltRule_RB_CutShuff'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen AltRuleV2CutShuff_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4 3 3 3 3];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning; 
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 75]};%ClassifierOpts.TestTrlNumRange_Learning(1);%
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                  %  ClassifierOpts.NrepShufperFold=20; % for now only
              
                case 'Learning3D_Shape_Color_Rule_Xgen_AltRule_HiTh_RB' % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule Hi performance Threshold
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen AltRule_HiTh_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4*ones(1,5)];
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.6 0.6 0.6 0.6 0.6];
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                case 'Learning3D_Shape_Color_Rule_Xgen_SameRule_RB' % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule with Same Rule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen SameRule_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4*ones(1,5)]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.5 0.5 0.5 0.5]; 
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;%ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]};             % Seqhist value for this condition
                    ClassifierOpts.SkipSeqHistTrain=1; % are we taking all trials for training data
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conditions
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance'};%,'Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                    ClassifierOpts.UseCV=1;
                case 'Learning3D_Shape_Color_Rule_Xgen_AltRuleR1_RB'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule for Rule 1
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen AltRuleR1_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4*ones(1,5)]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.4 0.4 0.4 0.4 0.4];  
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials               
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[1]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=0; % skip copying the train data
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.DupTrainTestOrder='last';
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conditions
                    ClassifierOpts.LimFactorTrialVal={[1]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest'; 
                    ClassifierOpts.PlotFunction={'MainPerformance'};%,'Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
               
                case 'Learning3D_Shape_Color_Rule_Xgen_SameRuleR1_RB'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule for Rule 1
                    ClassifierOpts.Name='Learning3D_Shape_Color_Rule Xgen SameRuleR1_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[4*ones(1,5)]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.4 0.4 0.4 0.4 0.4];  
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 10 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 1 1]; % correct trials               
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[1]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=0; % skip copying the train data
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.DupTrainTestOrder='last';
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conditions
                    ClassifierOpts.LimFactorTrialVal={[1]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest';
                    ClassifierOpts.PlotFunction={'MainPerformance'};%,'Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
               
                case 'Learning3D_Shape_ColorR3_Rule_Xgen_AltRuleR1_RB'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule with AltRule for Rule 1
                    ClassifierOpts.Name='Learning3D_Shape_ColorR3_Rule Xgen AltRuleR1_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[3*ones(1,5)]; 
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.4 0.4 0.4 0.4 0.4];  
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[3 1],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[14 14 10]; % 10:balance congruency and seqhist % 13:balance response direction and seqhist
                    ClassifierOpts.TrialType=[3 3 1]; % correct trials               
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerf_Learning(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.3;0.1 0.3;-0.5 -0.1];
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=1; % skip copying the train data
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionIndex','CompressionDetails','CorrBeliefSensoryRep'};
                
                case 'Learning3D_Shape_Color_Color_Compression_RB'  % Comression AnalysisReward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Color_Compression_RB';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[5 3 3 3 3];   
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];            
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ColorCat','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1],[1],[1]};
                    ClassifierOpts.TrainCond2={[3],[3],[2]};
                    ClassifierOpts.TrainCond3={[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[1],[2],[3]};
                    ClassifierOpts.TestCond2 ={[1],[2],[3]};
                    ClassifierOpts.TestCond3 ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[8 4 4]; %8:balance response direction  
                    ClassifierOpts.TrialType=[3 1 1];  
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning; 
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(3);
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(1),[1,3]);%ClassifierOpts.TrainTrlNumRange_Learning(3);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat({[nan,nan]},[1 3]);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat({{nan,nan}},[1 3]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl=repmat({[]},[1 3]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1 3]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1 3]);%  we don't have one class classification here                    
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.RunPrelimSubspace=1;
                    ClassifierOpts.UseCV=0;
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=[1 0 0];
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=[1 0 0]; % skip copying the train data 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=[1 0 0];
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainOnly=[1 0 0]; % skip copying the train data 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTestOnly=[1 0 0];
                    ClassifierOpts.EqualizeTrials4Conds.DupTestOrder='last'; % are we taking the first or the last matching dimension to copy

%                     ClassifierOpts.LimFactorTrialName='AllTrlsTrainCorrTrlsTest'; % take all trials in train and correct trials in test
%                     ClassifierOpts.LimFactorTrialVal={[1],[1],[1]};% which dimensions are we taking the correct trials only
%                     ClassifierOpts.LimFactorTrialName2='AllTrlsTrainCorrTrlsTest';% take all trials in train and correct trials in test
%                     ClassifierOpts.LimFactorTrialVal2={[2],[2],[2]};
%                     ClassifierOpts.LimFactorTrialName3='AllTrlsTrainCorrTrlsTest';% take all trials in train and correct trials in test
%                     ClassifierOpts.LimFactorTrialVal3={[3],[3],[3]};
                    ClassifierOpts.PlotFunction={'CompressionIndex'};

                    %% look at orthogonality of representations
                case 'Learning3D_Shape_Color_Response_Xgen_Orhto'  % Reward Balanced(RB) Train D1:ColorCat D2:ShapeCat D3:Rule  with AltRule
                    ClassifierOpts.Name='Learning3D_Shape_Color_Response_Xgen_Orhto';
                    ClassifierOpts.NTrlRngTrainLearningArea=ClassifierOpts.NTrlRngTrainLearning; % number of trials to take from end of the block for training per area
                    ClassifierOpts.NTrlRngTestLearningArea=ClassifierOpts.NTrlRngTestLearning; % number of trials shift for Test
                    ClassifierOpts.ntrlPerCondArea=[3 3 3 3 3];
                    ClassifierOpts.LimitFromSwitchPerfArea=[0.5 0.6 0.6 0.6 0.6];
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD={'ResponseLoc','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.TrainCond ={[1],[2],[3],[1],[2],[3]};
                    ClassifierOpts.TrainCond2={[1],[2],[3],[1],[2],[3]};
                    ClassifierOpts.TrainCond3={[1],[3],[3],[1],[3],[3]};
                    ClassifierOpts.TestCond  ={[3],[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond3 ={[3],[3],[3],[3],[3],[3]};
                    nConds=length(ClassifierOpts.TrainCond);
                    ClassifierOpts.type=repmat({'TripleCrossCond'},[1 nConds]);
                    ClassifierOpts.ntrlPerCond=[9 9];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=[4 4 12]; % 4: balance congruency  12: balance incongruency and reward
                    ClassifierOpts.TrialType=[1 1 3]; % correct trials
                    ClassifierOpts.caxis_limits=ClassifierOpts.caxis_limits_Learning;
                    ClassifierOpts.TrainTrlNumRange=[ClassifierOpts.TrainTrlNumRange_Learning(3) repmat({[1 75 75 0]},[1,3])];
                    ClassifierOpts.TestTrlNumRange =repmat(ClassifierOpts.AllTrialsTriple(3),[1 nConds]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat({[nan,nan]},[1 nConds]);%ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat({{nan,nan}},[1 nConds]); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond=repmat({[0]},[1 nConds]); % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl=repmat({[]},[1 nConds]); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[]},[1 nConds]);% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3=repmat({[]},[1 nConds]);%  we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=ClassifierOpts.SpkCountPeriod_LearningShapeColor;
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.UseCV=1;
                    ClassifierOpts.PlotFunction={'MainPerformance'};
                    ClassifierOpts.IncludeAllClassifierInfo=1;
                    ClassifierOpts.EqualizeTrialsXConds=0;

                case 'Learning3D_Color_Shape_Shape_Xgen'  %Evolution of shape and color category Train D1:ColorCat D2:ShapeCat D3:ShapeCat with AltRule 
                    ClassifierOpts.Name='Learning3D_Color_Shape_Shape_Xgen'; 
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ShapeCat','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TestTrlNumRange_Learning;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35]; 
                    ClassifierOpts.RunPrelimSubspace=0;
                    ClassifierOpts.PlotFunction={'MainPerformance','Congruency','CompressionImage'};
                   
                %% look at change of  representation of shared response during learning                               
                case '3D_Color_Response_XgenR2R3Entropy'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat 
                    ClassifierOpts.Name='3D Color Category Response XgenR2R3Entropy';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[2],[2]};
                    ClassifierOpts.TrainCond2={[3],[3]};
                    ClassifierOpts.TrainCond3={[2],[2]};
                    ClassifierOpts.TestCond  ={[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3]};
                    ClassifierOpts.TestCond3 ={[3],[3]};
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -100 100 0]},[1 2]);%ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -100 100 0]},[1 2]);%ClassifierOpts.AllTrialsTriple(1:2);%
                    ClassifierOpts.MeanSubtractByRule=1;  
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; % was 1 equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[3],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1], [1 2;2 2;3 2]}; % Dim/Cond     
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis 
                case '3D_Shared_Color_Response_EntropyOld'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat 
                    ClassifierOpts.Name='3D Shared Color Response EntropyOld';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1],[1]} ;
                    ClassifierOpts.TrainCond2={[3],[3]} ;
                    ClassifierOpts.TrainCond3={[2],[2]} ;
                    ClassifierOpts.TestCond  ={[3],[3]} ;
                    ClassifierOpts.TestCond2 ={[3],[3]} ;
                    ClassifierOpts.TestCond3 ={[3],[3]} ;
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -100 100 0]},[1 2]);%ClassifierOpts.AllTrialsTriple(1:2);%%
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -100 100 0]},[1 2]);%ClassifierOpts.AllTrialsTriple(1:2);%repmat({[-1 -100 100 0]},[1 2]);%
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[3],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1], [1 2;2 2;3 2]}; % Dim/Cond     
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis 
                   
                    %% Entropy Analysis              
                case '3D_Shared_Color_Response_EntropyR3'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat(Only correct trls)
                    ClassifierOpts.Name='3D Shared Color Response EntropyR3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]} ;
                    ClassifierOpts.TestCond3 ={[3]} ;
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 4]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 1]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);   
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis 
                    ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainOnly=1; % skip copying the train data(in non DupTrainTest Condition)
                   
                case '3D_Shared_Color_Response_EntropyR2'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat 
                    ClassifierOpts.Name='3D Shared Color Response EntropyR2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();    % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 4]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 1]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis                    
               
                case '3D_Shared_Color_Response_EntropyR3Bal'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat(balanced)
                    ClassifierOpts.Name='3D Shared Color Response EntropyR3Bal';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]} ;
                    ClassifierOpts.TestCond3 ={[3]} ;
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();  % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);   
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis 

                case '3D_Shared_Color_Response_EntropyR3Bal_BalCongTest'  % Use Balanced Cong for test Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat(balanced)
                    ClassifierOpts.Name='3D Shared Color Resp EntropyR3Bal_BalCongTest';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]} ;
                    ClassifierOpts.TestCond3 ={[3]} ;
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning();  % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %  balance reward
                    ClassifierOpts.StimCongruencyTest=[4 4 4]; %  balance congruency for test
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);   
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis     
                   
                case '3D_Shared_Color_Response_EntropyR2Bal'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat 
                    ClassifierOpts.Name='3D Shared Color Response EntropyR2Bal';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts=obj.SetClassifierSetLearningParameters(ClassifierOpts);
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond_Learning(); 
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.TrainTrlNumRange_Learning(1);%repmat({[-1 -100 100 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis                    
               
                case '3D_Shared_Color_Response_EntropyInCongR3'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat use Incongruent trials only
                    ClassifierOpts.Name='3D Shared Color Response Entropy InCongR3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]} ;
                    ClassifierOpts.TestCond3 ={[3]} ;
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[12 12 12]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -100 100 0]},[1 2]);%
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -100 100 0]},[1 2]);%
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);   
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis                   
                case '3D_Shared_Color_Response_EntropyInCongR2'  % Train D1:ResponseLoc D2:ResponseLoc D3:ColorCat use Incongruent trials only
                    ClassifierOpts.Name='3D Shared Color Response Entropy InCongR2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[1]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[12 12 12]; %  balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -100 100 0]},[1 2]);%
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -100 100 0]},[1 2]);%
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[nan],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';  
                    ClassifierOpts.PlotFunction={'TransferEntropyAnalysis','PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots=ClassifierOpts.TriplePlotsFunc(ClassifierOpts);  
                    ClassifierOpts.ExchangeableCalShuffClassifier=0;
                    ClassifierOpts.UseCV=0; % we don't want cross validation for this analysis 
                   
                    %% Supllemental Analysis                               
                                   
                case '3D_Color_Response_XgenR2R3'  % Train D1:ResponseLoc(2/2) D2:ColorCat(2/2) D3:ColorCat Correct(3/2)
                    ClassifierOpts.Name='3D Color Category Response XgenR2R3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[2]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; %7: Balance Reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; %  equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[3]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls';
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond            
                case '3D_Color_Response_XgenR1R2R3BalInCong'   % Train D1:ResponseLoc(2/2) D2:ColorCat(2/2) D3:ColorCat Correct&Incorrect(3/2) BalanceIncongruent
                    ClassifierOpts.Name='3D Color Category Response XgenR1R2R3BalInCong';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1],[1]} ;
                    ClassifierOpts.TrainCond2={[3],[3]} ;
                    ClassifierOpts.TrainCond3={[3],[3]} ;
                    ClassifierOpts.TestCond  ={[2],[2]};
                    ClassifierOpts.TestCond2 ={[2],[2]} ;
                    ClassifierOpts.TestCond3 ={[2],[2]} ;
                    ClassifierOpts.ntrlPerCond={[5 5],[5 5],[5 5]};  
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[12 12 12]; % 12: Balance Incongruent and Reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; % equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[3],[nan]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls'; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1],[1 2;2 2;3 2]}; % Dim/Cond 
                case '3D_Color_Response_XgenR1R2R3BalInCongV2' % Train D1:ResponseLoc(2/2) D2:ColorCat(2/2) D3:ColorCat Correct(3/2)
                    ClassifierOpts.Name='3D Color Category Response XgenR1R2R3BalInCongV2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1],[1]} ;
                    ClassifierOpts.TrainCond2={[3],[3]} ;
                    ClassifierOpts.TrainCond3={[3],[3]} ;
                    ClassifierOpts.TestCond  ={[2],[3]};
                    ClassifierOpts.TestCond2 ={[2],[1]} ;
                    ClassifierOpts.TestCond3 ={[2],[2]} ;
                    ClassifierOpts.ntrlPerCond={[5 5],[5 5],[5 5]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[12 12 4]; %12: Balance Incongruent and Reward 4: Balance Congruency
                    ClassifierOpts.TrialType=[3 3 1]; % 3:all trials 1: correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1:2);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conds                   
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1],[1 2;2 2;3 2]}; % Dim/Cond   
                
                    %% in this series of tests we want to see how much the cross color decoding we are seeing
                    %between correct trials of R1 and R3 is the effect of response bleeding into it
                    % so we test the Color category decoding between R2 and R1 R3
                    % and then test the response decoding of R2 on R1 in
                    % correct trials. In this way we are testing the effect
                    % of response across the axes.
                    % in 3D_Color_Response_Xgen_R2R1 we use ColorML
                    % in 3D_Color_Response_Xgen_R2R1_V2 we use ColorCat and train on the end of the blocks
                    % in Learning_3D_Color_Response_Xgen_R2R1_V2 and Learning_3D_Color_Response_Xgen_R2R1_V2_Rev  we do
                    % 3D_Color_Response_Xgen_R2R1_V2 during learning
                    % in 3D_Color_Response_Xgen_R2R1_V3 we use ColorCat and incongruent trials only  
                    
                case '3D_Color_Response_Xgen_R2R1'     % Train D1:ColorML(2/3) D2:ColorML(2/1) D3:ResponseLoc(2/1) all in correct trials 
                    ClassifierOpts.Name='3D Color Category Response R1R2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorML','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency  
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[]; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]};
                case '3D_Color_Response_Xgen_R2R1_V2'  % Train D1:ColorML(2/3) D2:ColorML(2/1) D3:ResponseLoc(2/1) all in correct trials
                    ClassifierOpts.Name='3D Color Category Response R1R2_V2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3]};
                    ClassifierOpts.TrainCond2={[2],[1]};
                    ClassifierOpts.TrainCond3={[2],[1]};
                    ClassifierOpts.TestCond  ={[3],[2]};
                    ClassifierOpts.TestCond2 ={[1],[2]};
                    ClassifierOpts.TestCond3 ={[1],[2]};
                    ClassifierOpts.ntrlPerCond={[5 5],[5 5],[5 5]};   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[4 4 4]; % balance congruency  
                    ClassifierOpts.TrialType=[1 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -75 75 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -75 75 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.EqualizeTrialsXConds=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[]; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1],[1 2;2 2;3 2]};
                case '3D_Color_Response_Xgen_R2R1_V3'  % Train D1:ColorML(2/3) D2:ColorML(2/1) D3:ResponseLoc(2/1) all in correct trials and incongruent trials
                    ClassifierOpts.Name='3D Color Category Response R1R2_V3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3]};
                    ClassifierOpts.TrainCond2={[2],[1]};
                    ClassifierOpts.TrainCond3={[2],[1]};
                    ClassifierOpts.TestCond  ={[3],[2]};
                    ClassifierOpts.TestCond2 ={[1],[2]};
                    ClassifierOpts.TestCond3 ={[1],[2]};
                    ClassifierOpts.ntrlPerCond={[10],[10],[10]};   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest={[2],[2],[2]};
                    ClassifierOpts.StimCongruency=[1 1 1]; % incongruent trials  
                    ClassifierOpts.TrialType=[1 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -800 800 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -800 800 0]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.EqualizeTrialsXConds=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1:2); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1:2); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[]};% we don't have one class classification here
                    ClassifierOpts.SpkCountPeriod=[]; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1],[1 2;2 2;3 2]};                  
                case 'Learning_3D_Color_Response_Xgen_R2R1_V2'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning 3D Color Category Response R1R2_V2';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[10 10 10]; % balance congruency and seqhist 
                    ClassifierOpts.TrialType=[1 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -200 200 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =repmat({[1 125 50 ClassifierOpts.NTrlStpLearning]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% we don't have one class classification here                    
                    if IndStrFieldName==2;ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35];
                    elseif IndStrFieldName==3;ClassifierOpts.SpkCountPeriod=[-0.1 0.2;-0.1 0.2;-0.1 0.2];end
                    ClassifierOpts.PlotFunction={'MainPerformance'};
                case 'Learning_3D_Color_Response_Xgen_R2R1_V2_Rev'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning 3D Color Category Response R1R2_V2Rev';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.TestCond3 ={[1]};
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[10 10 10]; % balance congruency and seqhist 
                    ClassifierOpts.TrialType=[1 1 1]; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -200 200 0]},[1 2]);
                    ClassifierOpts.TestTrlNumRange =repmat({[-1 -125 50 ClassifierOpts.NTrlStpLearning]},[1 2]);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% we don't have one class classification here                   
                    if IndStrFieldName==2;ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35];
                    elseif IndStrFieldName==3;ClassifierOpts.SpkCountPeriod=[-0.1 0.1;-0.1 0.1;-0.1 0.1];end
                    ClassifierOpts.PlotFunction={'MainPerformance'};
               
                  %% Extra conditions (needs to be cleaned)                                                                        
              
                case '3D_Color_Xgen_Bhv'  % train on rule 2 test on correct and incorrect trials in rule 3
                    ClassifierOpts.Name='3D Color Category Discrimination Xgen Bhv';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[2]};
                    ClassifierOpts.TrainCond2={[2],[2]};
                    ClassifierOpts.TrainCond3={[2],[2]};
                    ClassifierOpts.TestCond  ={[3],[1]};
                    ClassifierOpts.TestCond2 ={[3],[1]};
                    ClassifierOpts.TestCond3 ={[3],[1]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[4 4];
                    ClassifierOpts.StimCongruency=7; % balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[-1 -100 100 0]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.LimFactorTrialName='CorrectTrlsTrainIncorTrlsTest'; % correct train in correct test
                    ClassifierOpts.LimFactorTrialVal={[1],[1]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName2='AllTrlsTrainCorrTrlsTest';% take all trials in train and correct trials in test
                    ClassifierOpts.LimFactorTrialVal2={[2],[2]};
                    ClassifierOpts.LimFactorTrialName3='AllTrlsTrainIncorTrlsTest';% take correct trials in train and incorrect trials in test
                    ClassifierOpts.LimFactorTrialVal3={[3],[3]};
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1],[1 2;2 2;3 2]}; % Dim/Cond
                case '3D_Color_Response_XgenTest'  % train/test on 1/3 on response loc bal congcorrincorr and train test on 2/3 color cat balance cong
                    ClassifierOpts.Name='3D Color Category Response XgenTest';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1]} ;
                    ClassifierOpts.TrainCond2={[2]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]} ;
                    ClassifierOpts.TestCond3 ={[3]} ;
                    ClassifierOpts.ntrlPerCond={[1 1 1 1],[10 10],[10 10]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1 1 1],[2 2],[2 2]};
                    ClassifierOpts.StimCongruency=[6 4 4 ]; % balance congruency for the colorcat  dimensions and congruency and corrincorr for response location
                    ClassifierOpts.TrialType=[3 1 1]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conds
                    %   ClassifierOpts.LimFactorTrialVal={[2 3]};% which dimensions are we taking the correct trials only
                    %   ClassifierOpts.LimFactorTrialName='CorrectTrls';
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond
                case '3D_Color_Response_XgenR2'   % train/test on 2 on response loc and color cat balance corrincorr
                    ClassifierOpts.Name='3D Color Category Response XgenR2';
                    ClassifierOpts.Rule=[2 ];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={[3 4],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[2]} ;
                    ClassifierOpts.TrainCond2={[2]} ;
                    ClassifierOpts.TrainCond3={[2]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond={[3 3],[3 3],[3 3]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1],[1 1],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 7]; % balance reward
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; % don't equalize trials across conds
                    %   ClassifierOpts.LimFactorTrialVal={[2 3]};% which dimensions are we taking the correct trials only
                    %   ClassifierOpts.LimFactorTrialName='CorrectTrls';
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond
                case '3D_Color_Response_XgenR1R2R3'   % Train D1:ResponseLoc(1/2) D2:ResponseLoc(3/2) D3:ColorCat Correct(3/2)
                    ClassifierOpts.Name='3D Color Category Response XgenR1R2R3';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorML','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1]} ;
                    ClassifierOpts.TrainCond2={[3]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    %ClassifierOpts.ntrlPerCond={[10 10],[10 10],[10 10]};   % number of trials per condition of response direction
                    %ClassifierOpts.ntrlPerCondTest={[4 4],[4 4],[4 4]};
                    ClassifierOpts.ntrlPerCond={[10 10],[10 10],[2 2]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[4 4],[4 4],[1 1]};
                    ClassifierOpts.StimCongruency=[7 7 4]; % balance response direction for first two and correct incorrection for third
                    ClassifierOpts.TrialType=[3 3 1]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=0; % don't equalize trials across conds
                   % ClassifierOpts.LimFactorTrialVal={[3]};% which dimensions are we taking the correct trials only
                   %ClassifierOpts.LimFactorTrialName='CorrectTrls'; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond                        
                case '3D_Color_Response_XgenR1R2R3BalCong'    % Train D1:ResponseLoc(1/2) D2:ResponseLoc(3/2) D3:ColorCat Correct(3/2) Balance Congruenct 
                   ClassifierOpts.Name='3D Color Category Response XgenR1R2R3BalCong';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorCat','Rule'};
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond' };
                    ClassifierOpts.TrainCond ={[1]} ;
                    ClassifierOpts.TrainCond2={[3]} ;
                    ClassifierOpts.TrainCond3={[3]} ;
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[2]} ;
                    ClassifierOpts.TestCond3 ={[2]} ;
                    ClassifierOpts.ntrlPerCond={[1 1 1 1],[1 1 1 1],[1 1 1 1]};   % number of trials per condition of response direction
                    ClassifierOpts.ntrlPerCondTest={[1 1 1 1],[1 1 1 1],[1 1 1 1]};
                    ClassifierOpts.StimCongruency=[6 6 6]; % balance response direction for first two and correct incorrection for third
                    ClassifierOpts.TrialType=[3 3 3]; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple(1);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple(1); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple(1); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];
                    ClassifierOpts.EqualizeTrialsXConds=1; % don't equalize trials across conds
                    ClassifierOpts.LimFactorTrialVal={[3]};% which dimensions are we taking the correct trials only
                    ClassifierOpts.LimFactorTrialName='CorrectTrls'; 
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.TriplePlots={[1 1;2 1;3 1]}; % Dim/Cond                        
                %% here we are looking at timing and magnitude of cross decoding of response between R2 and R1R3
                % and color category between R2 and R3. 
                % In 3D_Color_Response_XgenR2R3 we look at the timing of
                % response in R2 and compare it with timing of color
                % information in R2 and R3 with equalized trials
                
                % In 3D_Color_Response_XgenR1R2R3BalInCong we test both
                % on correct and incorrect (for color category) and
                % equalize the trials 
                
                % in 3D_Color_Response_XgenR1R2R3BalInCongV2 we test the response on Incongruent trails but
                % balance congruenct for color category for correct trials 
                % we don't equalize trials here             
                case 'Learning3D_Color_Shape_Response_Xgen'  %
                    ClassifierOpts.Name='Learning3D_Color_Shape_Response_Xgen';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ResponseLoc','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1];
                    ClassifierOpts.StimCongruency=11; % balance congruency and response direction
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -500 500 0]};
                    ClassifierOpts.TestTrlNumRange ={[-1 -500 500 0]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% one class categorization label for third dimension                                      
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35];             
                
                case '3D_FineTuneColorCategoryClassifier' % fine tune color classifier 
                    ClassifierOpts.Name='3D Color Category FineTune';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorML','Rule'};
                    ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[2],[2]};
                    ClassifierOpts.TrainCond2={[3],[3],[3]};
                    ClassifierOpts.TrainCond3={[3],[3],[3]};
                    ClassifierOpts.TestCond  ={[2],[2],[2]};
                    ClassifierOpts.TestCond2 ={[3],[3],[3]};
                    ClassifierOpts.TestCond3 ={[2],[2],[2]};
                    ClassifierOpts.ntrlPerCond=[5 5];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; %Balance Congruency
                    ClassifierOpts.TrialType=1; % Correct trials
                    ClassifierOpts.caxis_limits=[0.35 0.65];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};%  we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                    ClassifierOpts.Kernel={'linear','gaussian','rbf'};
                    ClassifierOpts.LinearSVMFitFunction={'fitcsvm','fitcsvm','fitcsvm'};
                    %ClassifierOpts.CrossValidate=[1 0 1 0 ];
                case 'XTemp_AllObjects'  % Xtemporal train and test on category of all objects for each rule
                    ClassifierOpts.Name='All Objects Discrimination';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'AllObjects','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'AllObjects','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'AllObjects','Rule'};
                    ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond','TripleCrossCond','TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[4 4];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; %Balance Congruency
                    ClassifierOpts.TrialType=1; % Correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};%  we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','PerfTripleSuperimposed','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
                case '3D_ColorCategoryFineTuneSig' % fine tune color classifier for significance test
                    ClassifierOpts.Name='3D Color Category FineTune Significance';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors     = {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_3ndD= {'ColorML','Rule'};
                    ClassifierOpts.Levels     ={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevelsNo50],[ClassifierOpts.Rule]};
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TrainCond3={[3]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[2]};
                    ClassifierOpts.ntrlPerCond=[4 4];
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; %Balance Congruency
                    ClassifierOpts.TrialType=1; % Correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.TestTrlNumRange =ClassifierOpts.AllTrialsTriple;
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=ClassifierOpts.LimitFromSwitchPerfTriple; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=ClassifierOpts.LimitFromSwitchPerf_OperatiomTriple; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.One_Class_ResponseLbl={[],[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[],[],[]};%  we don't have one class classification here
                    ClassifierOpts.PlotFunction={'PerfTripleInd','Scores','CompareTiming'};
                    ClassifierOpts.SpkCountPeriod=[];  
                    ClassifierOpts.NrepShuf=20; % how many shuffle we have we resmapling of train and test
                case 'ResponseLocation_BalCorr'
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorr';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3],[1],[3]};%ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond ={[2],[2],[2],[2]};%ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[9 9];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=12; % balance incongruent
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.MaxMatchTrialConds=[0 0 1 1];
                    obj.RunCrossTemporalClassifer=0;
            end
            nConds=length(ClassifierOpts.TrainCond);   
            % always skip matching the train trials(because it changes the shuffle dist)
            ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain=ones(1,nConds);
            if ~isfield(ClassifierOpts.EqualizeTrials4Conds,'SkipDupTrainTest')
                ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest=zeros(1,nConds);
            end
            if ~isfield(ClassifierOpts.EqualizeTrials4Conds,'SkipDupTest')
                ClassifierOpts.EqualizeTrials4Conds.SkipDupTest=zeros(1,nConds);
            end

            if length(ClassifierOpts.TrialType)==1;ClassifierOpts.TrialType=repmat(ClassifierOpts.TrialType,[1 3]);end
            if length(ClassifierOpts.StimCongruency)==1;ClassifierOpts.StimCongruency=repmat(ClassifierOpts.StimCongruency,[1 3]);end
            % define classifier chance level 
            if ~isfield(ClassifierOpts,'ChanceLevel');ClassifierOpts.ChanceLevel=0.5;end
            % fill some missing variables  
            if ~iscell(ClassifierOpts.ntrlPerCond)
                if sum(ClassifierOpts.ntrlPerCond)~=(ClassifierOpts.ntrlPerCond(1)*length(ClassifierOpts.ntrlPerCond)) & ...
                        ~contains(ClassifierOpts.Name,'Congruency')   
                    error('number of trials/condition must be equal')
                end
            end
            if ~isfield(ClassifierOpts,'TrainTrlNumRange')
                ClassifierOpts.TrainTrlNumRange=repmat({[0 0 0 0]},[1 nConds]); % include all trails
                ClassifierOpts.TestTrlNumRange =repmat({[0 0 0 0]},[1 nConds]); % include all trails
            end
            ClassifierOpts.RunCrossTemporalClassifer=obj.RunCrossTemporalClassifer;
            NConds=length(ClassifierOpts.TrainCond);
            if ~isfield(ClassifierOpts,'LimFactorTrialVal')
                ClassifierOpts.LimFactorTrialVal=repmat({nan},1,nConds);
                ClassifierOpts.LimFactorTrialName=repmat({nan},1,nConds);
            end
            if ~isfield(ClassifierOpts,'ntrlPerCondTest');ClassifierOpts.ntrlPerCondTest=ceil(ClassifierOpts.ntrlPerCond/2);end
            % update obj.SpkCountPeriod if we have values in ClassifierOpts.SpkCountPeriod
            if ~isfield(ClassifierOpts,'SpkCountPeriod')              
                ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35];
            end

            % update one-class response label for both dimensions
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl');ClassifierOpts.One_Class_ResponseLbl=cell(1,NConds);end
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl2');ClassifierOpts.One_Class_ResponseLbl2=cell(1,NConds);end
            % if we are running cross temporal then change file name
            if obj.RunCrossTemporalClassifer==1 | AnalysisOpts.RunCrossTemporalClassifer==1
                ClassifierOpts.Name=[ClassifierOpts.Name '_XTMP'];
                ClassifierOpts.PlotFunction={'PerfTripleInd'};
            end
            if  ClassifierOpts.IncludeAllClassifierInfo==1 % this is full informtion for classifier
                ClassifierOpts.Name=[ClassifierOpts.Name '_F'];
            end
            if contains(ClassifierOpts.Name,'Learning') 
                ClassifierOpts.SkipSeqHistTrain=1; % if we are skipping to apply SeqHist to learning
                ClassifierOpts.Name=[ClassifierOpts.Name '_SkTrSq'];
            end
            % if we have mean subtracted each rule then show it
            if ClassifierOpts.MeanSubtractByRule==1;ClassifierOpts.Name=[ClassifierOpts.Name '_MS'];end
            % if we have zscore and detrend the data then add it to the name
            if obj.ZscoreFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_ZS'];end
            % if we have detrended the data then add it to the name
            if obj.DetrendFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_DT'];end
            % change name if we are using matching trials or not
            if obj.MaxMatchTrialConds==0;ClassifierOpts.Name=[ClassifierOpts.Name '_TR'];end % trial Random
            % if for learning we are doing reverese 
            if contains(ClassifierOpts.Name,'Learning') & AnalysisOpts.ClassifierLearningTrlSweepDir<0
                ClassifierOpts.Name=[ClassifierOpts.Name '_Rev'];
            end
            if contains(ClassifierOpts.Name,'Learning') | contains(ClassifierOpts.Name,'BalInCongV')% use repetition for cluster runs only for shuffle
                AnalysisOpts.UseRep4Cluster=1;
            end

            % if we are using cross validation 
            if ClassifierOpts.UseCV & contains(ClassifierOpts.Name,'Entropy','IgnoreCase',1)
                ClassifierOpts.Name=[ClassifierOpts.Name '_CV'];end
            % indicate if we are not using cross validation 
            if ~ClassifierOpts.UseCV
                ClassifierOpts.Name=[ClassifierOpts.Name '_NoCV'];
            end
            % if we are imposing Nrep
            if ~isnan(AnalysisOpts.Classifier_Nrep);ClassifierOpts.Nrep=AnalysisOpts.Classifier_Nrep;end
            % if we don't have cross validation
            if ~isfield(ClassifierOpts,'CrossValidate');ClassifierOpts.CrossValidate=zeros(1,NConds);end  
            % adjust the tyClassifierOptspe for number of trials 
            if ~iscell(ClassifierOpts.ntrlPerCond)
                ClassifierOpts.ntrlPerCond=repmat({ClassifierOpts.ntrlPerCond},[1 3]);
            end
            if ~iscell(ClassifierOpts.ntrlPerCondTest)
                ClassifierOpts.ntrlPerCondTest=repmat({ClassifierOpts.ntrlPerCondTest},[1 3]);
            end
            % if we are running a dummy file then decrease the number of repetitions to 5
            if AnalysisOpts.RunDummyFile;ClassifierOpts.Nrep=2;ClassifierOpts.NrepShuf=2;ClassifierOpts.NrepShufperFold=2;end
            if  AnalysisOpts.SweepClassifierConds ;ClassifierOpts.MeanSubtractByRule=0;end %we don't need to subtract mean
            
            AnalysisOpts.DividSpockClassifier=ClassifierOpts.DividSpockClassifier;
            AnalysisOpts.ExchangeableCalShuffClassifier=ClassifierOpts.ExchangeableCalShuffClassifier;
            ClassifierOpts.NConds=nConds;
            obj.ClustStatTst_p_threshold=ClassifierOpts.ClustStatTst_p_threshold;
           
            % if we have a learning condition then add the specs to the end of the file 
            if contains(ClassifierOpts.Name,'Learning','IgnoreCase',true)
                if ClassifierOpts.NTrlStpLearning(ClassifierOpts.AreaNum)==5
                    LearningStepTxt='';
                else
                    LearningStepTxt=['_' num2str(ClassifierOpts.NTrlStpLearning(ClassifierOpts.AreaNum))];
                end
                ExtrName=[sprintf('%i_%i_%i_%i%s',ClassifierOpts.NTrlRngTrainLearningArea(ClassifierOpts.AreaNum),...
                    ClassifierOpts.NTrlRngTestLearningArea(ClassifierOpts.AreaNum),...
                    ClassifierOpts.ntrlPerCondArea(ClassifierOpts.AreaNum),...
                    ClassifierOpts.LimitFromSwitchPerfArea(ClassifierOpts.AreaNum)*100),LearningStepTxt];
                ClassifierOpts.Name=[ClassifierOpts.Name ExtrName];
            end
             % if we have a entropy condition then add the specs to the end of the file 
            if contains(ClassifierOpts.Name,'Entropy','IgnoreCase',true)
                ExtrName=sprintf('%i_%i_%i',ClassifierOpts.NTrlRngTrainLearningArea(ClassifierOpts.AreaNum),...
                    ClassifierOpts.NTrlRngTestLearningArea(ClassifierOpts.AreaNum),...
                    ClassifierOpts.ntrlPerCondArea(ClassifierOpts.AreaNum));
                ClassifierOpts.Name=[ClassifierOpts.Name ExtrName];
            end
            % copy all of the opts into AnalysisOpts
            AnalysisOpts.CurrentClassifierOpts=ClassifierOpts;
        end
       
        function [ClassifierOpts,obj]=DefineClassifierTestOptionsBackup2(obj,TestName,varargin) % prepare options for each type of test we want to run
            %@TestName name of the test we want to do 'XTemp_Rule' 'XTemp_Cat_Color' 'XTemp_Cat_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isscalar(TestName);TestName=AnalysisOpts.PopulationAna.Classifier_TaskNameSet{TestName};end
            
            ClassifierOpts.Nrep=250;
            ClassifierOpts.NrepShuf=1000;
            ClassifierOpts.holdout_frac=0.1;
            ClassifierOpts.RunCrossTemporalClassifer=0; % run these tests in cross temporal
            ClassifierOpts.MeanSubtractByRule=0; % are we zero meaning each rule before doing analysis
            % get indices for future use
            ClassifierOpts.Congruency.Ind   =strcmp(AnalysisOpts.factornames,'Congruency');
            ClassifierOpts.Reward.Ind       =strcmp(AnalysisOpts.factornames,'Reward');
            ClassifierOpts.ResponseLoc.Ind  =strcmp(AnalysisOpts.factornames,'ResponseLoc');
            ClassifierOpts.ColorML.Ind      =strcmp(AnalysisOpts.factornames,'ColorML');
            ClassifierOpts.ShapeML.Ind      =strcmp(AnalysisOpts.factornames,'ShapeML');
            ClassifierOpts.ColorCat.Ind     =strcmp(AnalysisOpts.factornames,'ColorCat');
            ClassifierOpts.ShapeCat.Ind     =strcmp(AnalysisOpts.factornames,'ShapeCat');
            ClassifierOpts.Rule.Ind         =strcmp(AnalysisOpts.factornames,'Rule');
            ClassifierOpts.SeqHist.Ind      =strcmp(AnalysisOpts.factornames,'SeqHist');
            ClassifierOpts.none.Ind         =[];
            % define values for each factor
            ClassifierOpts.Congruency.Val   =[0 1];
            ClassifierOpts.Reward.Val       =[0 1];
            ClassifierOpts.ResponseLoc.Val  =[1 2 3 4];
            ClassifierOpts.ResponseLoc.ValRule={[1 2],[3 4],[1 2]};
            ClassifierOpts.ColorML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ShapeML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ColorCat.Val     =[1 2];
            ClassifierOpts.ShapeCat.Val     =[1 2];
            ClassifierOpts.Rule.Val         =[1 2 3];
            ClassifierOpts.SeqHist.Val      =[0 1];
            ClassifierOpts.none.Val         =1;
            
            % all of the combinations of train and test
            ClassifierOpts.TrainAllCombs={[1],[2],[3],[2],[3],[1]};
            ClassifierOpts.TestAllCombs ={[2],[3],[1],[1],[2],[3]};
            ClassifierOpts.AllCombPlotPair={[1 4],[2 5],[3 6]}; %pairs of conditions to be plotted together
            ClassifierOpts.TrainTriple1={[1],[2],[3]};ClassifierOpts.TestTriple1={[1],[2],[3]};
            ClassifierOpts.TrainTriple2={[1],[2],[3]};ClassifierOpts.TestTriple2={[2],[1],[2]};
            ClassifierOpts.TrainTriple3={[1],[2],[3]};ClassifierOpts.TestTriple3={[3],[3],[1]};           
            ClassifierOpts.ColorOnRule=1; %color results based on their rule
            ClassifierOpts.NTrlStpLearning=5; % number of steps for trial shifts in learning
            ClassifierOpts.ThPerfLow=0.5; % threshold for learning perfromance low
            ClassifierOpts.ThPerfHigh=0.6;% threshold for learning perfromance high
            switch TestName
                case 'XTemp_Cat_Color'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'XTemp_Cat_Shape'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Shape Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'XTemp_Cat_Color_Xgen_SingML'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Color Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=0;
                 case 'XTemp_Abstract_Color_Xgen_SingML'   %  train on one rule and test on the other rule Xgeneralization(Color) using single MLs ( check abstraction, train on one half test on the other half)
                    ClassifierOpts.Name='Cross Rule Abstract Color Category Disc SingML';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimFactorTrialVal=repmat({[1]},1,6); %nan no abstract test, 1: train/test on including 0/100 2:train test excluding 0/100
                    obj.RunCrossTemporalClassifer=0;    
                case 'Cat_Color_Xgen_SingML_XTemp'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Color Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=1;
                case 'XTemp_Cat_Shape_Xgen_SingML'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Shape Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=0;
                case 'Cat_Shape_Xgen_SingML_XTemp'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Shape Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=1;
                    
                case 'XTemp_Stim_Color'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Stimulus Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0 0.5];                    
                case 'XTemp_Stim_Shape'  % Xtemporal train and test on category of shape feature for each rule
                    ClassifierOpts.Name='Shape Stimulus Discrimination';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'}; % ShapeML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0 0.5];
                    
                case 'XTemp_Stim_Color_Xgen'   % Xtemporal train on one rule and test on the other rule Xgeneralization
                    ClassifierOpts.Name='Cross Rule Stimulus Color Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0 0.5];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Stim_Shape_Xgen'   % Xtemporal train on one rule and test on the other rule Xgeneralization
                    ClassifierOpts.Name='Cross Rule Stimulus Shape Discrimination';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0 0.5];
                    ClassifierOpts.MeanSubtractByRule=1;
                    %% shape and color decoding with balanced response direction
                case 'XTemp_Cat_Color_BalRespDir'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination BalRespDir';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of response
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of response
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                case 'XTemp_Cat_Shape_BalRespDir'  % Xtemporal train and test on category of shape feature for each rule
                    ClassifierOpts.Name='Shape Category Discrimination BalRespDir';
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                    %   ClassifierOpts.Kernel='RBF';
                case 'XTemp_Cat_Color_Xgen_BalRespDir'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) Use categorical
                    ClassifierOpts.Name='Cross Rule Color Category Disc BalRespDir';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Cat_Shape_Xgen_BalRespDir'   % Xtemporal train on one rule and test on the other rule Xgeneralization(shape) Use categorical
                    ClassifierOpts.Name='Cross Rule Shape Category Disc BalRespDir';
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.MeanSubtractByRule=1;
                    %% additional test conditions for sensory representations
                case 'XTemp_Cat_Color_BalRespDirCong' % classify Color Cat balance congruency and corrincorr
                    % note that for this condition we need to balance
                    % response direction for the axis of the response
                    ClassifierOpts.Name='Color Category Discrimination BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'XTemp_Cat_Color_BalRespDir_Xval'  % Xvalidate Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination BalRespDir Xval';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[3]};
                    ClassifierOpts.TestCond ={[3]};
                    ClassifierOpts.ntrlPerCond=[5 5];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                    ClassifierOpts.CrossValidate=1;
                    %   ClassifierOpts.Kernel='RBF';
                    %% %%%%%%%%%%%%%% response location tests %%%%%%%%%%%%%%%%%%%%%%%%
                case 'ResponseLocation_BalCorr' % classify where the animal has responded
                    ClassifierOpts.Name='ResponseLoc Discrimination BalCorr';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect and don't care about congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'ResponseLocation_BalCong' % classify where the animal has responded balance congruency and corrincorr
                    ClassifierOpts.Name='ResponseLoc Discrimination BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[1],[3]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'ResponseLocation_Xgen_BalCorr' % classify where the animal has responded
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorr';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3]};%ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond ={[3],[1]};%ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect and don't care about congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=0;
                case 'ResponseLocation_Xgen_BalCorr_XTemp' % classify where the animal has responded
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorr';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3]};%ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond ={[3],[1]};%ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect and don't care about congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=1;
                case 'ResponseLocation_Xgen_BalCong' % classify where the animal has responded with cangruency balance
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[3],[1]};
                    %  ClassifierOpts.Rule=[1 2 3];
                    %  ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    %  ClassifierOpts.type='CrossCond';
                    %  ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    %  ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=0;
                case 'ResponseLocation_Xgen_BalCong_XTemp' % classify where the animal has responded with cangruency balance
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[3],[1]};
                    %  ClassifierOpts.Rule=[1 2 3];
                    %  ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    %  ClassifierOpts.type='CrossCond';
                    %  ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    %  ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    obj.RunCrossTemporalClassifer=1;
                    %% control conditions to fine tune the classifier
                case 'FineTune_Cat_Color_Xgen'   % FineTune  train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='FineTune Cross Rule Color Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond ={[2],[2],[2],[2],[2]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.CrossValidate=[0 0 0 0 0 ];
                    ClassifierOpts.Lambda=[0 0.001 0.01 0.1 1];
                case 'FineTune_Stim_Color'  % FineTune train and test on category of color feature for each rule
                    ClassifierOpts.Name='FineTune Color Stimulus Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[2],[2],[2],[2],[2] };
                    ClassifierOpts.TestCond ={[2],[2],[2],[2],[2] };
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.1 0.4];
                    ClassifierOpts.Lambda=[0 0 0 0.001 0.01 0.1 1];
                    ClassifierOpts.Kernel={'linear','linear','linear','linear','linear'};
                    ClassifierOpts.CrossValidate=[0 0 0 0 0 0];
                case 'FineTune_Stim_Color_Kernel'  % FineTune train and test on category of color feature for each rule with differnet kernels kernel
                    ClassifierOpts.Name='FineTune Color Stimulus Discrimination Kernel';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[2],[2],[2],[2]};
                    ClassifierOpts.TestCond ={[2],[2],[2],[2]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.1 0.4];
                    ClassifierOpts.Kernel={'gaussian','gaussian','linear','linear'};
                    ClassifierOpts.CrossValidate=[1 0 1 0 ];
                    ClassifierOpts.Nrep=20;
                case 'XTemp_AllObjects'  % Xtemporal train and test on category of all objects for each rule
                    ClassifierOpts.Name='All Objects Discrimination';
                    ClassifierOpts.TargetFactors= {'AllObjects','Rule'}; % all of the objects
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[1],[3]};
                    ClassifierOpts.ntrlPerCond=[3];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=0; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0 0.5];
                    obj.ZscoreFactorData=1; % let's zscore factor data
                case 'Learning_Cat_Color_Resp_Xgen'
                    ClassifierOpts.Name='Learning_Color_Resp BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TestCond  ={[2]};
                    ClassifierOpts.TestCond2 ={[1]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.TrainTrlNumRange={[-1 -200 200 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 500 500 0]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.caxis_limits=[0.3 1];
                    %% look at the evolution of sensory information
                case 'Learning_Cat_Color_Color_Xgen_AltRule'  % Train and test of category of color simoultanously for two rules
                    ClassifierOpts.Name='Learning_Color_Color Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    
                case 'Learning_Cat_Shape_Color_Xgen_AltRule'  % train and test for shape(1) and color(2) and then test trials in rule 3
                    ClassifierOpts.Name='Learning_Shape_Color Category Discrimination Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    
                case 'Learning_Cat_Shape_Color_Xgen_SameRule'  % train and test for shape(1) and color(2) and then test trials in rule 3 in same rule
                    ClassifierOpts.Name='Learning_Shape_Color Category Discrimination Xgen SameRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 1.1]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]}; % Seqhist value for this condition
                    
                    %% look at the evolution of rule information
                case 'Learning_Cat_Shape_Rule_Xgen_AltRule'  % train and test for shape(1) and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Shape_Rule Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    
                case 'Learning_Cat_Shape_Rule_Xgen_AltRule_HiPerf'  % train and test for shape(1) and Rule(1,3) and then test trials in rule 3 with AltRule when performance at the beginning of the block is high
                    ClassifierOpts.Name='Learning_Shape_Rule Category Disc Xgen AltRule HiPerf';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfHigh]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    
                case 'Learning_Cat_Color_Rule_Xgen_AltRule'  % train and test for color(2) and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Color_Rule Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    
                case 'Learning_Cat_Color_Rule_Xgen_AltRule_HiPerf'  % train and test for color(2) and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Color_Rule Category Disc Xgen AltRule HiPerf';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfHigh]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    %% test conditions
                case 'Learning_Cat_Color_Rule_Xgen_AltRule_Test'  % train and test for color(2) and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Color_Rule Category Disc Xgen AltRule Test';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan ClassifierOpts.ThPerfLow]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    ClassifierOpts.Nrep=5;
                    ClassifierOpts.NrepShuf=5;
                    %% look at effect of congruency 
                case 'Learning_Congruency_Rule_Xgen_AltRule'  % train and test for congruency and Rule(1,3) and then test trials in rule 3 with AltRule but look at congruency
                    ClassifierOpts.Name='Learning_Congruency_Rule Xgen AltRule';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type=repmat({'DoubleCrossCond'},1,5);
                    ClassifierOpts.TrainCond ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.TrainCond2={[1,3],[1,3],[1,3],[1,3],[1,3]};
                    ClassifierOpts.TestCond  ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency(incong cong)
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -75 75 0]},1,5);
                    ClassifierOpts.TestTrlNumRange =repmat({[1 125 50 ClassifierOpts.NTrlStpLearning]},1,5);
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf=repmat({[nan ClassifierOpts.ThPerfLow]},1,5); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat({{nan,'smaller'}},1,5); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[1],[1],[1],[1]};   % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl=repmat({[]},1,5); % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2=repmat({[3]},1,5);  % one class categorization label for second dimension                    
                    ClassifierOpts.LimFactorTrialVal={nan,[0 1],[1 0],[0 0],[1 1]}; % if we are limiting factor trial% this congruency factor
               
                case 'Learning_Congruency_Shape_Color_Xgen_AltRule'
                    ClassifierOpts.Name='Learning_Congruency_Shape_Color Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type=repmat({'DoubleCrossCond'},1,5);
                    ClassifierOpts.TrainCond ={[1],[1],[1],[1],[1]};
                    ClassifierOpts.TrainCond2={[2],[2],[2],[2],[2]};
                    ClassifierOpts.TestCond  ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -75 75 0]},1,5);
                    ClassifierOpts.TestTrlNumRange =repmat({[1 125 50 ClassifierOpts.NTrlStpLearning]},1,5);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat({[nan ClassifierOpts.ThPerfLow]},1,5); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat({{nan,'smaller'}},1,5); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[1],[1],[1],[1]}; % Seqhist value for this condition
                    ClassifierOpts.LimFactorTrialVal={nan,[0 1],[1 0],[0 0],[1 1]}; % if we are limiting factor trial% this congruency factor
           case 'Learning_Congruency_Shape_Color_Xgen_AltRule_Test'
                    ClassifierOpts.Name='Learning_Congruency_Shape_Color Xgen AltRuleTest';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type=repmat({'DoubleCrossCond'},1,5);
                    ClassifierOpts.TrainCond ={[1],[1],[1],[1],[1]};
                    ClassifierOpts.TrainCond2={[2],[2],[2],[2],[2]};
                    ClassifierOpts.TestCond  ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3],[3],[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange=repmat({[-1 -50 50 0]},1,5);
                    ClassifierOpts.TestTrlNumRange =repmat({[1 125 50 ClassifierOpts.NTrlStpLearning]},1,5);
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf=repmat({[nan ClassifierOpts.ThPerfLow]},1,5); %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation=repmat({{nan,'smaller'}},1,5); %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[1],[1],[1],[1]}; % Seqhist value for this condition
                    ClassifierOpts.LimFactorTrialVal={nan,[0 1],[1 0],[0 0],[1 1]}; % if we are limiting factor trial% this congruency factor        
                %% do 3D conditions 
                case 'Learning3D_Color_Shape_Rule_Xgen_AltRule'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[2]};
                    ClassifierOpts.TrainCond2={[1],[1]};
                    ClassifierOpts.TrainCond3={[1,3],[1,3]};
                    ClassifierOpts.TestCond  ={[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3]};
                    ClassifierOpts.TestCond3 ={[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -75 75 0],[-1 -75 75 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning],[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.45],[nan ClassifierOpts.ThPerfHigh]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'},{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3],[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;-0.5 0];
               case 'Learning3D_Color_Shape_Rule_Xgen_AltRule_HiTh'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen AltRule_HiTh'; % with 0.5 performance TH
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[2]};
                    ClassifierOpts.TrainCond2={[1],[1]};
                    ClassifierOpts.TrainCond3={[1,3],[1,3]};
                    ClassifierOpts.TestCond  ={[3],[3]};
                    ClassifierOpts.TestCond2 ={[3],[3]};
                    ClassifierOpts.TestCond3 ={[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -75 75 0],[-1 -75 75 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning],[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5],[nan ClassifierOpts.ThPerfHigh]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'},{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1],[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[],[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[],[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3],[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;-0.5 0];     
               case 'Learning3D_Color_Shape_Rule_Xgen_SameRule'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with SameRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Rule Xgen SameRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 3],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=[3 3];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -75 75 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[0]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;-0.5 0];
                    ClassifierOpts.RunPrelimSubspace=0;
               
                case 'Learning3D_Color_Shape_Shape_Xgen'  % train color(3) color Rule 2 and shape 1 and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Shape_Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ShapeCat','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[3]};
                    ClassifierOpts.TrainCond3={[1]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                     ClassifierOpts.ntrlPerCond=[3 3];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -75 75 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 ClassifierOpts.NTrlStpLearning]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.40]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[3]};% one class categorization label for third dimension                    
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35];    
                case 'Learning3D_Color_Shape_Response_Xgen'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning3D_Color_Shape_Response_Xgen';
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ShapeCat','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ResponseLoc','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[1 2],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[1]};
                    ClassifierOpts.TrainCond3={[1]};
                    ClassifierOpts.TestCond  ={[1]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.TestCond3 ={[3]};
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1];
                    ClassifierOpts.StimCongruency=11; % balance congruency and response direction
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -500 500 0]};
                    ClassifierOpts.TestTrlNumRange ={[-1 -500 500 0]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
      %             ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% one class categorization label for third dimension                                      
                    ClassifierOpts.SpkCountPeriod=[0.1 0.35;0.1 0.35;0.1 0.35]; 
                  %% 3D conditions without learning 
                case '3D_Color_Cat_Xgen'  % train shape(1) color Rule 2 and Rule(1,3) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='3D_Color_Cat_Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.TargetFactors_2ndD= {'ColorML','Rule'};                    
                    ClassifierOpts.TargetFactors_3ndD={'ColorML','Rule'};
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_3ndD={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]}; 
                    ClassifierOpts.type={'TripleCrossCond'};
                    ClassifierOpts.TrainCond =ClassifierOpts.TrainTriple1;
                    ClassifierOpts.TrainCond2=ClassifierOpts.TrainTriple2;
                    ClassifierOpts.TrainCond3=ClassifierOpts.TrainTriple3;
                    ClassifierOpts.TestCond  =ClassifierOpts.TestTriple1;
                    ClassifierOpts.TestCond2 =ClassifierOpts.TestTriple2;
                    ClassifierOpts.TestCond3 =ClassifierOpts.TestTriple3;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency and response direction
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -800 800 0]};
                    ClassifierOpts.TestTrlNumRange ={[-1 -800 800 0]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan nan]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,nan}}; %what operation are we doing when we limit the performance from switch
                    %             ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[]};% we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl3={[]};% one class categorization label for third dimension
                    ClassifierOpts.SpkCountPeriod=[];                    
            end
            nConds=length(ClassifierOpts.TrainCond);
            % define classifier chance level 
            if ~isfield(ClassifierOpts,'ChanceLevel');ClassifierOpts.ChanceLevel=0.5;end
            % fill some missing variables
            if sum(ClassifierOpts.ntrlPerCond)~=(ClassifierOpts.ntrlPerCond(1)*length(ClassifierOpts.ntrlPerCond)) & ~contains(ClassifierOpts.Name,'Congruency')
                error('number of trials/condition must be equal')
            end
            if ~isfield(ClassifierOpts,'TrainTrlNumRange')
                ClassifierOpts.TrainTrlNumRange=repmat({[0 0 0 0]},[1 nConds]); % include all trails
                ClassifierOpts.TestTrlNumRange =repmat({[0 0 0 0]},[1 nConds]); % include all trails
            end
            ClassifierOpts.RunCrossTemporalClassifer=obj.RunCrossTemporalClassifer;
            NConds=length(ClassifierOpts.TrainCond);
            if ~isfield(ClassifierOpts,'LimFactorTrialVal');ClassifierOpts.LimFactorTrialVal=repmat({nan},1,nConds);end
            if ~isfield(ClassifierOpts,'ntrlPerCondTest');ClassifierOpts.ntrlPerCondTest=ceil(ClassifierOpts.ntrlPerCond/2);end
            % update obj.SpkCountPeriod if we have values in ClassifierOpts.SpkCountPeriod
            if ~isfield(ClassifierOpts,'SpkCountPeriod');ClassifierOpts.SpkCountPeriod=[];end
            % update one-class response label for both dimensions
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl');ClassifierOpts.One_Class_ResponseLbl=cell(1,NConds);end
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl2');ClassifierOpts.One_Class_ResponseLbl2=cell(1,NConds);end
            % if we are running cross temporal then change file name
            if obj.RunCrossTemporalClassifer==1;ClassifierOpts.Nrep=50;ClassifierOpts.Name=[ClassifierOpts.Name '_XTMP'];end
            % if we have mean subtracted each rule then show it
            if ClassifierOpts.MeanSubtractByRule==1;ClassifierOpts.Name=[ClassifierOpts.Name '_MS'];end
            % if we have zscore and detrend the data then add it to the name
            if obj.ZscoreFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_ZS'];end
            % if we have detrended the data then add it to the name
            if obj.DetrendFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_DT'];end
            % change name if we are using matching trials or not
            if obj.MaxMatchTrialConds==0;ClassifierOpts.Name=[ClassifierOpts.Name '_TR'];end % trial Random
            % if we are imposing Nrep
            if ~isempty(AnalysisOpts.Classifier_Nrep);ClassifierOpts.Nrep=AnalysisOpts.Classifier_Nrep;end
            % if we don't have cross validation
            if ~isfield(ClassifierOpts,'CrossValidate');ClassifierOpts.CrossValidate=zeros(1,NConds);end            
        end
        function [ClassifierOpts,obj]=DefineClassifierTestOptionsBackup(obj,TestName,varargin) % BackUP prepare options for each type of test we want to run
            %@TestName name of the test we want to do 'XTemp_Rule' 'XTemp_Cat_Color' 'XTemp_Cat_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isscalar(TestName);TestName=AnalysisOpts.PopulationAna.Classifier_TaskNameSet{TestName};end
            
            ClassifierOpts.Nrep=250;
            ClassifierOpts.NrepShuf=1000;
            ClassifierOpts.holdout_frac=0.1;
            ClassifierOpts.RunCrossTemporalClassifer=0; % run these tests in cross temporal
            ClassifierOpts.MeanSubtractByRule=0; % are we zero meaning each rule before doing analysis
            % get indices for future use
            ClassifierOpts.Congruency.Ind   =strcmp(AnalysisOpts.factornames,'Congruency');
            ClassifierOpts.Reward.Ind       =strcmp(AnalysisOpts.factornames,'Reward');
            ClassifierOpts.ResponseLoc.Ind  =strcmp(AnalysisOpts.factornames,'ResponseLoc');
            ClassifierOpts.ColorML.Ind      =strcmp(AnalysisOpts.factornames,'ColorML');
            ClassifierOpts.ShapeML.Ind      =strcmp(AnalysisOpts.factornames,'ShapeML');
            ClassifierOpts.ColorCat.Ind     =strcmp(AnalysisOpts.factornames,'ColorCat');
            ClassifierOpts.ShapeCat.Ind     =strcmp(AnalysisOpts.factornames,'ShapeCat');
            ClassifierOpts.Rule.Ind         =strcmp(AnalysisOpts.factornames,'Rule');
            ClassifierOpts.SeqHist.Ind      =strcmp(AnalysisOpts.factornames,'SeqHist');
            % define values for each factor
            ClassifierOpts.Congruency.Val   =[0 1];
            ClassifierOpts.Reward.Val       =[0 1];
            ClassifierOpts.ResponseLoc.Val  =[1 2 3 4];
            ClassifierOpts.ResponseLoc.ValRule={[1 2],[3 4],[1 2]};
            ClassifierOpts.ColorML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ShapeML.Val      =AnalysisOpts.StimulusMorphLevels;
            ClassifierOpts.ColorCat.Val     =[1 2];
            ClassifierOpts.ShapeCat.Val     =[1 2];
            ClassifierOpts.Rule.Val         =[1 2 3];
            ClassifierOpts.SeqHist.Val      =[0 1];
            % all of the combinations of train and test
            ClassifierOpts.TrainAllCombs={[1],[2],[3],[2],[3],[1]};
            ClassifierOpts.TestAllCombs ={[2],[3],[1],[1],[2],[3]};
            ClassifierOpts.AllCombPlotPair={[1 4],[2 5],[3 6]}; %pairs of conditions to be plotted together
            ClassifierOpts.ColorOnRule=1; %color results based on their rule
            switch TestName
                case 'XTemp_Rule_Xgen_BalRespDir' % Xtemporal train and test on three rule identity
                    ClassifierOpts.Name='Rule Discrimination BalRespDir';
                    ClassifierOpts.TargetFactors= {'Rule','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[ClassifierOpts.Rule],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1,3],[2,3]};
                    ClassifierOpts.TestCond ={[2]  ,[1]};
                    ClassifierOpts.ntrlPerCond=[10 10];   % number of trials per condition
                    ClassifierOpts.StimCongruency=8; % equalize response location
                    ClassifierOpts.TrialType=1; % take correct trials
                    ClassifierOpts.caxis_limits=[0.5 1];
                    ClassifierOpts.SpkCntStartFieldName='FIXATE_AQUIRED';
                    ClassifierOpts.RunCrossTemporalClassifer=0;
                    ClassifierOpts.One_Class_ResponseLbl={[3],[3]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    
                case 'XTemp_Rule_Xgen_NoBal' % Xtemporal train and test on three rule identity
                    ClassifierOpts.Name='Rule Discrimination NoBal';
                    ClassifierOpts.TargetFactors= {'Rule','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[ClassifierOpts.Rule],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1,3],[2,3]};
                    ClassifierOpts.TestCond ={[2]  ,[1]};
                    ClassifierOpts.ntrlPerCond=[30];   % number of trials per condition
                    ClassifierOpts.StimCongruency=0; % don't care about congruency
                    ClassifierOpts.TrialType=1; % take correct trials
                    ClassifierOpts.caxis_limits=[0.5 1];
                    ClassifierOpts.SpkCntStartFieldName='FIXATE_AQUIRED';
                    ClassifierOpts.RunCrossTemporalClassifer=0;
                    ClassifierOpts.One_Class_ResponseLbl={[3],[3]};
                    ClassifierOpts.MeanSubtractByRule=0;
                case 'XTemp_Rule_Xgen_NoBal_AllTrls' % Xtemporal train and test on three rule identity
                    ClassifierOpts.Name='Rule Discrimination NoBal AllTrls';
                    ClassifierOpts.TargetFactors= {'Rule','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[ClassifierOpts.Rule],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1,3],[2,3]};
                    ClassifierOpts.TestCond ={[2]  ,[1]};
                    ClassifierOpts.ntrlPerCond=[30];   % number of trials per condition
                    ClassifierOpts.StimCongruency=0; % don't care about congruency
                    ClassifierOpts.TrialType=3; % take correct trials
                    ClassifierOpts.caxis_limits=[0.5 1];
                    ClassifierOpts.SpkCntStartFieldName='FIXATE_AQUIRED';
                    ClassifierOpts.RunCrossTemporalClassifer=0;
                    ClassifierOpts.One_Class_ResponseLbl={[3],[3]};
                    ClassifierOpts.MeanSubtractByRule=0;
                case 'XTemp_Feature_Xgen' % Xtemporal train and test on features of the rules
                    ClassifierOpts.Name='Rule Feature Discrimination';
                    ClassifierOpts.TargetFactors= {'Feature','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1],[2],[2]},[1 2 3]};%1: shape 2: color
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1,2],[1,3]};
                    ClassifierOpts.TestCond ={[3]  ,[2] };
                    ClassifierOpts.ntrlPerCond=[30];   % number of trials per condition
                    ClassifierOpts.StimCongruency=0; % we don't care about congruency
                    ClassifierOpts.TrialType=1; % take correct trials
                    ClassifierOpts.caxis_limits=[0.5 1];
                    ClassifierOpts.SpkCntStartFieldName='FIXATE_AQUIRED';
                    ClassifierOpts.RunCrossTemporalClassifer=0;
                    ClassifierOpts.One_Class_ResponseLbl={[2],[2]}; % compare similarity to color
                    ClassifierOpts.MeanSubtractByRule=0;
                case 'XTemp_Axis_Xgen' % Xtemporal train and test on features of the rules
                    ClassifierOpts.Name='Rule Axis Discrimination';
                    ClassifierOpts.TargetFactors= {'Axis','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1],[2],[1]},[1 2 3]};%1: axis1 2: axis 2
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1,2],[2,3]};
                    ClassifierOpts.TestCond ={[3]  ,[1]};
                    ClassifierOpts.ntrlPerCond=[30];   % number of trials per condition
                    ClassifierOpts.StimCongruency=0; % we don't care about congruency
                    ClassifierOpts.TrialType=1; % take correct trials
                    ClassifierOpts.caxis_limits=[0.5 1];
                    ClassifierOpts.SpkCntStartFieldName='FIXATE_AQUIRED';
                    ClassifierOpts.RunCrossTemporalClassifer=0;
                    ClassifierOpts.One_Class_ResponseLbl={[1],[1]}; % compare similarity to axis 1
                    ClassifierOpts.MeanSubtractByRule=0;
                case 'XTemp_Stim_Color'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Stimulus Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits='auto';
                case 'XTemp_Cat_Color'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    % ClassifierOpts.Kernel='RBF'; % try RBF kernel for this
                case 'XTemp_Cat_Shape'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Shape Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    % ClassifierOpts.Kernel='RBF'; % try RBF kernel for this
                case 'XTemp_Cat_Color_Xgen_SingML'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Color Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Cat_Color_InCorr'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination Incorr';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[1],[3]};
                    ClassifierOpts.ntrlPerCond=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=2; % take only incorrect trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'XTemp_Cat_Color_Xgen_BalRespDir'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) Use categorical
                    ClassifierOpts.Name='Cross Rule Color Category Disc BalRespDir';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 0.7];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Cat_Color_BalRespDir'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination BalRespDir';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                    %ClassifierOpts.Kernel='RBF';
                case 'XTemp_Cat_Shape_BalRespDir'  % Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Shape Category Discrimination BalRespDir';
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                    %   ClassifierOpts.Kernel='RBF';
                case 'XTemp_Cat_Color_BalRespDir_Xval'  % Xvalidate Xtemporal train and test on category of color feature for each rule
                    ClassifierOpts.Name='Color Category Discrimination BalRespDir Xval';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.Rule=[3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[3]};
                    ClassifierOpts.TestCond ={[3]};
                    ClassifierOpts.ntrlPerCond=[5 5];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.holdout_frac=0.5;
                    ClassifierOpts.CrossValidate=1;
                    %   ClassifierOpts.Kernel='RBF';
                case 'XTemp_Cat_Shape_Xgen_SingML'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) using single MLs
                    ClassifierOpts.Name='Cross Rule Shape Category Discrimination SingML';
                    ClassifierOpts.TargetFactors= {'ShapeML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Cat_Color_Xgen'   % Xtemporal train on one rule and test on the other rule Xgeneralization(Color) Use categorical
                    ClassifierOpts.Name='Cross Rule Color Category Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};%[AnalysisOpts.StimulusMorphLevels]
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[6 6];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'XTemp_Stim_Color_Xgen'   % Xtemporal train on one rule and test on the other rule Xgeneralization
                    ClassifierOpts.Name='Cross Rule Stimulus Color Discrimination';
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take only correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'ResponseLocation' % classify where the animal has responded
                    ClassifierOpts.Name='ResponseLoc Discrimination';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond={[1],[2],[3]};
                    ClassifierOpts.TestCond ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect and don't care about congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                case 'ResponseLocation_Xgen_BalCorr' % classify where the animal has responded
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorr';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[3]};%ClassifierOpts.TrainAllCombs;
                    ClassifierOpts.TestCond ={[1]};%ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.ntrlPerCondTest=[1 1];   % number of trials per condition of correct and incorrect
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect and don't care about congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                case 'ResponseLocation_Xgen_BalCong' % classify where the animal has responded
                    ClassifierOpts.Name='XRule ResponseLoc Discrimination Xgen BalCorrCong';
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'};
                    ClassifierOpts.Rule=[1 3];
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    ClassifierOpts.type='CrossCond';
                    ClassifierOpts.TrainCond={[1],[3]};
                    ClassifierOpts.TestCond ={[3],[1]};
                    %                     ClassifierOpts.Rule=[1 2 3];
                    %                     ClassifierOpts.Levels={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % for each rule test on respective axis since there very few incorrect trials on the other axis
                    %                     ClassifierOpts.type='CrossCond';
                    %                     ClassifierOpts.TrainCond=ClassifierOpts.TrainAllCombs;
                    %                     ClassifierOpts.TestCond =ClassifierOpts.TestAllCombs;
                    ClassifierOpts.ntrlPerCond=[1 1 1 1];   % number of trials per condition of correct and incorrect cong incong
                    ClassifierOpts.ntrlPerCondTest=[1 1 1 1]; % number of trials per condition of correct and incorrec cong incong
                    ClassifierOpts.StimCongruency=6; % balance correct and incorrect and congruency
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    %%%%% 2D conditions: We train on one condition first and then use the same predictors and response to test another dimension
                case '2D_Cat_Color_Shape'  % Xtemporal train and test on category of color feature for each rule double condition
                    ClassifierOpts.Name='2D_Color_Shape Category Discrimination';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorML','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ShapeML','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]};%[1 2]
                    ClassifierOpts.Levels_2ndD={[AnalysisOpts.StimulusMorphLevels],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond ={[1],[2],[3]};
                    ClassifierOpts.TrainCond2={[1],[2],[3]};
                    ClassifierOpts.TestCond  ={[1],[2],[3]};
                    ClassifierOpts.TestCond2 ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4; % balance congruency for category 1 and 2
                    ClassifierOpts.TrialType=1; % take correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[0 0 0 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[0 0 0 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                case '2D_Cat_Color_Shape_BalRespDir'  % Xtemporal train and test on category of color feature for each rule double condition balanced response direction
                    ClassifierOpts.Name='2D_Color_Shape Category Discrimination BalRespDir';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ShapeCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond ={[1],[2],[3]};
                    ClassifierOpts.TrainCond2={[1],[2],[3]};
                    ClassifierOpts.TestCond  ={[1],[2],[3]};
                    ClassifierOpts.TestCond2 ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[0 0 0 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[0 0 0 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                case '2D_Cat_Color_Resp'  % Xtemporal train and test on category of color feature for each rule double condition
                    ClassifierOpts.Name='2D_Color_Resp Category Discrimination';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type='SameCond';
                    ClassifierOpts.TrainCond ={[1],[2],[3]};
                    ClassifierOpts.TrainCond2={[1],[2],[3]};
                    ClassifierOpts.TestCond  ={[1],[2],[3]};
                    ClassifierOpts.TestCond2 ={[1],[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[0 0 0 0],[0 0 0 0],[0 0 0 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[0 0 0 0],[0 0 0 0],[0 0 0 0]};  % include all trails
                case '2D_Cat_Color_Resp_Xgen'  % Xtemporal train and test on category of color feature for each rule double condition
                    ClassifierOpts.Name='2D_Color_Resp Category Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','DoubleCrossCond','DoubleCrossCond','SameCond'};
                    ClassifierOpts.TrainCond ={[3],[3],[2],[3]};
                    ClassifierOpts.TrainCond2={[3],[3],[1],[3]};
                    ClassifierOpts.TestCond  ={[2],[1],[3],[3]};
                    ClassifierOpts.TestCond2 ={[2],[1],[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                case '2D_Cat_Color_Resp_Xgen_BalRespDir'  % Xtemporal train and test on category of color feature for each rule double condition
                    ClassifierOpts.Name='2D_Color_Resp Category Disc Xgen BalRespDir';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','DoubleCrossCond','DoubleCrossCond','SameCond'};
                    ClassifierOpts.TrainCond ={[3],[3],[2],[3]};
                    ClassifierOpts.TrainCond2={[3],[3],[1],[3]};
                    ClassifierOpts.TestCond  ={[2],[1],[3],[3]};
                    ClassifierOpts.TestCond2 ={[2],[1],[3],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                case '2D_Cat_Color_Color_Xgen'  % Train and test of category of color simoultanously for two rules
                    ClassifierOpts.Name='2D_Color_Color Category Discrimination Xgen';
                    ClassifierOpts.Rule=[2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3],[3]};
                    ClassifierOpts.TrainCond2={[2],[2]};
                    ClassifierOpts.TestCond  ={[2],[3]};
                    ClassifierOpts.TestCond2 ={[2],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                case '2D_Cat_Resp_Resp_Xgen'  % Train and test of category of color simoultanously for two rules
                    ClassifierOpts.Name='2D_Resp_Resp Category Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ResponseLoc','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels     ={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3],[3]};
                    ClassifierOpts.TrainCond2={[1],[1]};
                    ClassifierOpts.TestCond  ={[1],[3]};
                    ClassifierOpts.TestCond2 ={[1],[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=8; % balance response direction
                    ClassifierOpts.TrialType=3; % all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0],[-1 -100 100 0]}; % include all trails
                    ClassifierOpts.TestTrlNumRange ={[-1 -100 100 0],[-1 -100 100 0]};  % include all trails
                    ClassifierOpts.MeanSubtractByRule=1;
                    %% these are conditions during learning
                case 'Learning_Cat_Color_Color_Xgen'  % Train and test of category of color simoultanously for two rules
                    ClassifierOpts.Name='Learning_Color_Color Category Discrimination Xgen';
                    ClassifierOpts.Rule=[2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.Nrep=50;
                case 'Learning_Cat_Shape_Color_Xgen'  % train and test for shape(1) and color(2) and then test trials in rule 3
                    ClassifierOpts.Name='Learning_Shape_Color Category Discrimination Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=4; % balance congruency
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -100 100 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.Nrep=50;
                case 'Learning_Cat_Color_Color_Xgen_AltRule'  % Train and test of category of color simoultanously for two rules
                    ClassifierOpts.Name='Learning_Color_Color Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ColorCat','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[3]};
                    ClassifierOpts.TrainCond2={[2]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 5]};
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.Nrep=50;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.SeqHistCond={[1]}; % Seqhist value for this condition
                    
                case 'Learning_Cat_Shape_Rule_Xgen_AltRule'  % (last 50 trials only)train and test for shape(1) and Rule(1,2) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Shape_Rule Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 5]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.Nrep=50;
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                case 'Learning_Cat_Shape_Rule_Xgen_AltRule_HiPerf'  % (last 50 trials only)train and test for shape(1) and Rule(1,3) and then test trials in rule 3 with AltRule when performance at the beginning of the block is high
                    ClassifierOpts.Name='Learning_Shape_Rule Category Disc Xgen AltRule HiPerf';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[1]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 5]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.7]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'bigger'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.Nrep=50;
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    
                case 'Learning_Cat_Color_Rule_Xgen_AltRule'  % (last 50 trials only)train and test for shape(1) and Rule(1,2) and then test trials in rule 3 with AltRule
                    ClassifierOpts.Name='Learning_Color_Rule Category Disc Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'};
                    ClassifierOpts.TargetFactors_2ndD={'Rule','Rule'};
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={[1 2 3],[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2]};
                    ClassifierOpts.TrainCond2={[1,3]};
                    ClassifierOpts.TestCond  ={[3]};
                    ClassifierOpts.TestCond2 ={[3]};
                    ClassifierOpts.ntrlPerCond=[4 4];   % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];
                    ClassifierOpts.StimCongruency=10; % balance congruency and seqhist
                    ClassifierOpts.TrialType=1; % correct trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange ={[1 125 50 5]};
                    ClassifierOpts.MeanSubtractByRule=0;
                    ClassifierOpts.LimitFromSwitchPerf={[nan 0.5]}; %limits FromSwitch perfromance [TrainSet TestSet]
                    ClassifierOpts.LimitFromSwitchPerf_Operation={{nan,'smaller'}}; %what operation are we doing when we limit the performance from switch
                    ClassifierOpts.Nrep=50;
                    ClassifierOpts.SeqHistCond={[1]};             % Seqhist value for this condition
                    ClassifierOpts.One_Class_ResponseLbl={[]}; % we don't have one class classification here
                    ClassifierOpts.One_Class_ResponseLbl2={[3]};  % one class categorization label for second dimension
                    
                case 'Learning_Cat_Color_Resp_Xgen_Xtemp' % go forward from switch but do cross temporal for early and late
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen_Xtemp';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type='DoubleCrossCond';
                    ClassifierOpts.TrainCond ={[3],[3]};
                    ClassifierOpts.TrainCond2={[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[2],[2]}; % this is tested on morphlevel
                    ClassifierOpts.TestCond2 ={[1],[1]}; % this is tested on Response location
                    ClassifierOpts.ntrlPerCond=[3 3];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=4;%    Balance congruency
                    ClassifierOpts.TrialType=1; %correct trial
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[1 50 50 0],[-1 -50 50 0]};
                    ClassifierOpts.TestTrlNumRange={[-1 -50 50 0],[-1 -50 50 0]};
                    ClassifierOpts.RunCrossTemporalClassifer=1; % run these tests in cross temporal
                case 'Learning_Cat_Color_Resp_Xgen' % go forward from switch
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=4;%    Balance congruency
                    ClassifierOpts.TrialType=1; %correct trial
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                case 'Learning_Cat_Color_Resp_Xgen_SMP' % go forward from switch SAMPLE CODE to test
                    ClassifierOpts.Name='Learning Color_Resp Class XgenSMP';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=4;%    Balance congruency %balance response location
                    ClassifierOpts.TrialType=1; %correct trial %3 take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=2;
                    %  ClassifierOpts.SeqHistCond={[1],[1],[1]}; % Seqhist value for this condition
                case 'Learning_Cat_Shape_Resp_Xgen' % go forward from switch
                    ClassifierOpts.Name='Learning Shape_Resp Class Xgen';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=4;% Balance congruency
                    ClassifierOpts.TrialType=1; %correct trial
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                case 'Learning_Cat_Color_Resp_Xgen_AltRule' % go forward from switch but when the block sequence is 1 2 3 same neurons
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[4 3],[2 1]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;%   Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1; %correct trial
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[1],[1],[1]}; % Seqhist value for this condition
                case 'Learning_Cat_Color_Resp_Xgen_SameRule' % go forward from switch but when the block sequence is 3 2 3(same Neurons)
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen SameRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[4 3],[2 1]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;    %Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1;          %correct trial %3 take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[0],[0],[0]}; % Seqhist value for this condition
                case 'Learning_Cat_Color_Resp_Xgen_AltRule150' % go forward from switch but when the block sequence is 1 2 3 same neurons
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen AltRule150';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[4 3],[2 1]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;%   Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1; %correct trial
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 150 50 10] ,[1 150 50 10]};
                    ClassifierOpts.TestTrlNumRange ={[1 150 50 10] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[1],[1],[1]}; % Seqhist value for this condition
                case 'Learning_Cat_Color_Resp_Xgen_SameRule150' % go forward from switch but when the block sequence is 3 2 3(same Neurons)
                    ClassifierOpts.Name='Learning Color_Resp Class Xgen SameRule150';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[4 3],[2 1]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;    %Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1;          %correct trial %3 take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 150 50 10] ,[1 150 50 10]};
                    ClassifierOpts.TestTrlNumRange ={[1 150 50 10] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[0],[0],[0]}; % Seqhist value for this condition
                case 'Learning_Cat_Shape_Resp_Xgen_AltRule' % go forward from switch but when the block sequence is 1 2 3 same neurons
                    ClassifierOpts.Name='Learning Shape_Resp Class Xgen AltRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;    %Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1; %correct trial %3 take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[1],[1],[1]}; % Seqhist value for this condition
                case 'Learning_Cat_Shape_Resp_Xgen_SameRule' % go forward from switch but when the block sequence is 3 2 3(same Neurons)
                    ClassifierOpts.Name='Learning Shape_Resp Class Xgen SameRule';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ShapeCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type={'DoubleCrossCond','SameCond','DoubleCrossCond'};
                    ClassifierOpts.TrainCond ={[2],[3],[3]}; % train on ColorCat
                    ClassifierOpts.TrainCond2={[1],[3],[3]}; % train on ResponseLoc
                    ClassifierOpts.TestCond  ={[3],[3],[2]}; % Test on ColorCat
                    ClassifierOpts.TestCond2 ={[3],[3],[1]}; % Test on ResponseLoc
                    ClassifierOpts.ntrlPerCond=[4 4];    % number of trials per condition of congruency
                    ClassifierOpts.ntrlPerCondTest=[1 1];% number of trials per condition of congruency for test
                    ClassifierOpts.StimCongruency=10;    %Balance congruency  and SeqHist
                    ClassifierOpts.TrialType=1; %correct trial %3 take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -50 50 0],[1 100 50 5] ,[1 100 50 5]};
                    ClassifierOpts.TestTrlNumRange ={[1 100 50 5] ,[-1 -50 50 0],[-1 -50 50 0] };
                    ClassifierOpts.SpkCountPeriod=[0.1 0.4;0.3 0.6]; % spike count time period for sensory and response
                    ClassifierOpts.Nrep=100;
                    ClassifierOpts.SeqHistCond={[0],[0],[0]}; % Seqhist value for this condition
                case 'Learning_Cat_Color_Resp_Xgen_Rev' % go back from switch
                    ClassifierOpts.Name='Learning Color_Resp Cat Classification Xgen Rev';
                    ClassifierOpts.Rule=[1 2 3];
                    ClassifierOpts.TargetFactors= {'ColorCat','Rule'}; % ColorML can be used if we have enough trails
                    ClassifierOpts.TargetFactors_2ndD={'ResponseLoc','Rule'}; % target factor for the second dimension
                    ClassifierOpts.Levels={[1 2],[ClassifierOpts.Rule]};
                    ClassifierOpts.Levels_2ndD={{[1 2],[3 4],[1 2]},[ClassifierOpts.Rule]}; % second dimension levels
                    ClassifierOpts.type='DoubleCrossCond';
                    ClassifierOpts.TrainCond={[3]};
                    ClassifierOpts.TestCond ={[2]}; % this is tested on morphlevel
                    ClassifierOpts.TestCond2={[1]}; % this is tested on Response location
                    ClassifierOpts.ntrlPerCond=[2 2];   % number of trials per condition of congruency
                    ClassifierOpts.StimCongruency=7; % balance correct and incorrect trials
                    ClassifierOpts.TrialType=3; % take all trials
                    ClassifierOpts.caxis_limits=[0.3 1];
                    ClassifierOpts.MeanSubtractByRule=1;
                    ClassifierOpts.TrainTrlNumRange={[-1 -150 50 5]};
                    ClassifierOpts.TestTrlNumRange={[-1 -50 50 0]};
            end
            nConds=length(ClassifierOpts.TrainCond);
            % fill some missing variables
            if sum(ClassifierOpts.ntrlPerCond)~=(ClassifierOpts.ntrlPerCond(1)*length(ClassifierOpts.ntrlPerCond))
                error('number of trials/condition must be equal')
            end
            if ~isfield(ClassifierOpts,'TrainTrlNumRange')
                ClassifierOpts.TrainTrlNumRange=repmat({[0 0 0 0]},[1 nConds]); % include all trails
                ClassifierOpts.TestTrlNumRange =repmat({[0 0 0 0]},[1 nConds]); % include all trails
            end
            ClassifierOpts.RunCrossTemporalClassifer=obj.RunCrossTemporalClassifer;
            NConds=length(ClassifierOpts.TrainCond);
            if ~isfield(ClassifierOpts,'ntrlPerCondTest');ClassifierOpts.ntrlPerCondTest=ceil(ClassifierOpts.ntrlPerCond/2);end
            % update obj.SpkCountPeriod if we have values in ClassifierOpts.SpkCountPeriod
            if ~isfield(ClassifierOpts,'SpkCountPeriod');ClassifierOpts.SpkCountPeriod=[];end
            % update one-class response label for both dimensions
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl');ClassifierOpts.One_Class_ResponseLbl=cell(1,NConds);end
            if ~isfield(ClassifierOpts,'One_Class_ResponseLbl2');ClassifierOpts.One_Class_ResponseLbl2=cell(1,NConds);end
            % if we are running cross temporal then change file name
            if obj.RunCrossTemporalClassifer==1;ClassifierOpts.Nrep=50;ClassifierOpts.Name=[ClassifierOpts.Name '_XTMP'];end
            % if we have mean subtracted each rule then show it
            if ClassifierOpts.MeanSubtractByRule==1;ClassifierOpts.Name=[ClassifierOpts.Name '_MS'];end
            % if we have zscore and detrend the data then add it to the name
            if obj.ZscoreFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_ZS'];end
            % if we have detrended the data then add it to the name
            if obj.DetrendFactorData==1;ClassifierOpts.Name=[ClassifierOpts.Name '_DT'];end
        end
        function Tasks2Compare=ClassifierComparisionOpts(obj,ComparisonName,varargin) % prepare options for classifier comparisions
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            Tasks2Compare.ComparisonName=ComparisonName;
            SpkCntStartFieldName=@(x) arrayfun(@(x) AnalysisOpts.SpkCntStartFieldName,1:x,'UniformOutput',0);
            
            %  ClassifierOpts.TrainCond={[1],[3]};
            %  ClassifierOpts.TestCond ={[3],[1]};
            Tasks2Compare.TrainAllCombs={[1],[2],[3],[2],[3],[1]};
            Tasks2Compare.TestAllCombs ={[2],[3],[1],[1],[2],[3]};
            Tasks2Compare.AllCombPlotPair={[1 4],[2 5],[3 6]}; %pairs of conditions to be plotted together
            Tasks2Compare.AllCombPlotPair_Col_Rep={[2 1],[5 2],[1 1]}; %pairs of conditions to be plotted together for color and response
            Tasks2Compare.AllCombPlotPair_Shap_Rep={[1 1],[6 1],[1 1]}; %pairs of conditions to be plotted together for color and response
            Tasks2Compare.AllCombPlotTriple={[1 1 4],[2 2 5],[3 3 6]}; %triple of conditions to be plotted together
            Tasks2Compare.PlotCombs3D={[1 1;1 2;1 3],[2 1;2 2],[2 3;3 2],[3 1;3 3]}; % Dim/Cond for 3D conditions

            Tasks2Compare.Area2Look=AnalysisOpts.AreaNames;
            nArea=length(Tasks2Compare.Area2Look);
            Tasks2Compare.NormalizebyMax=0; % are we normalizing by max
            Tasks2Compare.MeanStdPlotType=3*ones(1,10);% just plot by line
            Tasks2Compare.TimeStrStp={AnalysisOpts.CurrentAxisLimits(AnalysisOpts)};
            switch ComparisonName
                %% Summery of all of the areaas together for each analysis in 3D
                case '3D_Cat_Color_Area_Summery'
                    Tasks2Compare.MainTasks={'3D_Color_Cat_Xgen'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.PlotCombs3D;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case '3D_Cat_Color_Response_Compare' % superimpose color and response
                    Tasks2Compare.MainTasks={'3D_Color_Response_XgenBalInCongV5','3D_Color_Response_XgenBalInCongV5'};
                    Tasks2Compare.Area2Look=AnalysisOpts.AreaNames(1); % look at PFC only for this 
                    nArea=length(Tasks2Compare.Area2Look);
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1 6;1 6],[3 6;3 6]};% look at shared color and shared response 
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];    
                    Tasks2Compare.NormalizebyMax=[1 1];
                    Tasks2Compare.MeanStdPlotType=[3 1];
                    Tasks2Compare.TimeStrStp={[AnalysisOpts.PaperSpec.StrTime_SAMPLE_ON AnalysisOpts.PaperSpec.EndTime_SAMPLE_ON],...
                        [0.175 0.5]};
                case '3D_Cat_Color_XgenCol_Compare' % Compare color encodin and cross rule color encoding
                    Tasks2Compare.MainTasks={'3D_Color_Response_XgenBalInCongV2','3D_Color_Response_XgenBalInCongV2'};
                    Tasks2Compare.Area2Look=AnalysisOpts.AreaNames(1:5); % look at PFC only for this 
                    nArea=length(Tasks2Compare.Area2Look);
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[3 6;3 6],[3 2;3 2]};% look at shared color and same task color ( Trn2/Tst3 -> Trn3/Tst3) Dim 3 is correct only, Dim 2 is correctincorrect
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];    
                    Tasks2Compare.NormalizebyMax=[1 0];
                    Tasks2Compare.MeanStdPlotType=[3 1];
                    Tasks2Compare.TimeStrStp={[AnalysisOpts.PaperSpec.StrTime_SAMPLE_ON AnalysisOpts.PaperSpec.EndTime_SAMPLE_ON]};    
                case '3D_Response_XgenResponse_Compare' % Compare response encodin and cross rule response encoding
%                      ClassifierOpts.TrainCond ={[1],[3],[1],[3],[3],[1]};
%                     ClassifierOpts.TrainCond2={[3],[3],[1],[3],[3],[3]};
%                     ClassifierOpts.TrainCond3={[3],[3],[1],[3],[3],[2]};
%                     ClassifierOpts.TestCond  ={[1],[3],[2],[2],[1],[3]};
%                     ClassifierOpts.TestCond2 ={[1],[3],[2],[2],[1],[3]};
%                     ClassifierOpts.TestCond3 ={[1],[3],[2],[2],[1],[3]};
                    Tasks2Compare.MainTasks={'3D_Color_Response_XgenBalInCongV2','3D_Color_Response_XgenBalInCongV2'};
                    Tasks2Compare.Area2Look=AnalysisOpts.AreaNames(1:5); % look at PFC only for this 
                    nArea=length(Tasks2Compare.Area2Look);
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1 6;1 6],[1 2;1 2]};% look at shared color and same task color ( Trn2/Tst3 -> Trn3/Tst3) Dim 3 is correct only, Dim 2 is correctincorrect
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];    
                    Tasks2Compare.NormalizebyMax=[1 0];
                    Tasks2Compare.MeanStdPlotType=[3 1];
                    Tasks2Compare.TimeStrStp={[AnalysisOpts.PaperSpec.StrTime_SAMPLE_ON AnalysisOpts.PaperSpec.EndTime_SAMPLE_ON]};       
                %% Summery of all of the areaas together for each analysis
                case 'Cat_Color_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Cat_Color_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color','XTemp_Cat_Color_Xgen_SingML','XTemp_Cat_Color_Xgen_SingML'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Cat_Abstract_Color_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color','XTemp_Abstract_Color_Xgen_SingML','XTemp_Abstract_Color_Xgen_SingML'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];                   
                case 'Cat_Color_BalRespDir_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color_BalRespDir'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Cat_Color_Xgen_BalRespDir_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color_BalRespDir','XTemp_Cat_Color_Xgen_BalRespDir','XTemp_Cat_Color_Xgen_BalRespDir'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Cat_Shape_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Shape'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Cat_Shape_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Shape','XTemp_Cat_Shape_Xgen_SingML','XTemp_Cat_Shape_Xgen_SingML'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Stim_Color_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Stim_Color'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Stim_Color_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Stim_Color','XTemp_Stim_Color_Xgen','XTemp_Stim_Color_Xgen'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Stim_Shape_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Stim_Shape'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'Stim_Shape_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Stim_Shape','XTemp_Stim_Shape_Xgen','XTemp_Stim_Shape_Xgen'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotTriple;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'AllObjs_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_AllObjects'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    %% Look at response encoing and Xgeneralization of response
                case 'Resp_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'ResponseLocation_BalCorr','ResponseLocation_Xgen_BalCorr','ResponseLocation_Xgen_BalCong'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1 1 1],[2 1 1],[3 2 2]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=0; % are we normalizing by max
                    %% look at summery fo areas comparing color and shape timing and response
                case 'Col_Resp_Xgen_BalCong_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color_Xgen_SingML','ResponseLocation_Xgen_BalCong'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotPair_Col_Rep;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=1; % are we normalizing by max
                case 'Shape_Resp_Xgen_BalCong_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Shape_Xgen_SingML','ResponseLocation_Xgen_BalCong'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotPair_Shap_Rep;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=1; % are we normalizing by max
                case 'Col_Resp_Xgen_BalCorr_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Color_Xgen_SingML','ResponseLocation_Xgen_BalCorr'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotPair_Col_Rep;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=1; % are we normalizing by max
                case 'Shape_Resp_Xgen_BalCorr_Area_Summery'
                    Tasks2Compare.MainTasks={'XTemp_Cat_Shape_Xgen_SingML','ResponseLocation_Xgen_BalCorr'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond=Tasks2Compare.AllCombPlotPair_Shap_Rep;
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=1; % are we normalizing by max
                    %% simoultanous comparision of timing between color and response
                case 'Learning_Cat_Color_Resp_Xgen_Area_Summery' % simoultanously look at response and color encoding
                    Tasks2Compare.Area2Look={'PFC'}; % looking at PFC for now
                    nArea=1;
                    Tasks2Compare.MainTasks={'Learning_Cat_Color_Resp_Xgen'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1 1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    Tasks2Compare.NormalizebyMax=0; % are we normalizing by max
                    Tasks2Compare.Dimension={[1 2]}; % which dimension of the classifier we are looking at
                    %% comapre fine tune conditions
                case 'FineTune_Cat_Color_Xgen_Area_Summery'
                    Tasks2Compare.MainTasks={'FineTune_Cat_Color_Xgen'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3],[4],[5]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'FineTune_Stim_Color_Area_Summery'
                    Tasks2Compare.MainTasks={'FineTune_Stim_Color'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3],[4],[5]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                case 'FineTune_Stim_Color_Kernel_Area_Summery'
                    Tasks2Compare.MainTasks={'FineTune_Stim_Color_Kernel'};
                    Tasks2Compare.nMainTasks=length(Tasks2Compare.MainTasks);
                    Tasks2Compare.TaskInd=repmat(Tasks2Compare.MainTasks,[1 nArea]);
                    Tasks2Compare.Cond={[1],[2],[3],[4]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(nArea*Tasks2Compare.nMainTasks);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 nArea*Tasks2Compare.nMainTasks]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=arrayfun(@(x) repmat(Tasks2Compare.Area2Look(x),[1 Tasks2Compare.nMainTasks]),1:nArea,'UniformOutput' ,0);
                    Tasks2Compare.Area=[Tasks2Compare.Area{:}];
                    %% Individual conditions
                case 'Xgen_Col_Resp_BalCong' % compare cross generalization in color R3/2 and response R3/1 BalCong
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen_SingML','ResponseLocation_Xgen_BalCong'};
                    Tasks2Compare.Cond={[2],[1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                    
                case 'Xgen_Col_Resp_BalCorr' % compare cross generalization in color R3/2 and response R3/1
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen_SingML','ResponseLocation_Xgen_BalCorr'};
                    Tasks2Compare.Cond={[2],[1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                    
                case 'Xgen_ColBalRespDir_Resp_BalCong' % compare cross generalization in color R3/2 and response R3/1 when color is balanced response dir
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen_BalRespDir','ResponseLocation_Xgen_BalCong'};
                    Tasks2Compare.Cond={[2],[1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                    
                case 'Xgen_Col_Learning' % compare cross generalization of color
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen','XTemp_Cat_Color_Xgen'};
                    Tasks2Compare.Cond={[3],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'FromSwitch','ToSwitch'};
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                case 'Xgen_Col_Shp_Resp'
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen_SingML','ResponseLocation_Xgen_BalCorr','XTemp_Cat_Shape_Xgen'};
                    Tasks2Compare.Cond={[1],[2],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(3);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                    % plot 2D comparisions now
                case '2D_Cat_Color_Shape'
                    Tasks2Compare.TaskInd={'2D_Cat_Color_Shape','2D_Cat_Color_Shape'};
                    Tasks2Compare.Cond={[3],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'FromSwitch','ToSwitch'};
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                case '2D_Cat_Color_Resp'
                    Tasks2Compare.TaskInd={'2D_Cat_Color_Resp','2D_Cat_Color_Resp'};
                    Tasks2Compare.Cond={[2],[2]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'FromSwitch','ToSwitch'};
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                case '2D_Cat_Color_Resp_Xgen'
                    Tasks2Compare.TaskInd={'2D_Cat_Color_Resp_Xgen','2D_Cat_Color_Resp_Xgen'};
                    Tasks2Compare.Cond={[1],[1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'FromSwitch','ToSwitch'};
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                    %% compare timing between areas
                case 'Xgen_Cat_Color_Area' % compare cross generalization in color R3/2  between areas
                    Tasks2Compare.TaskInd=repmat({'XTemp_Cat_Color_Xgen_SingML'},[1 5]);
                    Tasks2Compare.Cond={[3],[3],[3],[3],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(5);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 5]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=AnalysisOpts.AreaNames;
                case 'Xgen_Resp_Area' % compare cross generalization in color R3/2 and response R3/1
                    Tasks2Compare.TaskInd=repmat({'ResponseLocation_Xgen_BalCorr'},[1 5]);
                    Tasks2Compare.Cond={[4],[4],[4],[4],[4]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(5);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 5]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=AnalysisOpts.AreaNames;
                case 'Cat_Color_Area'
                    Tasks2Compare.TaskInd=repmat({'XTemp_Cat_Color'},[1 5]);
                    Tasks2Compare.Cond={[3],[3],[3],[3],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(5);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 5]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=AnalysisOpts.AreaNames;
                case 'ResponseLocation_Area'
                    Tasks2Compare.TaskInd=repmat({'ResponseLocation'},[1 5]);
                    Tasks2Compare.Cond={[2],[2],[2],[2],[2]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(5);
                    Tasks2Compare.TrlSpkTimeFieldName=repmat({'AllTrials'},[1 5]);
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area=AnalysisOpts.AreaNames;
                    
                    %% compare cross rule generalization in color and response between areas
                case 'Xgen_Index_Color' % color generalization ability
                    Tasks2Compare.TaskInd={'XTemp_Cat_Color_Xgen_SingML','XTemp_Cat_Color'};
                    Tasks2Compare.Cond={[5],[3]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
                case 'Xgen_Index_Resp' % Resp generalization ability
                    Tasks2Compare.TaskInd={'ResponseLocation_Xgen_BalCorr','ResponseLocation_BalCorr'};
                    Tasks2Compare.Cond={[1],[1]};
                    Tasks2Compare.SpkCntStartFieldName=SpkCntStartFieldName(2);
                    Tasks2Compare.TrlSpkTimeFieldName={'AllTrials','AllTrials'};
                    Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
                    Tasks2Compare.Area={AnalysisOpts.Area2look{1},AnalysisOpts.Area2look{1}};
            end
            Tasks2Compare.NComparisons=length(Tasks2Compare.TaskInd);
        end
        function [ClassifierResults,ClassifierOpts]=RunCrossTemporalClassiferAnalysis(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % if this is a calculation of shuffled distribution then
            % prepare the data
            [ShuffTxt,CondSet,TrlRngSet,RepSet]=obj.ReadClassifierSpockRunConds(ClassifierOpts);

            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);
            
            % before starting the analysis count the number of necessary conditions per neurons
            % and limit the neurons based on what we want
            [FactorData,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            FactorDataBuff=FactorData;
            % now get the classifer performance per crosstime point
            
            for nCond=1:length(CondSet)% loop on conditions
                Cond=CondSet(nCond);
                               
                % get trial range data for this
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                if nXTrlPnt>1;error('Use learning algorithm for moving trials');end
                ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(1)};
                ThisTestTrialRange=TestTrlRange{TestTrlInd(1)};
                
                % now limit factor data trials to these trial range we want
                % generate factor data for training
                FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                % generate factordata for testing
                FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
                FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
                if isfield(ClassifierOpts,'MaxMatchTrialConds')
                    obj.MaxMatchTrialConds=ClassifierOpts.MaxMatchTrialConds(Cond);
                end
                if obj.MaxMatchTrialConds==0;warning('MaxMatch condition is turned off');end
                
                for rep=1:ClassifierOpts.Nrep        % loop on repetition per condition
                    tic
                    fprintf('\nTrain/Testing %sClassfier on Condition Train:%s | Test:%s Rep:%i',ShuffTxt,obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),rep)
                    % if this is a shuffled test then permute the labels of training set
                    if obj.CalShuff
                        % grab random set of data
                        [predictors,response,TrainDataAllFactors,TestDataAllFactors]=obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,...
                            FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'MaxMatchTrialConds',obj.MaxMatchTrialConds);
                        response{1}=response{1}(randperm(numel(response{1})));
                    else
                        % grab random set of data
                        [predictors,response,TrainDataAllFactors,TestDataAllFactors]=...
                            obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'MaxMatchTrialConds',obj.MaxMatchTrialConds);
                        % calculate intrinsic dimensionality of train and test data combined as well
                        %  ClassifierResults(nCond).Rep(rep).no_IDdims=obj.CalculateIntrinsicDimensionality(cat(1,predictors{1},predictors{2}),'PCAExpVar');
                        % keep some data 
                        %  ClassifierResults(nCond).Rep(rep).TrainDataAllFactors=TrainDataAllFactors;
                        ClassifierResults(nCond).TrialRange.Rep(rep).TestDataAllFactors=TestDataAllFactors(:,FactorInds2Keep);             
                    end
                    
                    % if we are changing the distribution of train
                    % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)                      
                    [TrainDataAllFactors,~,~,TestDataAllFactors,~,~,predictors,~,~,response,~,~]= ...
                        obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                        TrainDataAllFactors,[],[],TestDataAllFactors,[],[],...
                        predictors,[],[],response,[],[],1);
                            
                    if ~ClassifierOpts.RunCrossTemporalClassifer
                        % train and test classifier on different time points
                        [ClassifierResults(nCond).TrialRange.Rep(rep).Observed,~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                            response,ClassifierOpts,'ThisClassifierCond',Cond),1:nXtimePnt,'UniformOutput',0);
                        ClassifierOpts=ClassifierOpts{1};
                    else % if we are running a cross temporal classificaiton then train on one point and test it on the rest
                        ClassifierResults(nCond).TrialRange.Rep(rep).Observed=cell(1,nXtimePnt);
                        for tTrain=1:TimeMatrixSize(1)
                            [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,tTrain)}],response,ClassifierOpts,'ThisClassifierCond',Cond);
                            % test this classifier on all of the time
                            % points of test
                            IndThisConds=arrayfun(@(x) find(TrainTimInd==tTrain & TestTimInd==x),1:TimeMatrixSize(2));
                            [ClassifierResults(nCond).TrialRange.Rep(rep).Observed(IndThisConds),~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,x)}],...
                                response,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                            ClassifierOpts=ClassifierOpts{1};
                        end
                    end
                    % copy data
                    %  ClassifierResults(nCond).Rep(rep).trainingPredictors   = predictors{1};
                    %  ClassifierResults(nCond).Rep(rep).trainingResponse     = response{1};
                    %  ClassifierResults(nCond).Rep(rep).validationPredictors = predictors{2};
                    %  ClassifierResults(nCond).Rep(rep).validationResponse   = response{2};
                    fprintf(' Elapsed Time:%0.2f',toc);
                end
            end
            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            % save off the variables
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',...
                ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',...
                ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedDate','ALL');
            
        end
        function [ClassifierResults,ClassifierOpts]=Run2DCrossTemporalClassiferAnalysis(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis for 2 simultanous features
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % now create a mesh of time points and run classifier train and test repectively
            NTim=length(AnalysisOpts.Time);
            % check if we are running a cross temporal analysis or single time analysis
            if ClassifierOpts.RunCrossTemporalClassifer==1 % prepare for a cross temporal classifier analysis
                TimeMatrixSize=[NTim NTim];
                [TrainTimInd,TestTimInd]=ind2sub(TimeMatrixSize,1:NTim^2);
                nXtimePnt=NTim^2;
            elseif ClassifierOpts.RunCrossTemporalClassifer==0
                TimeMatrixSize=[1 NTim];
                TrainTimInd=1:NTim;
                TestTimInd=1:NTim;
                nXtimePnt=NTim;
            end
            ClassifierOpts.TimeMatrixSize=TimeMatrixSize;
            % get a waitbar
            % f = waitbar(0,'','Name','Training/Testing SVM Classifier...');
            
            % now get the classifer performance per crosstime point
            for Cond=1:length(ClassifierOpts.TrainCond) % loop on conditions
                for rep=1:ClassifierOpts.Nrep        % loop on repetition per condition
                    %    waitbar(rep/ClassifierOpts.Nrep,f,sprintf('repetition:%i',rep))
                    fprintf('\nTrain/Testing Classfier on Condition Train:%s | Test:%s Rep:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),rep);
                    isok=0;
                    while isok==0 % make sure we have enough trials for both categories in both dimensions
                        % grab random set of data
                        [predictors,response,ClassifierResults(Cond).Rep(rep).TrainDataAllFactors,ClassifierResults(Cond).Rep(rep).TestDataAllFactors]=...
                            obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond);
                        
                        % now get train/test data on the second factor as well
                        TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
                        DataLabels_Train_2ndD=ClassifierResults(Cond).Rep(rep).TrainDataAllFactors(:,TargetFactors_2ndDInd);
                        DataLabels_Test_2ndD =ClassifierResults(Cond).Rep(rep).TestDataAllFactors(:,TargetFactors_2ndDInd);
                        if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                            DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                            DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                        end
                        response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                        if iscell(ClassifierOpts.Levels_2ndD{1})
                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond{Cond}==ClassifierOpts.Levels_2ndD{2}};
                            Levels_2ndD_Test=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond{Cond}==ClassifierOpts.Levels_2ndD{2}};
                        else
                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                            Levels_2ndD_Test=ClassifierOpts.Levels_2ndD{1};
                        end
                        if length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 | ...
                                ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))
                            isok=0;
                        else
                            isok=1;
                        end
                    end
                    % train and test classifier on different time points
                    [ClassifierResults(Cond).Rep(rep).Observed,~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                        response,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                    ClassifierOpts=ClassifierOpts{1};
                    
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(Cond).Rep(rep).Observed_2ndD] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                        response_2ndD,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                    
                    % copy train/test data
                    ClassifierResults(Cond).Rep(rep).trainingPredictors   = predictors{1};
                    ClassifierResults(Cond).Rep(rep).trainingResponse     = response{1};
                    ClassifierResults(Cond).Rep(rep).validationPredictors = predictors{2};
                    ClassifierResults(Cond).Rep(rep).validationResponse   = response{2};
                    
                    % calculate intrinsic dimensionality of train and test data combined as well
                    ClassifierResults(Cond).Rep(rep).no_IDdims=obj.CalculateIntrinsicDimensionality(cat(1,predictors{1},predictors{2}),'PCAExpVar');
                end
            end
            % save off the variables
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',...
                ['_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',...
                ['_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'WantedDate','ALL');
        end
        function [ClassifierResults,ClassifierOpts]=Run2DCrossTemporalClassiferAnalysis_DoubleCrossCond(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis for 2 simultanous features in two different cross conditions
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % now create a mesh of time points and run classifier train and test repectively
            NTim=length(AnalysisOpts.Time);
            % check if we are running a cross temporal analysis or single time analysis
            if ClassifierOpts.RunCrossTemporalClassifer==1 % prepare for a cross temporal classifier analysis
                TimeMatrixSize=[NTim NTim];
                [TrainTimInd,TestTimInd]=ind2sub(TimeMatrixSize,1:NTim^2);
                nXtimePnt=NTim^2;
            elseif ClassifierOpts.RunCrossTemporalClassifer==0
                TimeMatrixSize=[1 NTim];
                TrainTimInd=1:NTim;
                TestTimInd=1:NTim;
                nXtimePnt=NTim;
            end
            ClassifierOpts.TimeMatrixSize=TimeMatrixSize;
            % get a waitbar
            % f = waitbar(0,'','Name','Training/Testing SVM Classifier...');
            
            % now get the classifer performance per crosstime point
            for Cond=1:length(ClassifierOpts.TrainCond) % loop on conditions
                for rep=1:ClassifierOpts.Nrep        % loop on repetition per condition
                    %    waitbar(rep/ClassifierOpts.Nrep,f,sprintf('repetition:%i',rep))
                    fprintf('\nTrain/Testing Classfier on Condition Train:%s | Test1:%s | Test2:%s Rep:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),rep);
                    isok=0;
                    while isok==0 % make sure we have enough trials for both categories in both dimensions
                        % grab random set of data
                        [predictors,response,ClassifierResults(Cond).Rep(rep).TrainDataAllFactors,~]=...
                            obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond);
                        % grab a second set of random data we will use the
                        % test data of this set of the second dimension but
                        % keep the training data from first set
                        [predictors2,response2,~,ClassifierResults(Cond).Rep(rep).TestDataAllFactors]=...
                            obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond);
                        
                        % now get train/test data on the second factor as well
                        TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
                        DataLabels_Train_2ndD=ClassifierResults(Cond).Rep(rep).TrainDataAllFactors(:,TargetFactors_2ndDInd);
                        DataLabels_Test_2ndD =ClassifierResults(Cond).Rep(rep).TestDataAllFactors(:,TargetFactors_2ndDInd);
                        if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                            DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                            DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                        end
                        response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                        
                        if iscell(ClassifierOpts.Levels_2ndD{1})
                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond{Cond}==ClassifierOpts.Levels_2ndD{2}};
                            Levels_2ndD_Test=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                        else
                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                            Levels_2ndD_Test=ClassifierOpts.Levels_2ndD{1};
                        end
                        if length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 | ...
                                ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))
                            isok=0;
                        else
                            isok=1;
                        end
                    end
                    
                    % train and test classifier on different time points
                    [ClassifierResults(Cond).Rep(rep).Observed,~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                        response,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                    ClassifierOpts=ClassifierOpts{1};
                    
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(Cond).Rep(rep).Observed_2ndD] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors2{2}(:,:,TestTimInd(x))}],...
                        response_2ndD,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                    
                    % copy train/test data
                    ClassifierResults(Cond).Rep(rep).trainingPredictors   = predictors{1};
                    ClassifierResults(Cond).Rep(rep).trainingResponse     = response{1};
                    ClassifierResults(Cond).Rep(rep).validationPredictors = predictors{2};
                    ClassifierResults(Cond).Rep(rep).validationResponse   = response{2};
                    
                    % calculate intrinsic dimensionality of train and test data combined as well
                    ClassifierResults(Cond).Rep(rep).no_IDdims=obj.CalculateIntrinsicDimensionality(cat(1,predictors{1},predictors{2}),'PCAExpVar');                   
                end
            end
            % save off the variables
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',...
                ['_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',...
                ['_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName],'WantedDate','ALL');
        end        
        function SweepClassifierConditions(obj,FactorData,ClassifierOpts,FactorLevelComb,varargin)% sweeps values for classifer conditions
             global AnalysisOpts
             obj=obj.ParseParams(varargin) ; %%Process optional inputs
             
             RepPerCondfunc=@(nrep,x) repmat({nrep*ones(1,size(x{1},2))},[1,3]);
             NConds=ClassifierOpts.NConds;
             % if we have many trials then change the condtion
             ntrlPerCond=ClassifierOpts.ntrlPerCond{1}(1);     
             if ntrlPerCond~=1
                 ntrlPerCondSet=[ntrlPerCond-1 ntrlPerCond ntrlPerCond+1 ntrlPerCond+2];
             elseif ntrlPerCond==1
                 ntrlPerCondSet=[1 2 3 4];  
             end
             % if we are processing learning conditions 
             if contains(ClassifierOpts.Name,'Learning')
                 % set the sweep conidions based on learning or non learning condition
                 TestTrlNumRangeSet =[30:10:50];%[50 -50];
                 TrainTrlNumRangeSet=[50 75];   % 50 75 100             
                 ntrlPerCondSet=[2 3 4];
                 for cond=1:NConds
                     if strcmp(ClassifierOpts.LimitFromSwitchPerf_Operation{cond}{2},'smaller')
                         LimitFromSwitchPerfSet{cond}=[0.4 0.45 0.5];
                     elseif  strcmp(ClassifierOpts.LimitFromSwitchPerf_Operation{cond}{2},'bigger')
                         LimitFromSwitchPerfSet{cond}=[0.7 0.6 0.5];
                     else
                         LimitFromSwitchPerfSet{cond}=nan;
                     end
                 end
             else 
                 TestTrlNumRangeSet=nan;
                 TrainTrlNumRangeSet=nan;
                 LimitFromSwitchPerfSet={[nan]};
             end
                             
             s=1;
             for TestTrlNumRange=TestTrlNumRangeSet
                 for TrainTrlNumRange=TrainTrlNumRangeSet
                     for ntrlPerCond=ntrlPerCondSet
                         for LimitFromSwitchPerf=1:length(LimitFromSwitchPerfSet{1})
                             ClassifierOpts.ntrlPerCond=RepPerCondfunc(ntrlPerCond,ClassifierOpts.ntrlPerCond);   % number of trials per condition of congruency                           
                            
                             if ~isnan(TrainTrlNumRange)
                                 ClassifierOpts.LimitFromSwitchPerf=arrayfun(@(x) [nan,LimitFromSwitchPerfSet{x}(LimitFromSwitchPerf)],1:NConds,'UniformOutput',0); %limits FromSwitch perfromance [TrainSet TestSet]
                                 ClassifierOpts.TrainTrlNumRange=repmat({[-1 -1*TrainTrlNumRange TrainTrlNumRange 0]},[1 NConds]);
                                 if TestTrlNumRange>0 % test from biginning of the block
                                     ClassifierOpts.TestTrlNumRange =repmat({[1 125 TestTrlNumRange ClassifierOpts.NTrlStpLearning(AnalysisOpts.AreaNum)]},[1 NConds]);
                                 elseif TestTrlNumRange<0 % test from end of the block
                                     ClassifierOpts.TestTrlNumRange =repmat({[-1 -125 TestTrlNumRange ClassifierOpts.NTrlStpLearning(AnalysisOpts.AreaNum)]},[1 NConds]);
                                 end
                             end
                             
                             %% run algorithm now
                             fprintf(2,'\nSweeping conditions for %s Area:%s \nLimitFromSwitchPerf:%0.2f,TestTrlNumRange:%i,TrainTrlNumRange:%i,ntrlPerCond:%i',...
                                 ClassifierOpts.Name,AnalysisOpts.CurrentCh_AreaName,LimitFromSwitchPerf,TestTrlNumRange,TrainTrlNumRange,ntrlPerCond);
                             obj.TrialFunc.RevertCh_2look;
                             [~,~,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
                            % fill in the data  
                             NeuronStats_Sweep(s).TestTrlNumRange=TestTrlNumRange;
                             NeuronStats_Sweep(s).TrainTrlNumRange=TrainTrlNumRange;
                             NeuronStats_Sweep(s).ntrlPerCond=ntrlPerCond;
                             NeuronStats_Sweep(s).IncludedNeu4Ana_Num=ClassifierOpts.IncludedNeu4Ana_Num; 
                             NeuronStats_Sweep(s).IncludedNeu4Ana_Num_Silas=ClassifierOpts.IncludedNeu4Ana_AnimalNum(1);
                             NeuronStats_Sweep(s).IncludedNeu4Ana_Num_Chico=ClassifierOpts.IncludedNeu4Ana_AnimalNum(2); 
                             if ~isnan(TrainTrlNumRange)
                                 NeuronStats_Sweep(s).LimitFromSwitchPerf=arrayfun(@(x) LimitFromSwitchPerfSet{x}(LimitFromSwitchPerf),1:NConds,'UniformOutput',1); %limits FromSwitch perfromance [TrainSet TestSet]
                             else
                                 NeuronStats_Sweep(s).LimitFromSwitchPerf=LimitFromSwitchPerf;
                             end
                             s=s+1;
                         end
                     end
                 end
             end
             % save the data now
             obj.ManData.SaveVar('Classifier',NeuronStats_Sweep,['Test_' ClassifierOpts.TestName],...
                 ['_ParamSweep_' AnalysisOpts.CurrentCh_AreaName],'WantedDate','ALL'); 
            
        end
        function CollectTableClassifierSweepParam(obj,TestName,varargin)% saves data for sweep param in a table for all areas
            % TestName is the cell array of desired classifier test
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            for t=1:length(TestName) %loop on test 
                for Ar=1:5 % loop on areas
                    AreaName=AnalysisOpts.AreaNames{Ar};
                    temp=obj.ManData.LoadVar('Classifier',['Test_' TestName{t}],...
                    ['_ParamSweep_' AreaName],0,'WantedDate','ALL');                 
                    % save this on a sheet in a xls file
                    [~,~,TableFullPath]=obj.ManData.GetFileName('Classifier',...
                        ['Test_'  TestName{t} '_ParamSweep'],'WantedCh','ALL');
                    if ~isempty(temp)
                        T=struct2table(temp);
                        obj.FigParams.SaveTable(T,[TableFullPath(1:end-4)],'TabelSheet',AreaName);
                    else
                        fprintf(2,'\nData for %s Area %s does not exist',TestName{t},AreaName)
                    end
                end                
            end
        end
        function out=CreateSummeryofAllClassifierTestConds(obj,varargin) % creates a table of all test conditions for the classifier 
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            TaskList=AnalysisOpts.PopulationAna.Classifier_TaskNameSet;
            out=[];
            ClassifierOpts=cellfun(@(x) obj.DefineClassifierTestOptions(x),TaskList,'UniformOutput',0);
            OptsFields=fieldnames(ClassifierOpts{1});
            out=cell2mat(cellfun(@(x) obj.ManData.CopyStructFields(x,out,OptsFields),ClassifierOpts,'UniformOutput',0));           
        end
        function [ClassifierResults,ClassifierOpts]=Run3DCrossTemporalClassiferAnalysis_TripleCrossCond_Learning(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis for 3 simultanous features in three different cross conditions during learning
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierOpts.ConcatinateMethod='SepTimePoint'; % for PCA analysis
            ClassifierOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
            DimTxt={'','2','3'};                      
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorData);

            % if this is a calculation of shuffled distribution then
            % prepare the data
            if obj.CalShuff
                ShuffTxt=sprintf('Shuf_C%i_',AnalysisOpts.CalShuffleClassifier_Cond);
                rng(AnalysisOpts.CalShuffleClassifier_Cond)
                ClassifierOpts.Nrep=ClassifierOpts.NrepShuf; % change the number of repetitions
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.CalShuffleClassifier_TrlRng(x),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.CalShuffleClassifier_TrlRng(x)),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondSet  =CondInds(AnalysisOpts.CalShuffleClassifier_Cond);
                TrlRngSet=TrlRngInds(AnalysisOpts.CalShuffleClassifier_Cond);
            elseif AnalysisOpts.DividSpockClassifier
                ShuffTxt=sprintf('C%i_',AnalysisOpts.DividSpockClassifier_Cond);
                rng(AnalysisOpts.DividSpockClassifier_Cond);
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockClassifier_TrlRng(x),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockClassifier_TrlRng(x)),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondSet  =CondInds(AnalysisOpts.DividSpockClassifier_Cond);
                TrlRngSet=TrlRngInds(AnalysisOpts.DividSpockClassifier_Cond);
            else
                ShuffTxt='';
                CondSet=1:length(ClassifierOpts.TrainCond);
            end
            
            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);
            
            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of type
            % get the ind of factors of test we are keeping
            ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
            FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
            ClassifierResults=[];ClassifierResults_Shuffled=[];
            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14) || sum(ClassifierOpts.StimCongruency==15)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                if ~(obj.CalShuff |AnalysisOpts.DividSpockClassifier) ;TrlRngSet=1:nXTrlPnt;end
                
                for nTrlRng=1:length(TrlRngSet)
                    TrlRng=TrlRngSet(nTrlRng);
                    
                    ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                    
                    % now limit factor data trials to these trial range we want
                    % generate factor data for training
                    FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                    
                    % if we are limitign based on block performance then
                    if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                    
                    for rep=1:ClassifierOpts.Nrep        % loop on repetition per condition
                        %    waitbar(rep/ClassifierOpts.Nrep,f,sprintf('repetition:%i',rep))
                        fprintf('\nTrain/Testing Train1:%s Test1:%s | Train2:%s Test2:%s | Train3:%s Test3:%s TrlRng:%i Rep:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                            obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),...
                            obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond3{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond3{Cond}),TrlRng,rep);
                        isok=0;
                        while isok==0 % make sure we have enough trials for both categories in both dimensions
                            % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                            if strcmp(type,'TripleCrossCond')
                                % grab random set of data
                                [predictors ,response , TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                    ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',0);
                                
                                [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,~,~,predictors2SpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                    ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',2);
                                
                                [predictors3,response3,Train3DataAllFactors, Test3DataAllFactors,~,~,predictors3SpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond3{Cond},...
                                    ClassifierOpts.TestCond3{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',3);                                                             
                                % euqalize trials across conditions
                                [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                    TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                    predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.EqualizeTrialsAcrossConds(ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                                    response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                    TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                    predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                            end
                            % if we are changing the distribution of train
                            % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                            [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                predictors,predictors2,predictors3,response,response2,response3,1);

                             [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                predictors,predictors2,predictors3,response,response2,response3,2);

                              [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                predictors,predictors2,predictors3,response,response2,response3,3);
                            
                            % now get train/test data on the second factor as well
                            TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
                            DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
                            if isempty(ClassifierOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                                DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
                            else
                                DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
                            end
                            
                            % now get train/test data on the third factor as well
                            TargetFactors_3ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_3ndD{1});
                            DataLabels_Train_3ndD= Train3DataAllFactors(:,TargetFactors_3ndDInd);
                            if isempty(ClassifierOpts.One_Class_ResponseLbl3{Cond}) % if we are not doing one class
                                DataLabels_Test_3ndD = Test3DataAllFactors(:,TargetFactors_3ndDInd);
                            else
                                DataLabels_Test_3ndD = ClassifierOpts.One_Class_ResponseLbl3{Cond}*ones(size(response3{2}));
                            end
                            % if strcmp(ClassifierOpts.TargetFactors{1},'ColorCat') & strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ResponseLoc')
                            % % flip response direction for rules
                            %   DataLabels_Train_2ndD=obj.ManData.FlipRepDirection(DataLabels_Train_2ndD);
                            %   DataLabels_Test_2ndD=obj.ManData.FlipRepDirection(DataLabels_Test_2ndD);
                            %end
                            
                            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                                DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                            end
                            response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                            
                             if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                DataLabels_Train_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_3ndD);    % categorize morph levels
                                DataLabels_Test_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_3ndD);    % categorize morph levels
                            end
                            response_3ndD=[{DataLabels_Train_3ndD} {DataLabels_Test_3ndD}];
                            
                            % check so that the labels are the same as what we have specificed for the second dimension
                            if iscell(ClassifierOpts.Levels_2ndD{1})
                                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                Levels_2ndD_Train=[1 2];
                                Levels_2ndD_Test =[1 2];
                            else
                                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1};
                            end
                            
                            % check so that the labels are the same as what we have specificed for the third dimension
                            if iscell(ClassifierOpts.Levels_3ndD{1})
                                Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TrainCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                                Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TestCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                Levels_3ndD_Train=[1 2];
                                Levels_3ndD_Test =[1 2];
                            else
                                Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1};
                                Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1};
                            end
                            
                            if ((length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |... % test dim 2
                                    ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                    ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                    isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})) | ...
                                    ((length(unique(DataLabels_Train_3ndD))==1 | length(unique(DataLabels_Test_3ndD))==1 |... % test dim 3
                                    ~isempty(setdiff(unique(DataLabels_Train_3ndD)',Levels_3ndD_Train)) | ...
                                    ~isempty(setdiff(unique(DataLabels_Test_3ndD)',Levels_3ndD_Test))) & ...
                                    isnan(ClassifierOpts.One_Class_ResponseLbl3{Cond}))
                                isok=0;
                            else
                                isok=1;
                            end
                        end
                                                
                        % if one of the dimensions has rule information then add mean activity to that
                        [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.AdjustMeanActivity4Rule(ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                            TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors);
                        
                        if obj.CalShuff % shuffle training data
                            response{1}=response{1}(randperm(numel(response{1})));
                            response_2ndD{1}=response_2ndD{1}(randperm(numel(response_2ndD{1})));
                            response_3ndD{1}=response_3ndD{1}(randperm(numel(response_3ndD{1})));
                            % calculate intrinsic dimensionality of train and test data combined as well
                          %  ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).no_IDdims=obj.CalculateIntrinsicDimensionality(cat(1,predictors{1},predictors{2}),'PCAExpVar');
                        end
                         %% run some preliminary subspace analysis as well in case we want to correlate with results
                        if sum(strcmp(TargetFields,'Congruency')) & ~sum(ClassifierOpts.StimCongruency==12) & ~sum(ClassifierOpts.StimCongruency==1)                          
                            for Dim=1:3
                                % Run subspace analysis on different time points
                                % on the all dimensions
                                eval(sprintf('[Subspace%s,~,~,~,FactorDataTiled] =obj.DiscoverSubspaces(cat(1,predictors%s{1},predictors%s{2}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(predictors%s{1},1)) 2*ones(1,size(predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s] =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace%s.CondScore{1}{x} Subspace%s.CondScore{2}{x}},[]),1:AnalysisOpts.NTim);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{1}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{2}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                
                                % if we have any spike count classification that we need to do then do that
                                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    % run geometry analysis for the third dimension
                                    eval(sprintf('[Subspace%sSpkCnt{SpkCnt},~,~,~,FactorDataTiledSpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,predictors%sSpkCnt{1}{SpkCnt},predictors%sSpkCnt{2}{SpkCnt}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(predictors%s{1},1)) 2*ones(1,size(predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s_SpkCntPrd%i,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s_SpkCntPrd%i] =obj.CalculateAnglesBetSubspaces({Subspace%sSpkCnt{SpkCnt}.CondScore{1}{1} Subspace%sSpkCnt{SpkCnt}.CondScore{2}{1}},[]);',DimTxt{Dim},SpkCnt,DimTxt{Dim},SpkCnt,DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{1}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{2}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                end
                            end
                        end
                        %% now train and test classifier                         
                        [ClassifierResults,ClassifierOpts]=obj.RunClassifier3D(ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize);
                       
                        if ~obj.CalShuff
                            % save the factor data
                            %just keep ColorML and ShapeML reward Rule and response location
                            % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TrainDataAllFactors =TrainDataAllFactors(:,FactorInds2Keep);
                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors(:,FactorInds2Keep);
                            % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Train2DataAllFactors=Train2DataAllFactors(:,FactorInds2Keep);
                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors(:,FactorInds2Keep);
                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors(:,FactorInds2Keep);
                        end
                        %% train and test of shuffled data    
                        if AnalysisOpts.ExchangeableCalShuffClassifier & ~obj.CalShuff % then shuffle training labels 
                            fprintf(2,'Running permutation test on the data')
                            response{1}=response{1}(randperm(numel(response{1})));
                            response_2ndD{1}=response_2ndD{1}(randperm(numel(response_2ndD{1})));
                            response_3ndD{1}=response_3ndD{1}(randperm(numel(response_3ndD{1})));
                            
                            [ClassifierResults_Shuffled]=obj.RunClassifier3D(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize);                      
                        end
                       
                        % copy train/test data
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).trainingPredictors   = predictors{1};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).trainingResponse     = response{1};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).validationPredictors = predictors{2};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).validationResponse   = response{2};
                    end
                end
            end
            
            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            % save off the variables
            ExtraStrSave= ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file           
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
            
            % if we have also calculated the shuffle save the shuffle data too
             if AnalysisOpts.ExchangeableCalShuffClassifier & ~obj.CalShuff
                 ShuffTxtExchange=['Shuf_' ShuffTxt];
                 ExtraStrSaveShuff=['_' ShuffTxtExchange ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                 obj.ManData.DeleteFile('Classifier',ExtraStrSaveShuff,1,'WantedDate','ALL');
                 obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults',ExtraStrSaveShuff,'WantedDate','ALL');
                 obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuff,'WantedDate','ALL');
             end
        end
        function [ClassifierResults,ClassifierOpts]=Run3DClassiferAnalysis_TripleCrossCond_LearningCV(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis for 3 simultanous features in three different cross conditions during learning with cross validation
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierOpts.ConcatinateMethod='SepTimePoint'; % for PCA analysis
            ClassifierOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
            DimTxt={'','2','3'};                      
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorData);
            ClassifierOpts=obj.DetermineDimCVspecs(ClassifierOpts); % determine cross validation specs 
          
            [ShuffTxt,CondSet,TrlRngSet,RepSet]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            
            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);
            
            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of type
            % get the ind of factors of test we are keeping
            ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
            FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
            AnalysisOpts.FactorInds2KeepInd=FactorInds2Keep; % save the indices
            ClassifierResults=[];ClassifierResults_Shuffled=[];
            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14) || sum(ClassifierOpts.StimCongruency==15)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                
                % if we have the whole range of TrlRngSet then choose the one for this condition
                if iscell(TrlRngSet);ThisTrlRngSet=TrlRngSet{Cond};else;ThisTrlRngSet=TrlRngSet;end
                
                for nTrlRng=1:length(ThisTrlRngSet)
                    TrlRng=ThisTrlRngSet(nTrlRng);
                    
                    ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                    
                    % now limit factor data trials to these trial range we want generate factor data for training
                    FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                    
                    % if we are limitign based on block performance then
                    if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                    
                    for rep=1:length(RepSet)       % loop on repetition per condition
                      %  CVfoldResults=[]; % initialize this rep
                      
                        for cvf=1:ClassifierOpts.nCVfold(nCond) % loop on cross validation fold
                            FoldTimeTic=tic;
                            PrepTimeTic=tic;
                            fprintf('\nTrain/Testing Train1:%s Test1:%s | Train2:%s Test2:%s | Train3:%s Test3:%s TrlRng:%i Rep:%i CV:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                                obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),...
                                obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond3{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond3{Cond}),TrlRng,rep,cvf);
                            isok=0;
                            ClassifierOpts.CurrCVfold=cvf;
                            
                            % sample train and test trials 
                            while isok==0 % make sure we have enough trials for both categories in both dimensions
                                % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                                if strcmp(type,'TripleCrossCond')
                                    % grab random set of data for Dim 1
                                    [predictors ,response , TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt,TrainDataAllFactors3D,TestDataAllFactors3D]=...
                                        obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                        ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',0);
                                    % grab random set of data for Dim 2
                                    [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,~,~,predictors2SpkCnt,Train2DataAllFactors3D,Test2DataAllFactors3D]=...
                                        obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                        ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',2);
                                    % grab random set of data for Dim 3
                                    [predictors3,response3,Train3DataAllFactors, Test3DataAllFactors,~,~,predictors3SpkCnt,Train3DataAllFactors3D,Test3DataAllFactors3D]=...
                                        obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond3{Cond},...
                                        ClassifierOpts.TestCond3{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',3);
                                    % euqalize trials across conditions
                                    [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                        TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                        predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.EqualizeTrialsAcrossConds(ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                                        response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                        TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                        predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                end
                                % if we are changing the distribution of train
                                % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                                [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                    Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                    obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                    TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                    predictors,predictors2,predictors3,response,response2,response3,1);
                                
                                [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                    Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                    obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                    TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                    predictors,predictors2,predictors3,response,response2,response3,2);
                                
                                [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                    Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                    obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                    TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                    predictors,predictors2,predictors3,response,response2,response3,3);
                                
                                % now get train/test data on the second factor as well
                                TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
                                DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
                                if isempty(ClassifierOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                                    DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
                                else
                                    DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
                                end
                                
                                % now get train/test data on the third factor as well
                                TargetFactors_3ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_3ndD{1});
                                DataLabels_Train_3ndD= Train3DataAllFactors(:,TargetFactors_3ndDInd);
                                if isempty(ClassifierOpts.One_Class_ResponseLbl3{Cond}) % if we are not doing one class
                                    DataLabels_Test_3ndD = Test3DataAllFactors(:,TargetFactors_3ndDInd);
                                else
                                    DataLabels_Test_3ndD = ClassifierOpts.One_Class_ResponseLbl3{Cond}*ones(size(response3{2}));
                                end
                                % if strcmp(ClassifierOpts.TargetFactors{1},'ColorCat') & strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ResponseLoc')
                                % % flip response direction for rules
                                %   DataLabels_Train_2ndD=obj.ManData.FlipRepDirection(DataLabels_Train_2ndD);
                                %   DataLabels_Test_2ndD=obj.ManData.FlipRepDirection(DataLabels_Test_2ndD);
                                %end
                                
                                if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                    DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                                    DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                                end
                                response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                                
                                if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                    DataLabels_Train_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_3ndD);    % categorize morph levels
                                    DataLabels_Test_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_3ndD);    % categorize morph levels
                                end
                                response_3ndD=[{DataLabels_Train_3ndD} {DataLabels_Test_3ndD}];
                                
                                % check so that the labels are the same as what we have specificed for the second dimension
                                if iscell(ClassifierOpts.Levels_2ndD{1})
                                    Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                    Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                    Levels_2ndD_Train=[1 2];
                                    Levels_2ndD_Test =[1 2];
                                else
                                    Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                                    Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1};
                                end
                                
                                % check so that the labels are the same as what we have specificed for the third dimension
                                if iscell(ClassifierOpts.Levels_3ndD{1})
                                    Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TrainCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                                    Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TestCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                                elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                    Levels_3ndD_Train=[1 2];
                                    Levels_3ndD_Test =[1 2];
                                else
                                    Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1};
                                    Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1};
                                end
                                
                                if ((length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |... % test dim 2
                                        ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                        ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                        isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})) | ...
                                        ((length(unique(DataLabels_Train_3ndD))==1 | length(unique(DataLabels_Test_3ndD))==1 |... % test dim 3
                                        ~isempty(setdiff(unique(DataLabels_Train_3ndD)',Levels_3ndD_Train)) | ...
                                        ~isempty(setdiff(unique(DataLabels_Test_3ndD)',Levels_3ndD_Test))) & ...
                                        isnan(ClassifierOpts.One_Class_ResponseLbl3{Cond}))
                                    isok=0;
                                else
                                    isok=1;
                                end
                            end
                            
                            %% if one of the dimensions has rule information then add mean activity to that
                            [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.AdjustMeanActivity4Rule(ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors);
                                                      
                            PrepTimeToc=toc(PrepTimeTic);     
                            %% generate shuffle distribution
                            if cvf==1 && obj.CalShuff==1 % generate shuffle labels once for each repetition
                                ClassifierOpts.ClassifierShuffleLabel{1}=CreateShuffleDist4Classifier(obj,TrainDataAllFactors,TestDataAllFactors,response,ClassifierOpts,1,Cond);
                                ClassifierOpts.ClassifierShuffleLabel{2}=CreateShuffleDist4Classifier(obj,Train2DataAllFactors,Test2DataAllFactors,response_2ndD,ClassifierOpts,2,Cond);
                                ClassifierOpts.ClassifierShuffleLabel{3}=CreateShuffleDist4Classifier(obj,Train3DataAllFactors,Test3DataAllFactors,response_3ndD,ClassifierOpts,3,Cond);
                            end
                             %% now train and test classifier(no shuffle in this stage at all)
                            [ClassifierResults,ClassifierOpts,RunData]=obj.RunClassifier3D(ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,0,NaN);
                                                        
                            %% run some preliminary subspace analysis as well in case we want to correlate with results
                            SubspaceTimeTic=tic;
                            if 0 & sum(strcmp(TargetFields,'Congruency')) & ~sum(ClassifierOpts.StimCongruency==12) & ~sum(ClassifierOpts.StimCongruency==1) & ClassifierOpts.RunPrelimSubspace==1
                                for Dim=1:3
                                    % Run subspace analysis on different time points on the all dimensions
                                    eval(sprintf('[Subspace%s,~,~,~,FactorDataTiled] =obj.DiscoverSubspaces(cat(1,RunData.predictors%s{1},RunData.predictors%s{2}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s] =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace%s.CondScore{1}{x} Subspace%s.CondScore{2}{x}},[]),1:AnalysisOpts.NTim);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{1}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{2}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                    
                                    % if we have any spike count classification that we need to do then do that
                                    for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        % run geometry analysis for the third dimension
                                        eval(sprintf('[Subspace%sSpkCnt{SpkCnt},~,~,~,FactorDataTiledSpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,RunData.predictors%sSpkCnt{1}{SpkCnt},RunData.predictors%sSpkCnt{2}{SpkCnt}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                        eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s_SpkCntPrd%i,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s_SpkCntPrd%i] =obj.CalculateAnglesBetSubspaces({Subspace%sSpkCnt{SpkCnt}.CondScore{1}{1} Subspace%sSpkCnt{SpkCnt}.CondScore{2}{1}},[]);',DimTxt{Dim},SpkCnt,DimTxt{Dim},SpkCnt,DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                        eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{1}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                        eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{2}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                    end
                                end
                            end
                            SubspaceTimeToc=toc(SubspaceTimeTic);
                           
                            %% save test data
                            if ~obj.CalShuff
                                % save the factor data just keep ColorML and ShapeML reward Rule and response location                             
                                ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors;%[CVTestDataAllFactors(:,1:5) mean(CVTestDataAllFactors(:,6:9,:),3)];
                                ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors;%[CVTest2DataAllFactors(:,1:5) mean(CVTest2DataAllFactors(:,6:9,:),3)];
                                ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors;%[CVTest3DataAllFactors(:,1:5) mean(CVTest3DataAllFactors(:,6:9,:),3)];
                            end
                            %% save this classifier result folds 
                            CVfoldResults(cvf)= ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep);
                            
                            %% train and test of shuffled data
                            if obj.CalShuff % then shuffle training labels
                                ShuffleRun=1; % are we shuffleing the trining data 
                                for repshuff=1:ClassifierOpts.NrepShufperFold % shuffle classifie within fold
                                    fprintf(2,'\nRunning permutation test on the data, Rep %i',repshuff)
                                    % RunData uses the same data for this run for the shuffle as well
                                    [ClassifierResults_Shuffled]=obj.RunClassifier3D(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,repshuff,ClassifierOpts,RunData.predictors,RunData.response,RunData.predictors2,RunData.response_2ndD,RunData.predictors3,RunData.response_3ndD,...
                                        RunData.predictorsSpkCnt,RunData.predictors2SpkCnt,RunData.predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);
                                    
                                    CVfoldResults_Shuffled(repshuff,cvf)= ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff);
                                end
                            end
                            FoldTimeToc=toc(FoldTimeTic);
                            fprintf(' PrepTime:%0.2f SubSpcTime:%0.2f FoldTime:%0.2f ',PrepTimeToc,SubspaceTimeToc,FoldTimeToc);                           
                        end
                        
                        %% take average of the values across CV folds
                        ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep)=obj.AverageCVfoldData(CVfoldResults(1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);                        
                       
                        if obj.CalShuff
                            for repshuff=1:ClassifierOpts.NrepShufperFold
                                ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff)=obj.AverageCVfoldData(CVfoldResults_Shuffled(repshuff,1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                            end
                        end
                    end
                end
            end
            
            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            if ~obj.CalShuff
                % save off the variables( this is
                ExtraStrSave= ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
                obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
                if strcmp(ShuffTxt,'C1_') || isempty(ShuffTxt) % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
                end                
            elseif obj.CalShuff
                % if we have also calculated the shuffle save the shuffle data too
                % save both observed and shuffle in one fule
                ExtraStrSaveShuff=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',ExtraStrSaveShuff,1,'WantedDate','ALL');
                obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSaveShuff,'WantedDate','ALL'); % save shuffled results
                obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSaveShuff,'WantedDate','ALL'); % save observed results
                if strcmp(ShuffTxt,'Shuf_C1_') || isempty(ShuffTxt)    % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuff,'WantedDate','ALL');
                end
            end
        end
        function [ClassifierResults,ClassifierOpts]=Run3DClassiferAnalysis_TripleCrossCond_LearningCVCorrectShuff(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % With correct shuffling procidure, runs cross temporal classifier anlaysis for 3 simultanous features in three different cross conditions during learning with cross validation
%             running a classifier analysis for three simultaneous features in three different cross conditions during learning with cross-validation.
%             Here are the main steps and functionalities of this code:
% 
%            * Setting up variables and options based on input parameters and global variables.
%            * Determining the target field (e.g., 'StimCongruency') and cross-validation specifications.
%            * Looping through different conditions and trial ranges.
%            * Performing data preprocessing, including applying a neuron dropping algorithm.
%            * Running a classifier analysis using cross-validation and collecting the results.
%            * Calculating a shuffle distribution if specified.
%            * Applying some conditions and filtering on the data based on various criteria.
%            * Continuing with learning analysis and cross-validation for the first condition.

            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierOpts.ConcatinateMethod='SepTimePoint'; % for PCA analysis
            ClassifierOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
            TargetFactorsInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors{1});
            TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
            TargetFactors_3ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_3ndD{1});
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_2ndD=1;else;DimMethod_2ndD=2;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_3ndD=1;else;DimMethod_3ndD=2;
            end
            % if our factors are based on the rule then adjust the shuffleing procidure so the end factor data is based on the rule as well
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},'Rule')
                DimMethod_2ndD=3;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},'Rule')
                DimMethod_3ndD=3;
            end
            DimTxt={'','2','3'};                      
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorData);
            ClassifierOpts=obj.DetermineDimCVspecs(ClassifierOpts); % determine cross validation specs 
          
            [ShuffTxt,CondSet,TrlRngSet,RepSet]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            ExtraStrSaveShuffLabel=[ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_ShuffleLabels'];

            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);


            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of type
            % get the ind of factors of test we are keeping
            ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
            FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
            AnalysisOpts.FactorInds2KeepInd=FactorInds2Keep; % save the indices
            ClassifierResults=[];ClassifierResults_Shuffled=[];

            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                
                % if we have the whole range of TrlRngSet then choose the one for this condition
                if iscell(TrlRngSet);ThisTrlRngSet=TrlRngSet{Cond};else;ThisTrlRngSet=TrlRngSet;end
                
                for nTrlRng=1:length(ThisTrlRngSet)
                    TrlRng=ThisTrlRngSet(nTrlRng);
                    
                    ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                    
                    % now limit factor data trials to these trial range we want generate factor data for training
                    FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                  
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                    
                    % if we are limitign based on block performance then
                    if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                  
                    % create a shuffle distribution for the subsequenct shufflings for each dimension
                    if AnalysisOpts.GetOnlyShuffLabelsClassifier % generate shuffle labels once for each repetition
                        ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV3(obj,FactorData,ClassifierOpts,FactorLevelComb,1,Cond,TrlRng);
                        ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV3(obj,FactorData,ClassifierOpts,FactorLevelComb,2,Cond,TrlRng);
                        ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV3(obj,FactorData,ClassifierOpts,FactorLevelComb,3,Cond,TrlRng);
                    elseif obj.CalShuff==1 % generate shuffle labels once for each repetition
                        ClassifierOpts4Shuff=obj.ManData.LoadVar('Classifier','ClassifierOpts',ExtraStrSaveShuffLabel,0,'WantedDate','ALL');
                        ClassifierOpts=obj.ManData.CopyVars2Struct(ClassifierOpts,'ClassifierShuffleLabel',ClassifierOpts4Shuff.ClassifierShuffleLabel,...
                            'ClassifierShuffleTrialIndex',ClassifierOpts4Shuff.ClassifierShuffleTrialIndex,'ClassifierShuffleTrainCondIndex',ClassifierOpts4Shuff.ClassifierShuffleTrainCondIndex);
                    end
                       
                    if ~AnalysisOpts.GetOnlyShuffLabelsClassifier % we are only getting classifier label then skip the rest
                        %% determine what condition we are computing the data for
                        if obj.CalShuff==1 % if we are running shuffle
                            if RepSet==ClassifierOpts.NrepShufperFold+1 % this is observed
                                ShuffObservedRound=0;
                                repshuffSet=1;
                            else   % this is shuffle
                                ShuffObservedRound=1;
                                repshuffSet=RepSet;
                            end
                            RepSet=1:ClassifierOpts.NrepShuf;
                        else % this is for mean and STD
                            ShuffObservedRound=0;
                            repshuffSet=1;
                        end

                        for repshuff=1:length(repshuffSet) % shuffle classifier repetition
                            %   repshuff=repshuffSet(nrepshuff);
                            fprintf(2,'\nRunning permutation test on the data, Rep %i',repshuff)

                            if ShuffObservedRound
                                NewFactorDataDim1=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorData,repshuff,1,FactorLevelComb,TargetFactorsInd,1,TargetFactorsInd,Cond,TrlRng);
                                NewFactorDataDim2=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorData,repshuff,2,FactorLevelComb,TargetFactors_2ndDInd,DimMethod_2ndD,TargetFactorsInd,Cond,TrlRng);
                                NewFactorDataDim3=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorData,repshuff,3,FactorLevelComb,TargetFactors_3ndDInd,DimMethod_3ndD,TargetFactorsInd,Cond,TrlRng);
                            else
                                NewFactorDataDim1=FactorData;
                                NewFactorDataDim2=FactorData;
                                NewFactorDataDim3=FactorData;
                            end

                            for rep=1:length(RepSet)       % loop on repetition per condition
                                %  CVfoldResults=[]; % initialize this rep
                                FoldTimeTic=tic;
                                for cvf=1:ClassifierOpts.nCVfold(nCond) % loop on cross validation fold

                                    fprintf('\nTrain/Testing Train1:%s Test1:%s | Train2:%s Test2:%s | Train3:%s Test3:%s TrlRng:%i Rep:%i CV:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond3{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond3{Cond}),TrlRng,rep,cvf);

                                    ClassifierOpts.CurrCVfold=cvf;

                                    PrepTimeTic=tic;
                                    isok=0;
                                    %% sample train and test trials
                                    while isok==0 % make sure we have enough trials for both categories in both dimensions
                                        % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                                        if strcmp(type,'TripleCrossCond')
                                            % grab random set of data for Dim 1
                                            [predictors ,response , TrainDataAllFactors,TestDataAllFactors,TrainStimInds,~,predictorsSpkCnt,TrainDataAllFactors3D,TestDataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(NewFactorDataDim1,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                                ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',0);
                                            % grab random set of data for Dim 2
                                            [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,Train2StimInds,~,predictors2SpkCnt,Train2DataAllFactors3D,Test2DataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(NewFactorDataDim2,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                                ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',2);
                                            % grab random set of data for Dim 3
                                            [predictors3,response3,Train3DataAllFactors, Test3DataAllFactors,Train3StimInds,~,predictors3SpkCnt,Train3DataAllFactors3D,Test3DataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(NewFactorDataDim3,ClassifierOpts,ClassifierOpts.TrainCond3{Cond},...
                                                ClassifierOpts.TestCond3{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',3);
                                            % euqalize trials across conditions
                                            [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,ClassifierOpts]=obj.EqualizeTrialsAcrossConds(ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                                                response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                            % copy some of the data into ClassifierOpts for future use 
                                            ClassifierOpts=obj.ManData.CopyVars2Struct(ClassifierOpts,'TrainStimInds',TrainStimInds,'Train2StimInds',Train2StimInds,'Train3StimInds',Train3StimInds,...
                                                'TrainDataAllFactors',TrainDataAllFactors,'TestDataAllFactors',TestDataAllFactors,...
                                                'Train2DataAllFactors',Train2DataAllFactors,'Test2DataAllFactors',Test2DataAllFactors,...
                                                'Train3DataAllFactors',Train3DataAllFactors,'Test3DataAllFactors',Test3DataAllFactors);
                                        end
                                        % if we are changing the distribution of train
                                        % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,1);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,2);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,3);

                                        % now get train/test data on the second factor as well
                                        DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
                                        if isempty(ClassifierOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                                            DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
                                        else
                                            DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
                                        end

                                        % now get train/test data on the third factor as well
                                        DataLabels_Train_3ndD= Train3DataAllFactors(:,TargetFactors_3ndDInd);
                                        if isempty(ClassifierOpts.One_Class_ResponseLbl3{Cond}) % if we are not doing one class
                                            DataLabels_Test_3ndD = Test3DataAllFactors(:,TargetFactors_3ndDInd);
                                        else
                                            DataLabels_Test_3ndD = ClassifierOpts.One_Class_ResponseLbl3{Cond}*ones(size(response3{2}));
                                        end
                                        % if strcmp(ClassifierOpts.TargetFactors{1},'ColorCat') & strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ResponseLoc')
                                        % % flip response direction for rules
                                        %   DataLabels_Train_2ndD=obj.ManData.FlipRepDirection(DataLabels_Train_2ndD);
                                        %   DataLabels_Test_2ndD=obj.ManData.FlipRepDirection(DataLabels_Test_2ndD);
                                        %end

                                        if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                            DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                                            DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                                        end
                                        response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];

                                        if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                            DataLabels_Train_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_3ndD);    % categorize morph levels
                                            DataLabels_Test_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_3ndD);    % categorize morph levels
                                        end
                                        response_3ndD=[{DataLabels_Train_3ndD} {DataLabels_Test_3ndD}];

                                        % check so that the labels are the same as what we have specificed for the second dimension
                                        if iscell(ClassifierOpts.Levels_2ndD{1})
                                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                            Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                        elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                            Levels_2ndD_Train=[1 2];
                                            Levels_2ndD_Test =[1 2];
                                        else
                                            Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                                            Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1};
                                        end

                                        % check so that the labels are the same as what we have specificed for the third dimension
                                        if iscell(ClassifierOpts.Levels_3ndD{1})
                                            Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TrainCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                                            Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TestCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                                        elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                                            Levels_3ndD_Train=[1 2];
                                            Levels_3ndD_Test =[1 2];
                                        else
                                            Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1};
                                            Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1};
                                        end

                                        if ((length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |... % test dim 2
                                                ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})) | ...
                                                ((length(unique(DataLabels_Train_3ndD))==1 | length(unique(DataLabels_Test_3ndD))==1 |... % test dim 3
                                                ~isempty(setdiff(unique(DataLabels_Train_3ndD)',Levels_3ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_3ndD)',Levels_3ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl3{Cond}))
                                            isok=0;
                                        else
                                            isok=1;
                                        end
                                    end

                                    %% if one of the dimensions has rule information then add mean activity to that
                                    [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.AdjustMeanActivity4Rule(ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                                        predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                                        TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                        TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors);

                                    PrepTimeToc=toc(PrepTimeTic);

                                    %% now train and test classifier(no shuffle in this stage at all)
                                    if ShuffObservedRound==0
                                        [ClassifierResults,ClassifierOpts,RunData]=obj.RunClassifier3D_Optimized(ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,0,NaN);

                                        %% run some preliminary subspace analysis as well in case we want to correlate with results
                                        SubspaceTimeTic=tic;
                                        if sum(strcmp(TargetFields,'Congruency')) & ~sum(ClassifierOpts.StimCongruency==12) & ~sum(ClassifierOpts.StimCongruency==1) & ClassifierOpts.RunPrelimSubspace==1
                                            for Dim=1:3
                                                % Run subspace analysis on different time points on the all dimensions
                                                eval(sprintf('[Subspace%s,~,~,~,FactorDataTiled] =obj.DiscoverSubspaces(cat(1,RunData.predictors%s{1},RunData.predictors%s{2}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s] =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace%s.CondScore{1}{x} Subspace%s.CondScore{2}{x}},[]),1:AnalysisOpts.NTim);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{1}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{2}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace

                                                % if we have any spike count classification that we need to do then do that
                                                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                                    % run geometry analysis for the third dimension
                                                    eval(sprintf('[Subspace%sSpkCnt{SpkCnt},~,~,~,FactorDataTiledSpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,RunData.predictors%sSpkCnt{1}{SpkCnt},RunData.predictors%sSpkCnt{2}{SpkCnt}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s_SpkCntPrd%i,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s_SpkCntPrd%i] =obj.CalculateAnglesBetSubspaces({Subspace%sSpkCnt{SpkCnt}.CondScore{1}{1} Subspace%sSpkCnt{SpkCnt}.CondScore{2}{1}},[]);',DimTxt{Dim},SpkCnt,DimTxt{Dim},SpkCnt,DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{1}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{2}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                end
                                            end
                                        end
                                        SubspaceTimeToc=toc(SubspaceTimeTic);

                                        %% save test data
                                        if ~obj.CalShuff
                                            % save the factor data just keep ColorML and ShapeML reward Rule and response location
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors;%[CVTestDataAllFactors(:,1:5) mean(CVTestDataAllFactors(:,6:9,:),3)];
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors;%[CVTest2DataAllFactors(:,1:5) mean(CVTest2DataAllFactors(:,6:9,:),3)];
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors;%[CVTest3DataAllFactors(:,1:5) mean(CVTest3DataAllFactors(:,6:9,:),3)];
                                        end
                                        %% save this classifier result folds
                                        CVfoldResults(cvf)= ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep);
                                    end
                                    %% train and test of shuffled data
                                    if ShuffObservedRound==1 & obj.CalShuff % then shuffle training labels
                                        ShuffleRun=1; % are we shuffleing the trining data
                                        % RunData uses the same data for this run for the shuffle as well
                                        %                                         [ClassifierResults_Shuffled]=obj.RunClassifier3D(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,repshuff,ClassifierOpts,RunData.predictors,RunData.response,RunData.predictors2,RunData.response_2ndD,RunData.predictors3,RunData.response_3ndD,...
                                        %                                             RunData.predictorsSpkCnt,RunData.predictors2SpkCnt,RunData.predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);
                                        [ClassifierResults_Shuffled,ClassifierOpts]=obj.RunClassifier3D_Optimized(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,repshuff,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);

                                        CVfoldResults_Shuffled(repshuff,cvf)= ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff);
                                        SubspaceTimeToc=0;
                                    end
                                    TocRepInnerTime=toc(PrepTimeTic);
                                    fprintf('** %s RepTime:%0.2f PrepTime:%0.2f SubSpcTime:%0.2f ',ShuffTxt,TocRepInnerTime,PrepTimeToc,SubspaceTimeToc);
                                end % loop on fold
                                FoldTimeToc=toc(FoldTimeTic);
                                fprintf(2,'\n*********Total Fold Time:%0.2f *******',FoldTimeToc);

                                %% take average of the values across CV folds
                                if ShuffObservedRound==0
                                    ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep)=obj.AverageCVfoldData(CVfoldResults(1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                end

                                if ShuffObservedRound==1 & obj.CalShuff
                                    %  for repshuff=1:ClassifierOpts.NrepShufperFold
                                    ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff,rep)=obj.AverageCVfoldData(CVfoldResults_Shuffled(repshuff,1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                    %  end
                                end

                            end  % loop on repetition
                        end % loop on shuffle repetition
                    end
                end % loop on ntrl range
            end % loop on Cond
            
            if AnalysisOpts.GetOnlyShuffLabelsClassifier % if we are only saving shuffle label classifier
                ClassifierResults=[];
                obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuffLabel,'WantedDate','ALL');
                return
            end

            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            if ~obj.CalShuff
                % save off the variables( this is
                ExtraStrSave= ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
                obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
                if strcmp(ShuffTxt,'C1_') || isempty(ShuffTxt) % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
                end
            elseif obj.CalShuff
                ExtraStrSaveShuff=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                % if we have also calculated the shuffle save the shuffle data too
                % save both observed and shuffle in one fule
                obj.ManData.DeleteFile('Classifier',ExtraStrSaveShuff,1,'WantedDate','ALL');
                if ShuffObservedRound==1
                    obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSaveShuff,'WantedDate','ALL'); % save shuffled results
                else % save observed
                    obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSaveShuff,'WantedDate','ALL'); % save observed results
                end
                if strcmp(ShuffTxt,'Shuf_C1_') || isempty(ShuffTxt)    % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuff,'WantedDate','ALL');
                end
            end
        end
        function [ClassifierResults,ClassifierOpts]=Run3DClassiferAnalysis_TripleCrossCond_LearningCVCorrectShuffV2(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % With correct shuffling procidure, runs cross temporal classifier anlaysis for 3 simultanous features in three different cross conditions during learning with cross validation
%             corrected so that the shuffling is applied before any trial range 
%             shuffles the trial order
%             running a classifier analysis for three simultaneous features in three different cross conditions during learning with cross-validation.
%             Here are the main steps and functionalities of this code:
% 
%            * Setting up variables and options based on input parameters and global variables.
%            * Determining the target field (e.g., 'StimCongruency') and cross-validation specifications.
%            * Looping through different conditions and trial ranges.
%            * Performing data preprocessing, including applying a neuron dropping algorithm.
%            * Running a classifier analysis using cross-validation and collecting the results.
%            * Calculating a shuffle distribution if specified.
%            * Applying some conditions and filtering on the data based on various criteria.
%            * Continuing with learning analysis and cross-validation for the first condition.
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierOpts.ConcatinateMethod='SepTimePoint'; % for PCA analysis
            ClassifierOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
            TrialNumInd=strcmp(AnalysisOpts.factornames,'TrialNum');

            TargetFactorsInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors{1});
            TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
            TargetFactors_3ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_3ndD{1});
            
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_2ndD=1;else;DimMethod_2ndD=2;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_3ndD=1;else;DimMethod_3ndD=2;
            end
            % if our factors are based on the rule then adjust the shuffleing procidure so the end factor data is based on the rule as well
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},'Rule')
                DimMethod_2ndD=3;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},'Rule')
                DimMethod_3ndD=3;
            end
            DimTxt={'','2','3'};     
            AnalysisOpts.DimTxt={'','2','3'}; 
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorData);
            ClassifierOpts=obj.DetermineDimCVspecs(ClassifierOpts); % determine cross validation specs 
          
            [ShuffTxt,CondSet,TrlRngSet,RepSet]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            RepSetBuff=RepSet;

            ExtraStrSaveShuffLabel=[ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' num2str(AnalysisOpts.DividSpockClassifier_Cond) '_ShuffleLabels'];

            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);

            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            FactorDataBuff=rmfield(FactorDataBuff,'dataMean');
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of type
            % get the ind of factors of test we are keeping
            ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
            FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
            AnalysisOpts.FactorInds2KeepInd=FactorInds2Keep; % save the indices
            ClassifierResults=[];ClassifierResults_Shuffled=[];

            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                ClassifierOpts.CurrCond=Cond;
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14) || sum(ClassifierOpts.StimCongruency==15)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
                
                % create a shuffle distribution for the subsequenct shufflings for each dimension
               if obj.CalShuff==1
                    ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,1,Cond,1);
                    ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,2,Cond,1);
                    ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,3,Cond,1);
               end

                if ~AnalysisOpts.GetOnlyShuffLabelsClassifier % we are only getting classifier label then skip the rest
                    %% run the code
                    % create learning trials for this condition
                    [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);

                    % if we have the whole range of TrlRngSet then choose the one for this condition
                    if iscell(TrlRngSet);ThisTrlRngSet=TrlRngSet{Cond};else;ThisTrlRngSet=TrlRngSet;end
                   if AnalysisOpts.UseRep4Cluster==1;ThisTrlRngSet=unique(ThisTrlRngSet);end

                    % determine what condition we are computing the data for
                    if obj.CalShuff==1 % if we are running shuffle
                        if RepSetBuff==ClassifierOpts.NrepShufperFold+1 % this is observed
                            ShuffObservedRound=0;obj.ShuffObservedRoundObj=0;
                            repshuffSet=1;
                            fprintf(2,'\n*****Running Observed rep')
                        else   % this is shuffle
                            ShuffObservedRound=1;obj.ShuffObservedRoundObj=1;
                            if AnalysisOpts.UseRep4Cluster==1
                                repshuffSet=RepSetBuff;
                            else
                                repshuffSet=RepSet;
                            end
                            fprintf(2,'\n*****Running Shuffle reps')
                        end
                        RepSet=1:ClassifierOpts.NrepShuf;
                    else % this is for mean and STD
                        ShuffObservedRound=0;obj.ShuffObservedRoundObj=0;
                        repshuffSet=1;
                    end

                    for repshuff=1:length(repshuffSet) % shuffle classifier repetition
                        fprintf(2,'\nRunning permutation test on the data, Rep %i',repshuff)

                        if  obj.CalShuff & ShuffObservedRound
                            if length(repshuffSet)>1;error('This code does not work here');end
                            NewFactorDataDim1Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,1,FactorLevelComb,TargetFactorsInd,2,TargetFactorsInd,Cond,1);
                            NewFactorDataDim2Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,2,FactorLevelComb,TargetFactors_2ndDInd,2,TargetFactorsInd,Cond,1);
                            NewFactorDataDim3Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,3,FactorLevelComb,TargetFactors_3ndDInd,2,TargetFactorsInd,Cond,1);
                        else
                            NewFactorDataDim1Buff=FactorDataBuff;
                            NewFactorDataDim2Buff=FactorDataBuff;
                            NewFactorDataDim3Buff=FactorDataBuff;
                        end

                        % if we are skipping applying SeqHist to traning data
                        NewFactorDataDim1Buff=obj.SkipSeqHistTrain(NewFactorDataDim1Buff,ClassifierOpts,Cond);
                        NewFactorDataDim2Buff=obj.SkipSeqHistTrain(NewFactorDataDim2Buff,ClassifierOpts,Cond);
                        NewFactorDataDim3Buff=obj.SkipSeqHistTrain(NewFactorDataDim3Buff,ClassifierOpts,Cond);

                        for nTrlRng=1:length(ThisTrlRngSet)
                            TrlRng=ThisTrlRngSet(nTrlRng);

                            ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                            ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                           
                            % now limit factor data trials to these trial range we want generate factor data for training
                            NewFactorDataDim1=obj.LimitTrialsBasedonFactor(NewFactorDataDim1Buff,'TrialNum',ThisTrainTrialRange);
                            NewFactorDataDim2=obj.LimitTrialsBasedonFactor(NewFactorDataDim2Buff,'TrialNum',ThisTrainTrialRange);
                            NewFactorDataDim3=obj.LimitTrialsBasedonFactor(NewFactorDataDim3Buff,'TrialNum',ThisTrainTrialRange);

                            % generate factordata for test
                            FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);

                            % if we are limitign based on block performance then
                            if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                                % generate factor data for test
                                NewFactorDataDim1=obj.LimitTrialsBasedonFactor(NewFactorDataDim1,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                                NewFactorDataDim2=obj.LimitTrialsBasedonFactor(NewFactorDataDim2,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                                NewFactorDataDim3=obj.LimitTrialsBasedonFactor(NewFactorDataDim3,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});

                                % generate factordata for training
                                FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                            end

                            for rep=1:length(RepSet)       % loop on repetition per condition
                                %  CVfoldResults=[]; % initialize this rep
                                FoldTimeTic=tic;
                                for cvf=1:ClassifierOpts.nCVfold(nCond) % loop on cross validation fold

                                    fprintf('\nTrain/Testing Train1:%s Test1:%s | Train2:%s Test2:%s | Train3:%s Test3:%s Cond:%i RepSuff:%i TrlRng:%i Rep:%i CV:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond3{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond3{Cond}),Cond,repshuff,TrlRng,rep,cvf);

                                    ClassifierOpts.CurrCVfold=cvf;

                                    PrepTimeTic=tic;
                                    isok=0;
                                    %% sample train and test trials
                                    while isok==0 % make sure we have enough trials for both categories in both dimensions
                                        % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                                        if strcmp(type,'TripleCrossCond')
                                            try
                                                % grab random set of data for Dim 1
                                                [predictors ,response , TrainDataAllFactors,TestDataAllFactors,TrainStimInds,~,predictorsSpkCnt,TrainDataAllFactors3D,TestDataAllFactors3D]=...
                                                    obj.GrabThisRepClassifierData(NewFactorDataDim1,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                                    ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',0);                                             
                                                % grab random set of data for Dim 2
                                                [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,Train2StimInds,~,predictors2SpkCnt,Train2DataAllFactors3D,Test2DataAllFactors3D]=...
                                                    obj.GrabThisRepClassifierData(NewFactorDataDim2,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                                    ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',2);
                                                % grab random set of data for Dim 3
                                                [predictors3,response3,Train3DataAllFactors, Test3DataAllFactors,Train3StimInds,~,predictors3SpkCnt,Train3DataAllFactors3D,Test3DataAllFactors3D]=...
                                                    obj.GrabThisRepClassifierData(NewFactorDataDim3,ClassifierOpts,ClassifierOpts.TrainCond3{Cond},...
                                                    ClassifierOpts.TestCond3{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',3);
                                                % euqalize trials across conditions
                                                [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                    TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                    predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,ClassifierOpts]=obj.EqualizeTrialsAcrossConds(ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                                                    response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                    TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                    predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                            catch ME
                                                error(ME.message);
                                            end
                                            if cvf==1
                                                % copy some of the data into ClassifierOpts for future use
                                                ClassifierOpts=obj.ManData.CopyVars2Struct(ClassifierOpts,'TrainStimInds',TrainStimInds,'Train2StimInds',Train2StimInds,'Train3StimInds',Train3StimInds,...
                                                    'TrainDataAllFactors',TrainDataAllFactors,'TestDataAllFactors',TestDataAllFactors,...
                                                    'Train2DataAllFactors',Train2DataAllFactors,'Test2DataAllFactors',Test2DataAllFactors,...
                                                    'Train3DataAllFactors',Train3DataAllFactors,'Test3DataAllFactors',Test3DataAllFactors);
                                            end
                                        end
                                        % if we are changing the distribution of train
                                        % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,1,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,2,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                    
                                        % adjust the labels
                                        [DataLabels_Train,DataLabels_Train_2ndD,DataLabels_Train_3ndD, DataLabels_Test,DataLabels_Test_2ndD,...
                                            DataLabels_Test_3ndD, Levels_Train,Levels_2ndD_Train,Levels_3ndD_Train, ...
                                            Levels_Test,Levels_2ndD_Test,Levels_3ndD_Test,response,response_2ndD,response_3ndD]=obj.AdjustClassifierLabels(ClassifierOpts,Cond,TrainDataAllFactors,Train2DataAllFactors,...
                                            Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,response,response2,response3,TargetFactorsInd,TargetFactors_2ndDInd,TargetFactors_3ndDInd);

                                        if ((length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |... % test dim 2
                                                ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})) | ...
                                                ((length(unique(DataLabels_Train_3ndD))==1 | length(unique(DataLabels_Test_3ndD))==1 |... % test dim 3
                                                ~isempty(setdiff(unique(DataLabels_Train_3ndD)',Levels_3ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_3ndD)',Levels_3ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl3{Cond}))
                                            isok=0;
                                        else
                                            isok=1;
                                        end
                                    end

                                    %% if one of the dimensions has rule information then add mean activity to that
                                    [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.AdjustMeanActivity4Rule(ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                                        predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                                        TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                        TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors);

                                    PrepTimeToc=toc(PrepTimeTic);

                                    %% now train and test classifier(no shuffle in this stage at all)
                                    if ShuffObservedRound==0
                                        [ClassifierResults,ClassifierOpts]=obj.RunClassifier3D_Optimized(ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,0,NaN);

                                        %% run some preliminary subspace analysis as well in case we want to correlate with results
                                        SubspaceTimeTic=tic;
                                        if sum(strcmp(TargetFields,'Congruency')) & ~sum(ClassifierOpts.StimCongruency==12) & ~sum(ClassifierOpts.StimCongruency==1) & ClassifierOpts.RunPrelimSubspace==1
                                            for Dim=1:3
                                                % Run subspace analysis on different time points on the all dimensions
                                                eval(sprintf('[Subspace%s,~,~,~,FactorDataTiled] =obj.DiscoverSubspaces(cat(1,RunData.predictors%s{1},RunData.predictors%s{2}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s] =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace%s.CondScore{1}{x} Subspace%s.CondScore{2}{x}},[]),1:AnalysisOpts.NTim);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{1}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{2}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace

                                                % if we have any spike count classification that we need to do then do that
                                                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                                    % run geometry analysis for the third dimension
                                                    eval(sprintf('[Subspace%sSpkCnt{SpkCnt},~,~,~,FactorDataTiledSpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,RunData.predictors%sSpkCnt{1}{SpkCnt},RunData.predictors%sSpkCnt{2}{SpkCnt}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s_SpkCntPrd%i,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s_SpkCntPrd%i] =obj.CalculateAnglesBetSubspaces({Subspace%sSpkCnt{SpkCnt}.CondScore{1}{1} Subspace%sSpkCnt{SpkCnt}.CondScore{2}{1}},[]);',DimTxt{Dim},SpkCnt,DimTxt{Dim},SpkCnt,DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{1}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{2}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                end
                                            end
                                        end
                                        SubspaceTimeToc=toc(SubspaceTimeTic);

                                        %% save test data
                                        if ~obj.CalShuff
                                            % save the factor data just keep ColorML and ShapeML reward Rule and response location
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors;%(:,FactorInds2Keep);%[CVTestDataAllFactors(:,1:5) mean(CVTestDataAllFactors(:,6:9,:),3)];
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors;%(:,FactorInds2Keep);%[CVTest2DataAllFactors(:,1:5) mean(CVTest2DataAllFactors(:,6:9,:),3)];
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors;%(:,FactorInds2Keep);%[CVTest3DataAllFactors(:,1:5) mean(CVTest3DataAllFactors(:,6:9,:),3)];
                                        end
                                        %% save this classifier result folds
                                        CVfoldResults(cvf)= ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep);
                                    end
                                    %% train and test of shuffled data
                                    if ShuffObservedRound==1 & obj.CalShuff % then shuffle training labels
                                        ShuffleRun=1; % are we shuffleing the trining data
                                        % RunData uses the same data for this run for the shuffle as well
                                        % [ClassifierResults_Shuffled]=obj.RunClassifier3D(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,repshuff,ClassifierOpts,RunData.predictors,RunData.response,RunData.predictors2,RunData.response_2ndD,RunData.predictors3,RunData.response_3ndD,...
                                        % RunData.predictorsSpkCnt,RunData.predictors2SpkCnt,RunData.predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);
                                       
                                        [ClassifierResults_Shuffled,ClassifierOpts]=obj.RunClassifier3D_Optimized(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);

                                        CVfoldResults_Shuffled(repshuff,cvf)= ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(rep);
                                        SubspaceTimeToc=0;
                                    end
                                    TocRepInnerTime=toc(PrepTimeTic);
                                    fprintf('** %s RepTime:%0.2f PrepTime:%0.2f SubSpcTime:%0.2f ',ShuffTxt,TocRepInnerTime,PrepTimeToc,SubspaceTimeToc);
                                end % loop on fold
                                FoldTimeToc=toc(FoldTimeTic);

                                %% take average of the values across CV folds
                                if ShuffObservedRound==0
                                    fprintf(2,'\n*********Total Fold Time:%0.2f Saving Observed*******',FoldTimeToc);
                                    ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep)=obj.AverageCVfoldData(CVfoldResults(1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                end

                                if ShuffObservedRound==1 & obj.CalShuff
                                    fprintf(2,'\n*********Total Fold Time:%0.2f Saving Shuffle*******',FoldTimeToc);
                                    %  for repshuff=1:ClassifierOpts.NrepShufperFold
                                    ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff,rep)=obj.AverageCVfoldData(CVfoldResults_Shuffled(repshuff,1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                    %  end
                                end

                            end  % loop on repetition
                        end % loop on shuffle repetition
                    end % loop on ntrl range
                end
            end % loop on Cond

            if AnalysisOpts.GetOnlyShuffLabelsClassifier % if we are only saving shuffle label classifier
                ClassifierResults=[];
                ClassifierOpts=obj.ManData.rmfieldExept(ClassifierOpts,{'ClassifierShuffleLabel','ClassifierShuffleTrialIndex','ClassifierShuffleTrainCondIndex'});
                obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuffLabel,'WantedDate','ALL');
                return
            end

            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            if ~obj.CalShuff
                % save off the variables( this is
                ExtraStrSave= ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
                obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL','SaveAnalysisOpts',0);
                if strcmp(ShuffTxt,'C1_') || isempty(ShuffTxt) % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL','SaveAnalysisOpts',0);
                end
            elseif obj.CalShuff
                ExtraStrSaveShuff=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                % if we have also calculated the shuffle save the shuffle data too
                % save both observed and shuffle in one fule
                obj.ManData.DeleteFile('Classifier',ExtraStrSaveShuff,1,'WantedDate','ALL');
                if ShuffObservedRound==1
                    obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0); % save shuffled results
                else % save observed
                    obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0); % save observed results
                end
                if strcmp(ShuffTxt,'ShLb_C1_') || isempty(ShuffTxt)    % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0);
                end
            end
        end

        function [ClassifierResults,ClassifierOpts]=Run3DClassiferAnalysis_TripleCrossCond_LearningCVShuffTrlOrder(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % With correct shuffling procidure, runs cross temporal classifier anlaysis for 3 simultanous features in three different cross conditions during learning with cross validation
%             shuffles the trial order
%             running a classifier analysis for three simultaneous features in three different cross conditions during learning with cross-validation.
%             Here are the main steps and functionalities of this code:
% 
%            * Setting up variables and options based on input parameters and global variables.
%            * Determining the target field (e.g., 'StimCongruency') and cross-validation specifications.
%            * Looping through different conditions and trial ranges.
%            * Performing data preprocessing, including applying a neuron dropping algorithm.
%            * Running a classifier analysis using cross-validation and collecting the results.
%            * Calculating a shuffle distribution if specified.
%            * Applying some conditions and filtering on the data based on various criteria.
%            * Continuing with learning analysis and cross-validation for the first condition.
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierOpts.ConcatinateMethod='SepTimePoint'; % for PCA analysis
            ClassifierOpts.MainTargetFactor={'Quadrants'};% can be Quadrants ColorMLComb
            TrialNumInd=strcmp(AnalysisOpts.factornames,'TrialNum');

            TargetFactorsInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors{1});
            TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
            TargetFactors_3ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_3ndD{1});
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_2ndD=1;else;DimMethod_2ndD=2;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},ClassifierOpts.TargetFactors{1})
                DimMethod_3ndD=1;else;DimMethod_3ndD=2;
            end
            % if our factors are based on the rule then adjust the shuffleing procidure so the end factor data is based on the rule as well
            if strcmp(ClassifierOpts.TargetFactors_2ndD{1},'Rule')
                DimMethod_2ndD=3;
            end
            if strcmp(ClassifierOpts.TargetFactors_3ndD{1},'Rule')
                DimMethod_3ndD=3;
            end
            if obj.CalShuffTrlOrder==1;obj.CalShuff=1;end % if we are shuffling the trial order then we are  shuffleing 

            DimTxt={'','2','3'};                      
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorData);
            ClassifierOpts=obj.DetermineDimCVspecs(ClassifierOpts); % determine cross validation specs 
          
            [ShuffTxt,CondSet,TrlRngSet,RepSet]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            ExtraStrSaveShuffLabel=[ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_ShuffleLabelsTrialOrder'];
            RepSetBuff=RepSet;
            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);

              % if we are cutting the shuffling only to two episodes
            if contains(ClassifierOpts.Name,'CutShuf')
                ClassifierOpts.TestTrlNumRange ={[1 125 50 5]}; 
            end
            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            % if we are cutting the shuffling only to two episodes
            if contains(ClassifierOpts.Name,'CutShuf')
                ClassifierOpts.TestTrlNumRange ={[1 125 50 75]}; 
            end
          

            FactorDataBuff=rmfield(FactorDataBuff,'dataMean');
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of type
            % get the ind of factors of test we are keeping
            ClassifierOpts.FactorInds2Keep=AnalysisOpts.FactorInds2Keep;
            FactorInds2Keep=cellfun(@(x) find(ClassifierOpts.(x).Ind),ClassifierOpts.FactorInds2Keep);
            AnalysisOpts.FactorInds2KeepInd=FactorInds2Keep; % save the indices
            ClassifierResults=[];ClassifierResults_Shuffled=[];

            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                ClassifierOpts.CurrCond=Cond;   
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14) || sum(ClassifierOpts.StimCongruency==15)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end

                % if we are shuffling the data at the level of trial number order then shuffle it here

                %  if AnalysisOpts.GetOnlyShuffLabelsClassifier % generate shuffle labels once for each repetition
                ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,1,Cond,1);
                ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,2,Cond,1);
                ClassifierOpts=CreateShuffleDist4ClassifierCorrectShuffV5(obj,FactorDataBuff,ClassifierOpts,FactorLevelComb,3,Cond,1);
                %                elseif obj.CalShuff==1 % generate shuffle labels once for each repetition
                %                     ClassifierOpts4Shuff=obj.ManData.LoadVar('Classifier','ClassifierOpts',ExtraStrSaveShuffLabel,0,'WantedDate','ALL');
                %                     ClassifierOpts=obj.ManData.CopyVars2Struct(ClassifierOpts,'ClassifierShuffleLabel',ClassifierOpts4Shuff.ClassifierShuffleLabel,...
                %                         'ClassifierShuffleTrialIndex',ClassifierOpts4Shuff.ClassifierShuffleTrialIndex,'ClassifierShuffleTrainCondIndex',ClassifierOpts4Shuff.ClassifierShuffleTrainCondIndex);
                %                 end

                if ~AnalysisOpts.GetOnlyShuffLabelsClassifier % we are only getting classifier label then skip the rest
                    %% run the code
                    % create learning trials for this condition
                    [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);

                    % if we have the whole range of TrlRngSet then choose the one for this condition
                    if iscell(TrlRngSet);ThisTrlRngSet=TrlRngSet{Cond};else;ThisTrlRngSet=TrlRngSet;end

                    % determine what condition we are computing the data for
                    if obj.CalShuffTrlOrder==1 % if we are running shuffle
                        if RepSetBuff==ClassifierOpts.NrepShufperFold+1 % this is observed
                            ShuffObservedRound=0;
                            repshuffSet=1;
                        else   % this is shuffle
                            ShuffObservedRound=1;
                            repshuffSet=RepSet;
                        end
                        RepSet=1:ClassifierOpts.NrepShuf;
                    else % this is for mean and STD
                        ShuffObservedRound=0;
                        repshuffSet=1;
                    end

                    for repshuff=1:length(repshuffSet) % shuffle classifier repetition
                        fprintf(2,'\nRunning permutation test on the data, Rep %i/%i',repshuff,length(repshuffSet))

                        if obj.CalShuff & ShuffObservedRound % switch the trialnums and use only the Method 2
                            if length(repshuffSet)>1; error('This Code would not work here');end
                            NewFactorDataTestDim1Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,1,FactorLevelComb,TrialNumInd,2,TargetFactorsInd,Cond,1);
                            NewFactorDataTestDim2Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,2,FactorLevelComb,TrialNumInd,2,TargetFactorsInd,Cond,1);
                            NewFactorDataTestDim3Buff=obj.ManData.SwapShuffleTrialsFactorData(ClassifierOpts,FactorDataBuff,1,3,FactorLevelComb,TrialNumInd,2,TargetFactorsInd,Cond,1);
                        else
                            NewFactorDataTestDim1Buff=FactorDataBuff;
                            NewFactorDataTestDim2Buff=FactorDataBuff;
                            NewFactorDataTestDim3Buff=FactorDataBuff;
                        end

                        for nTrlRng=1:length(ThisTrlRngSet)
                            TrlRng=ThisTrlRngSet(nTrlRng);

                            ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                            ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};

                            % now limit factor data trials to these trial range we want generate factor data for training
                            NewFactorDataTestDim1=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim1Buff,'TrialNum',ThisTestTrialRange);
                            NewFactorDataTestDim2=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim2Buff,'TrialNum',ThisTestTrialRange);
                            NewFactorDataTestDim3=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim3Buff,'TrialNum',ThisTestTrialRange);

                            % generate factordata for training
                            FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);

                            % if we are limitign based on block performance then
                            if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                                % generate factor data for test
                                NewFactorDataTestDim1=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim1,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                                NewFactorDataTestDim2=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim2,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                                NewFactorDataTestDim3=obj.LimitTrialsBasedonFactor(NewFactorDataTestDim3,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});

                                % generate factordata for training
                                FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                            end

                            for rep=1:length(RepSet)       % loop on repetition per condition
                                %  CVfoldResults=[]; % initialize this rep
                                FoldTimeTic=tic;
                                for cvf=1:ClassifierOpts.nCVfold(nCond) % loop on cross validation fold

                                    fprintf('\nTrain/Testing TrlShuff Train1:%s Test1:%s | Train2:%s Test2:%s | Train3:%s Test3:%s TrlRng:%i Rep:%i CV:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),...
                                        obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond3{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond3{Cond}),TrlRng,rep,cvf);

                                    ClassifierOpts.CurrCVfold=cvf;

                                    PrepTimeTic=tic;
                                    isok=0;
                                    %% sample train and test trials
                                    while isok==0 % make sure we have enough trials for both categories in both dimensions
                                        % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                                        if strcmp(type,'TripleCrossCond')
                                            % grab random set of data for Dim 1
                                            [predictors ,response , TrainDataAllFactors,TestDataAllFactors,TrainStimInds,~,predictorsSpkCnt,TrainDataAllFactors3D,TestDataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                                ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,NewFactorDataTestDim1,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',0);
                                            % grab random set of data for Dim 2
                                            [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,Train2StimInds,~,predictors2SpkCnt,Train2DataAllFactors3D,Test2DataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                                ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,NewFactorDataTestDim2,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',2);
                                            % grab random set of data for Dim 3
                                            [predictors3,response3,Train3DataAllFactors, Test3DataAllFactors,Train3StimInds,~,predictors3SpkCnt,Train3DataAllFactors3D,Test3DataAllFactors3D]=...
                                                obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond3{Cond},...
                                                ClassifierOpts.TestCond3{Cond},FactorLevelComb,Cond,NewFactorDataTestDim3,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',3);
                                            % euqalize trials across conditions
                                            [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,ClassifierOpts]=obj.EqualizeTrialsAcrossConds(ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                                                response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                           
                                            if cvf==1 % if this is the first CVf then save the data since this is the data that has been copied
                                                % copy some of the data into ClassifierOpts for future use
                                                ClassifierOpts=obj.ManData.CopyVars2Struct(ClassifierOpts,'TrainStimInds',TrainStimInds,'Train2StimInds',Train2StimInds,'Train3StimInds',Train3StimInds,...
                                                    'TrainDataAllFactors',TrainDataAllFactors,'TestDataAllFactors',TestDataAllFactors,...
                                                    'Train2DataAllFactors',Train2DataAllFactors,'Test2DataAllFactors',Test2DataAllFactors,...
                                                    'Train3DataAllFactors',Train3DataAllFactors,'Test3DataAllFactors',Test3DataAllFactors);
                                            end
                                        end
                                        % if we are changing the distribution of train
                                        % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,1,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,2,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);

                                        [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                            Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                                            obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                            TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                                            predictors,predictors2,predictors3,response,response2,response3,3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt);
                                        
                                        % adjust the labels 
                                                [DataLabels_Train,DataLabels_Train_2ndD,DataLabels_Train_3ndD, DataLabels_Test,DataLabels_Test_2ndD,...
                                                    DataLabels_Test_3ndD, Levels_Train,Levels_2ndD_Train,Levels_3ndD_Train, ...
                                                    Levels_Test,Levels_2ndD_Test,Levels_3ndD_Test,response,response_2ndD,response_3ndD]=obj.AdjustClassifierLabels(ClassifierOpts,Cond,TrainDataAllFactors,Train2DataAllFactors,...
                                                    Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,response,response2,response3,TargetFactorsInd,TargetFactors_2ndDInd,TargetFactors_3ndDInd);
                                            
                                        if ((length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |... % test dim 2
                                                ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})) | ...
                                                ((length(unique(DataLabels_Train_3ndD))==1 | length(unique(DataLabels_Test_3ndD))==1 |... % test dim 3
                                                ~isempty(setdiff(unique(DataLabels_Train_3ndD)',Levels_3ndD_Train)) | ...
                                                ~isempty(setdiff(unique(DataLabels_Test_3ndD)',Levels_3ndD_Test))) & ...
                                                isnan(ClassifierOpts.One_Class_ResponseLbl3{Cond}))
                                            isok=0;
                                        else
                                            isok=1;
                                        end
                                    end

                                    %% if one of the dimensions has rule information then add mean activity to that
                                    [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=obj.AdjustMeanActivity4Rule(ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                                        predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                                        TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                                        TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors);

                                    PrepTimeToc=toc(PrepTimeTic);

                                    %% now train and test classifier(no shuffle in this stage at all)
                                    if ShuffObservedRound==0
                                        [ClassifierResults,ClassifierOpts]=obj.RunClassifier3D_Optimized(ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,0,NaN);

                                        %% run some preliminary subspace analysis as well in case we want to correlate with results
                                        SubspaceTimeTic=tic;
                                        if sum(strcmp(TargetFields,'Congruency')) & ~sum(ClassifierOpts.StimCongruency==12) & ~sum(ClassifierOpts.StimCongruency==1) & ClassifierOpts.RunPrelimSubspace==1
                                            for Dim=1:3
                                                % Run subspace analysis on different time points on the all dimensions
                                                eval(sprintf('[Subspace%s,~,~,~,FactorDataTiled] =obj.DiscoverSubspaces(cat(1,RunData.predictors%s{1},RunData.predictors%s{2}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s] =arrayfun(@(x) obj.CalculateAnglesBetSubspaces({Subspace%s.CondScore{1}{x} Subspace%s.CondScore{2}{x}},[]),1:AnalysisOpts.NTim);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{1}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace
                                                eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2]=arrayfun(@(x) obj.CalculateCompressionBetSubspaces(FactorDataTiled{2}(x)),1:AnalysisOpts.NTim);',DimTxt{Dim}));  % Calculates compression for each subspace

                                                % if we have any spike count classification that we need to do then do that
                                                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                                    % run geometry analysis for the third dimension
                                                    eval(sprintf('[Subspace%sSpkCnt{SpkCnt},~,~,~,FactorDataTiledSpkCnt{SpkCnt}] =obj.DiscoverSubspaces(cat(1,RunData.predictors%sSpkCnt{1}{SpkCnt},RunData.predictors%sSpkCnt{2}{SpkCnt}),ClassifierOpts,[Train%sDataAllFactors;Test%sDataAllFactors],[ones(1,size(RunData.predictors%s{1},1)) 2*ones(1,size(RunData.predictors%s{2},1))]);',DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim},DimTxt{Dim}));
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).PairAngled%s_SpkCntPrd%i,~,ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).CosTheta%s_SpkCntPrd%i] =obj.CalculateAnglesBetSubspaces({Subspace%sSpkCnt{SpkCnt}.CondScore{1}{1} Subspace%sSpkCnt{SpkCnt}.CondScore{2}{1}},[]);',DimTxt{Dim},SpkCnt,DimTxt{Dim},SpkCnt,DimTxt{Dim},DimTxt{Dim})); % calculates angles between the planes that are fit to each condition
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression1_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{1}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                    eval(sprintf('[ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Subspace%sCompression2_SpkCntPrd%i]= obj.CalculateCompressionBetSubspaces(FactorDataTiledSpkCnt{SpkCnt}{2}(1));',DimTxt{Dim},SpkCnt));  % Calculates compression for each subspace
                                                end
                                            end
                                        end
                                        SubspaceTimeToc=toc(SubspaceTimeTic);

                                        %% save test data
                                     %   if ~obj.CalShuff
                                            % save the factor data just keep ColorML and ShapeML reward Rule and response location
                                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors;%(:,FactorInds2Keep);%[CVTestDataAllFactors(:,1:5) mean(CVTestDataAllFactors(:,6:9,:),3)];
                                     %       ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors;%(:,FactorInds2Keep);%[CVTest2DataAllFactors(:,1:5) mean(CVTest2DataAllFactors(:,6:9,:),3)];
                                     %       ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors;%(:,FactorInds2Keep);%[CVTest3DataAllFactors(:,1:5) mean(CVTest3DataAllFactors(:,6:9,:),3)];
                                     %   end
                                        %% save this classifier result folds
                                        CVfoldResults(cvf)= ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep);
                                    end
                                    %% train and test of shuffled data
                                    if ShuffObservedRound==1 & obj.CalShuff % then shuffle training labels
                                        ShuffleRun=1; % are we shuffleing the trining data
                                        % RunData uses the same data for this run for the shuffle as well
                                        % [ClassifierResults_Shuffled]=obj.RunClassifier3D(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,repshuff,ClassifierOpts,RunData.predictors,RunData.response,RunData.predictors2,RunData.response_2ndD,RunData.predictors3,RunData.response_3ndD,...
                                        % RunData.predictorsSpkCnt,RunData.predictors2SpkCnt,RunData.predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);
                                        [ClassifierResults_Shuffled,ClassifierOpts]=obj.RunClassifier3D_Optimized(ClassifierResults_Shuffled,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                                            predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff);
                                        
                                        % because in learning conditions are usually equalized we don't save all of the dimensions for shuffle
                                        ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors;%(:,FactorInds2Keep);%[CVTestDataAllFactors(:,1:5) mean(CVTestDataAllFactors(:,6:9,:),3)];
                                    %    ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors;%(:,FactorInds2Keep);%[CVTest2DataAllFactors(:,1:5) mean(CVTest2DataAllFactors(:,6:9,:),3)];
                                    %    ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(rep).Test3DataAllFactors =Test3DataAllFactors;%(:,FactorInds2Keep);%[CVTest3DataAllFactors(:,1:5) mean(CVTest3DataAllFactors(:,6:9,:),3)];
                                  
                                        CVfoldResults_Shuffled(repshuff,cvf)= ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(rep);
                                        SubspaceTimeToc=0;
                                    end
                                    TocRepInnerTime=toc(PrepTimeTic);
                                    fprintf('** %s RepTime:%0.2f PrepTime:%0.2f SubSpcTime:%0.2f ',ShuffTxt,TocRepInnerTime,PrepTimeToc,SubspaceTimeToc);
                                end % loop on fold
                                FoldTimeToc=toc(FoldTimeTic);
                                fprintf(2,'\n*********Total Fold Time:%0.2f *******',FoldTimeToc);

                                %% take average of the values across CV folds
                                if ShuffObservedRound==0
                                    ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep)=obj.AverageCVfoldData(CVfoldResults(1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                end

                                if ShuffObservedRound==1 & obj.CalShuff
                                    %  for repshuff=1:ClassifierOpts.NrepShufperFold
                                    ClassifierResults_Shuffled(nCond).TrialRange(nTrlRng).Rep(repshuff,rep)=obj.AverageCVfoldData(CVfoldResults_Shuffled(repshuff,1:ClassifierOpts.nCVfold(nCond)),ClassifierOpts);
                                    %  end
                                end

                            end  % loop on repetition
                        end % loop on shuffle repetition
                    end % loop on ntrl range
                end
            end % loop on Cond

            if AnalysisOpts.GetOnlyShuffLabelsClassifier % if we are only saving shuffle label classifier
                ClassifierResults=[];
                obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuffLabel,'WantedDate','ALL');
                return
            end

            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            if ~obj.CalShuff
                % save off the variables( this is
                ExtraStrSave= ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
                obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL','SaveAnalysisOpts',0);
                if strcmp(ShuffTxt,'C1_') || isempty(ShuffTxt) % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL','SaveAnalysisOpts',0);
                end
            elseif obj.CalShuff
                ExtraStrSaveShuff=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                % if we have also calculated the shuffle save the shuffle data too
                % save both observed and shuffle in one fule
                obj.ManData.DeleteFile('Classifier',ExtraStrSaveShuff,1,'WantedDate','ALL');
                if ShuffObservedRound==1
                    obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0); % save shuffled results
                else % save observed
                    obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0); % save observed results
                end
                if strcmp(ShuffTxt,'Shuf_C1_') || isempty(ShuffTxt)    % if this is the first condition then save
                    obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSaveShuff,'WantedDate','ALL','SaveAnalysisOpts',0);
                end
            end
        end
      
        function [DataLabels_Train,DataLabels_Train_2ndD,DataLabels_Train_3ndD, DataLabels_Test,DataLabels_Test_2ndD,...
                DataLabels_Test_3ndD, Levels_Train,Levels_2ndD_Train,Levels_3ndD_Train, ...
                Levels_Test,Levels_2ndD_Test,Levels_3ndD_Test,response,response_2ndD,response_3ndD]=AdjustClassifierLabels(obj,ClassifierOpts,Cond,TrainDataAllFactors,Train2DataAllFactors,...
                Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                 response,response2,response3,TargetFactorsInd,TargetFactors_2ndDInd,TargetFactors_3ndDInd,varargin)

            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % get train and test labels for the first factor
            DataLabels_Train= TrainDataAllFactors(:,TargetFactorsInd);
            if isempty(ClassifierOpts.One_Class_ResponseLbl{Cond}) % if we are not doing one class
                DataLabels_Test = TestDataAllFactors(:,TargetFactorsInd);
            else
                DataLabels_Test = ClassifierOpts.One_Class_ResponseLbl{Cond}*ones(size(response{2}));
            end

            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                DataLabels_Train=obj.ManData.CategorizeMorphlevel(DataLabels_Train);    % categorize morph levels
                DataLabels_Test=obj.ManData.CategorizeMorphlevel(DataLabels_Test);    % categorize morph levels
            end
            response=[{DataLabels_Train} {DataLabels_Test}];

            % now get train/test data on the second factor as well
            DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
            if isempty(ClassifierOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
            else
                DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
            end

            % now get train/test data on the third factor as well
            DataLabels_Train_3ndD= Train3DataAllFactors(:,TargetFactors_3ndDInd);
            if isempty(ClassifierOpts.One_Class_ResponseLbl3{Cond}) % if we are not doing one class
                DataLabels_Test_3ndD = Test3DataAllFactors(:,TargetFactors_3ndDInd);
            else
                DataLabels_Test_3ndD = ClassifierOpts.One_Class_ResponseLbl3{Cond}*ones(size(response3{2}));
            end

            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
            end
            response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];

  %          if(sum(DataLabels_Train_2ndD==response2{1})~=length(DataLabels_Train_2ndD));error('error here');end

            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                DataLabels_Train_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_3ndD);    % categorize morph levels
                DataLabels_Test_3ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_3ndD);    % categorize morph levels
            end

            response_3ndD=[{DataLabels_Train_3ndD} {DataLabels_Test_3ndD}];
%            if(sum(DataLabels_Train_3ndD==response3{1})~=length(DataLabels_Train_3ndD));error('error here');end

            % check so that the labels are the same as what we have specificed for the first dimension
            if iscell(ClassifierOpts.Levels{1})
                Levels_Train=ClassifierOpts.Levels{1}{ClassifierOpts.TrainCond{Cond}==ClassifierOpts.Levels{2}};
                Levels_Test =ClassifierOpts.Levels{1}{ClassifierOpts.TestCond{Cond}==ClassifierOpts.Levels{2}};
            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                Levels_Train=[1 2];
                Levels_Test =[1 2];
            else
                Levels_Train=ClassifierOpts.Levels{1};
                Levels_Test =ClassifierOpts.Levels{1};
            end

            % check so that the labels are the same as what we have specificed for the second dimension
            if iscell(ClassifierOpts.Levels_2ndD{1})
                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                Levels_2ndD_Train=[1 2];
                Levels_2ndD_Test =[1 2];
            else
                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1};
            end

            % check so that the labels are the same as what we have specificed for the third dimension
            if iscell(ClassifierOpts.Levels_3ndD{1})
                Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TrainCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
                Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1}{ClassifierOpts.TestCond3{Cond}==ClassifierOpts.Levels_3ndD{2}};
            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_3ndD{1},'ColorML'))
                Levels_3ndD_Train=[1 2];
                Levels_3ndD_Test =[1 2];
            else
                Levels_3ndD_Train=ClassifierOpts.Levels_3ndD{1};
                Levels_3ndD_Test =ClassifierOpts.Levels_3ndD{1};
            end
        end
        function ClassifierOpts=DetermineDimCVspecs(obj,ClassifierOpts,varargin) % determines what is the CV specs of a classifier
             global AnalysisOpts
             obj=obj.ParseParams(varargin) ; %%Process optional inputs
             %% general description
             % loop on dimensions if the rules are the same and the trial
             % types are the same and trial ranges are the same then we can
             % do stratified cross validation otherwise we will do only resampling
             % of the test data 
             
             NConds=ClassifierOpts.NConds;
             if ClassifierOpts.UseCV==0
                 ClassifierOpts.nCVfold=1*ones(1,NConds);
                 ClassifierOpts.CVspecs=zeros(3,NConds);return
             end
             
             % determine the number of CV folds
             CVfold=arrayfun(@(x) (ClassifierOpts.ntrlPerCond{x}(1)+ClassifierOpts.ntrlPerCondTest{x}(1))/ClassifierOpts.ntrlPerCondTest{x}(1),1:3);
             if sum(diff(CVfold)>0);error('Number of CV folds per dimention should be equal');end
             ClassifierOpts.nCVfold=CVfold(1)*ones(1,NConds);
             if iscell(ClassifierOpts.LimFactorTrialName)
                 LimFactorTrialName=num2str(cell2mat(ClassifierOpts.LimFactorTrialName));
             else
                 LimFactorTrialName=num2str(ClassifierOpts.LimFactorTrialName);
             end
             % determine the type of cross validation we need to do             
             for Dim2ndFlag=[0 2 3]
                 [Levels,~,~,TrainCond,TestCond,DimTxt,~,~,~,~,~,DimNum]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);
                 for Cond=1:NConds
                     % check if the conditions are identical
                     if ~(contains(LimFactorTrialName,'Trl') & sum(ClassifierOpts.LimFactorTrialVal{Cond}==DimNum)~=0) & TrainCond{Cond}==TestCond{Cond} &  sum(ClassifierOpts.TrainTrlNumRange{Cond}==ClassifierOpts.TestTrlNumRange{Cond})==4 & ...
                             (isnan(ClassifierOpts.LimitFromSwitchPerf{Cond}(1))==isnan(ClassifierOpts.LimitFromSwitchPerf{Cond}(2)) |    ClassifierOpts.LimitFromSwitchPerf{Cond}(1)==ClassifierOpts.LimitFromSwitchPerf{Cond}(2)) & ...
                             (isnan(ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1})==isnan(ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2}) |    strcmp(ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1},ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2}))
                         ClassifierOpts.CVspecs(DimNum,Cond)=1;
                     else
                         ClassifierOpts.CVspecs(DimNum,Cond)=0;
                     end
                     if iscell(Levels);Levels=Levels{1};end
                     % generate trial structure for each dimension
                     ClassifierOpts.(['TrainTrlStruct' DimTxt]).Lvl=cell2mat(arrayfun(@(x) repmat(x,[1 sum(ClassifierOpts.ntrlPerCond{DimNum})]),Levels,'UniformOutput',0));
                     ClassifierOpts.(['TrainTrlStruct' DimTxt]).StimCong=repmat(cell2mat(arrayfun(@(x) repmat(x,[1 ClassifierOpts.ntrlPerCond{DimNum}(x)]),...
                         1:size(obj.StimCongruencyConds{ClassifierOpts.StimCongruency(DimNum)},obj.StimCongruencyTrialDim(ClassifierOpts.StimCongruency(DimNum))),'UniformOutput',0)),[1 length(Levels)]);
                  
                     ClassifierOpts.(['TestTrlStruct' DimTxt]).Lvl=cell2mat(arrayfun(@(x) repmat(x,[1 sum(ClassifierOpts.ntrlPerCondTest{DimNum})]),Levels,'UniformOutput',0));
                     ClassifierOpts.(['TestTrlStruct' DimTxt]).StimCong=repmat(cell2mat(arrayfun(@(x) repmat(x,[1 ClassifierOpts.ntrlPerCondTest{DimNum}(x)]),...
                         1:size(obj.StimCongruencyConds{ClassifierOpts.StimCongruency(DimNum)},obj.StimCongruencyTrialDim(ClassifierOpts.StimCongruency(DimNum))),'UniformOutput',0)),[1 length(Levels)]);                                                        
                 end
             end  
             % if all of our dimensions in this condition are different then increase the number of cross validation
             for Cond=1:NConds
                 if ~sum(ClassifierOpts.CVspecs(:,Cond))
                     ClassifierOpts.nCVfold(Cond)=ClassifierOpts.nCVfoldNoIdentical;
                 end
             end
        end
        function [ClassifierResults,ClassifierOpts,UsedData4Run]=RunClassifier3D(obj,ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff,varargin) % run classifier on the data 
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            ClassifierRunTime=tic;
            ExtraInput={'ThisClassifierCond',Cond}; % extra input we want to give to the classifer
            %% prepare data with respect to cross validation
            % if ~ShuffleRun % | (ShuffleRun & repshuff==1)
            [ClassifierOpts,predictors,response,predictorsSpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors,response,predictorsSpkCnt,0);
            [ClassifierOpts,predictors2,response_2ndD,predictors2SpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors2,response_2ndD,predictors2SpkCnt,2);
            [ClassifierOpts,predictors3,response_3ndD,predictors3SpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors3,response_3ndD,predictors3SpkCnt,3);
          %  end
            %% if this is a shuffle run
%             if ShuffleRun
%                 %                 response{1}=response{1}(randperm(numel(response{1})));
%                 %                 response_2ndD{1}=response_2ndD{1}(randperm(numel(response_2ndD{1})));
%                 %                 response_3ndD{1}=response_3ndD{1}(randperm(numel(response_3ndD{1})));
%                 response{1}=ClassifierOpts.ClassifierShuffleLabel{1}(1:numel(response{1}),repshuff);
%                 response_2ndD{1}=ClassifierOpts.ClassifierShuffleLabel{2}(1:numel(response_2ndD{1}),repshuff);
%                 response_3ndD{1}=ClassifierOpts.ClassifierShuffleLabel{3}(1:numel(response_3ndD{1}),repshuff);
%             end

            %% now train and test classifier
            if ClassifierOpts.RunCrossTemporalClassifer==0
                % train and test classifier on different time points
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed,~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                    response,ClassifierOpts,ExtraInput{:}),1:nXtimePnt,'UniformOutput',0);
                ClassifierOpts=ClassifierOpts{1};
                
                % train and test classifier on different time points on the second dimension
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_2ndD] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors2{1}(:,:,TrainTimInd(x))} {predictors2{2}(:,:,TestTimInd(x))}],...
                    response_2ndD,ClassifierOpts,ExtraInput{:}),1:nXtimePnt,'UniformOutput',0);
                
                % train and test classifier on different time points on the third dimension
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_3ndD] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors3{1}(:,:,TrainTimInd(x))} {predictors3{2}(:,:,TestTimInd(x))}],...
                    response_3ndD,ClassifierOpts,ExtraInput{:}),1:nXtimePnt,'UniformOutput',0);
                
                % if we have any spike count classification that we need to do then do that
                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                    % train and test classifier on different time points
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_SpkCntPrd' num2str(SpkCnt)])]      = obj.SVMClassifier_Binary([{predictorsSpkCnt{1}{SpkCnt}} {predictorsSpkCnt{2}{SpkCnt}}], response,ClassifierOpts,ExtraInput{:});
                    
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_2ndD_SpkCntPrd' num2str(SpkCnt)])] = obj.SVMClassifier_Binary([{predictors2SpkCnt{1}{SpkCnt}} {predictors2SpkCnt{2}{SpkCnt}}],...
                        response_2ndD,ClassifierOpts,ExtraInput{:});
                    
                    % train and test classifier on different time points on the third dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_3ndD_SpkCntPrd' num2str(SpkCnt)])] = obj.SVMClassifier_Binary([{predictors3SpkCnt{1}{SpkCnt}} {predictors3SpkCnt{2}{SpkCnt}}],...
                        response_3ndD,ClassifierOpts,ExtraInput{:});
                end
            %% Cross temporal classifier
            elseif ClassifierOpts.RunCrossTemporalClassifer==1
                % if we are running a cross temporal classificaiton then train on one point and test it on the rest
                ClassifierResults(nCond).Rep(rep).Observed=cell(1,nXtimePnt);
                for tTrain=1:TimeMatrixSize(1)
                    % first dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,tTrain)}],response,ClassifierOpts,'ThisClassifierCond',Cond);
                    % test this classifier on all of the time points of test
                    IndThisConds=arrayfun(@(x) find(TrainTimInd==tTrain & TestTimInd==x),1:TimeMatrixSize(2));
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed(IndThisConds),~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,x)}],...
                        response,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                    ClassifierOpts=ClassifierOpts{1};
                    
                    % second dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors2{1}(:,:,tTrain)} {predictors2{2}(:,:,tTrain)}],response_2ndD,ClassifierOpts,'ThisClassifierCond',Cond);
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_2ndD(IndThisConds)] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors2{1}(:,:,tTrain)} {predictors2{2}(:,:,x)}],...
                        response_2ndD,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                    
                    % train and test classifier on different time points on the third dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors3{1}(:,:,tTrain)} {predictors3{2}(:,:,tTrain)}],response_3ndD,ClassifierOpts,'ThisClassifierCond',Cond);
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_3ndD(IndThisConds)] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors3{1}(:,:,tTrain)} {predictors3{2}(:,:,x)}],...
                        response_3ndD,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                end
            end
            UsedData4Run=[];
            % output what data we have used for this run 
            UsedData4Run=obj.ManData.CopyVars2Struct(UsedData4Run,'predictors',predictors,'response',response,...
                'predictorsSpkCnt',predictorsSpkCnt,'predictors2',predictors2,'response_2ndD',response_2ndD,...
                'predictors2SpkCnt',predictors2SpkCnt,'predictors3',predictors3,'response_3ndD',response_3ndD,...
                'predictors3SpkCnt',predictors3SpkCnt);
            
            ClassifierRunTimeEnd=toc(ClassifierRunTime);
            fprintf(' Class Run Time:%0.2f',ClassifierRunTimeEnd);
        end
       
        
        
        function [ClassifierResults,ClassifierOpts,UsedData4Run]=RunClassifier3D_Optimized(obj,ClassifierResults,Cond,nCond,nTrlRng,rep,ClassifierOpts,predictors,response,predictors2,response_2ndD,predictors3,response_3ndD,...
                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize,ShuffleRun,repshuff,varargin) % run classifier on the data 
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            ClassifierRunTime=tic;
            ExtraInput={TrainTimInd,TestTimInd,nXtimePnt,'ThisClassifierCond',Cond}; % extra input we want to give to the classifer
            %% prepare data with respect to cross validation
            [ClassifierOpts,predictors,response,predictorsSpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors,response,predictorsSpkCnt,0);
            [ClassifierOpts,predictors2,response_2ndD,predictors2SpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors2,response_2ndD,predictors2SpkCnt,2);
            [ClassifierOpts,predictors3,response_3ndD,predictors3SpkCnt]=obj.GetCVfoldData(ClassifierOpts,Cond,predictors3,response_3ndD,predictors3SpkCnt,3);
         
            %% now train and test classifier
            if ClassifierOpts.RunCrossTemporalClassifer==0
                % train and test classifier on different time points
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed,~,ClassifierOpts] = obj.SVMClassifier_BinaryOptimized([{predictors{1}} {predictors{2}}],...
                    response,ClassifierOpts,ExtraInput{:});
                 
                % train and test classifier on different time points on the second dimension
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_2ndD] = obj.SVMClassifier_BinaryOptimized([{predictors2{1}} {predictors2{2}}],...
                    response_2ndD,ClassifierOpts,ExtraInput{:});
                
                % train and test classifier on different time points on the third dimension
                [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_3ndD] = obj.SVMClassifier_BinaryOptimized([{predictors3{1}} {predictors3{2}}],...
                    response_3ndD,ClassifierOpts,ExtraInput{:});
                
                % if we have any spike count classification that we need to do then do that
                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                    % train and test classifier on different time points
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_SpkCntPrd' num2str(SpkCnt)])]      = obj.SVMClassifier_BinaryOptimized([{predictorsSpkCnt{1}{SpkCnt}} {predictorsSpkCnt{2}{SpkCnt}}], response,ClassifierOpts,ExtraInput{:});
                    
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_2ndD_SpkCntPrd' num2str(SpkCnt)])] = obj.SVMClassifier_BinaryOptimized([{predictors2SpkCnt{1}{SpkCnt}} {predictors2SpkCnt{2}{SpkCnt}}],...
                        response_2ndD,ClassifierOpts,ExtraInput{:});
                    
                    % train and test classifier on different time points on the third dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_3ndD_SpkCntPrd' num2str(SpkCnt)])] = obj.SVMClassifier_BinaryOptimized([{predictors3SpkCnt{1}{SpkCnt}} {predictors3SpkCnt{2}{SpkCnt}}],...
                        response_3ndD,ClassifierOpts,ExtraInput{:});
                end
            %% Cross temporal classifier
            elseif ClassifierOpts.RunCrossTemporalClassifer==1
                % if we are running a cross temporal classificaiton then train on one point and test it on the rest
                ClassifierResults(nCond).Rep(rep).Observed=cell(1,nXtimePnt);
                for tTrain=1:TimeMatrixSize(1)
                    % first dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,tTrain)}],response,ClassifierOpts,'ThisClassifierCond',Cond);
                    % test this classifier on all of the time points of test
                    IndThisConds=arrayfun(@(x) find(TrainTimInd==tTrain & TestTimInd==x),1:TimeMatrixSize(2));
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed(IndThisConds),~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,tTrain)} {predictors{2}(:,:,x)}],...
                        response,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                    ClassifierOpts=ClassifierOpts{1};
                    
                    % second dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors2{1}(:,:,tTrain)} {predictors2{2}(:,:,tTrain)}],response_2ndD,ClassifierOpts,'ThisClassifierCond',Cond);
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_2ndD(IndThisConds)] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors2{1}(:,:,tTrain)} {predictors2{2}(:,:,x)}],...
                        response_2ndD,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                    
                    % train and test classifier on different time points on the third dimension
                    [~,~,~,ThisClassifier] = obj.SVMClassifier_Binary([{predictors3{1}(:,:,tTrain)} {predictors3{2}(:,:,tTrain)}],response_3ndD,ClassifierOpts,'ThisClassifierCond',Cond);
                    % train and test classifier on different time points on the second dimension
                    [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_3ndD(IndThisConds)] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors3{1}(:,:,tTrain)} {predictors3{2}(:,:,x)}],...
                        response_3ndD,ClassifierOpts,'UseThisClassifier',ThisClassifier,'ThisClassifierCond',Cond),1:TimeMatrixSize(2),'UniformOutput',0);
                end
            end
            UsedData4Run=[];
            % output what data we have used for this run 
            UsedData4Run=obj.ManData.CopyVars2Struct(UsedData4Run,'predictors',predictors,'response',response,...
                'predictorsSpkCnt',predictorsSpkCnt,'predictors2',predictors2,'response_2ndD',response_2ndD,...
                'predictors2SpkCnt',predictors2SpkCnt,'predictors3',predictors3,'response_3ndD',response_3ndD,...
                'predictors3SpkCnt',predictors3SpkCnt);
            
            ClassifierRunTimeEnd=toc(ClassifierRunTime);
            fprintf(' Class Run Time:%0.2f',ClassifierRunTimeEnd);
        end
       
        function [ClassifierOpts,predictors,response,predictorsSpkCnt]=GetCVfoldData(obj,ClassifierOpts,Cond,predictors,response,predictorsSpkCnt,Dim2ndFlag,varargin) % gets data for  cross validation fold for each dimension
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            [~,~,~,~,~,DimTxt,~,~,~,~,~,DimNum]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);
          
            if ClassifierOpts.UseCV==0;return;end % we are not doing stratified CV 
            
            % if this is the first fold then save it and return
            if ClassifierOpts.CurrCVfold==1
                ClassifierOpts.Dimpredictors{DimNum}=predictors;
                ClassifierOpts.Dimresponse{DimNum}=response;
                ClassifierOpts.DimpredictorsSpkCnt{DimNum}=predictorsSpkCnt;
                ClassifierOpts.UsedTrainTrials{DimNum}=[]; % initialze used trial trials

                % copy the Stimulus Indexes and Train and test data that are used 
                ClassifierOpts.DimTrainStimInds{DimNum}=ClassifierOpts.(['Train'  DimTxt 'StimInds']);
                ClassifierOpts.DimTrainStimInds{DimNum}=ClassifierOpts.(['Train'  DimTxt 'DataAllFactors']);
                ClassifierOpts.DimTrainStimInds{DimNum}=ClassifierOpts.(['Test'  DimTxt 'DataAllFactors']);
                return;
            end
            if ClassifierOpts.CVspecs(DimNum,Cond)==0 % then use the same predictors for training as the first fold
                predictors{1}=ClassifierOpts.Dimpredictors{DimNum}{1};
                response{1}=ClassifierOpts.Dimresponse{DimNum}{1};
                predictorsSpkCnt{1}=ClassifierOpts.DimpredictorsSpkCnt{DimNum}{1};
                return;
            end 
            %% if we are using the stratified space for this?            
            CurrTrainLvl=ClassifierOpts.(['TrainTrlStruct' DimTxt]).Lvl;
            CurrTrainStimCong=ClassifierOpts.(['TrainTrlStruct' DimTxt]).StimCong;
            CurrTestLvl=ClassifierOpts.(['TestTrlStruct' DimTxt]).Lvl;
            CurrTestStimCong=ClassifierOpts.(['TestTrlStruct' DimTxt]).StimCong;
            predictors=ClassifierOpts.Dimpredictors{DimNum};
            response=ClassifierOpts.Dimresponse{DimNum};
            predictorsSpkCnt=ClassifierOpts.DimpredictorsSpkCnt{DimNum};
            nTrainTrl=length(CurrTrainLvl); 
            % if not then sample from training data and save the sample numbers 
            for n=1:length(CurrTestLvl)
                % find a trial in train and replace this test trial with it
                TrialPool=find(CurrTrainLvl==CurrTestLvl(n) & CurrTrainStimCong==CurrTestStimCong(n));
                % remove already used trials from this
                TrialPool=setdiff(TrialPool,ClassifierOpts.UsedTrainTrials{DimNum});
                % now take one trial from this pool
                ThisTrial=TrialPool(1);
                ClassifierOpts.UsedTrainTrials{DimNum}=[ClassifierOpts.UsedTrainTrials{DimNum} ThisTrial];
                % now swap the data from training and testing 
                temp=predictors{1}(ThisTrial,:,:);
                predictors{1}(ThisTrial,:,:)=predictors{2}(n,:,:);
                predictors{2}(n,:,:)=temp;
                
                temp=response{1}(ThisTrial);
                response{1}(ThisTrial)=response{2}(n);
                response{2}(n)=temp;
                for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                    temp=predictorsSpkCnt{1}{SpkCnt}(ThisTrial,:);
                    predictorsSpkCnt{1}{SpkCnt}(ThisTrial,:)=predictorsSpkCnt{2}{SpkCnt}(n,:);
                    predictorsSpkCnt{2}{SpkCnt}(n,:)=temp;
                end
%                 if obj.CalShuff
%                     % do this swap for shuffle labels as well
%                     tempshuff=ClassifierOpts.ClassifierShuffleLabel{DimNum}(ThisTrial,:);
%                     ClassifierOpts.ClassifierShuffleLabel{DimNum}(ThisTrial,:)=ClassifierOpts.ClassifierShuffleLabel{DimNum}(n+nTrainTrl,:);
%                     ClassifierOpts.ClassifierShuffleLabel{DimNum}(n+nTrainTrl,:)=tempshuff;
%                 end
            end
        end
        function CVfoldResultsNew=AverageCVfoldData(obj,CVfoldResults,ClassifierOpts,varargin) % take average of the CV fold data for classifier results
             global AnalysisOpts
             obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
             if ClassifierOpts.UseCV==0;CVfoldResultsNew=CVfoldResults;return;end % we are not doing stratified CV 
              
             nCVfold=length(CVfoldResults); % how many folds we have run so far
             
             % search through the fields and see what fields we are taking an average 
             FieldNames=fieldnames(CVfoldResults);
             for f=1:length(FieldNames)
                 ThisField=FieldNames{f};
                 if contains(ThisField,'Observed')
                     nTim=length(CVfoldResults(1).(ThisField));
                     CellFeild=iscell(CVfoldResults(1).(ThisField));
                     if CellFeild
                         ObservedFields=fieldnames(CVfoldResults(1).(ThisField){1});
                     else
                         ObservedFields=fieldnames(CVfoldResults(1).(ThisField));
                     end
                     
                     for of=ObservedFields' % loop on fields
                         for n=1:nTim % loop on time
                             temp=[];
                             for cv=1:nCVfold % loop on cv
                                 if CellFeild
                                     temp=cat(3,CVfoldResults(cv).(ThisField){n}.(of{1}),temp);
                                 else
                                     temp=cat(3,CVfoldResults(cv).(ThisField).(of{1}),temp);
                                 end
                             end
                             if CellFeild
                                 CVfoldResultsNew.(ThisField){n}.(of{1})=mean(temp,3);
                             else
                                 CVfoldResultsNew.(ThisField).(of{1})=mean(temp,3);
                             end
                         end
                     end
                 elseif contains(ThisField,'AllFactors')
                     temp=[];
                     for cv=1:nCVfold
                         temp=cat(3,CVfoldResults(cv).(ThisField),temp);
                     end
                     if length(AnalysisOpts.FactorInds2KeepInd)>9;error('Update This code');end
                     CVfoldResultsNew.(ThisField)=[temp(:,AnalysisOpts.FactorInds2KeepInd(1:5),1) mean(temp(:,AnalysisOpts.FactorInds2KeepInd(6:9),:),3)];
                 else % then take an average across the CV reps
                     temp=mean(cell2mat(arrayfun(@(x) CVfoldResults(x).(ThisField)',1:nCVfold,'UniformOutput',0)),2)';
                     CVfoldResultsNew.(ThisField)=temp;
                 end
             end             
        end
        function CVfoldResultsNew=AverageRepData(obj,CVfoldResults,ClassifierOpts,varargin) % take average of the Reps fold data for classifier results
             global AnalysisOpts
             obj=obj.ParseParams(varargin) ; %%Process optional inputs
                          
             nCVfold=length(CVfoldResults); % how many folds we have run so far
             
             % search through the fields and see what fields we are taking an average 
             FieldNames=fieldnames(CVfoldResults);
             for f=1:length(FieldNames)
                 ThisField=FieldNames{f};
                 if contains(ThisField,'Observed')
                     nTim=length(CVfoldResults(1).(ThisField));
                     CellFeild=iscell(CVfoldResults(1).(ThisField));
                     if CellFeild
                         ObservedFields=fieldnames(CVfoldResults(1).(ThisField){1});
                     else
                         ObservedFields=fieldnames(CVfoldResults(1).(ThisField));
                     end
                     
                     for of=ObservedFields' % loop on fields
                         for n=1:nTim % loop on time
                             temp=[];
                             for cv=1:nCVfold % loop on cv
                                 if CellFeild
                                     temp=cat(3,CVfoldResults(cv).(ThisField){n}.(of{1}),temp);
                                 else
                                     temp=cat(3,CVfoldResults(cv).(ThisField).(of{1}),temp);
                                 end
                             end
                             if CellFeild
                                 CVfoldResultsNew.(ThisField){n}.(of{1})=mean(temp,3);
                             else
                                 CVfoldResultsNew.(ThisField).(of{1})=mean(temp,3);
                             end
                         end
                     end
                 elseif contains(ThisField,'AllFactors')
                     CVfoldResultsNew.(ThisField)=CVfoldResults(1).(ThisField);
                 else % then take an average across the CV reps
                     temp=mean(cell2mat(arrayfun(@(x) CVfoldResults(x).(ThisField)',1:nCVfold,'UniformOutput',0)),2)';
                     CVfoldResultsNew.(ThisField)=temp;
                 end
             end             
        end
        function [ClassifierResults,ClassifierOpts]=Run2DCrossTemporalClassiferAnalysis_DoubleCrossCond_Learning(obj,FactorData,FactorLevelComb,ClassifierOpts,varargin) % runs cross temporal classifier anlaysis for 2 simultanous features in two different cross conditions during learning
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % if this is a calculation of shuffled distribution then
            % prepare the data
            if obj.CalShuff
                ShuffTxt=sprintf('Shuf_C%i_',AnalysisOpts.CalShuffleClassifier_Cond);
                rng(AnalysisOpts.CalShuffleClassifier_Cond)
                ClassifierOpts.Nrep=ClassifierOpts.NrepShuf; % change the number of repetitions
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.CalShuffleClassifier_TrlRng(x),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.CalShuffleClassifier_TrlRng(x)),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondSet  =CondInds(AnalysisOpts.CalShuffleClassifier_Cond);
                TrlRngSet=TrlRngInds(AnalysisOpts.CalShuffleClassifier_Cond);
            elseif AnalysisOpts.DividSpockClassifier
                ShuffTxt=sprintf('C%i_',AnalysisOpts.DividSpockClassifier_Cond);
                rng(AnalysisOpts.DividSpockClassifier_Cond);
                % decode which condition and trial range we are
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockClassifier_TrlRng(x),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockClassifier_TrlRng(x)),1:length(ClassifierOpts.TrainCond),'UniformOutput',0));
                CondSet  =CondInds(AnalysisOpts.DividSpockClassifier_Cond);
                TrlRngSet=TrlRngInds(AnalysisOpts.DividSpockClassifier_Cond);
            else
                ShuffTxt='';
                CondSet=1:length(ClassifierOpts.TrainCond);
            end
            
            % now create a mesh of time points and run classifier train and test repectively
            [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);
            
            % apply neuron dropping algorithm
            [FactorDataBuff,IncludedNeurons,ClassifierOpts]=obj.ApplyNeuronDroppingAlgorithm4LearningAnlaysis(FactorData,ClassifierOpts,FactorLevelComb);
            
            ClassifierOpts.typebuff=ClassifierOpts.type; % take a copy of t
            % now get the classifer performance per crosstime point
            for nCond=1:length(CondSet) % loop on conditions
                Cond=CondSet(nCond);
                % if there is SeqHist you should consider them first
                if sum(ClassifierOpts.StimCongruency==9) || sum(ClassifierOpts.StimCongruency==10) || sum(ClassifierOpts.StimCongruency==13) || sum(ClassifierOpts.StimCongruency==14) || sum(ClassifierOpts.StimCongruency==15)
                    obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                if ~(obj.CalShuff |AnalysisOpts.DividSpockClassifier) ;TrlRngSet=1:nXTrlPnt;end
                
                for nTrlRng=1:length(TrlRngSet)
                    TrlRng=TrlRngSet(nTrlRng);
                    
                    ThisTrainTrialRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrialRange=TestTrlRange{TestTrlInd(TrlRng)};
                    
                    % now limit factor data trials to these trial range we want
                    % generate factor data for training
                    FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrialRange);
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrialRange);
                    
                    % if we are limitign based on block performance then
                    if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                    
                    for rep=1:ClassifierOpts.Nrep        % loop on repetition per condition
                        %    waitbar(rep/ClassifierOpts.Nrep,f,sprintf('repetition:%i',rep))
                        fprintf('\nTrain/Testing Classfier on Condition Train1:%s Test1:%s | Train2:%s Test2:%s TrlRng:%i Rep:%i',obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                            obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond}),TrlRng,rep);
                        isok=0;
                        while isok==0 % make sure we have enough trials for both categories in both dimensions
                            % grab a second set of random data we will use the test data of this set of the second dimension but keep the training data from first set
                            if ~strcmp(type,'SameCond')
                                % grab random set of data
                                [predictors ,response , TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},...
                                    ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange);
                                
                                [predictors2,response2,Train2DataAllFactors, Test2DataAllFactors,~,~,predictors2SpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond2{Cond},...
                                    ClassifierOpts.TestCond2{Cond},FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,'LookatDim2',1);
                                
                                % if we are using the same dataset for training in both dimensions then match the trials
                                if ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.TrainCond{Cond}
                                    if sum(ClassifierOpts.TestCond{Cond}==ClassifierOpts.TrainCond{Cond})
                                        predictors2{1}=predictors{1};
                                        response2{1}=response{1};
                                        Train2DataAllFactors=TrainDataAllFactors;
                                        if ~isempty(ClassifierOpts.SpkCountPeriod)
                                            predictors2SpkCnt{1}=predictorsSpkCnt{1};
                                        end
                                    else
                                        predictors{1}=predictors2{1};
                                        response{1}=response2{1};
                                        TrainDataAllFactors=Train2DataAllFactors;
                                        if ~isempty(ClassifierOpts.SpkCountPeriod)
                                            predictorsSpkCnt{1}=predictors2SpkCnt{1};
                                        end
                                    end
                                end
                                
                                if ClassifierOpts.TestCond2{Cond}==ClassifierOpts.TestCond{Cond}
                                    if sum(ClassifierOpts.TestCond{Cond}==ClassifierOpts.TrainCond2{Cond}) % if we have a condition in which train=3/2 and test=2/2 then we make sure we use different sets for train and test
                                        predictors{2}=predictors2{2};
                                        response{2}=response2{2};
                                        TestDataAllFactors=Test2DataAllFactors;
                                        if ~isempty(ClassifierOpts.SpkCountPeriod)
                                            predictorsSpkCnt{2}=predictors2SpkCnt{2};
                                        end
                                    else
                                        predictors2{2}=predictors{2};
                                        response2{2}=response{2};
                                        Test2DataAllFactors=TestDataAllFactors;
                                        if ~isempty(ClassifierOpts.SpkCountPeriod)
                                            predictors2SpkCnt{2}=predictorsSpkCnt{2};
                                        end
                                    end
                                end
                            elseif strcmp(type,'SameCond') % if we are testing the same condition then take data from the same condition
                                % grab random set of data
                                [predictors,response, TrainDataAllFactors,TestDataAllFactors,~,~,predictorsSpkCnt]=...
                                    obj.GrabThisRepClassifierData(FactorData,ClassifierOpts,ClassifierOpts.TrainCond{Cond},ClassifierOpts.TestCond{Cond},FactorLevelComb,Cond,FactorData,ThisTrainTrialRange,ThisTestTrialRange);
                                
                                predictors2=predictors;
                                response2=response;
                                Train2DataAllFactors=TrainDataAllFactors;
                                Test2DataAllFactors=TestDataAllFactors;
                                if ~isempty(ClassifierOpts.SpkCountPeriod)
                                    predictors2SpkCnt=predictorsSpkCnt;
                                end
                            end
                            % if we are changing the distribution of train
                            % and test trials for example for  congruency test train on congruent  test on incongruent or vice versa)
                            [TrainDataAllFactors,Train2DataAllFactors,TestDataAllFactors,Test2DataAllFactors,predictors,predictors2,response,response2]=...
                                obj.LimitLearningTrainTestTrialsWithFactor(ClassifierOpts,Cond,...
                                TrainDataAllFactors,Train2DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                                predictors,predictors2,response,response2);
                            
                            if ~obj.CalShuff
                                % save the factor data
                                FactorInds2Keep=[1:2];% 10:35]; % just keep ColorML and ShapeML data
                               % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TrainDataAllFactors =TrainDataAllFactors(:,FactorInds2Keep);
                                ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).TestDataAllFactors  =TestDataAllFactors(:,FactorInds2Keep);
                               % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Train2DataAllFactors=Train2DataAllFactors(:,FactorInds2Keep);
                                ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Test2DataAllFactors =Test2DataAllFactors(:,FactorInds2Keep);
                            end
                            
                            % now get train/test data on the second factor as well
                            TargetFactors_2ndDInd=obj.GetFactornameInd(ClassifierOpts.TargetFactors_2ndD{1});
                            DataLabels_Train_2ndD= Train2DataAllFactors(:,TargetFactors_2ndDInd);
                            if isempty(ClassifierOpts.One_Class_ResponseLbl2{Cond}) % if we are not doing one class
                                DataLabels_Test_2ndD = Test2DataAllFactors(:,TargetFactors_2ndDInd);
                            else
                                DataLabels_Test_2ndD = ClassifierOpts.One_Class_ResponseLbl2{Cond}*ones(size(response2{2}));
                            end
                            
                            % if strcmp(ClassifierOpts.TargetFactors{1},'ColorCat') & strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ResponseLoc')
                            % % flip response direction for rules
                            %   DataLabels_Train_2ndD=obj.ManData.FlipRepDirection(DataLabels_Train_2ndD);
                            %   DataLabels_Test_2ndD=obj.ManData.FlipRepDirection(DataLabels_Test_2ndD);
                            %end
                            
                            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                DataLabels_Train_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Train_2ndD);    % categorize morph levels
                                DataLabels_Test_2ndD=obj.ManData.CategorizeMorphlevel(DataLabels_Test_2ndD);    % categorize morph levels
                            end
                            response_2ndD=[{DataLabels_Train_2ndD} {DataLabels_Test_2ndD}];
                            
                            % check so that the labels are the same as what we have specificed for the second dimension
                            if iscell(ClassifierOpts.Levels_2ndD{1})
                                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TrainCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1}{ClassifierOpts.TestCond2{Cond}==ClassifierOpts.Levels_2ndD{2}};
                            elseif contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors_2ndD{1},'ColorML'))
                                Levels_2ndD_Train=[1 2];
                                Levels_2ndD_Test =[1 2];
                            else
                                Levels_2ndD_Train=ClassifierOpts.Levels_2ndD{1};
                                Levels_2ndD_Test =ClassifierOpts.Levels_2ndD{1};
                            end
                            
                            if (length(unique(DataLabels_Train_2ndD))==1 | length(unique(DataLabels_Test_2ndD))==1 |...
                                    ~isempty(setdiff(unique(DataLabels_Train_2ndD)',Levels_2ndD_Train)) | ...
                                    ~isempty(setdiff(unique(DataLabels_Test_2ndD)',Levels_2ndD_Test))) & ...
                                    isnan(ClassifierOpts.One_Class_ResponseLbl2{Cond})
                                isok=0;
                            else
                                isok=1;
                            end
                        end
                        
                        if obj.CalShuff % shuffle training data
                            response{1}=response{1}(randperm(numel(response{1})));
                            response_2ndD{1}=response_2ndD{1}(randperm(numel(response_2ndD{1})));
                        else
                            % calculate intrinsic dimensionality of train and test data combined as well
                            ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).no_IDdims=obj.CalculateIntrinsicDimensionality(cat(1,predictors{1},predictors{2}),'PCAExpVar');
                        end
                        
                        % train and test classifier on different time points
                        [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed,~,ClassifierOpts] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors{1}(:,:,TrainTimInd(x))} {predictors{2}(:,:,TestTimInd(x))}],...
                            response,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                        ClassifierOpts=ClassifierOpts{1};
                        
                        % train and test classifier on different time points on the second dimension
                        [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).Observed_2ndD] = arrayfun(@(x) obj.SVMClassifier_Binary([{predictors2{1}(:,:,TrainTimInd(x))} {predictors2{2}(:,:,TestTimInd(x))}],...
                            response_2ndD,ClassifierOpts),1:nXtimePnt,'UniformOutput',0);
                        
                        % if we have any spike count classification that we need to do then do that
                        for SpkCnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                            % train and test classifier on different time points
                            [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_SpkCntPrd' num2str(SpkCnt)])]      = obj.SVMClassifier_Binary([{predictorsSpkCnt{1}{SpkCnt}} {predictorsSpkCnt{2}{SpkCnt}}], response,ClassifierOpts);
                            
                            % train and test classifier on different time points on the second dimension
                            [ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).(['Observed_2ndD_SpkCntPrd' num2str(SpkCnt)])] = obj.SVMClassifier_Binary([{predictors2SpkCnt{1}{SpkCnt}} {predictors2SpkCnt{2}{SpkCnt}}],...
                                response_2ndD,ClassifierOpts);
                        end
                        
                        % copy train/test data
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).trainingPredictors   = predictors{1};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).trainingResponse     = response{1};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).validationPredictors = predictors{2};
                        % ClassifierResults(nCond).TrialRange(nTrlRng).Rep(rep).validationResponse   = response{2};
                    end
                end
            end
            
            ClassifierOpts.AnalysisOpts=AnalysisOpts;
            % save off the variables
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',...
                ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',...
                ['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedDate','ALL');
        end
        function [TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,...
                Test3DataAllFactors,predictors,predictors2,predictors3,response,response2,response3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=...
                LimitLearningTrainTestTrialsWithFactor(obj,ClassifierOpts,Cond,...
                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                predictors,predictors2,predictors3,response,response2,response3,LimitFactorValNum,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt)
            % if you want to limit a factor you NEED to include the name of
            % the factor in the name of classifier test
            % this function limits the train and test trails based on
            % value of a specific factor 
            %@LimiFactorName: Name of the factor ,@LimiFactorVal=[a b] a is
            %value for train and b is value for test
            %@ LimitFactorValNum is the dimension for this factor
            global AnalysisOpts
           
            DimTxtSet=[0 2 3];DimTxt={'','2','3'};
            if ~isfield(ClassifierOpts,['LimFactorTrialVal' num2str(DimTxt{LimitFactorValNum})]);return;end
            eval(sprintf('LimiFactorVal=ClassifierOpts.LimFactorTrialVal%s{Cond};',DimTxt{LimitFactorValNum}));
            eval(sprintf('ClassifierOpts.LimFactorTrialName=ClassifierOpts.LimFactorTrialName%s;',DimTxt{LimitFactorValNum}));
           
            if isnan(LimiFactorVal);return;end
            
            if contains(ClassifierOpts.Name,'Congruency')
                FactorInd=ClassifierOpts.Congruency.Ind;
                % change the train and test data
                TrainFactorVal=LimiFactorVal(1);TestFactorVal=LimiFactorVal(2);   
                Dim2Change=1:3;
            elseif contains(ClassifierOpts.Name,'Abstract')
                FactorInd=ClassifierOpts.(ClassifierOpts.TargetFactors{1}).Ind;
                % change the train and test data
                % randomly choose two morph levels for training and one for testing                 
                TrainFactorVal=[randsample([170 0 30],2) randsample([70 100 130],2) ];
                TestFactorVal=setdiff(AnalysisOpts.StimulusMorphLevelsNo50,TrainFactorVal);
                Dim2Change=1:3;
            elseif strcmp(ClassifierOpts.LimFactorTrialName,'CorrectTrls')
                FactorInd=ClassifierOpts.Reward.Ind;
                TrainFactorVal=1;TestFactorVal=1; % only take correct trials
                Dim2Change=LimiFactorVal;   
            elseif strcmp(ClassifierOpts.LimFactorTrialName,'CorrectTrlsTrainIncorTrlsTest') % keep correct trials at the train but change the test
                FactorInd=ClassifierOpts.Reward.Ind;
                TrainFactorVal=1;TestFactorVal=0; % only take correct trials for train and keep incorrect for test
                Dim2Change=LimiFactorVal;
            elseif strcmp(ClassifierOpts.LimFactorTrialName,'AllTrlsTrainIncorTrlsTest') % keep all trials at the train but change the test
                FactorInd=ClassifierOpts.Reward.Ind;
                TrainFactorVal=[0 1];TestFactorVal=0; % only take all trials for train and keep incorrect for test
                Dim2Change=LimiFactorVal;
             elseif strcmp(ClassifierOpts.LimFactorTrialName,'AllTrlsTrainCorrTrlsTest') % keep all trials at the train but change the test
                FactorInd=ClassifierOpts.Reward.Ind;
                TrainFactorVal=[0 1];TestFactorVal=1; % only take all trials for train and keep correct for test
                Dim2Change=LimiFactorVal;    
            end

            %% start removing trials for each dimension
            for Dim=Dim2Change % which dimensions we are working on
                [~,~,~,~,~,DimTxt,TestFactorTxt,TrainFactorTxt]=obj.getClassifierDimInfo(ClassifierOpts,DimTxtSet(Dim));
                eval(sprintf('DataExist4Dim=~isempty(%s);',TrainFactorTxt)); % check if we have data for this dim
                if DataExist4Dim
                    eval(sprintf('TrainInd=obj.ManData.FindValsinMat(%s(:,FactorInd),TrainFactorVal);',TrainFactorTxt));
                    eval(sprintf('TestInd=obj.ManData.FindValsinMat(%s(:,FactorInd),TestFactorVal);',TestFactorTxt));
                    
                    eval(sprintf('%s=%s(TrainInd,:);',TrainFactorTxt,TrainFactorTxt));
                    eval(sprintf('%s=%s(TestInd,:);',TestFactorTxt,TestFactorTxt));
                    eval(sprintf('predictors%s=[{predictors%s{1}(TrainInd,:,:)} {predictors%s{2}(TestInd,:,:)}];',DimTxt,DimTxt,DimTxt));
                    eval(sprintf('response%s=[{response%s{1}(TrainInd,:,:)} {response%s{2}(TestInd,:,:)}];',DimTxt,DimTxt,DimTxt));
                
                    if ~isempty(ClassifierOpts.SpkCountPeriod)
                        for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                             eval(sprintf('predictors%sSpkCnt{1}{i}=[predictors%sSpkCnt{1}{i}(TrainInd,:,:)];',DimTxt,DimTxt));
                             eval(sprintf('predictors%sSpkCnt{2}{i}=[predictors%sSpkCnt{2}{i}(TestInd,:,:)];',DimTxt,DimTxt));
                        end
                    end
                
                end
            end
                
        end
        function [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=GetTrialRangeforThisCond(obj,ClassifierOpts,Cond,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            TrainTrlRange=obj.ManData.GenMovingInds(ClassifierOpts.TrainTrlNumRange{Cond}(1),ClassifierOpts.TrainTrlNumRange{Cond}(2),ClassifierOpts.TrainTrlNumRange{Cond}(3),ClassifierOpts.TrainTrlNumRange{Cond}(4));
            TestTrlRange =obj.ManData.GenMovingInds(ClassifierOpts.TestTrlNumRange{Cond}(1),ClassifierOpts.TestTrlNumRange{Cond}(2),ClassifierOpts.TestTrlNumRange{Cond}(3),ClassifierOpts.TestTrlNumRange{Cond}(4));
            TrlNumMatrixSize=[length(TrainTrlRange) length(TestTrlRange)];
            nXTrlPnt=TrlNumMatrixSize(1)*TrlNumMatrixSize(2);
            [TrainTrlInd,TestTrlInd]=ind2sub(TrlNumMatrixSize,1:nXTrlPnt);
        end
        function [predictors,predictors2,predictors3,response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,ClassifierOpts]=EqualizeTrialsAcrossConds(obj,ClassifierOpts,Cond,predictors,predictors2,predictors3,...
                response,response2,response3,TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors,...
                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,varargin)
            % checks if we need to copy and paste train and test trials
            % across dimensions to make sure there are no overlapping
            % trials 
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
           
            if ClassifierOpts.EqualizeTrialsXConds==0
                ClassifierOpts.DupTrainTestDimSource{1}=1; % what is the dimension where we have copied the data for Train Test
                ClassifierOpts.DupTrainTestDimSource{2}=2; % what is the dimension where we have copied the data for Train Test
                ClassifierOpts.DupTrainTestDimSource{3}=3; % what is the dimension where we have copied the data for Train Test
                ClassifierOpts.DupTrainTestDimTarget={};% nowhere is this data being copied
                return;
            end % we don't need to equalize

            % look at the shared rule in training
            TrainCondsAll=[ClassifierOpts.TrainCond(Cond) ClassifierOpts.TrainCond2(Cond) ClassifierOpts.TrainCond3(Cond)];
            TestCondsAll =[ClassifierOpts.TestCond(Cond) ClassifierOpts.TestCond2(Cond) ClassifierOpts.TestCond3(Cond)];
            % see if there are duplicates in Training conditions
            RuleInd=obj.GetFactornameInd('Rule');
            DimTxt={'','2','3'};
            [DupTrain,~,UniqTrain,NDupTrain,DupLocTrain,nRuleTrain]=obj.ManData.FindDuplicateVals(TrainCondsAll);
            [DupTest,~,UniqTest,NDupTest,DupLocTest,nRuleTest]=obj.ManData.FindDuplicateVals(TestCondsAll);
            % for train and test duplicates look at each train and test condition
            DupTrainTest=(arrayfun(@(x) unique(TrainCondsAll{x}(TrainCondsAll{x}==TestCondsAll{x})),1:3,'UniformOutput',0));
            DupTrainTest=cell2mat(DupTrainTest(~cellfun(@isempty,DupTrainTest)));
            NDupTrainTest=length(DupTrainTest);
            %[DupTrainTest,~,~,NDupTrainTest]=obj.ManData.FindDuplicateVals({[UniqTest ;UniqTrain]});%([TrainCondsAll TestCondsAll]);
            ClassifierOpts.DupTrain=DupTrain;ClassifierOpts.DupTest=DupTest;ClassifierOpts.DupTrainTest=DupTrainTest;
            % now based on the shared conditions copy and paste data around
            if NDupTrain & ~NDupTest & ~NDupTrainTest % shared train rule: copy this shared rule across all conditions
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainOnly(Cond)
                    for n=1:NDupTrain
                        ThisTrainDataFactors=[];ThisTargTrainDataFactors=[];
                        ThisDupLoc=DupLocTrain{n};
                        nCond=find(ThisDupLoc,1,'first');
                        eval(sprintf('ThisTrainDataFactors=Train%sDataAllFactors;',DimTxt{nCond}));
                        ThisTrainTrials=ThisTrainDataFactors(:,RuleInd)==DupTrain(n);
                        % now copy the data into others
                        for on=setdiff(find(ThisDupLoc),nCond)
                            eval(sprintf('ThisTargTrainDataFactors=Train%sDataAllFactors;',DimTxt{on}));
                            ThisTargTrainTrials=ThisTargTrainDataFactors(:,RuleInd)==DupTrain(n);
                            eval(sprintf('predictors%s{1}(ThisTargTrainTrials,:,:)=predictors%s{1}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('response%s{1}(ThisTargTrainTrials)=response%s{1}(ThisTrainTrials);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('Train%sDataAllFactors(ThisTargTrainTrials,:)=Train%sDataAllFactors(ThisTrainTrials,:);',DimTxt{on},DimTxt{nCond}));
                            if ~isempty(ClassifierOpts.SpkCountPeriod)
                                for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    eval(sprintf('predictors%sSpkCnt{1}{i}(ThisTargTrainTrials,:,:)=predictors%sSpkCnt{1}{i}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                end
                            end
                        end
                    end
                end
                
            elseif ~NDupTrain & NDupTest & ~NDupTrainTest % shared test rule: copy this shared rule across all conditions
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTestOnly(Cond)
                    for n=1:NDupTest
                        ThisTestDataFactors=[];ThisTargTestDataFactors=[];
                        ThisDupLoc=DupLocTest{n};
                        nCond=find(ThisDupLoc,1,ClassifierOpts.EqualizeTrials4Conds.DupTestOrder);
                        eval(sprintf('ThisTestDataFactors=Test%sDataAllFactors;',DimTxt{nCond}));
                        ThisTestTrials=ThisTestDataFactors(:,RuleInd)==DupTest(n);
                        % now copy the data into others
                        for on=setdiff(find(ThisDupLoc),nCond)
                            eval(sprintf('ThisTargTestDataFactors=Test%sDataAllFactors;',DimTxt{on}));
                            ThisTargTestTrials=ThisTargTestDataFactors(:,RuleInd)==DupTest(n);
                            eval(sprintf('predictors%s{2}(ThisTargTestTrials,:,:)=predictors%s{2}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('response%s{2}(ThisTargTestTrials)=response%s{2}(ThisTestTrials);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('Test%sDataAllFactors(ThisTargTestTrials,:)=Test%sDataAllFactors(ThisTestTrials,:);',DimTxt{on},DimTxt{nCond}));
                            if ~isempty(ClassifierOpts.SpkCountPeriod)
                                for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    eval(sprintf('predictors%sSpkCnt{2}{i}(ThisTargTestTrials,:,:)=predictors%sSpkCnt{2}{i}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                end
                            end
                        end
                    end
                end
            elseif NDupTrain & NDupTest & ~NDupTrainTest   % shared test rule, shared train rule, no shared train and test rules
                
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainOnly(Cond)
                    % take care of train duplicates
                    for n=1:NDupTrain
                        ThisTrainDataFactors=[];ThisTargTrainDataFactors=[];
                        ThisDupLoc=DupLocTrain{n};
                        nCond=find(ThisDupLoc,1,'first');
                        eval(sprintf('ThisTrainDataFactors=Train%sDataAllFactors;',DimTxt{nCond}));
                        ThisTrainTrials=ThisTrainDataFactors(:,RuleInd)==DupTrain(n);
                        % now copy the data into others
                        for on=setdiff(find(ThisDupLoc),nCond)
                            eval(sprintf('ThisTargTrainDataFactors=Train%sDataAllFactors;',DimTxt{on}));
                            ThisTargTrainTrials=ThisTargTrainDataFactors(:,RuleInd)==DupTrain(n);
                            eval(sprintf('predictors%s{1}(ThisTargTrainTrials,:,:)=predictors%s{1}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('response%s{1}(ThisTargTrainTrials)=response%s{1}(ThisTrainTrials);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('Train%sDataAllFactors(ThisTargTrainTrials,:)=Train%sDataAllFactors(ThisTrainTrials,:);',DimTxt{on},DimTxt{nCond}));
                            if ~isempty(ClassifierOpts.SpkCountPeriod)
                                for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    eval(sprintf('predictors%sSpkCnt{1}{i}(ThisTargTrainTrials,:,:)=predictors%sSpkCnt{1}{i}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                end
                            end
                        end
                    end
                end
                % take care of test duplicates
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTestOnly(Cond)
                    for n=1:NDupTest
                        ThisTestDataFactors=[];ThisTargTestDataFactors=[];
                        ThisDupLoc=DupLocTest{n};
                        nCond=find(ThisDupLoc,1,ClassifierOpts.EqualizeTrials4Conds.DupTestOrder);
                        eval(sprintf('ThisTestDataFactors=Test%sDataAllFactors;',DimTxt{nCond}));
                        ThisTestTrials=ThisTestDataFactors(:,RuleInd)==DupTest(n);
                        % now copy the data into others
                        for on=setdiff(find(ThisDupLoc),nCond)
                            eval(sprintf('ThisTargTestDataFactors=Test%sDataAllFactors;',DimTxt{on}));
                            ThisTargTestTrials=ThisTargTestDataFactors(:,RuleInd)==DupTest(n);
                            eval(sprintf('predictors%s{2}(ThisTargTestTrials,:,:)=predictors%s{2}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('response%s{2}(ThisTargTestTrials)=response%s{2}(ThisTestTrials);',DimTxt{on},DimTxt{nCond}));
                            eval(sprintf('Test%sDataAllFactors(ThisTargTestTrials,:)=Test%sDataAllFactors(ThisTestTrials,:);',DimTxt{on},DimTxt{nCond}));
                            if ~isempty(ClassifierOpts.SpkCountPeriod)
                                for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    eval(sprintf('predictors%sSpkCnt{2}{i}(ThisTargTestTrials,:,:)=predictors%sSpkCnt{2}{i}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                end
                            end
                        end
                    end
                end
            elseif NDupTrainTest% shared test train rule : copy from the condition where there is shared train and test to all the rest conditions
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTrainTest(Cond)
                    for n=1:NDupTrainTest
                        ThisTrainDataFactors=[];ThisTestDataFactors=[];ThisTargTrainDataFactors=[];ThisTargTestDataFactors=[];
                        % replace training and test
                        ThisDupLoc=cellfun(@(x) logical(sum(x==DupTrainTest(n))),TrainCondsAll) & cellfun(@(x) logical(sum(x==DupTrainTest(n))),TestCondsAll);
                        nCond=find(ThisDupLoc,1,ClassifierOpts.EqualizeTrials4Conds.DupTrainTestOrder);
                        %%% take care of trackign which data has been used for train and test so we don't mix them 
                        ClassifierOpts.DupTrainTestDimSource{n}=nCond; % what is the dimension where we have copied the data for Train Test
                        ClassifierOpts.DupTrainTestDimTarget{n}=setdiff(find(ThisDupLoc),nCond);% where is this data being copied
                        %%%
                        eval(sprintf('ThisTrainDataFactors=Train%sDataAllFactors;',DimTxt{nCond}));
                        ThisTrainTrials=ThisTrainDataFactors(:,RuleInd)==DupTrainTest(n);
                        eval(sprintf('ThisTestDataFactors=Test%sDataAllFactors;',DimTxt{nCond}));
                        ThisTestTrials=ThisTestDataFactors(:,RuleInd)==DupTrainTest(n);
                        % now copy the data into others
                        for on=setdiff(1:length(ThisDupLoc),nCond)
                            % copy training data
                            eval(sprintf('ThisTargTrainDataFactors=Train%sDataAllFactors;',DimTxt{on}));
                            ThisTargTrainTrials=ThisTargTrainDataFactors(:,RuleInd)==DupTrainTest(n);
                            if sum(ThisTargTrainTrials)
                                eval(sprintf('predictors%s{1}(ThisTargTrainTrials,:,:)=predictors%s{1}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('response%s{1}(ThisTargTrainTrials)=response%s{1}(ThisTrainTrials);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('Train%sDataAllFactors(ThisTargTrainTrials,:)=Train%sDataAllFactors(ThisTrainTrials,:);',DimTxt{on},DimTxt{nCond}));
                                if ~isempty(ClassifierOpts.SpkCountPeriod)
                                    for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        eval(sprintf('predictors%sSpkCnt{1}{i}(ThisTargTrainTrials,:,:)=predictors%sSpkCnt{1}{i}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                    end
                                end
                            end
                            % copy test data
                            eval(sprintf('ThisTargTestDataFactors=Test%sDataAllFactors;',DimTxt{on}));
                            ThisTargTestTrials=ThisTargTestDataFactors(:,RuleInd)==DupTrainTest(n);
                            if sum(ThisTargTestTrials)
                                eval(sprintf('predictors%s{2}(ThisTargTestTrials,:,:)=predictors%s{2}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('response%s{2}(ThisTargTestTrials)=response%s{2}(ThisTestTrials);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('Test%sDataAllFactors(ThisTargTestTrials,:)=Test%sDataAllFactors(ThisTestTrials,:);',DimTxt{on},DimTxt{nCond}));
                                if ~isempty(ClassifierOpts.SpkCountPeriod)
                                    for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        eval(sprintf('predictors%sSpkCnt{2}{i}(ThisTargTestTrials,:,:)=predictors%sSpkCnt{2}{i}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                    end
                                end
                            end
                        end
                    end
                else % if we are skiping the copy of train and test then the 
                    for n=1:NDupTrainTest
                        ThisDupLoc=cellfun(@(x) sum(x==DupTrainTest(n)),TrainCondsAll);
                        %%% take care of trackign which data has been used for train and test so we don't mix them
                        ClassifierOpts.DupTrainTestDimSource{n}=ThisDupLoc; % what is the dimension where we have copied the data for Train Test
                        ClassifierOpts.DupTrainTestDimTarget{n}=ThisDupLoc;% where is this data being copied
                    end
                end
                % if there are other rules that are not shared between train and test but they are shared within train or test
              % copy duplications for train 
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTrain(Cond)
                    if ~isempty(setdiff(DupTrain,DupTrainTest)) % for train
                        for n=1:NDupTrain
                            ThisTrainDataFactors=[];ThisTargTrainDataFactors=[];
                            ThisDupLoc=DupLocTrain{n};
                            nCond=find(ThisDupLoc,1,'first');
                            eval(sprintf('ThisTrainDataFactors=Train%sDataAllFactors;',DimTxt{nCond}));
                            ThisTrainTrials=ThisTrainDataFactors(:,RuleInd)==DupTrain(n);
                            % now copy the data into others
                            for on=setdiff(find(ThisDupLoc),nCond)
                                eval(sprintf('ThisTargTrainDataFactors=Train%sDataAllFactors;',DimTxt{on}));
                                ThisTargTrainTrials=ThisTargTrainDataFactors(:,RuleInd)==DupTrain(n);
                                eval(sprintf('predictors%s{1}(ThisTargTrainTrials,:,:)=predictors%s{1}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('response%s{1}(ThisTargTrainTrials)=response%s{1}(ThisTrainTrials);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('Train%sDataAllFactors(ThisTargTrainTrials,:)=Train%sDataAllFactors(ThisTrainTrials,:);',DimTxt{on},DimTxt{nCond}));
                                if ~isempty(ClassifierOpts.SpkCountPeriod)
                                    for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        eval(sprintf('predictors%sSpkCnt{1}{i}(ThisTargTrainTrials,:,:)=predictors%sSpkCnt{1}{i}(ThisTrainTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                    end
                                end
                            end
                        end
                    end
                end
                % copy duplacations for test
                if ~ClassifierOpts.EqualizeTrials4Conds.SkipDupTest(Cond)
                    if ~isempty(setdiff(DupTest,DupTrainTest))% for test
                        for n=1:NDupTest
                            ThisTestDataFactors=[];ThisTargTestDataFactors=[];
                            ThisDupLoc=DupLocTest{n};
                            nCond=find(ThisDupLoc,1,'first');
                            eval(sprintf('ThisTestDataFactors=Test%sDataAllFactors;',DimTxt{nCond}));
                            ThisTestTrials=ThisTestDataFactors(:,RuleInd)==DupTest(n);
                            % now copy the data into others
                            for on=setdiff(find(ThisDupLoc),nCond)
                                eval(sprintf('ThisTargTestDataFactors=Test%sDataAllFactors;',DimTxt{on}));
                                ThisTargTestTrials=ThisTargTestDataFactors(:,RuleInd)==DupTest(n);
                                eval(sprintf('predictors%s{2}(ThisTargTestTrials,:,:)=predictors%s{2}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('response%s{2}(ThisTargTestTrials)=response%s{2}(ThisTestTrials);',DimTxt{on},DimTxt{nCond}));
                                eval(sprintf('Test%sDataAllFactors(ThisTargTestTrials,:)=Test%sDataAllFactors(ThisTestTrials,:);',DimTxt{on},DimTxt{nCond}));
                                if ~isempty(ClassifierOpts.SpkCountPeriod)
                                    for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        eval(sprintf('predictors%sSpkCnt{2}{i}(ThisTargTestTrials,:,:)=predictors%sSpkCnt{2}{i}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{nCond}));
                                    end
                                end
                            end
                        end
                    end
                end
            elseif ~NDupTrain & ~NDupTest & ~NDupTrainTest
                % no sharing
            end
       
          
            %% do specific corrections based on the current test name
            if contains(ClassifierOpts.Name,'Learning3D_Shape_Color_Color_Compression_RB') & Cond==1
                % then for the first condition copy the correct trials from dimension 3 to dimension 1
                % in this way the test data for shape is not contamiting the shape data in color
                if ClassifierOpts.TrainCond{1}(1)~=1 | ClassifierOpts.TrainCond{3}(1)~=1
                    error('This condition does not match what should happen');
                end
                TrainFactorDataNew=TrainDataAllFactors;
                % go through the correct trials in the first dimension 
                CorrectTrlsDim1=find(TrainDataAllFactors(:,ClassifierOpts.Reward.Ind));
                TrlSetInclude=ones(size(Train3DataAllFactors,1),1);
                for IndCorrect=CorrectTrlsDim1'
                    ColorCat=TrainDataAllFactors(IndCorrect,ClassifierOpts.ColorCat.Ind);
                    ShapeCat=TrainDataAllFactors(IndCorrect,ClassifierOpts.ShapeCat.Ind);
                    % now find corresponding shape and color in Train 3 data and replace it with this one 
                    ThisTrial=find(Train3DataAllFactors(:,ClassifierOpts.ColorCat.Ind)==ColorCat & ...
                        Train3DataAllFactors(:,ClassifierOpts.ShapeCat.Ind)==ShapeCat & TrlSetInclude,1,'first');
                    TrlSetInclude(ThisTrial)=0;
                    TrainFactorDataNew(IndCorrect,:)=Train3DataAllFactors(ThisTrial,:);
                    predictors{1}(IndCorrect,:)=predictors3{1}(ThisTrial,:);
                 end
                   TrainDataAllFactors=TrainFactorDataNew;    
                    % copy test data from Dim 3 to other two dimensions 
                    for on=1:2
                        eval(sprintf('ThisTargTestDataFactors=Test%sDataAllFactors;',DimTxt{on}));
                        ThisTargTestTrials=ThisTargTestDataFactors(:,RuleInd)==1;
                        eval(sprintf('predictors%s{2}(ThisTargTestTrials,:,:)=predictors%s{2}(ThisTargTestTrials,:,:);',DimTxt{on},DimTxt{3}));
                        eval(sprintf('response%s{2}(ThisTargTestTrials)=response%s{2}(ThisTargTestTrials);',DimTxt{on},DimTxt{3}));
                        eval(sprintf('Test%sDataAllFactors(ThisTargTestTrials,:)=Test%sDataAllFactors(ThisTargTestTrials,:);',DimTxt{on},DimTxt{3}));
                        if ~isempty(ClassifierOpts.SpkCountPeriod)
                            for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                                eval(sprintf('predictors%sSpkCnt{2}{i}(ThisTargTestTrials,:,:)=predictors%sSpkCnt{2}{i}(ThisTestTrials,:,:);',DimTxt{on},DimTxt{3}));
                            end
                        end
                    end

            elseif contains(ClassifierOpts.Name,'Learning3D_Shape_Color_Color_Compression_RB') & Cond==2
                % copy the data from last dimension of the test to all of the others
            end
        end
        function [ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=GetTimeRangeforThisCond(~,ClassifierOpts) % get time range for training classifier
            global AnalysisOpts
            
            NTim=length(AnalysisOpts.Time);
            % check if we are running a cross temporal analysis or single time analysis
            if ClassifierOpts.RunCrossTemporalClassifer==1 % prepare for a cross temporal classifier analysis
                TimeMatrixSize=[NTim NTim];
                [TrainTimInd,TestTimInd]=ind2sub(TimeMatrixSize,1:NTim^2);
                nXtimePnt=NTim^2;
            elseif ClassifierOpts.RunCrossTemporalClassifer==0
                TimeMatrixSize=[1 NTim];
                TrainTimInd=1:NTim;
                TestTimInd=1:NTim;
                nXtimePnt=NTim;
            end
            ClassifierOpts.TimeMatrixSize=TimeMatrixSize;
        end
        function [predictors,predictors2,predictors3,predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt]=AdjustMeanActivity4Rule(obj,ClassifierOpts,Cond,IncludedNeurons,predictors,predictors2,predictors3,...
                predictorsSpkCnt,predictors2SpkCnt,predictors3SpkCnt,...
                TrainDataAllFactors,Train2DataAllFactors,Train3DataAllFactors,...
                TestDataAllFactors,Test2DataAllFactors,Test3DataAllFactors) % adjust the activity for a rule by adding the mean
            global AnalysisOpts
           
            if ~ClassifierOpts.MeanSubtractByRule;return;end % no need to do this it has been done already
            DimFactorTxt={'','_2ndD','_3ndD'};
            DimTxt={'','2','3'};DimTxtNum=[0 2 3];
            % collapse rule data for predictors
            ThisMeanDataByRule=arrayfun(@(x) permute(cell2mat(obj.MeanDataByRule(IncludedNeurons,x)),[3 1 2]),1:3,'UniformOutput',0);
            if ~isempty(ClassifierOpts.SpkCountPeriod)
                ThisMeanDataByRule_SpkCnt=arrayfun(@(x) cell2mat(obj.MeanDataByRule_SpkCnt(IncludedNeurons,x)),1:3,'UniformOutput',0);
            end
             RuleInd=obj.GetFactornameInd('Rule');
            % loop on dimensions
            for Dim=1:3
                ThisTrainAllFactors=[]; ThisTestAllFactors=[];ThisTrainCond=[];ThisTestCond=[];
                [~,~,~,TrainCond,TestCond]=obj.getClassifierDimInfo(ClassifierOpts,DimTxtNum(Dim));
                if strcmp(ClassifierOpts.(['TargetFactors' DimFactorTxt{Dim}]){1},'Rule') | sum(TrainCond{Cond}==TestCond{Cond})
                    % then we are going to add the mean value for each rule to the predictors per channel
                    % loop on trials for test and train and add the mean
                    eval(sprintf('ThisTrainRule=Train%sDataAllFactors(:,RuleInd);',DimTxt{Dim}));
                    eval(sprintf('ThisTestRule=Test%sDataAllFactors(:,RuleInd);',DimTxt{Dim}));
                    ThisMeanTrain=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) ThisMeanDataByRule{x} ,ThisTrainRule','UniformOutput',0),62);
                    ThisMeanTest=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) ThisMeanDataByRule{x} ,ThisTestRule','UniformOutput',0),62);
                    eval(sprintf('predictors%s{1}=predictors%s{1}+ThisMeanTrain;',DimTxt{Dim},DimTxt{Dim}));
                    eval(sprintf('predictors%s{2}=predictors%s{2}+ThisMeanTest;',DimTxt{Dim},DimTxt{Dim}));
                    for i=1:size(ClassifierOpts.SpkCountPeriod,1)
                        ThisMeanTrainSpkCnt=transpose(cell2mat(arrayfun(@(x) ThisMeanDataByRule_SpkCnt{x}(:,i) ,ThisTrainRule','UniformOutput',0)));
                        ThisMeanTestSpkCnt =transpose(cell2mat(arrayfun(@(x) ThisMeanDataByRule_SpkCnt{x}(:,i) ,ThisTestRule','UniformOutput',0)));
                        eval(sprintf('predictors%sSpkCnt{1}{i}=predictors%sSpkCnt{1}{i}+ThisMeanTrainSpkCnt;',DimTxt{Dim},DimTxt{Dim}));
                        eval(sprintf('predictors%sSpkCnt{2}{i}=predictors%sSpkCnt{2}{i}+ThisMeanTestSpkCnt;',DimTxt{Dim},DimTxt{Dim}));
                    end
                end
            end
        end
        %% set of fucntions to grab trials for specific conditions for the classifier%%%
        function [predictors,response,TrainDataAllFactors,TestDataAllFactors,TrainStimInds,TestStimInds,predictorsSpkCnt,TrainDataAllFactors3D,TestDataAllFactors3D]=GrabThisRepClassifierData(obj,FactorData,ClassifierOpts,TrainCond,TestCond,FactorLevelComb,Cond,FactorDataTest,ThisTrainTrialRange,ThisTestTrialRange,varargin) %  grabs neurons and trials for this repetition of classfier analysis
            %@FactorData is taken from the output of PrepareData4ClassifierAnalysis
            %@TrainTestOpts.type: 'SameCond': train and test on the data from the same condition(rule) e.g. train and test on rule 1
            %@TrainTestOpts.type: 'CrossCond' train and test values are across different conditions e.g train on rule 2 and test on rule 3 and vice versa
            %@TrainTestOpts.TrainCond: condition 2 use train
            %@TrainTestOpts.TestCond: condition 2 use test
            %@TrainTestOpts.TargetFactors factors we are working on
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            NNeu=length(FactorData);
            
            if iscell(ClassifierOpts.type);type=ClassifierOpts.type{Cond};else;type=ClassifierOpts.type;end
            % double check if the type is really correct: if train and test
            % conditions are the same and they are using overlapping trials
            % then it should be same condition
            if ~strcmp(type,'SameCond') & TrainCond==TestCond & ...
                    isempty(setdiff( ThisTrainTrialRange,ThisTestTrialRange)) & isempty(setdiff(ThisTestTrialRange,ThisTrainTrialRange))
                type='SameCond';
            end
            DimTxtSet={'','2','3'};
            
            [~,~,~,~,~,DimTxt,~,~,~,~,~,DimNum]=obj.getClassifierDimInfo(ClassifierOpts,obj.LookatDim2);
            [~,FactorData,FactorDataTest,~,~,ClassifierOpts]=obj.DetermineStimCongruency(ClassifierOpts,DimNum,FactorData,FactorDataTest);
            FactorDataBuffSamp=FactorData;
            FactorDataTestBuffSamp=FactorDataTest;

            isok=0; % when to leave the sampling loop
            ntry=1; % number of sampling in the loop
            while(isok==0)
                try
                    switch type
                        case {'CrossCond','DoubleCrossCond','TripleCrossCond'}
                            % if the factordata for test set is different from train factor data then use that
                            if exist('FactorDataTest','var')
                                if isempty(FactorDataTest)
                                    FactorDataTest=FactorData;
                                end
                            else
                                FactorDataTest=FactorData;
                            end

                            % if train and test share a condition but they are different in another condition. In that case we have same condition and cross cond together
                            if sum(TrainCond==TestCond)
                                % if length(TestCond)>1;error('This condition is only for >1 train condition');end
                                % TrainCondSame=TrainCond((TrainCond==TestCond));
                                % get training data
                                % in this case if we have shared trials that is copied into this dimension then make sure remove those shared information from test data
                                IndTrainCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',TrainCond,'UniformOutput',0));

                                if ClassifierOpts.CurrCVfold>1 & ClassifierOpts.UseCV & ClassifierOpts.CVspecs(DimNum,Cond)==0
                                    % check if we have copied any data into this condition
                                    ThisTargetDim=cellfun(@(x) sum(DimNum==x),ClassifierOpts.DupTrainTestDimTarget);
                                    ThisSourceDim=cellfun(@(x) sum(DimNum==x),ClassifierOpts.DupTrainTestDimSource);
                                    if sum(ThisTargetDim)
                                        % then find the source for this and copy the data from the source for training
                                        SourceDim=ClassifierOpts.DupTrainTestDimSource{find(ThisTargetDim,1,'first')};
                                        SourceDimTxt=DimTxtSet{SourceDim};
                                    elseif sum(ThisSourceDim)
                                        SourceDim=DimNum;
                                        SourceDimTxt=DimTxt;
                                    end

                                    % then load the data that we have for this dimension  and return
                                    TrainData=ClassifierOpts.Dimpredictors{DimNum}{1};
                                    TrainDataLabels=ClassifierOpts.Dimresponse{DimNum}{1};
                                    TrainSpkCntData=ClassifierOpts.DimpredictorsSpkCnt{DimNum}{1};
                                    % copy the Stimulus Indexes and Train and test data that are used
                                    TrainStimInds=ClassifierOpts.(['Train'  SourceDimTxt 'StimInds']);
                                    TrainDataAllFactors=ClassifierOpts.(['Train'  DimTxt 'DataAllFactors']);
                                    TrainDataAllFactors3D=[];
                                    if length(TestCond)>1;error('This code can not be used here');end
                                    IndTrainCondOrg=IndTrainCond;
                                    % limit the indices of training to only the rule that is shared between train and test
                                    IndTrainCond=intersect(find(FactorLevelComb(:,2)==TestCond),IndTrainCond)';
                                    ThisIndTrainCond=arrayfun(@(x) find(IndTrainCondOrg==x),IndTrainCond);
                                    if max(ThisIndTrainCond)>length(TrainStimInds{1});
                                        ThisIndTrainCond=1:length(TrainStimInds{1});
                                    end
                                    % now trim the TrainStimInds so that it only includes the data from conditions we care about
                                    TrainStimInds=cellfun(@(x) x(ThisIndTrainCond),TrainStimInds,'Uniformoutput',0);
                                else
                                    [TrainData,TrainDataLabels,TrainDataAllFactors,TrainStimInds,TrainSpkCntData,TrainDataAllFactors3D]=obj.GrabDataFromCond(FactorData,IndTrainCond,FactorLevelComb,ClassifierOpts);
                                end

                                %devide all of the data into training and test data or remove training trials from the set of all trials
                                [~,FactorDataTest]=obj.SampleFactorDataTrainTest(FactorData,ClassifierOpts,TrainStimInds,IndTrainCond,FactorDataTest);

                                if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                                    % categorize morph levels
                                    TrainDataLabels=obj.ManData.CategorizeMorphlevel(TrainDataLabels);
                                end

                                IndTestCond =cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',TestCond,'UniformOutput',0));
                                CurrNTrl=ClassifierOpts.ntrlPerCond;
                                ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCondTest;
                                [TestData,TestDataLabels,TestDataAllFactors,TestStimInds,TestSpkCntData,TestDataAllFactors3D]=obj.GrabDataFromCond(FactorDataTest,IndTestCond,FactorLevelComb,ClassifierOpts,'GrabbingTestData',1);
                                ClassifierOpts.ntrlPerCond=CurrNTrl;
                            else
                                if ClassifierOpts.CurrCVfold>1 & ClassifierOpts.UseCV & ClassifierOpts.CVspecs(DimNum,Cond)==0
                                    TrainData=ClassifierOpts.Dimpredictors{DimNum}{1};
                                    TrainDataLabels=ClassifierOpts.Dimresponse{DimNum}{1};
                                    TrainSpkCntData=ClassifierOpts.DimpredictorsSpkCnt{DimNum}{1};
                                    % copy the Stimulus Indexes and Train and test data that are used
                                    TrainStimInds=ClassifierOpts.(['Train'  DimTxt 'StimInds']);
                                    TrainDataAllFactors=ClassifierOpts.(['Train'  DimTxt 'DataAllFactors']);
                                    TrainDataAllFactors3D=[];
                                else
                                    % get training data
                                    IndTrainCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',TrainCond,'UniformOutput',0));
                                    [TrainData,TrainDataLabels,TrainDataAllFactors,TrainStimInds,TrainSpkCntData,TrainDataAllFactors3D]=obj.GrabDataFromCond(FactorData,IndTrainCond,FactorLevelComb,ClassifierOpts);
                                end
                                % get test data( we are not applying congruency conditions on test data)
                                % get what is the minimum number of trials for this condition
                                IndTestCond =cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',TestCond,'UniformOutput',0));
                                CurrNTrl=ClassifierOpts.ntrlPerCond;
                                ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCondTest;
                                [TestData,TestDataLabels,TestDataAllFactors,TestStimInds,TestSpkCntData,TestDataAllFactors3D]=obj.GrabDataFromCond(FactorDataTest,IndTestCond,FactorLevelComb,ClassifierOpts,'GrabbingTestData',1);
                                ClassifierOpts.ntrlPerCond=CurrNTrl;
                            end
                            % return the values
                            % ClassifierOpts.ntrlPerCond=CurrNTrl;ClassifierOpts.StimCongruency=CurrStimCongruency;
                            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                                % categorize morph levels
                                TrainDataLabels=obj.ManData.CategorizeMorphlevel(TrainDataLabels);
                                TestDataLabels=obj.ManData.CategorizeMorphlevel(TestDataLabels);
                            end

                            predictors=[{TrainData} {TestData}];
                            response=[{TrainDataLabels} {TestDataLabels}];
                            predictorsSpkCnt=[{TrainSpkCntData} {TestSpkCntData}]; % get predictors for spike count
                        case 'SameCond'
                            if ClassifierOpts.CurrCVfold>1 & ClassifierOpts.UseCV & ClassifierOpts.CVspecs(DimNum,Cond)==1
                                if ClassifierOpts.EqualizeTrialsXConds;error('This condition would not work for equalized');end
                                % then load the data that we have and return
                                predictors=ClassifierOpts.Dimpredictors{DimNum};
                                response=ClassifierOpts.Dimresponse{DimNum};
                                predictorsSpkCnt=ClassifierOpts.DimpredictorsSpkCnt{DimNum};
                                % copy the Stimulus Indexes and Train and test data that are used
                                TrainStimInds=ClassifierOpts.(['Train'  DimTxt 'StimInds']);
                                TrainDataAllFactors=ClassifierOpts.(['Train'  DimTxt 'DataAllFactors']);
                                TestDataAllFactors=ClassifierOpts.(['Test'  DimTxt 'DataAllFactors']);

                                TrainDataAllFactors3D=[];TestDataAllFactors3D=[];TestStimInds=[];
                                return
                            end

                            IndTrainCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',TrainCond,'UniformOutput',0));

                            % if we are using CV fold and even if CVspecs is 0 we should remove the train data from test
                            if ClassifierOpts.CurrCVfold>1 & ClassifierOpts.UseCV & ClassifierOpts.CVspecs(DimNum,Cond)==0
                                if ClassifierOpts.EqualizeTrialsXConds;error('This condition would not work for equalized');end
                                % then load the data that we have for this dimension  and return
                                TrainData=ClassifierOpts.Dimpredictors{DimNum}{1};
                                TrainDataLabels=ClassifierOpts.Dimresponse{DimNum}{1};
                                TrainSpkCntData=ClassifierOpts.DimpredictorsSpkCnt{DimNum}{1};
                                % copy the Stimulus Indexes and Train and test data that are used
                                TrainStimInds=ClassifierOpts.(['Train'  DimTxt 'StimInds']);
                                TrainDataAllFactors=ClassifierOpts.(['Train'  DimTxt 'DataAllFactors']);
                                TrainDataAllFactors3D=[];

                            else
                                % get new training data
                                [TrainData,TrainDataLabels,TrainDataAllFactors,TrainStimInds,TrainSpkCntData,TrainDataAllFactors3D]=obj.GrabDataFromCond(FactorData,IndTrainCond,FactorLevelComb,ClassifierOpts);
                                if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                                    % categorize morph levels
                                    TrainDataLabels=obj.ManData.CategorizeMorphlevel(TrainDataLabels);
                                end
                            end

                            % remove training trials from the set of all trials and create the test
                            [~,FactorDataTest]=obj.SampleFactorDataTrainTest(FactorData,ClassifierOpts,TrainStimInds,IndTrainCond,[]);

                            CurrNTrl=ClassifierOpts.ntrlPerCond;
                            ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCondTest;
                            [TestData,TestDataLabels,TestDataAllFactors,TestStimInds,TestSpkCntData,TestDataAllFactors3D]=obj.GrabDataFromCond(FactorDataTest,IndTrainCond,FactorLevelComb,ClassifierOpts,'GrabbingTestData',1);
                            ClassifierOpts.ntrlPerCond=CurrNTrl;

                            if contains(ClassifierOpts.Name,'Category') & sum(strcmp(ClassifierOpts.TargetFactors{1},'ShapeML') | strcmp(ClassifierOpts.TargetFactors{1},'ColorML'))
                                % categorize morph levels
                                TestDataLabels=obj.ManData.CategorizeMorphlevel(TestDataLabels);
                            end

                            predictors=[{TrainData} {TestData}];
                            response=[{TrainDataLabels} {TestDataLabels}];
                            predictorsSpkCnt=[{TrainSpkCntData} {TestSpkCntData}];% get predictors for spike count

                    end
                    isok=1;
                catch ME
                    if ntry==1000
                        error('SERIOUS ERROR with sampling the data')
                    else
                        FactorData=FactorDataBuffSamp;
                        FactorDataTest=FactorDataTestBuffSamp;
                        warning('An error sampling the data trying again')
                        ntry=ntry+1;
                    end
                end
            end

        end
        function [FactorDataTrain,FactorDataTest]=SampleFactorDataTrainTest(obj,FactorData,ClassifierOpts,TrainStimInds,CondInds,FactorDataTest,varargin) % sample factor data for train and test
            %@TrainStimInds if is not empty then we will remove these trials and the rest will be test trials
            %@Factordata
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            
            NCond=length(CondInds);
            TrialNumInd=obj.GetFactornameInd('TrialNum'); % trial
            BlkOrderInd=obj.GetFactornameInd('BlkOrder');
            if ~isempty(FactorDataTest) % then train and test data are coming from different sets
                % if factor data come from a different but overlapping set  we need to remove
                % overlapping trials; we find any trial that matches others
                
                for Neu=1:length(FactorData)
                    % finds overlapping stimulus across FactorSets
                    TestInds=arrayfun(@(x) find(~sum(cell2mat(arrayfun(@(i) (FactorDataTest(Neu).AllFactors{CondInds(x)}(:,TrialNumInd)==FactorData(Neu).AllFactors{CondInds(x)}(i,TrialNumInd) & ...
                        FactorDataTest(Neu).AllFactors{CondInds(x)}(:,BlkOrderInd)==FactorData(Neu).AllFactors{CondInds(x)}(i,BlkOrderInd)),TrainStimInds{Neu}{x},'UniformOutput',0)),2)),1:NCond,'UniformOutput',0);
                    DiffFum(Neu,:)=[arrayfun(@(x) size(TestInds{x},1)-size(FactorDataTest(Neu).data{CondInds(x)},1),1:NCond)];
                    FactorDataTest(Neu).data(CondInds)=arrayfun(@(x) FactorDataTest(Neu).data{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                    % if we have spike count in factor data then deal with that as well
                    if ~isempty(FactorDataTest(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                        for i=1:length(FactorDataTest(Neu).FactorData_SpkCnt)
                            FactorDataTest(Neu).FactorData_SpkCnt{i}(CondInds)= arrayfun(@(x) FactorDataTest(Neu).FactorData_SpkCnt{i}{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                        end
                    end
                    FactorDataTest(Neu).AllFactors(CondInds)=arrayfun(@(x) FactorDataTest(Neu).AllFactors{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                end
                FactorDataTrain=[];
                
            else
                FactorDataTest=FactorData; % initialize it with factor data
                if ~isempty(TrainStimInds) % the we have used these for training data
                    for Neu=1:length(FactorData)
                        % sometimes factor data come from a different but
                        % overlapping set in that case we need to remove
                        % overlapping trials; we find any trial that matches others
                        TestInds=arrayfun(@(x) setdiff(1:size(FactorData(Neu).data{CondInds(x)},1),TrainStimInds{Neu}{x}),1:NCond,'UniformOutput',0); % find test inds
                        
                        FactorDataTest(Neu).data(CondInds)=arrayfun(@(x) FactorData(Neu).data{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                        % if we have spike count in factor data then deal with that as well
                        if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                            for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                                FactorDataTest(Neu).FactorData_SpkCnt{i}(CondInds)= arrayfun(@(x) FactorData(Neu).FactorData_SpkCnt{i}{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                            end
                        end
                        FactorDataTest(Neu).AllFactors(CondInds)=arrayfun(@(x) FactorData(Neu).AllFactors{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                    end
                    FactorDataTrain=[];
                else
                    for Neu=1:length(FactorData)
                        [FactorDataTrain(Neu).data,FactorDataTest(Neu).data,IncludeInd,WholdInd]=...
                            cellfun(@(x) obj.ManData.RandSampleMatrixwithProportion(x,ClassifierOpts.holdout_frac,1,[],[]),FactorData(Neu).data,'UniformOutput',0);
                        
                        [FactorDataTrain(Neu).AllFactors,FactorDataTest(Neu).AllFactors,IncludeInd,WholdInd]=...
                            arrayfun(@(x) obj.ManData.RandSampleMatrixwithProportion(FactorData(Neu).AllFactors{x},ClassifierOpts.holdout_frac,1,IncludeInd{x},WholdInd{x}),1:NCond,'UniformOutput',0);
                    end
                end
            end
            
        end
        function [FactorDataTrain,FactorDataTest]=SampleFactorDataTrainTestRaster(obj,RasterFactorData,TrainStimInds,TrainCondInds,TestStimInds,TestCondInds,varargin) % sample rast factor data for train and test andn limits this sampling to specific periods of time points
            
            %@TrainStimInds if is not empty then we will remove these trials and the rest will be test trials
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NCond=length(CondInds);
            
            if ~isempty(TrainStimInds) % the we have used these for training data
                for Neu=1:length(FactorData)
                    TestInds=arrayfun(@(x) setdiff(1:size(FactorData(Neu).data{CondInds(x)},1),TrainStimInds{Neu}{x}),1:NCond,'UniformOutput',0); % find test inds
                    FactorDataTest(Neu).data(CondInds)=arrayfun(@(x) FactorData(Neu).data{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                    
                    FactorDataTest(Neu).AllFactors(CondInds)=arrayfun(@(x) FactorData(Neu).AllFactors{CondInds(x)}(TestInds{x},:),1:NCond,'UniformOutput',0);
                end
                FactorDataTrain=[];
            end
        end
        function TrialCntSummery=CalTrialCountSummeryPerNeu(obj,FactorData,ClassifierOpts,TargetFactors,FactorLevelComb,varargin)% Calculates trialcount summery for factor data/neuron for target fators
            %@TargetFactors: Factors we want to count the number of trails per condition
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % TargetFactors={'ColorML','ResponseLoc'};
            NNeu=length(FactorData);
            NConds=length(FactorData(1).AllFactors);
            % calculate trials for combinations of conditions of intrest
            for Neu=1:NNeu  % loop on Neurons
                for Cond=1:NConds % loop on conditions
                    out=[];
                    % loop on the factors and get the number of trials for this factor data
                    for Factor=TargetFactors % loop on Target factors that we want to count the number of trails
                        FactorVals=ClassifierOpts.(Factor{1}).Val;
                        for Vals=FactorVals
                            if FactorLevelComb(Cond,2)==2 & strcmp(Factor{1},'SeqHist')
                                out.([ Factor{1} num2str(Vals)])=true(size(FactorData(Neu).AllFactors{Cond}(:,ClassifierOpts.(Factor{1}).Ind),1),1);
                            elseif strcmp(Factor{1},'none') % just count the number of trials
                                out.([ Factor{1} num2str(Vals)])=true(size(FactorData(Neu).AllFactors{Cond},1),1);
                            else
                                out.([ Factor{1} num2str(Vals)])=FactorData(Neu).AllFactors{Cond}(:,ClassifierOpts.(Factor{1}).Ind)==Vals;
                            end
                        end
                    end
                    
                    OutFieldNames=fieldnames(out)';
                    if length(TargetFactors)==1
                        Sum=(cellfun(@(y) sum(out.(y)),OutFieldNames(contains(OutFieldNames,TargetFactors{1})),'UniformOutput',0));
                        SumID=(cellfun(@(y) char(y),OutFieldNames(contains(OutFieldNames,TargetFactors{1})),'UniformOutput',0));
                        % turn this all into a structure so we can look at this for each cell in a summery
                        TrialCntSummery(Neu,Cond)=cell2struct([Sum],[SumID],2);
                    elseif length(TargetFactors)==2
                        Sum=(cellfun(@(x) (cellfun(@(y) sum(out.(x) & out.(y)),OutFieldNames(contains(OutFieldNames,TargetFactors{1})),'UniformOutput',0)),OutFieldNames(contains(OutFieldNames,TargetFactors{2})),'UniformOutput',0));
                        SumID=cellfun(@(x) cellfun(@(y) char([x '_' y]),OutFieldNames(contains(OutFieldNames,TargetFactors{1})),'UniformOutput',0),OutFieldNames(contains(OutFieldNames,TargetFactors{2})),'UniformOutput',0);
                        % turn this all into a structure so we can look at this for each cell in a summery
                        TrialCntSummery(Neu,Cond)=cell2struct([Sum{:}],[SumID{:}],2);
                    end
                end
            end            
        end
        function IncludedNeu=ApplyNeuronDroppingAlgorithm(obj,FactorData,ClassifierOpts,TargetFactors,NTrlTh,FactorLevelComb,Conds,varargin)% finds neurons that pass the criteria for the number of trials we want for this analysis
            %@TrialCntSummery output of the per neuron trial count from CalTrialCountSummeryPerNeu
            %@TargetFields Target fields in TrialCntSummery to check the number of trials
            %@NTrlTh, threshold for the number of trials for this neuron to be included in the anlysis
            %@Conds, index of the condition that we are looking at in the TrialCntSummery
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            TrialCntSummery=obj.CalTrialCountSummeryPerNeu(FactorData,ClassifierOpts,TargetFactors,FactorLevelComb);
            
            FieldNames=fieldnames(TrialCntSummery)';
            
            % if one of the target factors is 'ResponseLocation' then get the correspoding direction of the saccade for that condition
            if sum(contains(TargetFactors,'ResponseLoc'))
                ResLocVals=ClassifierOpts.ResponseLoc.ValRule;
                TargetFields=arrayfun(@(x) FieldNames(contains(FieldNames,['ResponseLoc' num2str(ResLocVals{x}(1))]) | ...
                    contains(FieldNames,['ResponseLoc' num2str(ResLocVals{x}(2))])),FactorLevelComb(Conds,2)','UniformOutput',0);
                % if one of the target factors is 'Congruency' then get thecorrespoding value for it 
            elseif sum(contains(TargetFactors,'Congruency'))
                IndConginTargFacotor=contains(TargetFactors,'Congruency');
                CongVals=obj.StimCongruencyConds{ClassifierOpts.StimCongruency(ClassifierOpts.CurrDim)};
                if size(CongVals,1)>1
                    CongVals=CongVals(:,IndConginTargFacotor)'; % find values for this condition
                end
                CongVals=unique(CongVals);
                if length(CongVals)==2
                 TargetFields=arrayfun(@(x) FieldNames(contains(FieldNames,['Congruency' num2str(CongVals(1))]) | ...
                    contains(FieldNames,['Congruency' num2str(CongVals(2))])),FactorLevelComb(Conds,2)','UniformOutput',0);              
                elseif length(CongVals)==3
                 TargetFields=arrayfun(@(x) FieldNames(contains(FieldNames,['Congruency' num2str(CongVals(1))]) | ...
                    contains(FieldNames,['Congruency' num2str(CongVals(2))]) | ...
                    contains(FieldNames,['Congruency' num2str(CongVals(3))])),FactorLevelComb(Conds,2)','UniformOutput',0);                           
                elseif length(CongVals)==1
                     TargetFields=arrayfun(@(x) FieldNames(contains(FieldNames,['Congruency' num2str(CongVals(1))])),FactorLevelComb(Conds,2)','UniformOutput',0);                     
                end
            else
                TargetFields=repmat({FieldNames},[1 length(Conds)]);
            end
            
            if sum(contains(TargetFactors,'SeqHist'))
                TargetFields=[TargetFields{:}];
                % we don't take rule 2 into account for seqhist
                TargetFields= arrayfun(@(x) unique(TargetFields(contains(TargetFields,['SeqHist' num2str(obj.SeqHistCond)]))),...
                    FactorLevelComb(Conds,2)','UniformOutput',0);  % SeqHistNum ind should be updates
            end
            
            NNeu=size(TrialCntSummery,1);
            if NNeu~=length(AnalysisOpts.nCh_2look);error('number of channels dont match');end
            for Neu=1:NNeu
                NtrlsNeu(Neu,:)= cell2mat(arrayfun(@(y) cell2mat(cellfun(@(x) [TrialCntSummery(Neu,y).(x)]'>=NTrlTh,TargetFields{y==Conds},'UniformOutput',0)),Conds,'UniformOutput',0));
            end
            IncludedNeu=sum(NtrlsNeu,2)==size(NtrlsNeu,2);
        end
        function [FactorData,IncludedNeurons]=ApplyNeuronDroppingAlgorithm4ThisAnlaysis(obj,FactorData,ClassifierOpts,FactorLevelComb,FactorDataTest,RunCond,ThisTrainTrlRange,ThisTestTrlRange,varargin) % applies neuron dropping algorithm for this analysis
            % synoposis is like ApplyNeuronDroppingAlgorithm
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if iscell(ClassifierOpts.type);type=ClassifierOpts.type{RunCond};else;type=ClassifierOpts.type;end
            TargetFields=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorDataTest); 
            switch type
                case 'CrossCond'
                    ClassifierOpts.CurrDim=1;
                    [~,~,~,NTrlTh,NTrlThTest]=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorDataTest);
                  %  NTrlTh=ClassifierOpts.ntrlPerCond(1);
                    IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond(RunCond)),'UniformOutput',0)));
                    IncludedNeu_Training=obj.ApplyNeuronDroppingAlgorithm(FactorData,ClassifierOpts,TargetFields,NTrlTh,FactorLevelComb,IndTrainCond);
                    
                  %  NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                    IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond(RunCond)),'UniformOutput',0));
                    IncludedNeu_Test=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest,ClassifierOpts,TargetFields,NTrlThTest,FactorLevelComb,IndTestCond);
                    % take final set of neurons who have enough trails for training and test conditions
                    IncludedNeurons=IncludedNeu_Training & IncludedNeu_Test;
                    FactorData=FactorData(IncludedNeurons);
                case {'DoubleCrossCond','TripleCrossCond'}
                    % double check if we are testing on different
                    % conditions
                    %  if  ClassifierOpts.TrainCond{RunCond}==ClassifierOpts.TestCond{RunCond} & isempty(setdiff(ThisTrainTrlRange,ThisTestTrlRange))
                    %     NTrlTh=ClassifierOpts.ntrlPerCond(1)+ClassifierOpts.ntrlPerCondTest(1); % sum up the total number of trails we need
                    %     IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond(RunCond)),'UniformOutput',0)));
                    %     IncludedNeu_Training=obj.ApplyNeuronDroppingAlgorithm(FactorData,ClassifierOpts,TargetFields,NTrlTh,FactorLevelComb,IndTrainCond);
                    %     IncludedNeu_Test=IncludedNeu_Training;
                    %% look at first dimension
                    ClassifierOpts.CurrDim=1;
                    [TargetFields,FactorData1,FactorDataTest1,NTrlTh1,NTrlThTest1]=obj.DetermineStimCongruency(ClassifierOpts,1,FactorData,FactorDataTest);
                    
                    if ClassifierOpts.TrainCond{RunCond}==ClassifierOpts.TestCond{RunCond}
                        [IncludedNeuronsTemp,SameCond]=obj.GetSameCondIncludedNeurons(ClassifierOpts,FactorLevelComb,FactorData,RunCond,TargetFields,0);
                       if SameCond
                           IncludedNeu_Training=IncludedNeuronsTemp;
                           IncludedNeu_Test=IncludedNeuronsTemp;
                       else
 %                         NTrlTh=ClassifierOpts.ntrlPerCond(1);
                           IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond(RunCond)),'UniformOutput',0)));
                           IncludedNeu_Training=obj.ApplyNeuronDroppingAlgorithm(FactorData1,ClassifierOpts,TargetFields,NTrlTh1,FactorLevelComb,IndTrainCond);
                           
                           %remove training trials from the test trials
                           TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData1(Neu).AllFactors{Cond},1),IndTrainCond,'UniformOutput',0),1:length(FactorData1),'UniformOutput',0);
                           [~,FactorDataTest1]=obj.SampleFactorDataTrainTest(FactorData1,ClassifierOpts,TrainStimInds,IndTrainCond,FactorDataTest1);
                           
                           % get neurons for first test
%                           NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                           IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond(RunCond)),'UniformOutput',0));
                           IncludedNeu_Test=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest1,ClassifierOpts,TargetFields,NTrlThTest1,FactorLevelComb,IndTestCond);
                       end
                    elseif sum(ClassifierOpts.TrainCond{RunCond}==ClassifierOpts.TestCond{RunCond}) && sum(ClassifierOpts.TrainCond{RunCond}==ClassifierOpts.TestCond{RunCond})<length(ClassifierOpts.TrainCond{RunCond}) % if we have a shared rule and a non shared rule
                        % it is the same condition for the shared rule and
                        % different condition for the other rule
                        if length(ClassifierOpts.TestCond{RunCond})>1;error('This condition can not be used for more than one rule ');end
                        % get the channel count for same condition
 %                       NTrlTh=ClassifierOpts.ntrlPerCond(1); % sum up the total number of trails we need
                        % find the condition that is same across training and test
                        SameTrainCond=ClassifierOpts.TrainCond{RunCond}(ClassifierOpts.TrainCond{RunCond}==ClassifierOpts.TestCond{RunCond});
                        IndTrainCond_Same=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',SameTrainCond,'UniformOutput',0)));
                        IncludedNeu_Training_Same=obj.ApplyNeuronDroppingAlgorithm(FactorData1,ClassifierOpts,TargetFields,NTrlTh1,FactorLevelComb,IndTrainCond_Same);
                        
                        % get the channel count for different condition
 %                       NTrlTh=ClassifierOpts.ntrlPerCond(1);
                        DiffTrainCond=ClassifierOpts.TrainCond{RunCond}(ClassifierOpts.TrainCond{RunCond}~=ClassifierOpts.TestCond{RunCond});
                        IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',DiffTrainCond,'UniformOutput',0)));
                        IncludedNeu_Training_Diff=obj.ApplyNeuronDroppingAlgorithm(FactorData1,ClassifierOpts,TargetFields,NTrlTh1,FactorLevelComb,IndTrainCond);
                        IncludedNeu_Training=IncludedNeu_Training_Same & IncludedNeu_Training_Diff; % take both same and different neurons
                        
                        %remove training trials from the test trials
                        TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData1(Neu).AllFactors{Cond},1),IndTrainCond_Same,'UniformOutput',0),1:length(FactorData1),'UniformOutput',0);
                        [~,FactorDataTest1]=obj.SampleFactorDataTrainTest(FactorData1,ClassifierOpts,TrainStimInds,IndTrainCond_Same,FactorDataTest1);
                        
 %                       NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                        IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond(RunCond)),'UniformOutput',0));
                        IncludedNeu_Test=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest1,ClassifierOpts,TargetFields,NTrlThTest1,FactorLevelComb,IndTestCond);
                    else
                        % get neurons for first training
 %                       NTrlTh=ClassifierOpts.ntrlPerCond(1);
                        IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond(RunCond)),'UniformOutput',0)));
                        IncludedNeu_Training=obj.ApplyNeuronDroppingAlgorithm(FactorData1,ClassifierOpts,TargetFields,NTrlTh1,FactorLevelComb,IndTrainCond);
                        % get neurons for first test
 %                       NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                        IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond(RunCond)),'UniformOutput',0));
                        IncludedNeu_Test=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest1,ClassifierOpts,TargetFields,NTrlThTest1,FactorLevelComb,IndTestCond);
                    end
                    %% look at the second dimension
                    ClassifierOpts.CurrDim=2;
                    %                     if  ClassifierOpts.TrainCond2{RunCond}==ClassifierOpts.TestCond2{RunCond} & isempty(setdiff(ThisTrainTrlRange,ThisTestTrlRange))
                    %                         NTrlTh=ClassifierOpts.ntrlPerCond(1)+ClassifierOpts.ntrlPerCondTest(1); % sum up the total number of trails we need
                    %                         IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond2(RunCond)),'UniformOutput',0)));
                    %                         IncludedNeu_Training2=obj.ApplyNeuronDroppingAlgorithm(FactorData,ClassifierOpts,TargetFields,NTrlTh,FactorLevelComb,IndTrainCond);
                    %                         IncludedNeu_Test2=IncludedNeu_Training2;
                    [TargetFields,FactorData2,FactorDataTest2,NTrlTh2,NTrlThTest2]=obj.DetermineStimCongruency(ClassifierOpts,2,FactorData,FactorDataTest);
                    if ClassifierOpts.TrainCond2{RunCond}==ClassifierOpts.TestCond2{RunCond}
                        [IncludedNeuronsTemp,SameCond]=obj.GetSameCondIncludedNeurons(ClassifierOpts,FactorLevelComb,FactorData2,RunCond,TargetFields,2);
                        if SameCond
                            IncludedNeu_Training2=IncludedNeuronsTemp;
                            IncludedNeu_Test2=IncludedNeuronsTemp;
                        else
%                             NTrlTh=ClassifierOpts.ntrlPerCond(1);
                            IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond2(RunCond)),'UniformOutput',0)));
                            IncludedNeu_Training2=obj.ApplyNeuronDroppingAlgorithm(FactorData2,ClassifierOpts,TargetFields,NTrlTh2,FactorLevelComb,IndTrainCond);
                            
                            %remove training trials from the test trials
                            TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData2(Neu).AllFactors{Cond},1),IndTrainCond,'UniformOutput',0),1:length(FactorData2),'UniformOutput',0);
                            [~,FactorDataTest2]=obj.SampleFactorDataTrainTest(FactorData2,ClassifierOpts,TrainStimInds,IndTrainCond,FactorDataTest2);
                            
                            % get neurons for first test
%                             NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                            IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond2(RunCond)),'UniformOutput',0));
                            IncludedNeu_Test2=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest2,ClassifierOpts,TargetFields,NTrlThTest2,FactorLevelComb,IndTestCond);
                        end
                    elseif sum(ClassifierOpts.TrainCond2{RunCond}==ClassifierOpts.TestCond2{RunCond}) && sum(ClassifierOpts.TrainCond2{RunCond}==ClassifierOpts.TestCond2{RunCond})<length(ClassifierOpts.TrainCond2{RunCond}) % if we have a shared rule and a non shared rule
                        % it is the same condition for the shared rule and
                        % different condition for the other rule
                        if length(ClassifierOpts.TestCond2{RunCond})>1;error('This condition can not be used for more than one rule ');end
                        % get the channel count for same condition
%                         NTrlTh=ClassifierOpts.ntrlPerCond(1); % sum up the total number of trails we need
                        % find the condition that is same across training and test
                        SameTrainCond=ClassifierOpts.TrainCond2{RunCond}(ClassifierOpts.TrainCond2{RunCond}==ClassifierOpts.TestCond2{RunCond});
                        IndTrainCond_Same=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',SameTrainCond,'UniformOutput',0)));
                        IncludedNeu_Training_Same2=obj.ApplyNeuronDroppingAlgorithm(FactorData2,ClassifierOpts,TargetFields,NTrlTh2,FactorLevelComb,IndTrainCond_Same);
                        
                        % get the channel count for different condition
%                         NTrlTh=ClassifierOpts.ntrlPerCond(1);
                        DiffTrainCond=ClassifierOpts.TrainCond2{RunCond}(ClassifierOpts.TrainCond2{RunCond}~=ClassifierOpts.TestCond2{RunCond});
                        IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',DiffTrainCond,'UniformOutput',0)));
                        IncludedNeu_Training_Diff2=obj.ApplyNeuronDroppingAlgorithm(FactorData2,ClassifierOpts,TargetFields,NTrlTh2,FactorLevelComb,IndTrainCond);
                        IncludedNeu_Training2=IncludedNeu_Training_Same2 & IncludedNeu_Training_Diff2; % take both same and different neurons
                        
                        %remove training trials from the test trials
                        TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData2(Neu).AllFactors{Cond},1),IndTrainCond_Same,'UniformOutput',0),1:length(FactorData2),'UniformOutput',0);
                        [~,FactorDataTest2]=obj.SampleFactorDataTrainTest(FactorData2,ClassifierOpts,TrainStimInds,IndTrainCond_Same,FactorDataTest2);
                        
%                        NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                        IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond2(RunCond)),'UniformOutput',0));
                        IncludedNeu_Test2=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest2,ClassifierOpts,TargetFields,NTrlThTest2,FactorLevelComb,IndTestCond);
                        
                    else
                        % get neurons for second training
%                         NTrlTh=ClassifierOpts.ntrlPerCond(1);
                        IndTrainCond2=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond2(RunCond)),'UniformOutput',0)));
                        IncludedNeu_Training2=obj.ApplyNeuronDroppingAlgorithm(FactorData2,ClassifierOpts,TargetFields,NTrlTh2,FactorLevelComb,IndTrainCond2);
                        
                        % get neurons for second test
%                         NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                        IndTestCond2=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond2(RunCond)),'UniformOutput',0));
                        IncludedNeu_Test2=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest2,ClassifierOpts,TargetFields,NTrlThTest2,FactorLevelComb,IndTestCond2);
                    end
                    %% if we have a third dimension look at the third dimension 
                    if strcmp(type,'TripleCrossCond')
                        ClassifierOpts.CurrDim=3;
                         %% look at first dimension
                         [TargetFields,FactorData3,FactorDataTest3,NTrlTh3,NTrlThTest3]=obj.DetermineStimCongruency(ClassifierOpts,3,FactorData,FactorDataTest);
                        if ClassifierOpts.TrainCond3{RunCond}==ClassifierOpts.TestCond3{RunCond}
                            [IncludedNeuronsTemp,SameCond]=obj.GetSameCondIncludedNeurons(ClassifierOpts,FactorLevelComb,...
                                FactorData3,RunCond,TargetFields,3);
                            if SameCond
                                IncludedNeu_Training3=IncludedNeuronsTemp;
                                IncludedNeu_Test3=IncludedNeuronsTemp;
                            else
%                                 NTrlTh=ClassifierOpts.ntrlPerCond(1);
                                IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond3(RunCond)),'UniformOutput',0)));
                                IncludedNeu_Training3=obj.ApplyNeuronDroppingAlgorithm(FactorData3,ClassifierOpts,TargetFields,NTrlTh3,FactorLevelComb,IndTrainCond);
                                
                                %remove training trials from the test trials
                                TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData3(Neu).AllFactors{Cond},1),IndTrainCond,'UniformOutput',0),1:length(FactorData3),'UniformOutput',0);
                                [~,FactorDataTest3]=obj.SampleFactorDataTrainTest(FactorData3,ClassifierOpts,TrainStimInds,IndTrainCond,FactorDataTest3);
                                
                                % get neurons for first test
%                                 NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                                IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond3(RunCond)),'UniformOutput',0));
                                IncludedNeu_Test3=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest3,ClassifierOpts,TargetFields,NTrlThTest3,FactorLevelComb,IndTestCond);
                            end
                        elseif sum(ClassifierOpts.TrainCond3{RunCond}==ClassifierOpts.TestCond3{RunCond}) && sum(ClassifierOpts.TrainCond3{RunCond}==ClassifierOpts.TestCond3{RunCond})<length(ClassifierOpts.TrainCond3{RunCond}) % if we have a shared rule and a non shared rule
                            % it is the same condition for the shared rule and
                            % different condition for the other rule
                            if length(ClassifierOpts.TestCond3{RunCond})>1;error('This condition can not be used for more than one rule ');end
                            % get the channel count for same condition
%                             NTrlTh=ClassifierOpts.ntrlPerCond(1); % sum up the total number of trails we need
                            % find the condition that is same across training and test
                            SameTrainCond=ClassifierOpts.TrainCond3{RunCond}(ClassifierOpts.TrainCond3{RunCond}==ClassifierOpts.TestCond3{RunCond});
                            IndTrainCond_Same=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',SameTrainCond,'UniformOutput',0)));
                            IncludedNeu_Training_Same3=obj.ApplyNeuronDroppingAlgorithm(FactorData3,ClassifierOpts,TargetFields,NTrlTh3,FactorLevelComb,IndTrainCond_Same);
                            
                            % get the channel count for different condition
%                             NTrlTh=ClassifierOpts.ntrlPerCond(1);
                            DiffTrainCond=ClassifierOpts.TrainCond3{RunCond}(ClassifierOpts.TrainCond3{RunCond}~=ClassifierOpts.TestCond3{RunCond});
                            IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',DiffTrainCond,'UniformOutput',0)));
                            IncludedNeu_Training_Diff3=obj.ApplyNeuronDroppingAlgorithm(FactorData3,ClassifierOpts,TargetFields,NTrlTh3,FactorLevelComb,IndTrainCond);
                            IncludedNeu_Training3=IncludedNeu_Training_Same3 & IncludedNeu_Training_Diff3; % take both same and different neurons
                            
                            %remove training trials from the test trials
                            TrainStimInds=arrayfun(@(Neu) arrayfun(@(Cond) 1:size(FactorData3(Neu).AllFactors{Cond},1),IndTrainCond_Same,'UniformOutput',0),1:length(FactorData3),'UniformOutput',0);
                            [~,FactorDataTest3]=obj.SampleFactorDataTrainTest(FactorData3,ClassifierOpts,TrainStimInds,IndTrainCond_Same,FactorDataTest3);
                            
%                             NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                            IndTestCond=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond3(RunCond)),'UniformOutput',0));
                            IncludedNeu_Test3=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest3,ClassifierOpts,TargetFields,NTrlThTest3,FactorLevelComb,IndTestCond);
                            
                        else
                            % get neurons for third training
%                             NTrlTh=ClassifierOpts.ntrlPerCond(1);
                            IndTrainCond3=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond3(RunCond)),'UniformOutput',0)));
                            IncludedNeu_Training3=obj.ApplyNeuronDroppingAlgorithm(FactorData3,ClassifierOpts,TargetFields,NTrlTh3,FactorLevelComb,IndTrainCond3);
                            
                            % get neurons for second test
%                             NTrlTh=ClassifierOpts.ntrlPerCondTest(1);
                            IndTestCond3=cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TestCond3(RunCond)),'UniformOutput',0));
                            IncludedNeu_Test3=obj.ApplyNeuronDroppingAlgorithm(FactorDataTest3,ClassifierOpts,TargetFields,NTrlThTest3,FactorLevelComb,IndTestCond3);
                        end
                        % take final set of neurons who have enough trails for training and test conditions
                        IncludedNeurons=IncludedNeu_Training & IncludedNeu_Training2 & IncludedNeu_Training3 & IncludedNeu_Test & IncludedNeu_Test2 & IncludedNeu_Test3;
                        FactorData=FactorData(IncludedNeurons);
                    else
                        % take final set of neurons who have enough trails for training and test conditions
                        IncludedNeurons=IncludedNeu_Training & IncludedNeu_Training2 & IncludedNeu_Test & IncludedNeu_Test2;
                        FactorData=FactorData(IncludedNeurons);
                    end
                                    
                case 'SameCond'
                    ClassifierOpts.CurrDim=1;
                    NTrlTh=ClassifierOpts.ntrlPerCond(1)+ClassifierOpts.ntrlPerCondTest(1); % sum up the total number of trails we need
                    IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.TrainCond(RunCond)),'UniformOutput',0)));
                    IncludedNeurons=obj.ApplyNeuronDroppingAlgorithm(FactorData,ClassifierOpts,TargetFields,NTrlTh,FactorLevelComb,IndTrainCond);
                    % take final set of neurons who have enough trails for training and test conditions
                    FactorData=FactorData(IncludedNeurons);
            end
            fprintf('\nNumber of included neurons after applying neuron dropping algorithm:%i/%i',sum(IncludedNeurons),length(IncludedNeurons))
        end
        function [TargetFields,FactorData,FactorDataTest,NTrlTh,NTrlThTest,ClassifierOpts]=DetermineStimCongruency(obj,ClassifierOpts,Dim,FactorData,FactorDataTest)  
            if length(ClassifierOpts.StimCongruency)==1
                Dim=1;
            end % we have the same stim congruency for all conditions

            if ClassifierOpts.StimCongruency(Dim)~=0
                TargetFields=obj.StimCongruencyFactorName(ClassifierOpts.StimCongruency(Dim));
            else 
                TargetFields={'none'};
            end

            if iscell(TargetFields{1});TargetFields=[TargetFields{:}];end 

            if iscell(ClassifierOpts.ntrlPerCond)
                NTrlTh=ClassifierOpts.ntrlPerCond{Dim}(1);
                NTrlThTest=ClassifierOpts.ntrlPerCondTest{Dim}(1);
                ClassifierOpts.ntrlPerCond=ClassifierOpts.ntrlPerCond{Dim};
                ClassifierOpts.ntrlPerCondTest=ClassifierOpts.ntrlPerCondTest{Dim};
            else
                NTrlTh=ClassifierOpts.ntrlPerCond(1);
                NTrlThTest=ClassifierOpts.ntrlPerCondTest(1);
            end
            
            ClassifierOpts.StimCongruency=ClassifierOpts.StimCongruency(Dim);

            % limit factor data and factor data test based on trial type 
            if ClassifierOpts.TrialType(Dim)==3;return;end% we don't need to change this
            FactorData=obj.LimitTrialsBasedonFactor(FactorData,'Reward',ClassifierOpts.TrialType(Dim));
            FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'Reward',ClassifierOpts.TrialType(Dim));            
        end
        function [IncludedNeurons,SameCond]=GetSameCondIncludedNeurons(obj,ClassifierOpts,FactorLevelComb,FactorData,RunCond,TargetFields,Dim2ndFlag)
            % checks if two conditions are the same for the classifier conditions
            [~,~,~,~,~,DimTxt,~,~,~,~,~,DimNum]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);
                       
           if iscell(ClassifierOpts.ntrlPerCond)
                NTrlTh=ClassifierOpts.ntrlPerCond{DimNum}(1);
                NTrlThTest=ClassifierOpts.ntrlPerCondTest{DimNum}(1);
            else
                NTrlTh=ClassifierOpts.ntrlPerCond(1);
                NTrlThTest=ClassifierOpts.ntrlPerCondTest(1);
            end
            
            if  sum(ClassifierOpts.(['TrainCond' DimTxt]){RunCond}==ClassifierOpts.(['TestCond' DimTxt]){RunCond})==length( ClassifierOpts.(['TrainCond' DimTxt]){RunCond}) & ...
                    sum(ClassifierOpts.TrainTrlNumRange{RunCond}==ClassifierOpts.TestTrlNumRange{RunCond})==4 & ...
                    (isnan(ClassifierOpts.LimitFromSwitchPerf{RunCond}(1))==isnan(ClassifierOpts.LimitFromSwitchPerf{RunCond}(2)) |    ClassifierOpts.LimitFromSwitchPerf{RunCond}(1)==ClassifierOpts.LimitFromSwitchPerf{RunCond}(2)) & ...
                    (isnan(ClassifierOpts.LimitFromSwitchPerf_Operation{RunCond}{1})==isnan(ClassifierOpts.LimitFromSwitchPerf_Operation{RunCond}{2}) |    strcmp(ClassifierOpts.LimitFromSwitchPerf_Operation{RunCond}{1},ClassifierOpts.LimitFromSwitchPerf_Operation{RunCond}{2}))
                         
                SameCond=1;
                NTrlTh=NTrlTh+NTrlThTest; % sum up the total number of trails we need
                IndTrainCond=unique(cell2mat(arrayfun(@(x) find(FactorLevelComb(:,2)==x)',cell2mat(ClassifierOpts.(['TrainCond' DimTxt])(RunCond)),'UniformOutput',0)));
                IncludedNeurons=obj.ApplyNeuronDroppingAlgorithm(FactorData,ClassifierOpts,TargetFields,NTrlTh,FactorLevelComb,IndTrainCond);
            else
                SameCond=0;IncludedNeurons=[];
            end
        end
        function [FactorData,IncludedNeurons,ClassifierOpts]=ApplyNeuronDroppingAlgorithm4LearningAnlaysis(obj,FactorData,ClassifierOpts,FactorLevelComb,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            FactorDataBuff=FactorData; % save a copy of factor data since it might change in each condition
            % limit the number of neurons for this
            nCond=length(ClassifierOpts.TrainCond);
            
            for Cond=1:nCond % loop on conditions
                if sum(ClassifierOpts.StimCongruency==9) | sum(ClassifierOpts.StimCongruency==10) | sum(ClassifierOpts.StimCongruency==13) | sum(ClassifierOpts.StimCongruency==14) | sum(ClassifierOpts.StimCongruency==15); obj.SeqHistCond=ClassifierOpts.SeqHistCond{Cond};end
                
                % create learning trials for this condition
                [TrainTrlRange,TestTrlRange,TrainTrlInd,TestTrlInd,nXTrlPnt]=obj.GetTrialRangeforThisCond(ClassifierOpts,Cond);
                
                for TrlRng=1:nXTrlPnt
                    % now limit factor data trials to these trial range we want
                    % generate factor data for training
                    ThisTrainTrlRange=TrainTrlRange{TrainTrlInd(TrlRng)};
                    ThisTestTrlRange=TestTrlRange{TestTrlInd(TrlRng)};
                    FactorData=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTrainTrlRange);
                    FactorData=obj.SkipSeqHistTrain(FactorData,ClassifierOpts,Cond); % are we skipping applying seqhist for training data?
                    % generate factordata for testing
                    FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataBuff,'TrialNum',ThisTestTrlRange);
                    % if we are limitign based on block performance then
                    if isfield(ClassifierOpts,'LimitFromSwitchPerf')
                        FactorData=obj.LimitTrialsBasedonFactor(FactorData,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(1),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{1});
                        % generate factordata for testing
                        FactorDataTest=obj.LimitTrialsBasedonFactor(FactorDataTest,'FromSwitchBhvPerf',ClassifierOpts.LimitFromSwitchPerf{Cond}(2),ClassifierOpts.LimitFromSwitchPerf_Operation{Cond}{2});
                    end
                    [~,IncludedNeuronsTrlRng(:,TrlRng,Cond)]=obj.ApplyNeuronDroppingAlgorithm4ThisAnlaysis(FactorData,ClassifierOpts,FactorLevelComb,FactorDataTest,Cond,ThisTrainTrlRange,ThisTestTrlRange);
                end
            end
            IncludedNeurons=squeeze(sum(sum(IncludedNeuronsTrlRng,2),3))==(nXTrlPnt*nCond);
            FactorData=FactorDataBuff(IncludedNeurons);
            % report neuron numbers
            ClassifierOpts=obj.ReportNeuronNumbers(ClassifierOpts,IncludedNeurons);
            obj.TrialFunc.UpdateCh_2look(find(IncludedNeurons)); % update included channels
        end
        function [Data,DataLabels,AllFactors,AllStimInds,SpkCntData,AllFactors3D]=GrabDataFromCond(obj,FactorData,CondInd,FactorLevelComb,opts,varargin) % grabs data for this condition
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if obj.MaxMatchTrialConds==1 % if we are matching trial conditions
                  [Data,DataLabels,AllFactors,AllStimInds,SpkCntData,AllFactors3D]=GrabDataFromCond_MaxMatchFullCorrect(obj,FactorData,CondInd,FactorLevelComb,opts,varargin{:});
            elseif obj.MaxMatchTrialConds==2
                 [Data,DataLabels,AllFactors,AllStimInds,SpkCntData,AllFactors3D]=GrabDataFromCond_MaxMatchFull(obj,FactorData,CondInd,FactorLevelComb,opts,varargin{:});
            else  % if we are randomly sampling the conditions
                [Data,DataLabels,AllFactors,AllStimInds,SpkCntData]=GrabDataFromCond_FullRandom(obj,FactorData,CondInd,FactorLevelComb,opts,varargin{:});
                AllFactors3D=[];
            end
        end
        function [Data,DataLabels,AllFactors,AllStimInds,SpkCntData]=GrabDataFromCond_FullRandom(obj,FactorData,CondInd,FactorLevelComb,opts,varargin) % grabs data for this condition fully random for all of neurons
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(FactorData);
            CongruencyInd=strcmp(AnalysisOpts.factornames,'Congruency');
            CorrIncorrInd=strcmp(AnalysisOpts.factornames,'Reward');
            ResponseInd=strcmp(AnalysisOpts.factornames,'ResponseLoc');
            SeqHistInd=strcmp(AnalysisOpts.factornames,'SeqHist');
            SpkCntData=cell(1);
            % grab data per neuron and concatinate
            for Neu=1:NNeu
                %if we are balancing congruent and incongruent trials
                switch opts.StimCongruency % we care about congruency condition
                    case 0 % we don't care about congruency
                        StimInds=cellfun(@(x) randsample(1:size(x,1),opts.ntrlPerCond),FactorData(Neu).data(CondInd),'UniformOutput',false);
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        %  Data(:,Neu,:)=cell2mat(transpose(cellfun(@(x) x(randsample(1:size(x,1),opts.ntrlPerCond),:),FactorData(Neu).data(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        
                    case {[1],[2],[3],[4],[5]}
                        % randomly sample data inds
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            x(:,CongruencyInd),obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                        
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        
                    case 6
                        % randomly sample data
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                            [x(:,CongruencyInd) x(:,CorrIncorrInd)],obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        
                    case 7
                        % randomly sample data inds
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            x(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    case 8
                        % equalize the number for response directions for each condition
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)),1:length(CondInd),'UniformOutput',0);
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    case 9
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about the response location
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                                FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{8}(FactorLevelComb(CondInd(x),2),:)),1:length(CondInd),'UniformOutput',0);
                        else
                            % randomly sample data
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                                [FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)',repmat(obj.SeqHistCond,[2 1])]),1:length(CondInd),'UniformOutput',0);
                        end
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    case 10
                        % balance congruency for each condition with a
                        % specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        
                        for ThisCond=1:length(CondInd)
                            if FactorLevelComb(CondInd(ThisCond),2)==2 % if it is 2 then we just care about balancing congruency
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                                    FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4}),ThisCond,'UniformOutput',0);
                            else
                                % randomly sample data with congruency and SeqHist
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                                    [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])]),ThisCond,'UniformOutput',0);
                            end
                        end
                        %                             if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about balancing congruency
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                        %                                     FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4}),1:length(CondInd),'UniformOutput',0);
                        %                             else
                        %                                 % randomly sample data with congruency and SeqHist
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                        %                                     [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])]),1:length(CondInd),'UniformOutput',0);
                        %                             end
                        
                        % get data for these inds
                        Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                        AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                end
                %% if these neurons are simoultanously recorded i.e. in one
                %recording then take one sample from everyone per
                % repetition
                if length(unique(AnalysisOpts.Ch_2look_RecDate))==1
                    if Neu==1 % get the repetitions for neuron 1 and apply it to the rest
                        StimIndsNeu1=StimInds;
                    end
                    Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimIndsNeu1{x},:),1:length(CondInd),'UniformOutput',0)));
                    AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimIndsNeu1{x},:),1:length(CondInd),'UniformOutput',0)));
                    StimInds=StimIndsNeu1;
                end
                %%
                AllStimInds{Neu}=StimInds;
                if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                    for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                        SpkCntData{i}(:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).FactorData_SpkCnt{i}{CondInd(x)}(StimInds{x}),1:length(CondInd),'UniformOutput',0)));
                    end
                end
            end
            
            % report the labels
            DataLabels=cell2mat(arrayfun(@(x) x*ones(sum(opts.ntrlPerCond),1),FactorLevelComb(CondInd,1),'UniformOutput',0));
            % produce warning if response direction of the data is not matching per neuron
            if size(unique(squeeze(AllFactors(:,6,:))','rows'),1)~=1;warning('Response Direction is not matching for each neuron');end
            % get average of the factors about the behavioral model
            %'Hybrid_W_Color1','Hybrid_W_Color2','Hybrid_W_Shape1','Hybrid_W_Shape2','Hybrid_Baxes',
            if length(unique(AnalysisOpts.Ch_2look_RecDate))==1
                AllFactors=AllFactors(:,:,1);
            else
                MeanBhvFact=mean(AllFactors,3);
                AllFactors=AllFactors(:,:,1);
                AllFactors(:,10:35)=MeanBhvFact(:,10:35); % get the mean values
            end
        end
        function [Data,DataLabels,AllFactors,AllStimInds,SpkCntData]=GrabDataFromCond_MaxMatch(obj,FactorData,CondInd,FactorLevelComb,opts,varargin) % grabs data for this condition but maximize matching the trials for each neuron
            % if you are taking a trial for a neuron 1) take the same trial for all of
            % the neurons that are simoultanously recorded with this neuron
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(FactorData);
            CongruencyInd=strcmp(AnalysisOpts.factornames,'Congruency');
            CorrIncorrInd=strcmp(AnalysisOpts.factornames,'Reward');
            ResponseInd=strcmp(AnalysisOpts.factornames,'ResponseLoc');
            SeqHistInd=strcmp(AnalysisOpts.factornames,'SeqHist');
            SpkCntData=cell(1);
            % pick the conditions based on simoultanously recorded neurons
            NeuGroups=cellfun(@(x) find(strcmp(AnalysisOpts.Ch_2look_RecDate,x)),unique(AnalysisOpts.Ch_2look_RecDate),'UniformOutput',0);
            
            % grab data per neuron and concatinate
            for NeuGrp=1:length(NeuGroups)
                Neu=NeuGroups{NeuGrp}(1); % pick the first neuron
                %if we are balancing congruent and incongruent trials
                switch opts.StimCongruency % we care about congruency condition
                    case 0 % we don't care about congruency
                        StimInds=cellfun(@(x) randsample(1:size(x,1),opts.ntrlPerCond),FactorData(Neu).data(CondInd),'UniformOutput',false);
                        
                    case {[1],[2],[3],[4],[5]}
                        
                        % randomly sample data inds
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            x(:,CongruencyInd),obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                        
                    case 6
                        % randomly sample data
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                            [x(:,CongruencyInd) x(:,CorrIncorrInd)],obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                        
                    case 7
                        % randomly sample data inds
                        [~,StimInds]=cellfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            x(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency}),FactorData(Neu).AllFactors(CondInd),'UniformOutput',0);
                    case 8
                        % equalize the number for response directions for each condition
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                            FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)),1:length(CondInd),'UniformOutput',0);
                    case 9
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about the response location
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                                FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{8}(FactorLevelComb(CondInd(x),2),:)),1:length(CondInd),'UniformOutput',0);
                        else
                            % randomly sample data
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                                [FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)',repmat(obj.SeqHistCond,[2 1])]),1:length(CondInd),'UniformOutput',0);
                        end
                    case 10
                        % balance congruency for each condition with a
                        % specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        
                        for ThisCond=1:length(CondInd)
                            if FactorLevelComb(CondInd(ThisCond),2)==2 % if it is 2 then we just care about balancing congruency
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                                    FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4}),ThisCond,'UniformOutput',0);
                            else
                                % randomly sample data with congruency and SeqHist
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                                    [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])]),ThisCond,'UniformOutput',0);
                            end
                        end
                        %                             if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about balancing congruency
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                        %                                     FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4}),1:length(CondInd),'UniformOutput',0);
                        %                             else
                        %                                 % randomly sample data with congruency and SeqHist
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                        %                                     [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])]),1:length(CondInd),'UniformOutput',0);
                        %                             end
                        
                end
                
                
                
                %% if these neurons are simoultanously recorded i.e. in one
                % recording then take one sample from everyone per repetition
                % loop through neurons of the this group and get the data for this
                % conditions
                for Neu=NeuGroups{NeuGrp}
                    Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    
                    AllStimInds{Neu}=StimInds;
                    if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                        for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                            SpkCntData{i}(:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).FactorData_SpkCnt{i}{CondInd(x)}(StimInds{x}),1:length(CondInd),'UniformOutput',0)));
                        end
                    end
                end
            end
            
            % report the labels
            DataLabels=cell2mat(arrayfun(@(x) x*ones(sum(opts.ntrlPerCond),1),FactorLevelComb(CondInd,1),'UniformOutput',0));
            % produce warning if response direction of the data is not matching per neuron
            if size(unique(squeeze(AllFactors(:,6,:))','rows'),1)~=1;warning('Response Direction is not matching for each neuron');end
            % get average of the factors about the behavioral model
            %'Hybrid_W_Color1','Hybrid_W_Color2','Hybrid_W_Shape1','Hybrid_W_Shape2','Hybrid_Baxes',
            if length(unique(AnalysisOpts.Ch_2look_RecDate))==1
                AllFactors=AllFactors(:,:,1);
            else
                MeanBhvFact=mean(AllFactors,3);
                AllFactors=AllFactors(:,:,1);
                AllFactors(:,10:35)=MeanBhvFact(:,10:35); % get the mean values
            end
        end
        function [Data,DataLabels,AllFactors,AllStimInds,SpkCntData,AllFactors3D]=GrabDataFromCond_MaxMatchFull(obj,FactorData,CondInd,FactorLevelComb,opts,varargin) % grabs data for this condition but maximize matching the trials for each neuron
            % if you are taking a trial for a neuron 1) take the same trial for all of
            % the neurons that are simoultanously recorded with this neuron
            % 2) match this object with all of the other neurons that are not
            % simoultanously recorded
            % if there are not enough number of trials then randomly choose anouther
            % object
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(FactorData);
            CongruencyInd=strcmp(AnalysisOpts.factornames,'Congruency');
            CorrIncorrInd=strcmp(AnalysisOpts.factornames,'Reward');
            ResponseInd=strcmp(AnalysisOpts.factornames,'ResponseLoc');
            ShapeMLInd=strcmp(AnalysisOpts.factornames,'ShapeML');
            ColorMLInd=strcmp(AnalysisOpts.factornames,'ColorML');
            RuleInd=strcmp(AnalysisOpts.factornames,'Rule');
            SeqHistInd=strcmp(AnalysisOpts.factornames,'SeqHist');
            SpkCntData=cell(1);
            % find match factors 
            MatchFactorsStimCongruency=obj.StimCongruencyFactorName{opts.StimCongruency};
            if ischar(MatchFactorsStimCongruency)
                MatchFactorsStimCongruencyInd= {strcmp(AnalysisOpts.factornames,MatchFactorsStimCongruency)};
            elseif iscell(MatchFactorsStimCongruency)
                MatchFactorsStimCongruencyInd=cellfun(@(x) strcmp(AnalysisOpts.factornames,x),MatchFactorsStimCongruency,'UniformOutput',0);
            end
            MatchInds=cellfun(@find ,[{ColorMLInd} {ShapeMLInd} {ResponseInd} {CorrIncorrInd} {RuleInd} MatchFactorsStimCongruencyInd]);% indexes we want trials to be matched
            
            % pick the conditions based on simoultanously recorded neurons
            NeuGroups=cellfun(@(x) find(strcmp(AnalysisOpts.Ch_2look_RecDate,x)),unique(AnalysisOpts.Ch_2look_RecDate),'UniformOutput',0);
            % % find the neuron with maximum number of combinations
            %NCombsNeurons=cell2mat(arrayfun(@(Neu) cellfun(@(x) obj.ManData.CalNumUniqueCombsofConds(x(:,1:2)),FactorData(Neu).AllFactors(CondInd),'UniformOutput',true)',1:NNeu,'UniformOutput',0));
            
            % initialize MatchFactors
            MatchFactors=cell(1,length(CondInd));
            % choose a random neuron to sample all of the trials from
            Neu=randsample(NNeu,1);
            % find the group this neuron belongs to
            FirstNeuGrp=find(cellfun(@(x) sum(x==Neu),NeuGroups));
            NeuGroupSet=[FirstNeuGrp setdiff(1:length(NeuGroups),FirstNeuGrp)]; % set of groups of neurons we are looping though
            % grab data per neuron and concatinate
            k=1;
            for NeuGrp=NeuGroupSet
                Neu=NeuGroups{NeuGrp}(1); % choose the first neuron from the group
                %if we are balancing congruent and incongruent trials
                switch opts.StimCongruency % we care about congruency condition
                    case 0 % we don't care about congruency
                        % error('This condition is no longer supported');
                        StimInds=cellfun(@(x) randsample(1:size(x,1),sum(opts.ntrlPerCond)),FactorData(Neu).data(CondInd),'UniformOutput',false);
                        
                    case {[1],[2],[3],[4],[5]}
                        
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                            FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                        
                    case {[6],[12]}
                        % randomly sample data
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                            [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,CorrIncorrInd)],obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                        
                    case 7
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                            FactorData(Neu).AllFactors{CondInd(x)}(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                    case 8
                        % equalize the number for response directions for each condition
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                            FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:),MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                    case 9
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        if length(unique(FactorLevelComb(CondInd,2)))>1 & sum(unique(FactorLevelComb(CondInd,2))==2)
                            error('This condition is only for one rule when there is rule 2 present');end
                        if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about the response location
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{8}(FactorLevelComb(CondInd(x),2),:),MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                        else
                            % randomly sample data
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                [FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);
                        end
                    case 10
                        % balance congruency for each condition with a
                        % specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        
                        for ThisCond=1:length(CondInd)
                            if FactorLevelComb(CondInd(ThisCond),2)==2 % if it is 2 then we just care about balancing congruency
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            else
                                % randomly sample data with congruency and SeqHist
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            end
                        end
                        %                             if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about balancing congruency
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition(opts.ntrlPerCond,...
                        %                                     FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd),obj.StimCongruencyConds{4}),1:length(CondInd),'UniformOutput',0);
                        %                             else
                        %                                 % randomly sample data with congruency and SeqHist
                        %                                 [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition(opts.ntrlPerCond,...
                        %                                     [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],[obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])]),1:length(CondInd),'UniformOutput',0);
                        %                             end
                    case 11 % balance congruency and response direction
                        % randomly sample data
                        if sum(FactorLevelComb(CondInd,2)==2)<length(CondInd) & sum(FactorLevelComb(CondInd,2)==2)>0;error('two rules cant be use at the ame time');end
                        if sum(FactorLevelComb(CondInd,2)==2);obj.StimCongruencyConds{11}=[0 3;0 4;1 3;1 4];end % change for rule 
                            
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                            [FactorData(Neu).AllFactors{CondInd(x)}(:,CongruencyInd) FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd)],...
                            obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),1:length(CondInd),'UniformOutput',0);                   
                    case 13 % balnce SeqHist and correct incorrect
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        for ThisCond=1:length(CondInd)
                            if FactorLevelComb(CondInd(ThisCond),2)==2 % if it is 2 then we just care about balancing congruency
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    FactorData(Neu).AllFactors{CondInd(x)}(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            else
                                % randomly sample data with reward and SeqHist
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [FactorData(Neu).AllFactors{CondInd(x)}(:,CorrIncorrInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            end
                        end
                    case 14 % balance response direction and SeqHist
                        % equalize the number for response directions for
                        % each condition with a specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        for ThisCond=1:length(CondInd)
                            if FactorLevelComb(CondInd(ThisCond),2)==2 % if it is 2 then we just care about balancing congruency
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd),obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:),MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            else
                                % randomly sample data with responsedirection and SeqHist
                                [~,StimInds(ThisCond)]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [FactorData(Neu).AllFactors{CondInd(x)}(:,ResponseInd) FactorData(Neu).AllFactors{CondInd(x)}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}(FactorLevelComb(CondInd(x),2),:)',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},FactorData(Neu).AllFactors{CondInd(x)}(:,MatchInds)),ThisCond,'UniformOutput',0);
                            end                          
                        end
                end  
                
                %% if these neurons are simoultanously recorded i.e. in one
                % recording then take one sample from everyone per repetition
                % loop through neurons of the this group and get the data for this
                % conditions
                % find all fo the neurons that are recorded simoultanously with this
                % neuron
                for Neu=NeuGroups{NeuGrp}
                    Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).data{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},:),1:length(CondInd),'UniformOutput',0)));
                    
                    AllStimInds{Neu}=StimInds;
                    if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                        for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                            SpkCntData{i}(:,Neu)=cell2mat(transpose(arrayfun(@(x) FactorData(Neu).FactorData_SpkCnt{i}{CondInd(x)}(StimInds{x}),1:length(CondInd),'UniformOutput',0)));
                        end
                    end
                end
                
                % now for the rest of the neurons find the trial with the best match for
                % this condition
                % first define match factors which are matching for ColorML ShapeML Response Rule Reward
                if k==1
                    MatchFactors=arrayfun(@(x) FactorData(Neu).AllFactors{CondInd(x)}(StimInds{x},MatchInds),1:length(CondInd),'UniformOutput',0);
                end
                k=k+1; % loop on neugroups
            end
            
            
            % report the labels
            DataLabels=cell2mat(arrayfun(@(x) x*ones(sum(opts.ntrlPerCond),1),FactorLevelComb(CondInd,1),'UniformOutput',0));
            % produce warning if response direction of the data is not matching per neuron
            if size(unique(squeeze(AllFactors(:,ResponseInd,:))','rows'),1)~=1
                error('Response Direction is not matching for each neuron');
            end
            % produce error if the congruency conditions is not matching for each neuron
            for mfi=1:length(MatchFactorsStimCongruencyInd)
                if size(unique(squeeze(AllFactors(:,MatchFactorsStimCongruencyInd{mfi},:))','rows'),1)~=1
                    error('Congruency Conditions is not matching for each neuron');
                end
            end
            % get average of the factors about the behavioral model
            %'Hybrid_W_Color1','Hybrid_W_Color2','Hybrid_W_Shape1','Hybrid_W_Shape2','Hybrid_Baxes',
            AllFactors3D=AllFactors;
            if length(unique(AnalysisOpts.Ch_2look_RecDate))==1
                AllFactors=AllFactors(:,:,1);
            else
                MeanBhvFact=mean(AllFactors,3);
                AllFactors=AllFactors(:,:,1);
                AllFactors(:,10:35)=MeanBhvFact(:,10:35); % get the mean values
                % for bhv performance take the average but across recordings 
                IndRecs=cellfun(@(x) find(strcmp(AnalysisOpts.Ch_2look_RecDate,x),1,'first'),unique(AnalysisOpts.Ch_2look_RecDate));
                bhvPerf=mean(AllFactors3D(:,43:46,IndRecs),3);
                AllFactors(:,43:46)=bhvPerf;                
            end
        end
        
        function [Data,DataLabels,AllFactors,AllStimInds,SpkCntData,AllFactors3D]=GrabDataFromCond_MaxMatchFullCorrect(obj,FactorData,CondInd,FactorLevelComb,opts,varargin) % grabs data for this condition but maximize matching the trials for each neuron
            % corrected so that it looks for the target dimension in this specific dimension rather than only the first dimension 
            % if you are taking a trial for a neuron 1) take the same trial for all of
            % the neurons that are simoultanously recorded with this neuron
            % 2) match this object with all of the other neurons that are not
            % simoultanously recorded
            % if there are not enough number of trials then randomly choose anouther
            % object
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NNeu=length(FactorData);
            CongruencyInd=strcmp(AnalysisOpts.factornames,'Congruency');
            CorrIncorrInd=strcmp(AnalysisOpts.factornames,'Reward');
            ResponseInd=strcmp(AnalysisOpts.factornames,'ResponseLoc');
            ShapeMLInd=strcmp(AnalysisOpts.factornames,'ShapeML');
            ColorMLInd=strcmp(AnalysisOpts.factornames,'ColorML');
            RuleInd=strcmp(AnalysisOpts.factornames,'Rule');
            SeqHistInd=strcmp(AnalysisOpts.factornames,'SeqHist');
            SpkCntData=cell(1);
            % find match factors 
            MatchFactorsStimCongruency=obj.StimCongruencyFactorName{opts.StimCongruency};
            if ischar(MatchFactorsStimCongruency)
                MatchFactorsStimCongruencyInd= {strcmp(AnalysisOpts.factornames,MatchFactorsStimCongruency)};
            elseif iscell(MatchFactorsStimCongruency)
                MatchFactorsStimCongruencyInd=cellfun(@(x) strcmp(AnalysisOpts.factornames,x),MatchFactorsStimCongruency,'UniformOutput',0);
            end
             MatchInds=cellfun(@find ,[{ColorMLInd} {ShapeMLInd} {ResponseInd} {CorrIncorrInd} {RuleInd} MatchFactorsStimCongruencyInd]);% indexes we want trials to be matched
            % get the target factor for this dimension 
            [TargetLevels,TargetFactor,~,~,~,DimTxt]=obj.getClassifierDimInfo(opts,obj.LookatDim2);
            TargetFactorInd=obj.GetFactornameInd(TargetFactor);

            if iscell(TargetLevels)
                TargetLevels=TargetLevels{unique(FactorLevelComb(CondInd,2))};
            end
            
            StimCong10WithCongCheck(1)=strcmp(TargetFactor,'Rule') & sum(contains(MatchFactorsStimCongruency,'Congruency')) & ...
                    (strcmp(opts.TargetFactors{1},'ShapeCat') | strcmp(opts.TargetFactors{1},'ColorCat')) & opts.StimCongruency==10;
            StimCong10WithCongCheck(2)= strcmp(TargetFactor,'Rule') & strcmp(opts.TargetFactors{1},'ResponseLoc') & opts.StimCongruency==13;
            
            if sum(StimCong10WithCongCheck)
                % then make sure we also balance the shape or color category so we have enough congruency trials per condition
                StimCong10WithCong=1;
            else
                StimCong10WithCong=0;
            end

            % if we are grabbing test data check if it is one class classification
            if obj.GrabbingTestData==1             
                if ~isempty(opts.(['One_Class_ResponseLbl' DimTxt]){opts.CurrCond}) % if we are not doing one class                  
                    TargetLevels = opts.(['One_Class_ResponseLbl' DimTxt]){opts.CurrCond};
                    if StimCong10WithCong==0
                        opts.ntrlPerCond=opts.ntrlPerCond*length(CondInd); % get double the number because we only have one category
                    end
                end
            end
            if size(TargetLevels,1)>1;TargetLevels=TargetLevels';end
            nTargetLvl=length(TargetLevels);
            % pick the conditions based on simoultanously recorded neurons
            NeuGroups=cellfun(@(x) find(strcmp(AnalysisOpts.Ch_2look_RecDate,x)),unique(AnalysisOpts.Ch_2look_RecDate),'UniformOutput',0);
            % % find the neuron with maximum number of combinations
            %NCombsNeurons=cell2mat(arrayfun(@(Neu) cellfun(@(x) obj.ManData.CalNumUniqueCombsofConds(x(:,1:2)),FactorData(Neu).AllFactors(CondInd),'UniformOutput',true)',1:NNeu,'UniformOutput',0));
            
            % initialize MatchFactors
            MatchFactors=cell(1,length(CondInd));
            % choose a random neuron to sample all of the trials from
            Neu=randsample(NNeu,1);
            % find the group this neuron belongs to
            FirstNeuGrp=find(cellfun(@(x) sum(x==Neu),NeuGroups));
            NeuGroupSet=[FirstNeuGrp setdiff(1:length(NeuGroups),FirstNeuGrp)]; % set of groups of neurons we are looping though
            % grab data per neuron and concatinate
            k=1;
            try
            for NeuGrp=NeuGroupSet
                Neu=NeuGroups{NeuGrp}(1); % choose the first neuron from the group
               
                % get the factor data for this neuron
                ThisFactors=obj.ManData.ReshapeCell2Mat(FactorData(Neu).AllFactors(CondInd),62); % now we have the train factors to be shuffled
                % divide the data based on the factor level into different cells
                ThisFactorsLevl=arrayfun(@(x) ThisFactors(ThisFactors(:,TargetFactorInd)==x,:),TargetLevels,'UniformOutput',0);
  
                % get the index of these trials based on Factor level comb
                FactLvlCmbBasedTrlIndexTrl=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) [1:size(FactorData(Neu).AllFactors{CondInd(x)},1)]',1:length(CondInd),'UniformOutput',0),62);
                FactLvlCmbBasedTrlIndexCondInd=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) x*ones(size(FactorData(Neu).AllFactors{CondInd(x)},1),1),1:length(CondInd),'UniformOutput',0),62);
              
                % sort based on target level
                FactLvlCmbBasedTrlIndexTrl=arrayfun(@(x) FactLvlCmbBasedTrlIndexTrl(ThisFactors(:,TargetFactorInd)==x,:),TargetLevels,'UniformOutput',0);
                FactLvlCmbBasedTrlIndexCondInd=arrayfun(@(x) FactLvlCmbBasedTrlIndexCondInd(ThisFactors(:,TargetFactorInd)==x,:),TargetLevels,'UniformOutput',0);

                %if we are balancing congruent and incongruent trials
                switch opts.StimCongruency % we care about congruency condition
                    case 0 % we don't care about congruency
                        error('This condition is no longer supported');
                        StimInds=cellfun(@(x) randsample(1:size(x,1),sum(opts.ntrlPerCond)),FactorData(Neu).data(CondInd),'UniformOutput',false);

                    case {[1],[2],[3],[4],[5]}
                        try
                            % randomly sample data
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                ThisFactorsLevl{x}(:,CongruencyInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                        catch
                            disp('error')
                        end
                    case {[6],[12]}
                        % randomly sample data
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                            [ThisFactorsLevl{x}(:,CongruencyInd) ThisFactorsLevl{x}(:,CorrIncorrInd)],obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);

                    case 7
                        % randomly sample data inds
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                            ThisFactorsLevl{x}(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);


                    case 8
                        % equalize the number for response directions for each condition
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % randomly sample data inds               
                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                            ThisFactorsLevl{x}(:,ResponseInd),obj.StimCongruencyConds{opts.StimCongruency}(unique(FactorLevelComb(CondInd,2)),:),MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                  
                    case 9
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        if length(unique(FactorLevelComb(CondInd,2)))>1 & sum(unique(FactorLevelComb(CondInd,2))==2)
                            error('This condition is only for one rule when there is rule 2 present');end
                        if unique(FactorLevelComb(CondInd,2))==2 % if it is 2 then we just care about the response location
                                        
                             [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                ThisFactorsLevl{x}(:,ResponseInd),TargetLevels,MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                      
                        else
                            % randomly sample data
                            [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                [ThisFactorsLevl{x}(:,ResponseInd) ThisFactorsLevl{x}(:,SeqHistInd)],[TargetLevels',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);

                        end
                    case 10
                        % balance congruency for each condition with a specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        % if length(unique(FactorLevelComb(CondInd,2)))>1;error('This condition is only for one rule');end
                        
                        if length(unique(FactorLevelComb(CondInd,2)))>1 & sum(unique(FactorLevelComb(CondInd,2))==2);error('R2 can not be with other rules');end
                       
                        if StimCong10WithCong==0
                            if unique(FactorLevelComb(CondInd,2))==2 & length(unique(FactorLevelComb(CondInd,2)))==1 % if it is 2 then we just care about balancing congruency
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    ThisFactorsLevl{x}(:,CongruencyInd),obj.StimCongruencyConds{4},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            else
                                % randomly sample data with congruency and SeqHist
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [ThisFactorsLevl{x}(:,CongruencyInd) ThisFactorsLevl{x}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            end
                        else
                            % first filter the SeqHistData      
                            IndThisSeqHist=arrayfun(@(x) ThisFactorsLevl{x}(:,SeqHistInd)==opts.SeqHistCond{opts.CurrCond},1:nTargetLvl,'uniformoutput',0);
                            ThisFactorsLevl=arrayfun(@(x) ThisFactorsLevl{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                            FactLvlCmbBasedTrlIndexTrl=arrayfun(@(x) FactLvlCmbBasedTrlIndexTrl{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                            FactLvlCmbBasedTrlIndexCondInd=arrayfun(@(x) FactLvlCmbBasedTrlIndexCondInd{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                             
                            if unique(FactorLevelComb(CondInd,2))==2 & length(unique(FactorLevelComb(CondInd,2)))==1 % if it is 2 then we just care about balancing congruency
                               error('this is wrong');
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    ThisFactorsLevl{x}(:,CongruencyInd),obj.StimCongruencyConds{4},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            else
                                    
                                % randomly sample data with congruency and SeqHist
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch([opts.ntrlPerCond opts.ntrlPerCond],...
                                    [ThisFactorsLevl{x}(:,CongruencyInd) ThisFactorsLevl{x}(:,opts.(opts.TargetFactors{1}).Ind)],...
                                    [1 1;0 1;1 2;0 2],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            end                                              
                        end
                        
                    case 11 % balance congruency and response direction
                        % randomly sample data
                        if sum(FactorLevelComb(CondInd,2)==2)<length(CondInd) & sum(FactorLevelComb(CondInd,2)==2)>0;error('two rules cant be use at the ame time');end
                        if sum(FactorLevelComb(CondInd,2)==2);obj.StimCongruencyConds{11}=[0 3;0 4;1 3;1 4];end % change for rule

                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                            [ThisFactorsLevl{x}(:,CongruencyInd) ThisFactorsLevl{x}(:,ResponseInd)],...
                            obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);

                    case 13 % balnce SeqHist and correct incorrect
                        % equalize the number for response directions for each condition with a specific seqHisr
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end

                        if length(unique(FactorLevelComb(CondInd,2)))>1 & sum(unique(FactorLevelComb(CondInd,2))==2);error('R2 can not be with other rules');end

                        if StimCong10WithCong==0
                            if unique(FactorLevelComb(CondInd,2))==2 & length(unique(FactorLevelComb(CondInd,2)))==1 % if it is 2 then we just care about balancing congruency
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    ThisFactorsLevl{x}(:,CorrIncorrInd),obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            else
                                % randomly sample data with reward and SeqHist
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [ThisFactorsLevl{x}(:,CorrIncorrInd) ThisFactorsLevl{x}(:,SeqHistInd)],...
                                    [obj.StimCongruencyConds{opts.StimCongruency}',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            end
                        else
                            % first filter the SeqHistData
                            IndThisSeqHist=arrayfun(@(x) ThisFactorsLevl{x}(:,SeqHistInd)==opts.SeqHistCond{opts.CurrCond},1:nTargetLvl,'uniformoutput',0);
                            ThisFactorsLevl=arrayfun(@(x) ThisFactorsLevl{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                            FactLvlCmbBasedTrlIndexTrl=arrayfun(@(x) FactLvlCmbBasedTrlIndexTrl{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                            FactLvlCmbBasedTrlIndexCondInd=arrayfun(@(x) FactLvlCmbBasedTrlIndexCondInd{x}(IndThisSeqHist{x},:),1:nTargetLvl,'uniformoutput',0);
                             
                            if unique(FactorLevelComb(CondInd,2))==2 & length(unique(FactorLevelComb(CondInd,2)))==1 % if it is 2 then we just care about balancing congruency
                               error('this is wrong');
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    ThisFactorsLevl{x}(:,CongruencyInd),obj.StimCongruencyConds{4},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            else
                                % randomly sample data with CorrIncorrInd and SeqHist
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch([opts.ntrlPerCond opts.ntrlPerCond],...
                                    [ThisFactorsLevl{x}(:,CorrIncorrInd) ThisFactorsLevl{x}(:,opts.(opts.TargetFactors{1}).Ind)],...
                                    [1 1;0 1;1 2;0 2],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            end                                              
                        end
                         
                    case 14 % balance response direction and SeqHist
                        % equalize the number for response directions for
                        % each condition with a specific seqHist
                        if ~strcmp(opts.TargetFactors{2},'Rule');error('This option is only for rule factors');end
                        if length(unique(FactorLevelComb(CondInd,2)))>1 & sum(unique(FactorLevelComb(CondInd,2))==2);error('R2 can not be with other rules');end

                            if unique(FactorLevelComb(CondInd,2))==2 & length(unique(FactorLevelComb(CondInd,2)))==1 % if it is 2 then we just care about balancing congruency
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithCondition_MaxMatch(opts.ntrlPerCond,...
                                    ThisFactorsLevl{x}(:,ResponseInd),TargetLevels,MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            else
                                % randomly sample data with responsedirection and SeqHist
                                [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                                    [ThisFactorsLevl{x}(:,ResponseInd) ThisFactorsLevl{x}(:,SeqHistInd)],...
                                    [TargetLevels',repmat(obj.SeqHistCond,[2 1])],MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                            end    

                    case 16 % balance incongruency and response direction
                        % randomly sample data
                        if sum(FactorLevelComb(CondInd,2)==2)<length(CondInd) & sum(FactorLevelComb(CondInd,2)==2)>0;error('two rules cant be use at the same time');end
                        if sum(FactorLevelComb(CondInd,2)==2);obj.StimCongruencyConds{16}=[0 3;0 4];end % change for rule

                        [~,StimInds]=arrayfun(@(x)obj.ManData.RandSampleWithDoubleCondition_MaxMatch(opts.ntrlPerCond,...
                            [ThisFactorsLevl{x}(:,CongruencyInd) ThisFactorsLevl{x}(:,ResponseInd)],...
                            obj.StimCongruencyConds{opts.StimCongruency},MatchFactors{x},ThisFactorsLevl{x}(:,MatchInds)),1:nTargetLvl,'UniformOutput',0);
                end  
                
                % convert stimulus inds into indexes similar to factor level comb
                FactLvlCmbBasedTrlIndexTrl_Conv    =obj.ManData.ReshapeCell2Mat(arrayfun(@(x) FactLvlCmbBasedTrlIndexTrl{x}(StimInds{x}),1:nTargetLvl,'UniformOutput',0),62);
                FactLvlCmbBasedTrlIndexCondInd_Conv=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) FactLvlCmbBasedTrlIndexCondInd{x}(StimInds{x}),1:nTargetLvl,'UniformOutput',0),62);
                StimInds_Conv=arrayfun(@(x) FactLvlCmbBasedTrlIndexTrl_Conv(FactLvlCmbBasedTrlIndexCondInd_Conv==x)',1:length(CondInd),'UniformOutput',0);

                %% if these neurons are simoultanously recorded i.e. in one
                %  recording then take one sample from everyone per repetition
                %  loop through neurons of the this group and get the data for this conditions
                %  find all fo the neurons that are recorded simoultanously with this neuron
                for Neu=NeuGroups{NeuGrp}
                    % get the data for this Neuron 
                    ThisNeuData=obj.ManData.ReshapeCell2Mat(FactorData(Neu).data(CondInd),62); % now we have the train factors to be shuffled
                    % divide the data based on the factor level into different cells
                    ThisNeuDataLevl=arrayfun(@(x) ThisNeuData(ThisFactors(:,TargetFactorInd)==x,:),TargetLevels,'UniformOutput',0);
                    if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                        for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                            ThisNeuDataSpk=obj.ManData.ReshapeCell2Mat(FactorData(Neu).FactorData_SpkCnt{i}(CondInd),62); % now we have the train factors to be shuffled
                            ThisNeuDataSpkLevl{i}=arrayfun(@(x) ThisNeuDataSpk(ThisFactors(:,TargetFactorInd)==x),TargetLevels,'UniformOutput',0);
                        end
                    end
                    % get the data 
                    Data(:,Neu,:)=cell2mat(transpose(arrayfun(@(x) ThisNeuDataLevl{x}(StimInds{x},:),1:nTargetLvl,'UniformOutput',0)));
                    AllFactors(:,:,Neu)=cell2mat(transpose(arrayfun(@(x) ThisFactorsLevl{x}(StimInds{x},:),1:nTargetLvl,'UniformOutput',0)));
                    if ~isempty(FactorData(Neu).FactorData_SpkCnt) % then get trials for spike counts as well
                        for i=1:length(FactorData(Neu).FactorData_SpkCnt)
                            SpkCntData{i}(:,Neu)=cell2mat(transpose(arrayfun(@(x) ThisNeuDataSpkLevl{i}{x}(StimInds{x}),1:nTargetLvl,'UniformOutput',0)));
                        end
                    end
                    AllStimInds{Neu}=StimInds_Conv;
                end
                
                % now for the rest of the neurons find the trial with the best match for
                % this condition
                % first define match factors which are matching for ColorML ShapeML Response Rule Reward
                if k==1
                    MatchFactors=arrayfun(@(x) ThisFactorsLevl{x}(StimInds{x},MatchInds),1:nTargetLvl,'UniformOutput',0);
                end
                k=k+1; % loop on neugroups
            end
            catch ME
                error(ME.message);
            end
            if StimCong10WithCong==1;opts.ntrlPerCond=opts.ntrlPerCond*2;end
            % report the labels
            DataLabels=cell2mat(arrayfun(@(x) x*ones(sum(opts.ntrlPerCond),1),TargetLevels','UniformOutput',0));
            % produce warning if response direction of the data is not matching per neuron
            if size(unique(squeeze(AllFactors(:,ResponseInd,:))','rows'),1)~=1
                warning('Response Direction is not matching for each neuron');
            end
            % produce error if the congruency conditions is not matching for each neuron
            for mfi=1:length(MatchFactorsStimCongruencyInd)
                if size(unique(squeeze(AllFactors(:,MatchFactorsStimCongruencyInd{mfi},:))','rows'),1)~=1
                    error('Congruency Conditions is not matching for each neuron');
                end
            end
            % get average of the factors about the behavioral model
            %'Hybrid_W_Color1','Hybrid_W_Color2','Hybrid_W_Shape1','Hybrid_W_Shape2','Hybrid_Baxes',
            AllFactors3D=AllFactors;
            if length(unique(AnalysisOpts.Ch_2look_RecDate))==1
                AllFactors=AllFactors(:,:,1);
            else
                MeanBhvFact=mean(AllFactors,3);
                AllFactors=AllFactors(:,:,1);
                AllFactors(:,10:35)=MeanBhvFact(:,10:35); % get the mean values
                % for bhv performance take the average but across recordings 
                IndRecs=cellfun(@(x) find(strcmp(AnalysisOpts.Ch_2look_RecDate,x),1,'first'),unique(AnalysisOpts.Ch_2look_RecDate));
                bhvPerf=mean(AllFactors3D(:,43:46,IndRecs),3);
                AllFactors(:,43:46)=bhvPerf;                
            end
        end
       

        function [FactorData,CatFactorData,FactorLevelComb,FactorLevels]=PrepareData4ClassifierAnalysis(obj,FactorizedData,ClassifierOpts,varargin) % prepares population data using factors fpr classifier analysis
            %@FactorizedData factorized data based on different defined factors
            %@TargetFactor factors used to organize the input data
            %@
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % if we have mixture of correct and incorrect trials then take
            % then take all of the trials 
            if length(ClassifierOpts.TrialType)>1 & sum(ClassifierOpts.TrialType==3);ClassifierOpts.TrialType=3;end
            
            for Neu=1:length(FactorizedData) % loop on the neurons
                % find the data for this factor
                [FactorData(Neu).data,FactorData(Neu).dataMean,FactorLevelComb,FactorLevels,FactorData(Neu).AllFactors,~,~,FactorData(Neu).FactorData_SpkCnt]=...
                    obj.GrabFactorDatabyLevel(FactorizedData(Neu),ClassifierOpts.TargetFactors,ClassifierOpts.Levels,'PCAonlyCorrTrls',ClassifierOpts.TrialType);
            end
            % concatinate mean data for factors
            CatFactorData=obj.ManData.ReshapeStruct2Mat(FactorData,'dataMean',3);
        end
        function FactorData=LimitTrialsBasedonFactor(obj,FactorData,FactorName,FactorValues,FactorOperation,varargin) % limits trials of a selection of based on limits imposed by an specific factor
            %@FactorData is the output of PrepareData4ClassifierAnalysis
            %@FactorName name of the factor we want to change
            %@FactorValues accepted values of this factor
            %@FactorOperation define what operation we are doign with
            %factor can be 'equal','bigger','smaller','interval(provide values in pairs of columns)'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isnan(FactorValues);return;end % we are not changing anything
            % if it is trial number but they are negative then reverse the order
            if strcmp('TrialNum',FactorName) & sum(FactorValues<0); FactorName='TrialNumReverse';end
            if ~exist('FactorOperation','var');FactorOperation='equal';end
            if isnan(FactorOperation);return;end % we are not changing anything

            FactorInd=find(strcmp(AnalysisOpts.factornames,FactorName));
            % loop through all of the structures and change the fields (remove data mean because it is not correct anymore
            for i=1:length(FactorData)
                switch FactorOperation
                    case 'equal'
                        IncludedTrls=cellfun(@(x) cell2mat(arrayfun(@(y) find(x(:,FactorInd)==y)',FactorValues,'Uniformoutput',0)),FactorData(i).AllFactors,'uniformoutput',0);
                    case 'bigger'
                        IncludedTrls=cellfun(@(x) cell2mat(arrayfun(@(y) find(x(:,FactorInd)>=y)',FactorValues,'Uniformoutput',0)),FactorData(i).AllFactors,'uniformoutput',0);
                    case 'smaller'
                        IncludedTrls=cellfun(@(x) cell2mat(arrayfun(@(y) find(x(:,FactorInd)<=y)',FactorValues,'Uniformoutput',0)),FactorData(i).AllFactors,'uniformoutput',0);
                    case 'interval'
                        IncludedTrls=cellfun(@(x) cell2mat(arrayfun(@(y) find(x(:,FactorInd)>=FactorValues(y,1) & x(:,FactorInd)<=FactorValues(y,2))',1:size(FactorValues,1),'Uniformoutput',0)),FactorData(i).AllFactors,'uniformoutput',0);
                end
                
                FactorData(i).AllFactors=arrayfun(@(x) FactorData(i).AllFactors{x}(IncludedTrls{x},:),1:length(IncludedTrls),'UniformOutput',0);
                FactorData(i).data=arrayfun(@(x) FactorData(i).data{x}(IncludedTrls{x},:),1:length(IncludedTrls),'UniformOutput',0);
                if ~isempty(FactorData(i).FactorData_SpkCnt) % loop on spike data if we have any
                    for k=1:length(FactorData(i).FactorData_SpkCnt)
                        FactorData(i).FactorData_SpkCnt{k}=arrayfun(@(x) FactorData(i).FactorData_SpkCnt{k}{x}(IncludedTrls{x},:),1:length(IncludedTrls),'UniformOutput',0);
                    end
                end
            end
            if isfield(FactorData,'dataMean')
                FactorData=rmfield(FactorData,'dataMean');
            end
        end
        function FactorData=SkipSeqHistTrain(obj,FactorData,ClassifierOpts,Cond)
            % if ClassifierOpts.SkipSeqHistTrain=1; then we don't apply SeqHist to train data

            if ClassifierOpts.SkipSeqHistTrain~=1;return;end
            SeqHistInd=ClassifierOpts.SeqHist.Ind;
            for Neu=1:length(FactorData)
                for i=1:length(FactorData(Neu).AllFactors)
                    FactorData(Neu).AllFactors{i}(:,SeqHistInd)=ClassifierOpts.SeqHistCond{Cond};
                end
            end
        end
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%SVM CLASSIFIER METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        function [Observed, Shuffled,ClassifierOpts,classificationSVM] = SVMClassifier_Binary(obj,predictors,response,ClassifierOpts,varargin)
            % Camden MacDowell 2019
            %
            % See MATLAB documentation for fitcsvm for more details.
            % Citation for decoding neural data using classifiers:
            % Pereira, Mitchell, Botvinick, 2008 NeuroImage. Machine Learning
            % Classifiers and fMRI: a tutorial overview
            %
            % @SYNPOSIS
            % Performs non-linear binary classification on matrix Data according to the
            % class identities in the last column of Data (see @Data). Automatically
            % tunes classifier hyperparameters kernalscale and boxcontrain using pre-built
            % baysian optimization (baysopt fnc). Optionally performs feature selection
            % (currently only supports ANOVA feature selection).
            %
            % @INPUTS
            % predictors: observations x features matrix. (i.e. trials x pixels for imaging data).
            %
            % response:  contains the response variable with the class identify of
            % each row.
            % if opts.UseSepTrainTestDataset=1 train and test are differnt data sets and must be supplied as cell in response
            % and predictor matrix e.g predictors={TrainData}{TestData}
            %
            % @varargin: see opts structure below
            %
            % @Optimized Hyperparameters:
            % @Box contraint: is the regularization parameter, where
            % increase = hard margin and thus high cost on missclassified points.
            %
            % @Kernal sclae is 1/gamma. This is the radius of influence of the sample
            % selected by the model as support vectors. If small then you end up with
            % lots of support vectors that really only apply to those specific points
            % (low radius of influence). If large than the opposite and the model is to
            % 'rigid'/contrained to capture the shape fo the data.
            %
            % @Kernel
            % RBF: sn ~Gaussian kernel. Good for representing highly varying terrains.
            global AnalysisOpts
            %% Set optional paramters
            opts.UseSepTrainTestDataset=1; % are we using a different set for train and test
            opts.holdout = 0.25; %fraction hold out data for validation
            opts.nshuf = 0; %Number of shuffles for shuffle test
            opts.pca = 0;  %First perform dimensionality reduction. Uses #PCs to explain 99% of variance.
            opts.Kfold=5; % cross validation folds
            opts.solver = 1; % solver to use
            % from MATLAB help
            % For better optimization accuracy when you have high-dimensional predictor data and the Regularization value is 'ridge', set any of these options for Solver:
            % 'sgd' 'asgd' 'dual' if Learner is 'svm' {'sgd','lbfgs'} {'asgd','lbfgs'} {'dual','lbfgs'} if Learner is 'svm'
            % Other options can result in poor optimization accuracy.
            % For better optimization accuracy when you have moderate- to low-dimensional predictor data and the Regularization value is 'ridge', set Solver to 'bfgs'.
            opts.MultiClass=0; % are we doing multiclass classification
            opts.MultiClassCoding='onevsall';
            opts.optimize_maxiter=5; % max iteration for optimization
            opts.ComputePosterior=0; % are we also computing posterior proabbility
            opts.ThisLinearSVMFitFunction='fitclinear';% could be 'fitclinear' 'fitcecoc'  'fitcsvm'
            opts.UseThisClassifier=[]; % are we using a predetermined classifier
            opts.ThisClassifierCond=[]; % current condition of the classifier
            %set appropriate solver;
            solver = {'bfgs',{'sgd','lbfgs'},'sgd','asgd','dual','lbfgs','default'};%for fitceoc{'SMO','ISDA','L1QP'};
            
            %Process optional inputs
            if mod(length(varargin), 2) ~= 0, error('Must pass key/value pairs for options.'); end
            for i = 1:2:length(varargin)
                try
                    opts.(varargin{i}) = varargin{i+1};
                catch
                    error('Couldn''t set option ''%s''.', varargin{2*i-1});
                end
            end
            
            %% check if we need to change any of the parameters
            if isfield(ClassifierOpts,'CrossValidate') % if we are defining crossvalidate in the options then change it
                opts.ThisCrossValidate=ClassifierOpts.CrossValidate(opts.ThisClassifierCond);
            else
                opts.ThisCrossValidate=0; % are we cross validating before training?
            end
            if isfield(ClassifierOpts,'Kernel') % if we are defining kernel in the options then change it
                opts.ThisSVMkernel=ClassifierOpts.Kernel{opts.ThisClassifierCond};
            else
                opts.ThisSVMkernel='linear'; % can also be gaussian for SVM
            end
            if isfield(ClassifierOpts,'Learner')
                opts.ThisLearner=ClassifierOpts.Learner{opts.ThisClassifierCond};
            else
                opts.ThisLearner='logistic'; % can be logistic or svm
            end            
            if isfield(ClassifierOpts,'Lambda') % if we are defining lambda in the options then change it
                opts.ThisLambda=ClassifierOpts.Lambda(opts.ThisClassifierCond);
            else
                opts.ThisLambda=1/60; % L2(ridge) regularizaiton lambda
            end            
            if isfield(ClassifierOpts,'Solver') % if we are defining solver in the options then change it
                opts.solver=ClassifierOpts.Solver(opts.ThisClassifierCond);
            end            
            if isfield(ClassifierOpts,'LinearSVMFitFunction') % if we are defining fit function 
                opts.ThisLinearSVMFitFunction=ClassifierOpts.LinearSVMFitFunction{opts.ThisClassifierCond};
            end            
            if numel(unique(response{1}))>2;opts.MultiClass=1;
                % warning('Using multiclass classifier')
            end % if we have more than one category then we are doing multiclass
            
            ClassifierOpts=obj.ManData.CopyStructFields(opts,ClassifierOpts,fieldnames(opts)); % copy data to our opts
            
            Observed = struct(); %Observed results structure
            Shuffled = struct(); %Shuffled results structure
            
            if opts.UseSepTrainTestDataset % we are using different sets of data for prediction and training
                trainingPredictors = predictors{1};
                trainingResponse = response{1};
                validationPredictors = predictors{2};
                validationResponse = response{2};
            else
                %Hold out data for validation. This is not used in tuning of classifier
                cvp = cvpartition(response, 'Holdout', opts.holdout);
                trainingPredictors = predictors(cvp.training, :);
                trainingResponse = response(cvp.training, :);
                validationPredictors = predictors(cvp.test, :);
                validationResponse = response(cvp.test, :);
            end
            % if we are training and testing the response across two axis then we need to change response direction labels 
            DiffTrnTstLabels=(AnalysisOpts.CheckAxis1Labels(trainingResponse) & AnalysisOpts.CheckAxis2Labels(validationResponse)) | ...
                (AnalysisOpts.CheckAxis2Labels(trainingResponse) & AnalysisOpts.CheckAxis1Labels(validationResponse)) && ...
                 ~AnalysisOpts.CheckBothAxisLabels(trainingResponse) && ~AnalysisOpts.CheckBothAxisLabels(validationResponse)  && contains(obj.Classifier_TaskName,'Response');            
            if  DiffTrnTstLabels  % we are testing on rule 2 and 3/1 response
                trainingResponse(trainingResponse==3)=1;
                trainingResponse(trainingResponse==4)=2;
                validationResponse(validationResponse==3)=1;
                validationResponse(validationResponse==4)=2;
            end
             
                
            %preform pca on the testing data, project validation data into pca space
            if opts.pca
                [coef, score, ~, ~, explain, mu] = pca(trainingPredictors);
                trainingPredictors = score(:,1:find(cumsum(explain)>99,1));
                validationPredictors = (coef(:,1:find(cumsum(explain)>99,1))'*(validationPredictors-repmat(mu,size(validationPredictors,1),1))')';
            end
            % put observations in colums for efficiency you should also mention this in the classifier as input
            % 'ObservationsIn','columns'
            trainingPredictors=trainingPredictors';
            if isempty(opts.UseThisClassifier) % then we are using this calssifier and testing the data only
                if ~opts.MultiClass
                    if opts.ThisCrossValidate
                        % Tune classifier hyperparameters using cross validation: Only use the training data for this.
                        %                     c = cvpartition(trainingResponse, 'kfold', opts.Kfold);
                        %                     optstune = struct('Optimizer','bayesopt','ShowPlots',false,'CVPartition',c,...
                        %                         'AcquisitionFunctionName','expected-improvement-plus','MaxObjectiveEvaluations',50);
                        %                     svmmod = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.SVMkernel,...
                        %                         'OptimizeHyperparameters','auto','HyperparameterOptimizationOptions',optstune,'Verbose',0,...
                        %                         'Solver',solver{opts.solver});
                        %
                        %                     % Build a classifier using tuned parameters and all training data
                        %                     classificationSVM = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.SVMkernel,'BoxConstraint',...
                        %                         svmmod.HyperparameterOptimizationResults.XAtMinObjective.BoxConstraint,...
                        %                         'KernelScale',svmmod.HyperparameterOptimizationResults.XAtMinObjective.KernelScale,'Solver',solver{opts.solver});
                        %  for optimize_maxiter=[5:10:50]
                        %             fprintf('\nMaxIter:%i MinObjective:%i',opts.optimize_maxiter,svmmod.HyperparameterOptimizationResults.MinEstimatedObjective )
                        %          end
                        %          optstune = struct('Optimizer','bayesopt','ShowPlots',true,'Verbose',1,...
                        %          'AcquisitionFunctionName','expected-improvement-plus','MaxObjectiveEvaluations',10);
                        %         classificationSVM = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.SVMkernel,'OptimizeHyperparameters',{'BoxConstraint','KernelScale'},...
                        %         'HyperparameterOptimizationOptions',optstune,'Solver',solver{opts.solver});
                        if strcmp(opts.ThisLearner,'svm')
                            c = cvpartition(trainingResponse, 'kfold', opts.Kfold);
                            optstune = struct('Optimizer','bayesopt','ShowPlots',false,'CVPartition',c,'Verbose',0,...
                                'AcquisitionFunctionName','expected-improvement-plus','MaxObjectiveEvaluations',opts.optimize_maxiter);
                            svmmod = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.ThisSVMkernel,...
                                'OptimizeHyperparameters',{'BoxConstraint','KernelScale'},'ObservationsIn','columns',...
                                'HyperparameterOptimizationOptions',optstune,'Solver','SMO');
                            
                            % Build a classifier using tuned parameters and all training data
                            classificationSVM = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.ThisSVMkernel,'BoxConstraint',...
                                svmmod.HyperparameterOptimizationResults.XAtMinObjective.BoxConstraint,'ObservationsIn','columns',...
                                'KernelScale',svmmod.HyperparameterOptimizationResults.XAtMinObjective.KernelScale,'Solver','SMO');
                        elseif strcmp(opts.ThisLearner,'logistic')
                            %  c = cvpartition(trainingResponse, 'kfold', opts.Kfold);
                            optstune = struct('Optimizer','bayesopt','ShowPlots',false,'Verbose',0);%,'CVPartition',c);
                            
                            [classificationSVM]  = fitclinear(trainingPredictors,trainingResponse,'ObservationsIn','columns','Solver',solver{opts.solver},'Verbose',0, ...
                                'Learner','logistic','OptimizeHyperparameters','auto','HyperparameterOptimizationOptions',...
                                struct('AcquisitionFunctionName','expected-improvement-plus'),...
                                'HyperparameterOptimizationOptions',optstune,'FitBias',true,'PostFitBias',true);
                        end
                        
                    else
                        % Build a classifier using without cross validation and all training data
                        if strcmp(opts.ThisLinearSVMFitFunction,'fitclinear') && strcmp(opts.ThisSVMkernel,'linear')
                            if strcmp(solver{opts.solver},'default') % then let matlab choose the solver
                                classificationSVM=fitclinear(trainingPredictors,trainingResponse,'ObservationsIn','columns','Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,...
                                    'Regularization','ridge','FitBias',true,'PostFitBias',true);
                            else
                                classificationSVM=fitclinear(trainingPredictors,trainingResponse,'ObservationsIn','columns','Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,...
                                    'Regularization','ridge','Solver',solver{opts.solver},'FitBias',true,'PostFitBias',true);
                            end
                        elseif strcmp(opts.ThisLinearSVMFitFunction,'fitcsvm') || ~strcmp(opts.ThisSVMkernel,'linear')
                            classificationSVM = fitcsvm(trainingPredictors',trainingResponse,'KernelFunction',opts.ThisSVMkernel,'Solver','SMO','KernelScale','auto');                      
                        end
                    end
                else % we are doing multi class classification
                    if ~opts.ThisCrossValidate
                        if strcmp(opts.ThisSVMkernel,'linear')
                            t = templateLinear('Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,'Regularization','ridge','Solver',solver{opts.solver});
                        else
                            t = templateSVM('Solver','SMO','KernelFunction',opts.ThisSVMkernel);
                        end
                        classificationSVM = fitcecoc(trainingPredictors,trainingResponse,'ObservationsIn','columns','Learners',t,'Coding', opts.MultiClassCoding);
                    else
                        tic
                        if strcmp(opts.ThisSVMkernel,'linear')
                            t = templateLinear('Learner',opts.ThisLearner,'Regularization','ridge');
                        else
                            t = templateSVM('KernelFunction',opts.ThisSVMkernel,'KernelFunction',opts.ThisSVMkernel);
                        end
                        optstune = struct('Optimizer','bayesopt','ShowPlots',false,'Verbose',0);
                        
                        classificationSVM = fitcecoc(trainingPredictors,trainingResponse,'ObservationsIn','columns',...
                            'Learners',t,'OptimizeHyperparameters','auto',...
                            'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName',...
                            'expected-improvement-plus'),'HyperparameterOptimizationOptions',optstune);
                        toc
                    end
                end
            else % use this classifier instead
                classificationSVM=opts.UseThisClassifier;
            end
            
            % project the test data and calculate performance metrics
            Observed=ProjectData2SVMhyperplane(obj,classificationSVM,validationPredictors,validationResponse,ClassifierOpts);
            
            % Now randomly shuffle the held out labels and use the same classifier
            % Compute validation predictions
            if opts.nshuf
                for shuf = 1:opts.nshuf
                    validationResponse_shuf = validationResponse(randperm(numel(validationResponse)));
                    Shuffled(shuf)=ProjectData2SVMhyperplane(obj,classificationSVM,validationPredictors,validationResponse_shuf,opts);
                    %
                    %                     [validationPredictions, validationScores] = validationPredictFcn(validationPredictors);
                    %                     Outstats = [];
                    %
                    %                     for i = 1:numel(unique(validationResponse))
                    %                         [Outstats(i).X,Outstats(i).Y,Outstats(i).T,Outstats(i).AUC,Outstats(i).OPTROCPT,Outstats(i).SUBY] =...
                    %                             perfcurve( validationResponse_shuf,validationScores(:,i),i);
                    %                     end
                    %
                    %                     % Compute validation accuracy
                    %                     correctPredictions = (validationPredictions ==  validationResponse_shuf);
                    %                     isMissing = isnan( validationResponse_shuf);
                    %                     correctPredictions = correctPredictions(~isMissing);
                    %                     validationAccuracy = sum(correctPredictions)/length(correctPredictions);
                    %
                    %                     Shuffled(shuf).AUC = mean([Outstats(:).AUC]);
                    %                     Shuffled(shuf).X = [cat(1,Outstats(:).X),cat(1,Outstats(:).Y)];
                    %                     Shuffled(shuf).Y = [cat(1,Outstats(:).Y),cat(1,Outstats(:).Y)];
                    %                     Shuffled(shuf).T = [cat(1,Outstats(:).T),cat(1,Outstats(:).T)];
                    %                     Shuffled(shuf).SubY = [cat(1,Outstats(:).X),cat(1,Outstats(:).Y)];
                    %                     Shuffled(shuf).Optrocpt = mean([Outstats(:).AUC]);
                    %                     Shuffled(shuf).Accurary = validationAccuracy;
                    %                     Shuffled(shuf).Predictions = validationPredictions;
                    %                     Shuffled(shuf).CorrectResponse =  validationResponse_shuf;
                    %                     Shuffled(shuf).Scores = validationScores;
                end
            else
                Shuffled=[];
            end
        end
       
        function [Observed, Shuffled,ClassifierOpts,classificationSVM] = SVMClassifier_BinaryOptimized(obj,predictors,response,ClassifierOpts,TrainTimInd,TestTimInd,nXtimePnt,varargin)
            % Camden MacDowell 2019
            %
            % See MATLAB documentation for fitcsvm for more details.
            % Citation for decoding neural data using classifiers:
            % Pereira, Mitchell, Botvinick, 2008 NeuroImage. Machine Learning
            % Classifiers and fMRI: a tutorial overview
            %
            % @SYNPOSIS
            % Performs non-linear binary classification on matrix Data according to the
            % class identities in the last column of Data (see @Data). Automatically
            % tunes classifier hyperparameters kernalscale and boxcontrain using pre-built
            % baysian optimization (baysopt fnc). Optionally performs feature selection
            % (currently only supports ANOVA feature selection).
            %
            % @INPUTS
            % predictors: observations x features matrix. (i.e. trials x pixels for imaging data).
            %
            % response:  contains the response variable with the class identify of
            % each row.
            % if opts.UseSepTrainTestDataset=1 train and test are differnt data sets and must be supplied as cell in response
            % and predictor matrix e.g predictors={TrainData}{TestData}
            %
            % @varargin: see opts structure below
            %
            % @Optimized Hyperparameters:
            % @Box contraint: is the regularization parameter, where
            % increase = hard margin and thus high cost on missclassified points.
            %
            % @Kernal sclae is 1/gamma. This is the radius of influence of the sample
            % selected by the model as support vectors. If small then you end up with
            % lots of support vectors that really only apply to those specific points
            % (low radius of influence). If large than the opposite and the model is to
            % 'rigid'/contrained to capture the shape fo the data.
            %
            % @Kernel
            % RBF: sn ~Gaussian kernel. Good for representing highly varying terrains.
            global AnalysisOpts
            %% Set optional paramters
            opts.UseSepTrainTestDataset=1; % are we using a different set for train and test
            opts.holdout = 0.25; %fraction hold out data for validation
            opts.nshuf = 0; %Number of shuffles for shuffle test
            opts.pca = 0;  %First perform dimensionality reduction. Uses #PCs to explain 99% of variance.
            opts.Kfold=5; % cross validation folds
            opts.solver = 1; % solver to use
            % from MATLAB help
            % For better optimization accuracy when you have high-dimensional predictor data and the Regularization value is 'ridge', set any of these options for Solver:
            % 'sgd' 'asgd' 'dual' if Learner is 'svm' {'sgd','lbfgs'} {'asgd','lbfgs'} {'dual','lbfgs'} if Learner is 'svm'
            % Other options can result in poor optimization accuracy.
            % For better optimization accuracy when you have moderate- to low-dimensional predictor data and the Regularization value is 'ridge', set Solver to 'bfgs'.
            opts.MultiClass=0; % are we doing multiclass classification
            opts.MultiClassCoding='onevsall';
            opts.optimize_maxiter=5; % max iteration for optimization
            opts.ComputePosterior=0; % are we also computing posterior proabbility
            opts.ThisLinearSVMFitFunction='fitclinear';% could be 'fitclinear' 'fitcecoc'  'fitcsvm'
            opts.UseThisClassifier=[]; % are we using a predetermined classifier
            opts.ThisClassifierCond=[]; % current condition of the classifier
            %set appropriate solver;
            solver = {'bfgs',{'sgd','lbfgs'},'sgd','asgd','dual','lbfgs','default'};%for fitceoc{'SMO','ISDA','L1QP'};
            
            %Process optional inputs
            if mod(length(varargin), 2) ~= 0, error('Must pass key/value pairs for options.'); end
            for i = 1:2:length(varargin)
                try
                    opts.(varargin{i}) = varargin{i+1};
                catch
                    error('Couldn''t set option ''%s''.', varargin{2*i-1});
                end
            end
            
            %% check if we need to change any of the parameters
            if isfield(ClassifierOpts,'CrossValidate') % if we are defining crossvalidate in the options then change it
                opts.ThisCrossValidate=ClassifierOpts.CrossValidate(opts.ThisClassifierCond);
            else
                opts.ThisCrossValidate=0; % are we cross validating before training?
            end
            if isfield(ClassifierOpts,'Kernel') % if we are defining kernel in the options then change it
                opts.ThisSVMkernel=ClassifierOpts.Kernel{opts.ThisClassifierCond};
            else
                opts.ThisSVMkernel='linear'; % can also be gaussian for SVM
            end
            if isfield(ClassifierOpts,'Learner')
                opts.ThisLearner=ClassifierOpts.Learner{opts.ThisClassifierCond};
            else
                opts.ThisLearner='logistic'; % can be logistic or svm
            end            
            if isfield(ClassifierOpts,'Lambda') % if we are defining lambda in the options then change it
                opts.ThisLambda=ClassifierOpts.Lambda(opts.ThisClassifierCond);
            else
                opts.ThisLambda=1/60; % L2(ridge) regularizaiton lambda
            end            
            if isfield(ClassifierOpts,'Solver') % if we are defining solver in the options then change it
                opts.solver=ClassifierOpts.Solver(opts.ThisClassifierCond);
            end            
            if isfield(ClassifierOpts,'LinearSVMFitFunction') % if we are defining fit function 
                opts.ThisLinearSVMFitFunction=ClassifierOpts.LinearSVMFitFunction{opts.ThisClassifierCond};
            end            
            if numel(unique(response{1}))>2;opts.MultiClass=1;
                % warning('Using multiclass classifier')
            end % if we have more than one category then we are doing multiclass
            
            ClassifierOpts=obj.ManData.CopyStructFields(opts,ClassifierOpts,fieldnames(opts)); % copy data to our opts
            
            Observed = struct(); %Observed results structure
            Shuffled = struct(); %Shuffled results structure
            
            if opts.UseSepTrainTestDataset % we are using different sets of data for prediction and training
                trainingPredictors = predictors{1};
                trainingResponse = response{1};
                validationPredictors = predictors{2};
                validationResponse = response{2};
            else
                %Hold out data for validation. This is not used in tuning of classifier
                cvp = cvpartition(response, 'Holdout', opts.holdout);
                trainingPredictors = predictors(cvp.training, :);
                trainingResponse = response(cvp.training, :);
                validationPredictors = predictors(cvp.test, :);
                validationResponse = response(cvp.test, :);
            end
            % if we are training and testing the response across two axis then we need to change response direction labels 
            DiffTrnTstLabels=(AnalysisOpts.CheckAxis1Labels(trainingResponse) & AnalysisOpts.CheckAxis2Labels(validationResponse)) | ...
                (AnalysisOpts.CheckAxis2Labels(trainingResponse) & AnalysisOpts.CheckAxis1Labels(validationResponse)) && ...
                 ~AnalysisOpts.CheckBothAxisLabels(trainingResponse) && ~AnalysisOpts.CheckBothAxisLabels(validationResponse)  && contains(obj.Classifier_TaskName,'Response');            
            if  DiffTrnTstLabels  % we are testing on rule 2 and 3/1 response
                trainingResponse(trainingResponse==3)=1;
                trainingResponse(trainingResponse==4)=2;
                validationResponse(validationResponse==3)=1;
                validationResponse(validationResponse==4)=2;
            end
             
                
            %preform pca on the testing data, project validation data into pca space
            if opts.pca
                [coef, score, ~, ~, explain, mu] = pca(trainingPredictors);
                trainingPredictors = score(:,1:find(cumsum(explain)>99,1));
                validationPredictors = (coef(:,1:find(cumsum(explain)>99,1))'*(validationPredictors-repmat(mu,size(validationPredictors,1),1))')';
            end
            % put observations in colums for efficiency you should also mention this in the classifier as input
            % 'ObservationsIn','columns'
            if size(trainingPredictors,3)==1 % we only have one time point
                TrainTimInd=1;TestTimInd=1;nXtimePnt=1;
            end
            if isempty(opts.UseThisClassifier) % then we are using this calssifier and testing the data only
                if ~opts.MultiClass
                    if opts.ThisCrossValidate
                        if strcmp(opts.ThisLearner,'svm')
                            c = cvpartition(trainingResponse, 'kfold', opts.Kfold);
                            optstune = struct('Optimizer','bayesopt','ShowPlots',false,'CVPartition',c,'Verbose',0,...
                                'AcquisitionFunctionName','expected-improvement-plus','MaxObjectiveEvaluations',opts.optimize_maxiter);
                            svmmod = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.ThisSVMkernel,...
                                'OptimizeHyperparameters',{'BoxConstraint','KernelScale'},'ObservationsIn','columns',...
                                'HyperparameterOptimizationOptions',optstune,'Solver','SMO');
                            
                            % Build a classifier using tuned parameters and all training data
                            classificationSVM = fitcsvm(trainingPredictors,trainingResponse,'KernelFunction',opts.ThisSVMkernel,'BoxConstraint',...
                                svmmod.HyperparameterOptimizationResults.XAtMinObjective.BoxConstraint,'ObservationsIn','columns',...
                                'KernelScale',svmmod.HyperparameterOptimizationResults.XAtMinObjective.KernelScale,'Solver','SMO');
                        elseif strcmp(opts.ThisLearner,'logistic')
                            %  c = cvpartition(trainingResponse, 'kfold', opts.Kfold);
                            optstune = struct('Optimizer','bayesopt','ShowPlots',false,'Verbose',0);%,'CVPartition',c);
                            
                            [classificationSVM]  = fitclinear(trainingPredictors,trainingResponse,'ObservationsIn','columns','Solver',solver{opts.solver},'Verbose',0, ...
                                'Learner','logistic','OptimizeHyperparameters','auto','HyperparameterOptimizationOptions',...
                                struct('AcquisitionFunctionName','expected-improvement-plus'),...
                                'HyperparameterOptimizationOptions',optstune,'FitBias',true,'PostFitBias',true);
                        end
                        
                    else
                        % Build a classifier using without cross validation and all training data
                        if strcmp(opts.ThisLinearSVMFitFunction,'fitclinear') && strcmp(opts.ThisSVMkernel,'linear')
                            if strcmp(solver{opts.solver},'default') % then let matlab choose the solver
                                classificationSVM=arrayfun(@(x) fitclinear(trainingPredictors(:,:,TrainTimInd(x))',trainingResponse,'ObservationsIn','columns','Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,...
                                    'Regularization','ridge','FitBias',true,'PostFitBias',true),1:nXtimePnt,'Uniformoutput',0);
                            else
                                classificationSVM=arrayfun(@(x) fitclinear(trainingPredictors(:,:,TrainTimInd(x))',trainingResponse,'ObservationsIn','columns','Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,...
                                    'Regularization','ridge','Solver',solver{opts.solver},'FitBias',true,'PostFitBias',true),1:nXtimePnt,'Uniformoutput',0);
                            end
                        elseif strcmp(opts.ThisLinearSVMFitFunction,'fitcsvm') || ~strcmp(opts.ThisSVMkernel,'linear')
                            classificationSVM = fitcsvm(trainingPredictors',trainingResponse,'KernelFunction',opts.ThisSVMkernel,'Solver','SMO','KernelScale','auto');                      
                        end
                    end
                else % we are doing multi class classification
                    trainingPredictors=trainingPredictors'; % attention to this
                    if ~opts.ThisCrossValidate
                        if strcmp(opts.ThisSVMkernel,'linear')
                            t = templateLinear('Learner',opts.ThisLearner,'Lambda',opts.ThisLambda,'Regularization','ridge','Solver',solver{opts.solver});
                        else
                            t = templateSVM('Solver','SMO','KernelFunction',opts.ThisSVMkernel);
                        end
                        classificationSVM = fitcecoc(trainingPredictors,trainingResponse,'ObservationsIn','columns','Learners',t,'Coding', opts.MultiClassCoding);
                    else
                        tic
                        if strcmp(opts.ThisSVMkernel,'linear')
                            t = templateLinear('Learner',opts.ThisLearner,'Regularization','ridge');
                        else
                            t = templateSVM('KernelFunction',opts.ThisSVMkernel,'KernelFunction',opts.ThisSVMkernel);
                        end
                        optstune = struct('Optimizer','bayesopt','ShowPlots',false,'Verbose',0);
                        
                        classificationSVM = fitcecoc(trainingPredictors,trainingResponse,'ObservationsIn','columns',...
                            'Learners',t,'OptimizeHyperparameters','auto',...
                            'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName',...
                            'expected-improvement-plus'),'HyperparameterOptimizationOptions',optstune);
                        toc
                    end
                end
            else % use this classifier instead
                classificationSVM=opts.UseThisClassifier;
            end
            
            % project the test data and calculate performance metrics
            Observed=arrayfun(@(x) ProjectData2SVMhyperplaneOptimized(obj,classificationSVM{x},validationPredictors(:,:,TestTimInd(x)),validationResponse,...
                ClassifierOpts,ClassifierOpts.IncludeAllClassifierInfo),1:nXtimePnt,'uniformoutput',0);
        end
               
        function ClassifierResults=PreprocessClassifierResults(obj,ClassifierResults,ClassifierOpts,Dim2ndFlag,ShuffFlag,varargin) % spits out the metrics after training the classifier
            %@ClassifierResults results after training the classifier
            %@Dim2ndFlag 1 is we are processing 2nd dimension data
            %@ShuffFlag are we processing shuffled data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierResults=obj.FixClassifierResultsError(ClassifierResults);% if we ahve error here
            [~,~,ObservedFieldName]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);
            TrialRange=isfield(ClassifierResults,'TrialRange'); % do we have trial range data?
            
            switch TrialRange
                case 0
                    % retrive data: the third dimension is the repetition
                    for Cond=1:length(ClassifierResults)
                        Nrep=length(ClassifierResults(Cond).Rep);
                        % get accuracy
                        ClassifierResults(Cond).Accuracy=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) reshape(cellfun(@(y) y.Accurary,ClassifierResults(Cond).Rep(x).(ObservedFieldName)),...
                            ClassifierOpts.TimeMatrixSize),1:Nrep,'UniformOutput',0),3);
                        %get AUC
                        if isfield(ClassifierResults(Cond),'AUC')
                            ClassifierResults(Cond).AUC=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) reshape(cellfun(@(y) y.AUC,ClassifierResults(Cond).Rep(x).(ObservedFieldName)),...
                                ClassifierOpts.TimeMatrixSize),1:Nrep,'UniformOutput',0),3);
                        end
                        if ~ShuffFlag
                            %get no_IDdims(no longer computing)
                            %  ClassifierResults(Cond).no_IDdims=obj.ManData.ReshapeCell2Mat(arrayfun(@(x)  ClassifierResults(Cond).Rep(x).no_IDdims,1:Nrep,'UniformOutput',0),3);
                            % get scores
                            %  ClassifierResults(Cond).Scores=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.Scores,ClassifierResults(Cond).Rep(x).Observed,'UniformOutput',0),3),...
                            %       1:ClassifierOpts.Nrep,'UniformOutput',0),4);
                            ClassifierResults(Cond).Scores= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.Scores,ClassifierResults(Cond).Rep(x).(ObservedFieldName),'UniformOutput',0),3),...
                                1:Nrep,'UniformOutput',0);
                        end
                        
                        % if we have any spike count data then retrieve those data as well
                        if isfield(ClassifierOpts,'SpkCountPeriod')
                            for spkcnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                Txt=sprintf('_SpkCntPrd%i',spkcnt);
                                ClassifierResults(Cond).(['Accuracy' Txt])=arrayfun(@(x) ClassifierResults(Cond).Rep(x).([ObservedFieldName Txt]).Accurary,1:Nrep,'UniformOutput',1);
                                if isfield(ClassifierResults(Cond),['AUC' Txt])                                    
                                    ClassifierResults(Cond).(['AUC' Txt])=arrayfun(@(x) ClassifierResults(Cond).Rep(x).([ObservedFieldName Txt]).AUC,1:Nrep,'UniformOutput',1);
                                end
                            end
                        end
                        if ~ClassifierOpts.MultiClass & ~ShuffFlag & isfield(ClassifierResults(Cond),'Beta')    
                            
                            % get Beta,Bias and KernelScale of the hyperplane
                            ClassifierResults(Cond).Beta= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.classificationSVM.Beta',ClassifierResults(Cond).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                                1:Nrep,'UniformOutput',0);
                            ClassifierResults(Cond).Bias= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.classificationSVM.Bias',ClassifierResults(Cond).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                                1:Nrep,'UniformOutput',0);
                            %   ClassifierResults(Cond).KernelScale= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.classificationSVM.KernelScale',ClassifierResults(Cond).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                            %       1:ClassifierOpts.Nrep,'UniformOutput',0);
                        end
                    end
                case 1 % we are looking during learning thus we have a trial range
                    IsFoldRep=isfield(ClassifierResults(1).TrialRange(1).Rep(1),'FoldRep'); % is there a fold rep for the suffle data
                  
                    for Cond=1:length(ClassifierResults)
                        Nrep=length(ClassifierResults(Cond).TrialRange(1).Rep);
                        nTrialRange=length(ClassifierResults(Cond).TrialRange);
                        for TrlRng=1:nTrialRange
                            if IsFoldRep==0
                                 % adjust the length of time 
                                ClassifierOpts.TimeMatrixSize=[1 length(ClassifierResults(Cond).TrialRange(1).Rep(1).Observed)];
                             
                                % get accuracy
                                ClassifierResults(Cond).TrialRange(TrlRng).Accuracy=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) reshape(cellfun(@(y) y.Accurary,ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName)),...
                                    ClassifierOpts.TimeMatrixSize),1:Nrep,'UniformOutput',0),3);
                                %get AUC
                                if isfield(ClassifierResults(Cond).TrialRange(TrlRng),'AUC')
                                    ClassifierResults(Cond).TrialRange(TrlRng).AUC=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) reshape(cellfun(@(y) y.AUC,ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName)),...
                                        ClassifierOpts.TimeMatrixSize),1:Nrep,'UniformOutput',0),3);
                                end
                                %get no_IDdims
                                if  ~ShuffFlag
                                    %  ClassifierResults(Cond).TrialRange(TrlRng).no_IDdims=obj.ManData.ReshapeCell2Mat(arrayfun(@(x)  ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).no_IDdims,1:Nrep,'UniformOutput',0),3);
                                    % get scores
                                    if isfield(ClassifierResults(1).TrialRange(1).Rep(1).(ObservedFieldName){1},'Scores')
                                        ClassifierResults(Cond).TrialRange(TrlRng).Scores= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.Scores,ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName),'UniformOutput',0),3),...
                                            1:Nrep,'UniformOutput',0);
                                    end
                                end
                                % if we have any spike count data then retrieve those data as well
                                for spkcnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                    Txt=sprintf('_SpkCntPrd%i',spkcnt);
                                    if isfield(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1),[ObservedFieldName Txt]) % check if we have computed spkcnt for this condition
                                        if iscell(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1).([ObservedFieldName Txt]))
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Accuracy' Txt])=arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]){1}.Accurary,1:Nrep,'UniformOutput',1);
                                        else
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Accuracy' Txt])=arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]).Accurary,1:Nrep,'UniformOutput',1);
                                        end
                                        if isfield(ClassifierResults(Cond).TrialRange(TrlRng),'AUC')
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['AUC' Txt])=arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]){1}.AUC,1:Nrep,'UniformOutput',1);
                                        end
                                    end
                                end
                                % get Beta Bias
                                if ~ClassifierOpts.MultiClass & ~ShuffFlag & isfield(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1).Observed{1},'Beta')                                    
                                    % get Beta,Bias and KernelScale of the hyperplane
                                    ClassifierResults(Cond).TrialRange(TrlRng).Beta= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.Beta',ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                                        1:Nrep,'UniformOutput',0);
                                    ClassifierResults(Cond).TrialRange(TrlRng).Bias= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.Bias',ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                                        1:Nrep,'UniformOutput',0);
                                    %    ClassifierResults(Cond).TrialRange(TrlRng).KernelScale= arrayfun(@(x) obj.ManData.ReshapeCell2Mat(cellfun(@(y) y.classificationSVM.KernelScale',ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).(ObservedFieldName),'UniformOutput',0),2),...
                                    %        1:ClassifierOpts.Nrep,'UniformOutput',0);
                                    
                                    for spkcnt=1:size(ClassifierOpts.SpkCountPeriod,1)
                                        Txt=sprintf('_SpkCntPrd%i',spkcnt);
                                        if isfield(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1),[ObservedFieldName Txt])% check if we have computed spkcnt for this condition
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Beta' Txt])=cell2mat(arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]){1}.Beta,1:Nrep,'UniformOutput',0));
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Bias' Txt])=(arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]){1}.Bias,1:Nrep,'UniformOutput',1));
                                            % ClassifierResults(Cond).TrialRange(TrlRng).(['KernelScale' Txt])=(arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(x).([ObservedFieldName Txt]).classificationSVM.KernelScale,1:ClassifierOpts.Nrep,'UniformOutput',1));
                                        end
                                   end
                                end
                            elseif IsFoldRep==1 % then we are processing the shuffle data for each fold
                                   % adjust the length of time 
                                ClassifierOpts.TimeMatrixSize=[1 length(ClassifierResults(Cond).TrialRange(1).Rep.FoldRep(1).Observed)];
                             
                                % in this case concatinate the repetitions in the third dimension
                                NFoldRepShuff=length(ClassifierResults(Cond).TrialRange(1).Rep(1).FoldRep);
                                % get accuracy(Dim 2:Time, Dim3:Shuffle Fold Rep, Dim4:Rep
                                ClassifierResults(Cond).TrialRange(TrlRng).Accuracy=obj.ManData.ReshapeCell2Mat(arrayfun(@(rep) obj.ManData.ReshapeCell2Mat(arrayfun(@(x) reshape(cellfun(@(y) y.Accurary,ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep).FoldRep(x).(ObservedFieldName)),...
                                    ClassifierOpts.TimeMatrixSize),1:NFoldRepShuff,'UniformOutput',0),3),1:Nrep,'UniformOutput',0),4);
                                % if we have any spike count data then retrieve those data as well
                                for spkcnt=1:size(ClassifierOpts.SpkCountPeriod,1) %Dim 1 Rep and Dim 2 Fold rep
                                    Txt=sprintf('_SpkCntPrd%i',spkcnt);
                                    if isfield(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1).FoldRep(1),[ObservedFieldName Txt])% check if we have computed spkcnt for this condition
                                        if iscell(ClassifierResults(Cond).TrialRange(TrlRng).Rep(1).FoldRep(1).([ObservedFieldName Txt]))
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Accuracy' Txt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(rep) arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep).FoldRep(x).([ObservedFieldName Txt]){1}.Accurary,1:NFoldRepShuff,'UniformOutput',1),1:Nrep,'UniformOutput',0),2);
                                        else
                                            ClassifierResults(Cond).TrialRange(TrlRng).(['Accuracy' Txt])=obj.ManData.ReshapeCell2Mat(arrayfun(@(rep) arrayfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep).FoldRep(x).([ObservedFieldName Txt]).Accurary,1:NFoldRepShuff,'UniformOutput',1),1:Nrep,'UniformOutput',0),2);
                                        end
                                    end
                                end
                            end
                        end
                    end                   
            end
%             if ShuffFlag
%                 % delete Rep field to save space
%                 ClassifierResults.TrialRange=rmfield(ClassifierResults.TrialRange,'Rep');
%             end
        end
        function Observed=ProjectData2SVMhyperplane(obj,classificationSVM,validationPredictors,validationResponse,opts,varargin) % projects data into SVM classifier
            %@classificationSVM model of the trained classifier
            %@validationPredictors and validationResponse test data to be projected in to the classifier hyperplane
            %@opts options
            
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % Create the result struct with predict function
            svmPredictFcn = @(x) predict(classificationSVM, x);
            %  validationPredictFcn = @(x) svmPredictFcn(x);
            
            % Compute validation predictions
            [validationPredictions, validationScores] = svmPredictFcn(validationPredictors);
            
            % if we are looking at the posteriors ?
            if opts.ComputePosterior
                [CompactSVMModel,Observed.PosteriorMdlParameters] = fitPosterior(compact(classificationSVM),validationPredictors,validationResponse);
                [~,Observed.validationPosterior]=predict(CompactSVMModel,validationPredictors);
            end
            
%             uniqueResp=unique(validationResponse);
%             if length(uniqueResp)>1
%                 Outstats = [];
%                 for i = 1:numel(uniqueResp)
%                     [Outstats(i).X,Outstats(i).Y,Outstats(i).T,Outstats(i).AUC,Outstats(i).OPTROCPT,Outstats(i).SUBY] = perfcurve(validationResponse,validationScores(:,i),uniqueResp(i));
%                     Observed.AUC = mean([Outstats(:).AUC]);
%                     %           Observed.X = [cat(1,Outstats(:).X),cat(1,Outstats(:).Y)];
%                     %           Observed.Y = [cat(1,Outstats(:).Y),cat(1,Outstats(:).Y)];
%                     %           Observed.T = [cat(1,Outstats(:).T),cat(1,Outstats(:).T)];
%                     %           Observed.SubY = [cat(1,Outstats(:).X),cat(1,Outstats(:).Y)];
%                 end
%             else
%                 Outstats=struct('X',nan,'Y',nan,'T',nan,'AUC',nan,'OPTROCPT',nan,'SUBY',nan);
%                 Observed.AUC=nan;
%             end
             
            
            % Compute validation accuracy
            correctPredictions = (validationPredictions == validationResponse);
            isMissing = isnan(validationResponse);
            correctPredictions = correctPredictions(~isMissing);
            
            %Save off all desired information
            Observed.Accurary = sum(correctPredictions)/length(correctPredictions);
            Observed.Scores = validationScores;
            %  Observed.Predictions = validationPredictions;
            
            % save classifier essential data such as alpha and beta weights
            % Observed.Classifier = classificationSVM;
            % Note from Matlab help of 'predict' function
            % If SVMModel.KernelParameters.Function is 'linear', then the classification score for the observation x is
            % Score=(x/KernelScale)'Beta+Bias; x is observation
            if ~opts.MultiClass & AnalysisOpts.IncludeAllClassifierInfo
                Observed.classificationSVM.Beta=classificationSVM.Beta;
                Observed.classificationSVM.Bias=classificationSVM.Bias;
                %Observed.classificationSVM.KernelScale=classificationSVM.KernelParameters.Scale;
            end
            if obj.CalShuff % remove all of the unneccessary fields
                Observed=obj.ManData.rmfieldExept(Observed,{'Accurary'});
            end            
        end
        
        function Observed=ProjectData2SVMhyperplaneOptimized(obj,classificationSVM,validationPredictors,validationResponse,opts,IncludeAllClassifierInfo,varargin) % projects data into SVM classifier
            %@classificationSVM model of the trained classifier
            %@validationPredictors and validationResponse test data to be projected in to the classifier hyperplane
            %@opts options
                                
            % Compute validation predictions
            [validationPredictions, validationScores] = predict(classificationSVM,validationPredictors);
                        
            % Compute validation accuracy
            correctPredictions = (validationPredictions == validationResponse);
            isMissing = isnan(validationResponse);
            correctPredictions = correctPredictions(~isMissing);
            
            if ~obj.CalShuff
                %Save off all desired information
                Observed.Accurary = sum(correctPredictions)/length(correctPredictions);
                Observed.Scores = validationScores;

                if ~opts.MultiClass & IncludeAllClassifierInfo
                   % Observed.classificationSVM.Beta=classificationSVM.Beta;
                   % Observed.classificationSVM.Bias=classificationSVM.Bias;
                    Observed.Beta=classificationSVM.Beta;
                    Observed.Bias=classificationSVM.Bias;
                  %  Observed.KernelScale=classificationSVM.KernelParameters.Scale;
                end
            else % if we are doing shuffling only keep the accuracy
                Observed.Accurary = sum(correctPredictions)/length(correctPredictions);
           end
        end
       
        % series of plotting functions for different components of classfier analysis
        function h=PlotXTemporalClassifierResults(obj,ClassifierResults,ClassifierOpts,PlotMode,Conds,Tasks2Compare,varargin) % plots the results from classifer analysis
            %@ClassifierResults ClassifierOpts: if you are comparing(CompareConds) conditions then put each condition in a cell
            %@PlotMode dictates which type of plots we want
            %@Conds (Cell or double) index of the conditions you want be plotted. If this a 'CompareConds' then each cell has to have one value
            % 'XTemp' plots crosstemporal performance with accuracy
            % 'CondDetail' Plots details of each condition indicated by variable Conds
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare variables
            Is3DTest=contains(ClassifierOpts.Name,'3D'); % is this condition 3D
            if iscell(obj.ClassifierResults_Shuff)
                for ii=1:length(obj.ClassifierResults_Shuff)
                    temp(ii)=obj.ClassifierResults_Shuff{ii};
                end
                obj.ClassifierResults_Shuff=temp;
            end
            if ~iscell(ClassifierOpts)
                if contains(ClassifierOpts.Name,'Color')
                    AnalysisOpts.CurrColorPalett=AnalysisOpts.ColorPalett3;
                elseif contains(ClassifierOpts.Name,'Shape')
                    AnalysisOpts.CurrColorPalett=AnalysisOpts.ColorPalett5;
                elseif contains(ClassifierOpts.Name,'Resp')
                    AnalysisOpts.CurrColorPalett=AnalysisOpts.ColorPalett7;
                end
            end
            
            NConds=length(ClassifierResults);
            if isempty(Conds);Conds=1:NConds;end
            
            if ~strcmp(PlotMode,'CompareConds') 
                % preprocess classifier results to have them in an easier shape
                ClassifierResults=obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0);
                % if we have shuffle data then preprocess them and then
                if ~isempty(obj.ClassifierResults_Shuff)
                    obj.ClassifierResults_Shuff=obj.PreprocessClassifierResults(obj.ClassifierResults_Shuff,ClassifierOpts,0,1);
                    obj.StatTest=obj.PerformStatTest(ClassifierResults,obj.ClassifierResults_Shuff,[],Conds);
                end          
            else
                % preprocess classifier results to have them in an easier shape
                ClassifierResults=arrayfun(@(x) obj.PreprocessClassifierResults(ClassifierResults{x},ClassifierOpts{x},0,0),1:NConds,'UniformOutput',0);
            end
            switch PlotMode
                case 'XTempPerf'
                    h=obj.FigParams.RenderFigure(1,[]);
                    obj.PutSGtitle4Figure(ClassifierOpts)
                    if NConds==6   % then we have all of the combinations of rules
                        [h,Sp]=obj.FigParams.RenderSubplots(1,3,h{1},[]);
                        
                        % plot image of the  accuracy
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(x),ClassifierOpts.AllCombPlotPair{x}(1),...
                            'ThisColor',AnalysisOpts.CurrColorPalett(ClassifierOpts.AllCombPlotPair{x}(1),:),'MeanStdPlotType',1),1:3);
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(x),ClassifierOpts.AllCombPlotPair{x}(2),...
                            'ThisColor',AnalysisOpts.CurrColorPalett(ClassifierOpts.AllCombPlotPair{x}(2),:),'MeanStdPlotType',1),1:3);
                    elseif contains(ClassifierOpts.Name,'Xgen','IgnoreCase',true)  
                        % get pairs of conditions
                        CondPairs=nchoosek(1:NConds,2);NCondPairs=size(CondPairs,1);
                        [h,Sp]=obj.FigParams.RenderSubplots(1,NCondPairs,h{1},3);
                        % plot image of the Xtemp accuracy
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(x),CondPairs(x,1),...
                            'ThisColor',AnalysisOpts.CurrColorPalett(CondPairs(x,1),:),'MeanStdPlotType',1),1:NCondPairs);
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(x),CondPairs(x,2),...
                            'ThisColor',AnalysisOpts.CurrColorPalett(CondPairs(x,2),:),'MeanStdPlotType',1),1:NCondPairs);
                    elseif Is3DTest
                        % plot each condition across different dimensions 
                         [h,Sp]=obj.FigParams.RenderSubplots(1,NConds,h{1},NConds);
                        % plot image of the Xtemp accuracy
                        arrayfun(@(cond) arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(cond),cond,...
                            'ThisColor',AnalysisOpts.CurrColorPalett(x,:),'MeanStdPlotType',1,'LookatDim2',x),1:3),1:NConds);
                                         
                    else
                        [h,Sp]=obj.FigParams.RenderSubplots(1,NConds,h{1},[]);
                        % plot image of the Xtemp accuracy
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(x),x,'ThisColor',AnalysisOpts.CurrColorPalett(x,:)),1:NConds);
                    end
                    
                    % plot all of performance metrics
                    %  arrayfun(@(x) obj.PlotSVMAllPerfMetrics(ClassifierResults,ClassifierOpts,Sp(x+NConds),x),1:NConds);
                case 'CondDetail' % plot detail of one condition
                    h=obj.FigParams.RenderFigure(1,[]);
                    [h,Sp]=obj.FigParams.RenderSubplots(2,2,h{1},[]);
                    
                    obj.PutSGtitle4Figure(ClassifierOpts)
                    % plot image of the Xtemp accuracy
                    obj.PlotXtempAccuracy(ClassifierResults,ClassifierOpts,Sp(1),Conds,'ThisColor',AnalysisOpts.CurrColorPalett(Conds,:));
                    % plot all of performance metrics
                    obj.PlotSVMAllPerfMetrics(ClassifierResults,ClassifierOpts,Sp(2),Conds);
                    %  Plot projection of scores into 1D space
                    obj.PlotSVMProjectionsScores1D(ClassifierResults,ClassifierOpts,Sp(3),Conds,0,0);
                    % plot results in PC space(TO BE PERFORMED)
                case 'CompareConds' % compares differnt conditions
                    ThisColor={[AnalysisOpts.ColorPalett1(1,:)],[AnalysisOpts.ColorPalett1(3,:)]};
                    if contains(Tasks2Compare.ComparisonName,'Area','IgnoreCase',true) &  ~contains(Tasks2Compare.ComparisonName,'Summery','IgnoreCase',true)% if we have are comparing area timings
                        AraCol=obj.FigParams.getColorPalet(5);
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(1,2,h{1},[]);
                        
                        % superimpose accuracy on each other without normalzing by max
                        h1= arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{x},ClassifierOpts{x},Sp(1),Conds{x},...
                            'ThisColor',AraCol(strcmp(Tasks2Compare.Area{x},AnalysisOpts.AreaNames),:),...
                            'NormalizebyMax',0,'MeanStdPlotType',3),1:NConds,'UniformOutput',1);
                        legend(h1,cellfun(@(x) x,Tasks2Compare.Area,'UniformOutput',0),'Location','best')
                        
                        % superimpose accuracy on each other with normalizing by max
                        h1= arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{x},ClassifierOpts{x},Sp(2),Conds{x},...
                            'ThisColor',AraCol(strcmp(Tasks2Compare.Area{x},AnalysisOpts.AreaNames),:),...
                            'NormalizebyMax',1,'MeanStdPlotType',3),1:NConds,'UniformOutput',1);
                        legend(h1,cellfun(@(x) x,Tasks2Compare.Area,'UniformOutput',0),'Location','best')
                        
                    elseif contains(Tasks2Compare.ComparisonName,'Summery','IgnoreCase',true)% if we are plotting timings
                        AraCol=obj.FigParams.getColorPalet(5);
                        h=obj.FigParams.RenderFigure(1,[]);
                        nRow=length(Tasks2Compare.Cond);
                        nCol=length(Tasks2Compare.Area2Look);
                        [h,Sp]=obj.FigParams.RenderSubplots(nRow,nCol,h{1},[]);
                        obj.PutSGtitle4ClassifierComparision(Tasks2Compare,ClassifierOpts,AnalysisOpts.ColorPalett1)
                        for Ar=1:nCol
                            for i=1:Tasks2Compare.nMainTasks
                                IndClassResults=(Ar-1)*Tasks2Compare.nMainTasks+i;
                                % superimpose accuracy on each other without normalzing by max
                                %                     h1= arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{IndClassResults},ClassifierOpts{IndClassResults},Sp((x-1)*nCol+Ar),Tasks2Compare.Cond{x}(i),...
                                %                         'ThisColor',AraCol(strcmp(Tasks2Compare.Area{IndClassResults},AnalysisOpts.AreaNames),:),'ThisLineStyle',i,...
                                %                         'NormalizebyMax',Tasks2Compare.NormalizebyMax,'MeanStdPlotType',3,'ThisTitle',Tasks2Compare.Area{IndClassResults}),1:length(Tasks2Compare.Cond),'UniformOutput',1);
                                h1= arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{IndClassResults},ClassifierOpts{IndClassResults},Sp((x-1)*nCol+Ar),Tasks2Compare.Cond{x}(i),...
                                    'ThisColor',AnalysisOpts.ColorPalett1(i,:),'ThisLineStyle',i,'SubtractBaseLine',Tasks2Compare.NormalizebyMax,'NPnts_SubtractBaseLine',sum(AnalysisOpts.Time<0),...
                                    'NormalizebyMax',Tasks2Compare.NormalizebyMax,'MeanStdPlotType',3,'ThisTitle',Tasks2Compare.Area{IndClassResults},...
                                    'ThisYLabel','Accuracy'),1:length(Tasks2Compare.Cond),'UniformOutput',1);
                                
                                % legend(h1,cellfun(@(x) x,Tasks2Compare.Area,'UniformOutput',0),'Location','best')
                            end
                        end
                        
                    elseif contains(Tasks2Compare.ComparisonName,'Xgen_Index','IgnoreCase',true) % if we are looking at generalization index
                        AraCol=obj.FigParams.getColorPalet(5);
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(1,3,h{1},[]);
                        
                        % superimpose accuracy on each other without normalzing by max
                        arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{x},ClassifierOpts{x},Sp(1),Conds{x},...
                            'ThisColor',AraCol(strcmp(Tasks2Compare.Area{x},AnalysisOpts.AreaNames),:),...
                            'NormalizebyMax',0,'MeanStdPlotType',3),1:NConds,'UniformOutput',1);
                        
                        obj.PlotSVMGeneraliztionIndex(ClassifierResults{2},ClassifierResults{1},ClassifierOpts{1},'Accuracy',Sp(2),Conds{2},Conds{1},[],Tasks2Compare.Area{1});
                        
                        obj.PlotSVMGeneraliztionIndex(ClassifierResults{2},ClassifierResults{1},ClassifierOpts{1},'Accuracy',Sp(3),Conds{2},Conds{1},1,Tasks2Compare.Area{1});
                        
                    else % if we are not comparing area timings
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(2,NConds+1,h{1},[]);
                        
                        % plot all of performance metrics
                        arrayfun(@(x) obj.PlotSVMAllPerfMetrics(ClassifierResults{x},ClassifierOpts{x},Sp(x),Conds{x},'ThisColor',x),1:NConds,'UniformOutput',0);
                        % subtitle([ComparisionOpts.TrlSpkTimeFieldName{1} ' ' ComparisionOpts.Area{1}],'FontWeight','bold','Color','blue')
                        % ylim([0.2 1])
                        
                        % Plot projection of scores into 1D space
                        arrayfun(@(x) obj.PlotSVMProjectionsScores1D(ClassifierResults{x},ClassifierOpts{x},Sp(x+NConds+1),Conds{x},0,0),1:NConds,'UniformOutput',0);
                        
                        % superimpose accuracy on each other
                        h1= arrayfun(@(x) obj.PlotXtempAccuracy(ClassifierResults{x},ClassifierOpts{x},Sp(NConds+1),Conds{x},'ThisColor',ThisColor{x},...
                            'NormalizebyMax',1,'MeanStdPlotType',3),1:NConds,'UniformOutput',1);
                        legend(h1,cellfun(@(x) x.TargetFactors{1},ClassifierOpts,'UniformOutput',0),'Location','best')
                        ylim([-0.2 1])
                        % superimpose avegrage encoding
                        h1=arrayfun(@(x) obj.PlotSVMProjectionsScores1D(ClassifierResults{x},ClassifierOpts{x},Sp(2*(NConds+1)),Conds{x},1,0,'ThisColor',x+NConds,...
                            'NormalizebyMax',1),1:NConds,'UniformOutput',1);
                        legend(h1,cellfun(@(x) x.TargetFactors{1},ClassifierOpts,'UniformOutput',0),'Location','best')
                    end
                    
            end
        end
        function htot=PlotXTemporalClassifierResults3D(obj,ClassifierResults,ClassifierOpts,PlotMode,Tasks2Compare,varargin) % plots the results from classifer analysis in 3D            
            %@ClassifierResults:  
            %@ClassifierOpts:    
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
                       
            DimTxt=[0 2 3]; % text for dimensions
            % update plot conditions 
             if ~contains(PlotMode,'Comparision')
                 [ClassifierOptsTemp,obj]=obj.DefineClassifierTestOptions(obj.Classifier_TaskName);
                 ClassifierOpts.PlotFunction=ClassifierOptsTemp.PlotFunction;
                 ClassifierOpts.TriplePlots=ClassifierOptsTemp.TriplePlots;
                 ClassifierOpts.caxis_limits=ClassifierOptsTemp.caxis_limits;
                 ClassifierOpts.caxis_limits_XTemp=ClassifierOptsTemp.caxis_limits_XTemp;
                 ClassifierOpts.enforceAxisLimits= ClassifierOptsTemp.enforceAxisLimits;
                 PlotFunctionSet=ClassifierOpts.PlotFunction;
                 nConds=length(ClassifierOpts.TrainCond);
                 % preprocess classifier results
                 ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0); %first dim
                 ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1,0);%second Dim
                 ClassifierResults_ndD{3}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,3,0);%third dim
                 % preprocess subspace information if we have any
                 ClassifierResults_ndD{1}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{1},ClassifierOpts,0,0); %first dim
                 ClassifierResults_ndD{2}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{2},ClassifierOpts,1,0);%second Dim
                 ClassifierResults_ndD{3}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{3},ClassifierOpts,3,0);%third dim
                 
                 obj=obj.PerformAllStatTests(ClassifierOpts,ClassifierResults_ndD); % do all of the statistical tests
            elseif contains(PlotMode,'Comparision')
                ClassifierOpts.enforceAxisLimits=0;
                for  TskCompId=1:Tasks2Compare.NComparisons
                    % preprocess classifier results for each dimension
                    ClassifierResults_ndD{TskCompId}{1}= obj.PreprocessClassifierResults(ClassifierResults{TskCompId},ClassifierOpts{TskCompId},0,0); %first dim
                    ClassifierResults_ndD{TskCompId}{2}= obj.PreprocessClassifierResults(ClassifierResults{TskCompId},ClassifierOpts{TskCompId},1,0);%second Dim
                    ClassifierResults_ndD{TskCompId}{3}= obj.PreprocessClassifierResults(ClassifierResults{TskCompId},ClassifierOpts{TskCompId},3,0);%third dim
                end
                NTiming=length(Tasks2Compare.TimeStrStp); % how many tim
                PlotFunctionSet=repmat({'ComparisionSummery'},1,NTiming);                
            end
             
            htot=[];k=1;
             % ExtraStr=obj.AddStr4ClassifierTitle(ClassifierOpts,Cond);
            %% now loop on the plot functions and plot the data for this condition  
            for PlotFunc=PlotFunctionSet
                h=[];h1=[];h2=[];Sp=[];Sp2=[];
                switch PlotFunc{1}
                    %% plot performance of the classifier
                    case 'PerfTripleInd' % plot indidual performances for each Triple
                        nCol=3;nRow=nConds;
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots([nRow],[nCol],h{1},[]);
                        obj.PutSGtitle4Figure(ClassifierOpts);
                        for Conds=1:nConds
                            for Dim=1:3
                                ns=(Conds-1)*nCol;
                                obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(Dim+ns),...
                                    Conds,[],Dim,'LookatDim2',DimTxt(Dim),'MeanStdPlotType',6,'ThisColor',1);%caxis([0.4 0.7]);
                            end
                        end
                        %% show superimposed version of the plots for classifier performance
                    case 'PerfTripleSuperimposed' % plot performance for triples but superimposed   
                        % plot conditions from ClassifierOpts.TrainTriple
                        TriplePlots=ClassifierOpts.TriplePlots;
                        nPlts=length(TriplePlots);
                        h=obj.FigParams.RenderFigure(2,[]);
                        [h1,Sp]=obj.FigParams.RenderSubplots([],[],h{1},nPlts);
                        obj.PutSGtitle4Figure(ClassifierOpts);
                        for CondTrip=1:nPlts
                            ThisTriplePlots=TriplePlots{CondTrip};
                            arrayfun(@(x) obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{ThisTriplePlots(x,1)},ClassifierOpts,'Accuracy',Sp(CondTrip),...
                                ThisTriplePlots(x,2),[],ThisTriplePlots(x,1),'LookatDim2',DimTxt(ThisTriplePlots(x,1)),'MeanStdPlotType',6,'ThisColor',ThisTriplePlots(x,2)),1:size(ThisTriplePlots,1));
                        end              
                        % show timing for these superimposed plots 
                        [h2,Sp2]=obj.FigParams.RenderSubplots([],[],h{2},nPlts);
                        for CondTrip=1:nPlts
                            ThisTriplePlots=TriplePlots{CondTrip};
                            arrayfun(@(x) obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{ThisTriplePlots(x,1)},ClassifierOpts,'Accuracy',Sp2(CondTrip),...
                                ThisTriplePlots(x,2),[],ThisTriplePlots(x,1),'LookatDim2',DimTxt(ThisTriplePlots(x,1)),'MeanStdPlotType',3,'ThisColor',ThisTriplePlots(x,2),...
                                'NormalizebyMax',1,'SubtractBaseLine',1,'NPnts_SubtractBaseLine','auto','WidthSmoothing',obj.WidthSmoothing),1:size(ThisTriplePlots,1));
                        end 
                        h=[h1 h2];
                        %% show scores for different objects
                    case 'Scores' % plot performance for triples but superimposed
                        nCol=3;nRow=nConds;
                        %  obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(nRow,nCol,h{1},[]);
                        for Conds=1:nConds
                            for Dim=1:3 % show projections and correlations for incongruent trials across three conditions
                                ns=(Conds-1)*nCol;
                                obj.PlotSVMProjectionsScores1D(ClassifierResults_ndD{Dim},ClassifierOpts,Sp(Dim+ns),Conds,0,DimTxt(Dim));
                            end
                        end
                        %% compare timing
                    case 'CompareTiming'
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(1,nConds,h{1},[]);
                        arrayfun(@(Conds) arrayfun(@(Dim) obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(Conds),...
                            Conds,[],Dim,'LookatDim2',DimTxt(Dim),'MeanStdPlotType',3,'ThisColor',Dim,'NormalizebyMax',1,...
                            'SubtractBaseLine',1,'NPnts_SubtractBaseLine','auto','WidthSmoothing',obj.WidthSmoothing),1:3,'UniformOutput',0),1:nConds,'UniformOutput',0);
                  
                    %% project scores into time axis so we see thier evolution in time
                    case 'ProjScores2D'
                        h=obj.FigParams.RenderFigure(1,[]);
                        [h,Sp]=obj.FigParams.RenderSubplots(1,1,h{1},[]);
                        TimPeriod=[-0.15 0]; % what time period we are looking at
                        obj.PlotSVMProjectionsScores2D(ClassifierResults_ndD{2},ClassifierResults_ndD{1},ClassifierOpts,...
                            Sp(1),1,0,TimPeriod,'ThisTargetFactor','Quadrants','TakeCorrectTrlsOnly',1,'LookatDim2',[2 0]);
              %% summery of comparision between conditions
                    case 'ComparisionSummery'
                        AraCol=obj.GetColorPalet4Factor('Area',[]);
                        h=obj.FigParams.RenderFigure(1,[]);
                        AnalysisOpts.ThisTimeAxisStart=Tasks2Compare.TimeStrStp{k}(1);
                        AnalysisOpts.ThisTimeAxisEnd=Tasks2Compare.TimeStrStp{k}(2); %limit current time axis                               %limit current time axis
                        
                    %    obj.PutSGtitle4ClassifierComparision(Tasks2Compare,ClassifierOpts,AnalysisOpts.ColorPalett1)
                        if contains(Tasks2Compare.ComparisonName,'Summery')
                            nRow=length(Tasks2Compare.Cond);
                            nCol=length(Tasks2Compare.Area2Look);
                            PlotCombs3D=Tasks2Compare.Cond;
                            [h,Sp]=obj.FigParams.RenderSubplots(nRow,nCol,h{1},[]);
                            for Ar=1:nCol % loop on area
                                for i=1:Tasks2Compare.nMainTasks %loop on tasks
                                    IndClassResults=(Ar-1)*Tasks2Compare.nMainTasks+i;
                                    arrayfun(@(x) arrayfun(@(y) obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{IndClassResults}{PlotCombs3D{x}(y,1)},ClassifierOpts{IndClassResults},'Accuracy',...
                                        Sp((x-1)*nCol+Ar),PlotCombs3D{x}(y,2),[],PlotCombs3D{x}(y,1),...
                                        'ThisColor',y,'ThisLineStyle',i,'SubtractBaseLine',Tasks2Compare.NormalizebyMax(y),'NPnts_SubtractBaseLine','auto',...
                                        'NormalizebyMax',Tasks2Compare.NormalizebyMax(y),'MeanStdPlotType',Tasks2Compare.MeanStdPlotType(y),'ThisTitle',Tasks2Compare.Area{IndClassResults},...
                                        'ThisYLabel','Accuracy','LookatDim2',DimTxt(PlotCombs3D{x}(y,1))),1:size(PlotCombs3D{x},1),'UniformOutput',0),1:length(Tasks2Compare.Cond),'UniformOutput',0);
                                end
                            end
                        elseif contains(Tasks2Compare.ComparisonName,'Compare')
                            PlotCombs3D=Tasks2Compare.Cond;
                            nRow=size(PlotCombs3D{1},1);
                            nCol=length(Tasks2Compare.Area2Look);
                            AreaNum=obj.ManData.getAreaNum(Tasks2Compare.Area2Look);
                            [h,Sp]=obj.FigParams.RenderSubplots(nRow,nCol,h{1},[]);

                            for Ar=1:nCol % loop on area
                                IndClassResults=(Ar-1)*Tasks2Compare.nMainTasks;
                                [~,MetricVals,TimeMetricVals]=arrayfun(@(x) arrayfun(@(y) obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{IndClassResults+x}{PlotCombs3D{x}(y,1)},ClassifierOpts{IndClassResults+x},'Accuracy',...
                                    Sp((y-1)*nCol+Ar),PlotCombs3D{x}(y,2),[],PlotCombs3D{x}(y,1),...
                                    'ThisColor',PlotCombs3D{x}(y,2),'ThisLineStyle',1,'SubtractBaseLine',Tasks2Compare.NormalizebyMax(y),'NPnts_SubtractBaseLine',AnalysisOpts.NPnts_SubtractBaseLine,...
                                    'NormalizebyMax',Tasks2Compare.NormalizebyMax(y),'MeanStdPlotType',Tasks2Compare.MeanStdPlotType(y),'ThisTitle',Tasks2Compare.Area{IndClassResults+x},...
                                    'ThisYLabel','Accuracy','WidthSmoothing',obj.WidthSmoothing,'LookatDim2',DimTxt(PlotCombs3D{x}(y,1))),1:size(PlotCombs3D{x},1),'UniformOutput',0),1:length(Tasks2Compare.Cond),'UniformOutput',0);

                                % compare onset latency between conditions if we want that
                                [LatencyAnalysis.Area(Ar).OnSetLatencySec1,LatencyAnalysis.Area(Ar).OnSetLatencySec2,...
                                    LatencyAnalysis.Area(Ar).pval]=arrayfun(@(x)  obj.ManData.CompareRiseTimesPaired(MetricVals{1}{x},...
                                    MetricVals{2}{x},TimeMetricVals{1}{x},1,AnalysisOpts.NPnts_SubtractBaseLine,1),...
                                    1:length(Tasks2Compare.Cond),'UniformOutput',0); % compares rise times of two distibutions
                            end
                            % plot oneset time differences for each area
                            h2=obj.FigParams.RenderFigure(1,[]);
                            [h2,Sp2]=obj.FigParams.RenderSubplots(nRow,1,h2{1},[]);

                            for Ar=1:nCol % loop on area
                                % plot comparision of differences in timings
                                arrayfun(@(x)  obj.FigParams.PlotMeanStd(Ar,LatencyAnalysis.Area(Ar).OnSetLatencySec1{x}'-LatencyAnalysis.Area(Ar).OnSetLatencySec2{x}',[],[],...
                                    'Onset difference(sec)' ,AnalysisOpts.AreaColors(AreaNum(Ar),:),2,[],'ErrBarColor','r',...
                                    'ForceShaded',1,'Sp',Sp2(x),'AppendTitles',1,'IsthisAxisTime',0,'bar_width',0.6),...
                                    1:length(Tasks2Compare.Cond),'UniformOutput',0); % compares rise times of two distibutions

                                arrayfun(@(x) obj.FigParams.AddDetailedSignificanceStar(Ar,LatencyAnalysis.Area(Ar).pval{x},...
                                    'r',Sp2(x),'SigStar_fontsize',15),1:length(Tasks2Compare.Cond),'UniformOutput',0);
                            end
                            xticks(AreaNum)
                            xticklabels(AnalysisOpts.AreaNames(AreaNum))
                            xtickangle(45)
                        end
                        AnalysisOpts.ThisTimeAxisStart=[];AnalysisOpts.ThisTimeAxisEnd=[];
                        
                       
                    case 'TransferEntropyAnalysis' % perform analysis on transfer entropy from color subspace to response
                       % plot transfer entropy results 
                      % CurrentFactorInds2Keep=AnalysisOpts.FactorInds2Keep;
                      % ClassifierOpts.FactorInds2Keep=AnalysisOpts.factornames;
                      % AnalysisOpts.FactorInds2Keep=AnalysisOpts.factornames;
                        if contains(ClassifierOpts.Name,'Old') | contains(ClassifierOpts.Name,'R2R3Entropy')
                            Conds2LookEntropy=1:2;
                        else
                            Conds2LookEntropy=1:ClassifierOpts.NConds;
                        end
                        h=obj.FigParams.RenderFigure(length(Conds2LookEntropy)*3,[]);
                        nRow=2;
                        nCol=4;
                        % set timing and axis limits                    
                        if  AnalysisOpts.GetIndStrFieldName(AnalysisOpts.SpkCntStartFieldName)==2 % sample on 
                            caxislims=[-0.05 0.05];
                        AnalysisOpts.ThisTimeAxisStart=-0.2;AnalysisOpts.ThisTimeAxisEnd=0.6; %limit current time axis                               %limit current time axis                                            
                        elseif AnalysisOpts.GetIndStrFieldName(AnalysisOpts.SpkCntStartFieldName)==3 % saccade onset
                            caxislims='auto';[-0.2 0.07];
                            AnalysisOpts.ThisTimeAxisStart=-0.15;AnalysisOpts.ThisTimeAxisEnd=0.075; %limit current time axis                               %limit current time axis
                        end
                        kk=0;AnalysisOpts.PlotEntropySig=1;
                        for SubtractMean4Entropy=2
                            AnalysisOpts.SubtractMean4Entropy=SubtractMean4Entropy;
                            for Conds=Conds2LookEntropy % we are running on condition two we train on the same set of trials for all conditiosn
                                nConds=find(Conds2LookEntropy==Conds);
                                [h1(Conds+kk*nConds),Sp{nConds}]=obj.FigParams.RenderSubplots(nRow,nCol,h{Conds+kk*nConds},[]);
                                %  eval(sprintf('Sp=Sp%i;',Conds));
                                obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                    Sp{nConds}((1:4)),Conds,'','TransferEntropy',[0 3],'ThisTargetFactor','ColorCat','caxis_limits',caxislims);

                                obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                    Sp{nConds}([(1:3)+nCol 4]),Conds,'','TransferEntropy',[2 3],'ThisTargetFactor','ColorCat','caxis_limits',caxislims);
                            end
                            kk=kk+1;
                        end
                
                        AnalysisOpts.ThisTimeAxisStart=[];AnalysisOpts.ThisTimeAxisEnd=[];
%                        AnalysisOpts.FactorInds2Keep=CurrentFactorInds2Keep;
                        h=[];
                end
                htot=[htot h h1 h2];k=k+1;
            end
        end
        function obj=PerformAllStatTests(obj,ClassifierOpts,ClassifierResults_ndD)
            global AnalysisOpts
            if ~isempty(obj.ClassifierResults_Shuff) % calculate stat test for shuffled data
                obj.ClassifierResults_Shuff=arrayfun(@(x) obj.PreprocessClassifierResults(obj.ClassifierResults_Shuff,ClassifierOpts,x,1),[0 1 3],'UniformOutput',0);
                obj.ClassifierResults_Observed=arrayfun(@(x) obj.PreprocessClassifierResults(obj.ClassifierResults_Observed,ClassifierOpts,x,1),[0 1 3],'UniformOutput',0);
                if ClassifierOpts.AnalysisOpts.ExchangeableCalShuffClassifier==1 % if we have done train and test on same samples
                    obj.ClustStatTst_dependent_samples=1;
                end

                if AnalysisOpts.SkipClassifierLearningPerfStatTest & contains(ClassifierOpts.Name,'Learning')% if we are skipping the learning performance stat test 
                    warning('Skipping the learning performance stat test... ');
                    obj.StatTest=[];
                else
                    obj.StatTest=arrayfun(@(x) obj.PerformStatTest(obj.ClassifierResults_Observed{x},obj.ClassifierResults_Shuff{x},[],[],...
                        'ClustStatTst_dependent_samples',obj.ClustStatTst_dependent_samples),1:3,'UniformOutput',0);
                end

                if contains(ClassifierOpts.Name,'Learning')
                    if ~strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Modified_MannKendall')
                        % perform  stat test for trial shuffle
                        obj.StatTestTrlShuff=arrayfun(@(x) obj.PerformStatTest(obj.ClassifierResults_Observed{x},obj.ClassifierResults_Shuff{x},'ClusterTrlShuffle',[],...
                            'ClustStatTst_dependent_samples',obj.ClustStatTst_dependent_samples),1:3,'UniformOutput',0);
                    elseif strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Modified_MannKendall') 
%                      obj.StatTestTrlShuff=arrayfun(@(x) obj.PerformStatTest(obj.ClassifierResults_Observed{x},obj.ClassifierResults_Shuff{x},'ClusterTrlShuffle',[],...
%                             'ClustStatTst_dependent_samples',obj.ClustStatTst_dependent_samples),1:3,'UniformOutput',0);
                        obj.StatTestTrlShuff=arrayfun(@(x) obj.PerformStatTest_ModelifiedMannKendall(ClassifierResults_ndD{x},'bonferroni',[],x),1:3,'UniformOutput',0);
                    end
                else
                    obj.StatTestTrlShuff=[];
                end
            elseif contains(ClassifierOpts.Name,'Learning') & strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Modified_MannKendall')
                % perform  stat test for trial shuffle using modified MannKendall Method
                obj.StatTestTrlShuff=arrayfun(@(x) obj.PerformStatTest_ModelifiedMannKendall(ClassifierResults_ndD{x},'bonferroni',[],x),1:3,'UniformOutput',0);
            end
        end
        function h=CharactrizeSubspaces(obj,ClassifierResults,ClassifierOpts,varargin) % % charactrizes subspaces in feature and response dimension
            %@ClassifierResults ClassifierOpts: if you are comparing(CompareConds) conditions then put each condition in a cell
            %@PlotMode dictates which type of plots we want
            %@Conds (Cell or double) index of the conditions you want be plotted.
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0);
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1);
            Condition=[1 2 3]; % which condition we are lookign at
            Dimension=[2 1 1]; % which dimension we are looking at
            TrlRngNum=[1 1 1]; % which trial range number we are looking at
            FlipAxis=[-1 1 1]; % are we flipping the axis
            NConds=length(Dimension);
            CondNames=[ {'Rule1 Shape'}  {'Rule2 Color'}    {'Rule3 Color'}];
            TimeInd=find(AnalysisOpts.Time>=0);
            TimeAxis=AnalysisOpts.Time(TimeInd);
            % get Beta weights for each condition
            ConditionSubspace=arrayfun(@(x) FlipAxis(x)*obj.ManData.ReshapeCell2Mat(ClassifierResults_ndD{Dimension(x)}(Condition(x)).TrialRange(TrlRngNum(x)).Beta,3),1:NConds,'UniformOutput',0);
            % take the mean of each condition and concatinate them
            ConditionSubspaceMean=cell2mat(cellfun(@(x) mean(x(TimeInd,:,:),3)',ConditionSubspace,'UniformOutput',0))';
            % get the identity for each condition
            CondInds=cell2mat(arrayfun(@(x) Condition(x)*ones(1,length(TimeInd)),1:NConds,'UniformOutput',0));
            %  take pca of Beta weights
            [PCA.coeff,PCA.score,~,~,PCA.explained]=pca(ConditionSubspaceMean);
            % plot PCA space
            h1=obj.PlotPCADatainTime(PCA,CondInds,TimeAxis,CondNames,[1 2 3],'pca');
            h2=obj.PlotPCADatainTime(PCA,CondInds,TimeAxis,CondNames,[4 5 6],'pca');
            % plot in tSne space
            [TsneData.score,TsneData.loss]=tsne(ConditionSubspaceMean,'Distance','correlation','NumDimensions',3);
            h3=obj.PlotPCADatainTime(TsneData,CondInds,TimeAxis,CondNames,[1 2 3],'tsne');
            % plot cross correlation
            h4=obj.PlotXcorrInTime(ConditionSubspaceMean',CondInds,TimeAxis,CondNames);
            h=[h1 h2 h3 h4];
        end
        function h=CharactrizeSharedSubspaces(obj,ClassifierResults,ClassifierOpts,varargin) % charactrizes shared subspaces
            % this function is mainly used with '2D_Cat_Color_Resp_Xgen'
            % classfier test condition
            %@ClassifierResults: for 2D_Cat_Color_Resp_Xgen
            %@ClassifierOpts: for 2D_Cat_Color_Resp_Xgen
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0);
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1);
            for Cond=1:4
                Conds=[Cond];%length(ClassifierOpts.TrainCond);
                nConds=length(Conds);
                h(Cond)=obj.FigParams.RenderFigure(1,[]);
                [h{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h{Cond},4*nConds);
                
                TimPeriod=[0 0.5]; % what time period we are looking at
                % plot accuracy of each condition
                % together
                for c=1:nConds
                    h1=obj.PlotXtempAccuracy(ClassifierResults_ndD{1},ClassifierOpts,Sp(c),Conds(c),'ThisColor',1,'NormalizebyMax',0,'MeanStdPlotType',3);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_ndD{2},ClassifierOpts,Sp(c),Conds(c),'ThisColor',2,'NormalizebyMax',0,'MeanStdPlotType',3);
                    ylabel([ClassifierOpts.TargetFactors{1} '/' ClassifierOpts.TargetFactors_2ndD{1}]);
                    subtitle([AnalysisOpts.TrlSpkTimeFieldName ' ' AnalysisOpts.Area2look{1}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],ClassifierOpts.TargetFactors{1},ClassifierOpts.TargetFactors_2ndD{1});
                    % plot 1D projections for both conditions
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_ndD{1},ClassifierOpts,Sp(c+1),Conds(c),0,0,'ThisTargetFactor','QuadrantsInCong');
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_ndD{2},ClassifierOpts,Sp(c+2),Conds(c),0,1,'ThisTargetFactor','QuadrantsInCong');
                    
                    % Choose the data we want to look at
                    obj.PlotSVMProjectionsScores2D(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(c+3),Conds(c),0,TimPeriod,'ThisTargetFactor','QuadrantsInCong');
                end
            end
        end
        function h=QuantifySharedSubspaces(obj,ClassifierResults,ClassifierOpts,varargin) % quanifies shared subspaces
            % this function is mainly used with '2D_Cat_Color_Color_Xgen'
            % or 2D_Cat_Color_Resp_Xgen
            % classfier test condition
            %@ClassifierResults: for 2D_Cat_Color_Color_Xgen or 2D_Cat_Color_Resp_Xgen
            %@ClassifierOpts:    for 2D_Cat_Color_Color_Xgen or 2D_Cat_Color_Resp_Xgen
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0);
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1);
            for Cond=1:2
                Conds=[Cond];%length(ClassifierOpts.TrainCond);
                nConds=length(Conds);
                h(Cond)=obj.FigParams.RenderFigure(1,[]);
                [h{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h{Cond},5*nConds);
                
                TimPeriod=[0 0.5]; % what time period we are looking at
                % plot accuracy of each condition
                % together
                for c=1:nConds
                    h1=obj.PlotXtempAccuracy(ClassifierResults_ndD{1},ClassifierOpts,Sp(c),Conds(c),'ThisColor',1,'NormalizebyMax',0,'MeanStdPlotType',3);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_ndD{2},ClassifierOpts,Sp(c),Conds(c),'ThisColor',2,'NormalizebyMax',0,'MeanStdPlotType',3);
                    ylabel([ClassifierOpts.TargetFactors{1} '/' ClassifierOpts.TargetFactors_2ndD{1}]);
                    subtitle([AnalysisOpts.TrlSpkTimeFieldName ' ' AnalysisOpts.Area2look{1}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],ClassifierOpts.TargetFactors{1},ClassifierOpts.TargetFactors_2ndD{1});
                    % plot 1D projections for both conditions
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_ndD{1},ClassifierOpts,Sp(c+1),Conds(c),0,0,'ThisTargetFactor','QuadrantsInCong');
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_ndD{2},ClassifierOpts,Sp(c+2),Conds(c),0,1,'ThisTargetFactor','QuadrantsInCong');
                    
                    % Choose the data we want to look at
                    obj.PlotSVMProjectionsScores2DPEV(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(c+3),Conds(c),TimPeriod,'corr','ThisTargetFactor','QuadrantsInCong');
                    obj.PlotSVMProjectionsScores2DPEV(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(c+4),Conds(c),TimPeriod,'kldiv','ThisTargetFactor','QuadrantsInCong');
                end
            end
        end
        function htot=QuantifySharedSubspaces_Learning3D(obj,ClassifierResults,ClassifierOpts,varargin) % quanifies shared subspaces during learning            
            %@ClassifierResults: for 'Learning_Cat_Shape_Color_Xgen','Learning_Cat_Color_Color_Xgen'
            %@ClassifierOpts:    for 'Learning_Cat_Shape_Color_Xgen','Learning_Cat_Color_Color_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
           
            AnalysisOpts.ShowStatPvalinPlot=0; % we don't need to show values in this plot

            [ClassifierOptsTemp,obj]=obj.DefineClassifierTestOptions(obj.Classifier_TaskName);
            ClassifierOpts.PlotFunction=ClassifierOptsTemp.PlotFunction;
            ClassifierOpts.TriplePlots=ClassifierOptsTemp.TriplePlots;
            ClassifierOpts.SpkCountPeriod=ClassifierOptsTemp.SpkCountPeriod;
            ClassifierOpts.caxis_limits=ClassifierOptsTemp.caxis_limits;
            PlotFunctionSet=ClassifierOpts.PlotFunction;
            
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0); %first dim
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1,0);%second Dim
            ClassifierResults_ndD{3}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,3,0);%third dim
            % preprocess subspace information if we have any 
            ClassifierResults_ndD{1}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{1},ClassifierOpts,0,0); %first dim 
            ClassifierResults_ndD{2}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{2},ClassifierOpts,1,0);%second Dim
            ClassifierResults_ndD{3}= obj.PreprocessSubspaceResults(ClassifierResults_ndD{3},ClassifierOpts,3,0);%third dim
             
            %% get the times of showing for each of the dimensions so if we are doing any statistical correction 
             % define the time average we want to take 
            if ~isempty(ClassifierOpts.SpkCountPeriod)
                Time2Look=ClassifierOpts.SpkCountPeriod;
            else
                Time2Look=[0 0.2;0 0.2;0 0.2]; % define the time period we want to avergae perfromance
            end    
            Time2LookDim=arrayfun(@(x) AnalysisOpts.Time>=Time2Look(x,1) & AnalysisOpts.Time<=Time2Look(x,2),1:size(Time2Look,1),'UniformOutput',0);  
            % we take the correct number of time points into account 
            for Dim=1:3 
                [~,TargetFactorTxt]=obj.getClassifierDimInfo(ClassifierOpts,AnalysisOpts.DimTxt(Dim));
                if contains(TargetFactorTxt,'Rule')
                   AnalysisOpts.ThisTimeAxisStart=Time2Look(Dim,1);AnalysisOpts.ThisTimeAxisEnd=Time2Look(Dim,2);
                   AnalysisOpts.Time2LookDim{Dim}=obj.FigParams.LimitTimeAxis(AnalysisOpts.Time,'');
                   AnalysisOpts.ThisTimeAxisStart=[];AnalysisOpts.ThisTimeAxisEnd=[];
                else
                    AnalysisOpts.Time2LookDim{Dim}=obj.FigParams.LimitTimeAxis(AnalysisOpts.Time,'');
                 end
            end
            
            %% perform statistical tests 
            obj=obj.PerformAllStatTests(ClassifierOpts,ClassifierResults_ndD); % do all of the statistical tests
            AnalysisOpts.Time2LookDim=[]; % empty it so no other code can use it
          
            %% plot results
            htot=[];  
            obj.FigParams.font_size=8;     
            for PlotFunction=PlotFunctionSet                   
                for Cond=1:length(ClassifierOpts.TrainCond)
                    Conds=Cond;
                    nConds=length(Conds);
                    ExtraStr=obj.AddStr4ClassifierTitle(ClassifierOpts,Cond);
                    for c=1:nConds
                        h=[];
                        switch PlotFunction{1}
                            case 'MainPerformance' % plot performance of the classifier during learning
                                nSp_h=6;nCol=4;nRow=3;
                                h=obj.FigParams.RenderFigure(1,[]);
                                [h,Sp]=obj.FigParams.RenderSubplots([nRow],[nCol],h{1},nSp_h*nConds);
                                obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                for Dim=1:3
                                    [~,TargetFactorTxt]=obj.getClassifierDimInfo(ClassifierOpts,AnalysisOpts.DimTxt(Dim));
                                    ns=(Dim-1)*nCol;TimeTitle=sprintf('Time:%0.2f->%0.2f',Time2Look(Dim,1),Time2Look(Dim,2));
                                    % plot classiifer perfromance image
                                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(1+ns),Conds,[],Dim);
                                   % obj.FigParams.SetAxisLimits('c',ClassifierOpts.caxis_limits,Dim);
                                   % obj.FigParams.ShiftColorMap(colormap,ClassifierOpts.caxis_limits(Dim,:),0.5)%caxis([0.3 0.7]);

                                    % plot average classifier performance and take runnning average with the amount of Dim 2
                                    % avergae with the performance
                                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(2+ns),Conds,Time2LookDim{Dim},Dim,'ThisTitle',['Avg Perf' TimeTitle ],...
                                        'WidthSmoothing',obj.WidthSmoothingDim2,'performtrend_stattest',1);axis tight;
                                    obj.FigParams.SetAxisLimits('y',ClassifierOpts.caxis_limits,Dim);
                                    xticks([60 80 100 120])
                                    v=axis;
                                    if (v(4)-v(3))<0.5
                                        yticks((floor(v(3) * 10) / 10):0.05:v(4))
                                    else
                                        yticks((floor(v(3) * 10) / 10):0.1:v(4))
                                    end
                                   
                                    % avegrage using the the spike count window
                                     obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(3+ns),Conds,Dim,Dim,'ThisTitle',['Spk Cnt Avg' TimeTitle],...
                                          'WidthSmoothing',obj.WidthSmoothingDim2,'performtrend_stattest',1);axis tight;%ylim([0.4 0.7]);
                                  %   obj.FigParams.SetAxisLimits('y',ClassifierOpts.caxis_limits,Dim);
                                     % plot learing with line
                                    if contains(TargetFactorTxt,'Rule')
                                        AnalysisOpts.ThisTimeAxisStart=Time2Look(Dim,1);AnalysisOpts.ThisTimeAxisEnd=Time2Look(Dim,2);
                                        obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(4+ns),Conds,[],Dim,'ThisTitle',['Avg ' TimeTitle],'PlotType','Line');
                                        AnalysisOpts.ThisTimeAxisStart=[];AnalysisOpts.ThisTimeAxisEnd=[]; 
                                    else 
                                        obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,'Accuracy',Sp(4+ns),Conds,[],Dim,'ThisTitle',['Avg ' TimeTitle],'PlotType','Line');
                                    end
                                 %   AnalysisOpts.ShowStatPvalinPlot=1;
                               %     obj.FigParams.SetAxisLimits('y',ClassifierOpts.caxis_limits,Dim);
                                end
                            case 'Congruency' % show correlations for incongruent objects across all of the conditions
                                nSp_h1=9;nCol=3;nRow=3;
                                %  obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                CondPairs=[1 2;1 3;2 3]; % what combinaiton of conditions we are looking at
                                CondPairsTxt=[0 2;0 3;2 3]; % text for the combinations
                                DimTxt=[0 1 3]; % text for dimensions
                                CongruencyField={'QuadrantsInCong','QuadrantsCong'};
                                for Cong=CongruencyField % loop on congruency conditions
                                    h1_temp=obj.FigParams.RenderFigure(1,[]);
                                    [h1_temp,Sp]=obj.FigParams.RenderSubplots(nRow,nCol,h1_temp{1},nSp_h1*nConds);
                                    for Dim=1:3 % show projections and correlations for incongruent trials across three conditions
                                        ns=(Dim-1)*nCol;
                                        % plot projection of incongruent or congruent  trials
                                        obj.PlotSVMProjectionsScores1D_Learning(ClassifierResults_ndD{Dim},ClassifierOpts,Sp(Dim),Conds(c),...
                                            0,DimTxt(Dim),'ThisTargetFactor',Cong{1});
                                        % plot correlation across dimensions
                                        obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{CondPairs(Dim,1)},ClassifierResults_ndD{CondPairs(Dim,2)},ClassifierOpts,...
                                            Sp(Dim+nCol),Conds(c),'Image','corr',CondPairsTxt(Dim,:),'ThisTargetFactor',Cong{1});
                                        % plot correlation across dimensions
                                        obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{CondPairs(Dim,1)},ClassifierResults_ndD{CondPairs(Dim,2)},ClassifierOpts,...
                                            Sp(Dim+2*nCol),Conds(c),'MeanStd','corr',CondPairsTxt(Dim,:),'ThisTargetFactor',Cong{1});
                                    end
                                    h=[h h1_temp];
                                end                                
                            case 'CompressionIndex'  % plot correlations to compression index and all of the other plots
                                    %obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                        
                                    %% plot compression index for all three rules
                                    % Rule 1 % look at Rule 1 which is in training
                                    %% below is the compression index based on the firing rate and it is not controlled for movement
%                                     obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{2},ClassifierOpts,...
%                                         Sp(1),Conds(c),'MeanStd','CompressionIndex',[2 2],'ThisTargetFactor','Quadrants','LookatDim2',1);
%                                     % Rule 2 % look at Rule 2 which is in training
%                                     obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{1},ClassifierOpts,...
%                                         Sp(2),Conds(c),'MeanStd','CompressionIndex',[0 0],'ThisTargetFactor','Quadrants','LookatDim2',1);
%                                     % Rule 3 % look at Rule 3 which is in test during learning
%                                     obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
%                                         Sp(3),Conds(c),'MeanStd','CompressionIndex',[0 3],'ThisTargetFactor','Quadrants','LookatDim2',2);
                               if contains(ClassifierOpts.Name,'Learning3D_Shape_Color_Color_Compression_RB')
                                    h=obj.FigParams.RenderFigure(1,[]);
                                    [h,Sp]=obj.FigParams.RenderSubplots([],[],h{1},1);
                                    obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                    for Rule=1:3
                                        obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                            Sp(1),Rule,'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                            'Encoding axis compression index','WidthSmoothingDim2',obj.WidthSmoothingDim2,'ThisExtraTargetFactor','ALL','performtrend_stattest',0);
                                    end
                                else
                                    h=obj.FigParams.RenderFigure(1,[]);
                                    [h,Sp]=obj.FigParams.RenderSubplots([],[],h{1},14);
                                    %% plot compression index during learning
                                    % plot compression index druing learning using encoding axis(ALL)
                                    [~,CompIndexEncoding]=obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                        Sp(4),Conds(c),'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                        'Encoding axis compression index','WidthSmoothingDim2',obj.WidthSmoothingDim2,'ThisExtraTargetFactor','ALL','performtrend_stattest',1);
                                
                                    % plot correlation of rule belief with compression index
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(5),Conds(c),'Line','RulePreStimCompres',[1 3],'ThisTargetFactor','Quadrants','LookatDim2',2,'ExtraData',CompIndexEncoding);
                                
                                    % plot correlation of rule belief with stimulus index in scatter plot
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(6),Conds(c),'Scatter','RulePreStimCompresScatter',[2 3],'ThisTargetFactor','Quadrants','LookatDim2',2,'ExtraData',CompIndexEncoding);
                                
                                    % plot correlation of rule belief with compression index in scatter plot using average compression
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(7),Conds(c),'Scatter','RulePreStimCompresScatterAvg',[2 3],'ThisTargetFactor','Quadrants','LookatDim2',2,'ExtraData',CompIndexEncoding);
                                
                                    % plot correlation encoding of quadrant objects during learning
                                    %                                     obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                    %                                         Sp(8),Conds(c),'QuadrantObjs','QuadrantCompressionImage',[0 1],'ThisTargetFactor','Quadrants');
                                    %                                     axis tight
                                
                                    % plot correlation of rule belief and stimulus encoding
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(8),Conds(c),'Scatter','StimEncodingCompresScatterAvg',[2 3],'ThisTargetFactor','Quadrants','LookatDim2',2,'ExtraData',CompIndexEncoding);
                                
                                    % plot compression index druing learning using encoding axis Congruent
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                        Sp(9),Conds(c),'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                        'Encoding axis compression index','WidthSmoothingDim2',obj.WidthSmoothingDim2,'ThisExtraTargetFactor','QuadrantsCong','performtrend_stattest',1);
                                    % plot compression index druing learning using encoding axis InCongruent
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                        Sp(10),Conds(c),'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                        'Encoding axis compression index','WidthSmoothingDim2',obj.WidthSmoothingDim2,'ThisExtraTargetFactor','QuadrantsInCong','performtrend_stattest',1);
                                
                                    % plot correlation of belief with behavioral performance in color and shape in scatter plot
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(11),Conds(c),'Scatter','CorrBeliefBhvPerfScatterAvg',[0 3],'ThisTargetFactor','Quadrants','LookatDim2',2,...
                                        'ThisTitle','Corr of Color Bhv Performance 10 trls and Task Belief');
                                
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(12),Conds(c),'Scatter','CorrBeliefBhvPerfScatterAvg',[0 3],'ThisTargetFactor','Quadrants','LookatDim2',2,...
                                        'ThisTitle','Corr of Shape Bhv Performance 10 trls and Task Belief');
                                
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(13),Conds(c),'Scatter','CorrBeliefBhvPerfScatterAvg',[0 3],'ThisTargetFactor','Quadrants','LookatDim2',2,...
                                        'ThisTitle','Corr of Color Bhv Performance 50 trls and Task Belief');
                                
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(14),Conds(c),'Scatter','CorrBeliefBhvPerfScatterAvg',[0 3],'ThisTargetFactor','Quadrants','LookatDim2',2,...
                                        'ThisTitle','Corr of Shape Bhv Performance 50 trls and Task Belief');
                                
                                end
                            case 'CompressionDetails' % plot all of the details of compression index calculations with distances
                               %  AnalysisOpts.ThisTimeAxisStart=-0.1;AnalysisOpts.ThisTimeAxisEnd=0.6;
                                % plot all of the encoding axis for first and last learning period   
                                 h=obj.FigParams.RenderFigure(2,[]);
                                 [h1,Sp]=obj.FigParams.RenderSubplots([],[],h{1},4); % for encoding axis examples
                                 obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                     Sp(1),Conds(c),'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                     'Encoding axis','ThisExtraTargetFactor','EncodingAxis');
                                 
                                 % plot encoding distances
                                 [~,~,EncodingDistVars]=obj.CalQuadrantCompressionEncodingAxis([],[]); % get the list of variables
                                 nvars=length(EncodingDistVars);
                                 [h2,Sp2]=obj.FigParams.RenderSubplots(2,[],h{2},nvars); % for encoding distances
                                 % get all of the encoding distance vars first
                                 [~,~,EncodingDist]=arrayfun(@(x) obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                     Sp2(x),Conds(c),'MeanStd','CompressionEncodingAxis',[0 1],'ThisTargetFactor','Quadrants',...
                                     'ThisYLabel','Encoding Distance','WidthSmoothingDim2',obj.WidthSmoothingDim2,'performtrend_stattest',1,'ThisExtraTargetFactor',['EncodingDist_' EncodingDistVars{x}]),1:nvars,'UniformOutput',0);                                                                                                   
                                % CompareDistanceShapeColorCongruency;
                                % h3=gcf;
                                 %  AnalysisOpts.ThisTimeAxisStart=[];AnalysisOpts.ThisTimeAxisEnd=[];
                                 h=[h1 h2];
                            case 'CompressionAxisAnalysis'
                                [h]=obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                                        [],Conds(c),'MeanStd','CompressionAxisAnalysis',[0 1],'ThisTargetFactor','Quadrants','ThisTitle',...
                                        [],'WidthSmoothingDim2',obj.WidthSmoothingDim2,'ThisExtraTargetFactor','ALL');
                                    
                            case 'CompressionImage' % look at the image of the comporession index 
                                    h=obj.FigParams.RenderFigure(1,[]);
                                    [h,Sp]=obj.FigParams.RenderSubplots([],[],h{1},2);
                                    %obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                    
                                    % plot correlation encoding of quadrant objects during learning
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(1),Conds(c),'QuadrantObjs','QuadrantCompressionImage',[2 3],'ThisTargetFactor','Quadrants');
                                    subplot(Sp(5));axis tight
                                    % plot compression index druing learning using encoding axis
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(2),Conds(c),'MeanStd','CompressionEncodingAxis',[2 3],'ThisTargetFactor','Quadrants','ThisTitle',...
                                        'Encoding axis compression index','WidthSmoothingDim2',obj.WidthSmoothingDim2);                           
                            case 'CorrBeliefSensoryRep'   % if we want to plot correlation of representations in time                                
                                    h=obj.FigParams.RenderFigure(1,[]);
                                    [h,Sp]=obj.FigParams.RenderSubplots([],[],h{1},3);
                                    obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                   % dimension 1 has to be senosory and
                                    % dimension 3 has to be rule 
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(1),Conds(c),'Line','PreStimScoreCorr',[2 3],'ThisTargetFactor','QuadrantsInCong','performtrend_stattest',1);
                                    
                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(2),Conds(c),'Line','PreStimScoreCorr',[2 3],'ThisTargetFactor','QuadrantsCong','performtrend_stattest',1);

                                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                        Sp(3),Conds(c),'Line','PreStimScoreCorr',[2 3],'ThisTargetFactor','Quadrants','performtrend_stattest',1);

                            case 'CorrBeliefMotorRep' % correlates rule belief to the motor 
                                h=obj.FigParams.RenderFigure(1,[]);
                                [h,Sp]=obj.FigParams.RenderSubplots([],[],h{1},2);
                                obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                                % dimension 1/2 has to be responseloc anddimension 3 has to be rule
                                obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{3},ClassifierOpts,...
                                    Sp(1),Conds(c),'Line','BeleifRespScoreCorr',[0 3],'ThisTargetFactor','ResponseLoc','performtrend_stattest',1);
                                
                                obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{2},ClassifierResults_ndD{3},ClassifierOpts,...
                                    Sp(2),Conds(c),'Line','BeleifRespScoreCorr',[2 3],'ThisTargetFactor','ResponseLoc','performtrend_stattest',1);                                
                        end
                        htot=[htot h];
                    end
                end
            end
        end
        function h=QuantifySharedSubspaces_Learning(obj,ClassifierResults,ClassifierOpts,varargin) % quanifies shared subspaces during learning
            % this function is mainly used with 'Learning_Cat_Shape_Color_Xgen' or 'Learning_Cat_Color_Color_Xgen'
            % classfier test condition
            %@ClassifierResults: for 'Learning_Cat_Shape_Color_Xgen','Learning_Cat_Color_Color_Xgen'
            %@ClassifierOpts:    for 'Learning_Cat_Shape_Color_Xgen','Learning_Cat_Color_Color_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0);
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1,0);
            
            if ~isempty(obj.ClassifierResults_Shuff) % calculate stat test for shuffled data
                obj.ClassifierResults_Shuff=arrayfun(@(x) obj.PreprocessClassifierResults(obj.ClassifierResults_Shuff,ClassifierOpts,x-1,1),1:2,'UniformOutput',0);
                obj.StatTest=arrayfun(@(x) obj.PerformStatTest(ClassifierResults_ndD{x},obj.ClassifierResults_Shuff{x},[],[]),1:2,'UniformOutput',0);
            end
            for Cond=1:length(ClassifierOpts.TrainCond)
                Conds=Cond;
                nConds=length(Conds);
                ExtraStr=obj.AddStr4ClassifierTitle(ClassifierOpts,Cond);
                for c=1:nConds                    
                    h(Cond)=obj.FigParams.RenderFigure(1,[]);
                    [h{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h{Cond},4*nConds);
                    obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                    %% plot performance of the classifier during learning
                    Time2Look=AnalysisOpts.Time>=0 & AnalysisOpts.Time<=0.2 ;
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{1},ClassifierOpts,'Accuracy',Sp(1),Conds,[],1);%caxis([0.4 0.7]);
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{1},ClassifierOpts,'Accuracy',Sp(2),Conds,Time2Look,1);axis tight;ylim([0.4 0.7]);
                    
                    % plot accuracy in time during learning for second dimension
                    Time2Look=AnalysisOpts.Time>=0 & AnalysisOpts.Time<=0.2 ;
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{2},ClassifierOpts,'Accuracy',Sp(3),Conds,[],2);%caxis([0.4 0.7]);
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_ndD{2},ClassifierOpts,'Accuracy',Sp(4),Conds,Time2Look,2);axis tight; ylim([0.4 0.6]);
                    
                    h1(Cond)=obj.FigParams.RenderFigure(1,[]);
                    [h1{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h1{Cond},8*nConds);
                 %   obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                    
                    % plot 1D projections for both conditions
                    obj.PlotSVMProjectionsScores1D_Learning(ClassifierResults_ndD{1},ClassifierOpts,Sp(1),Conds(c),0,0,'ThisTargetFactor','QuadrantsInCong');
                    obj.PlotSVMProjectionsScores1D_Learning(ClassifierResults_ndD{2},ClassifierOpts,Sp(2),Conds(c),0,1,'ThisTargetFactor','QuadrantsInCong');
                    
                    % Choose the data we want to look at
                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(3),Conds(c),'MeanStd','corr','ThisTargetFactor','QuadrantsInCong');
                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(4),Conds(c),'Image','corr','ThisTargetFactor','QuadrantsInCong');
                    
                    % do the same plot for congruent trials
                    % plot 1D projections for both conditions
                    obj.PlotSVMProjectionsScores1D_Learning(ClassifierResults_ndD{1},ClassifierOpts,Sp(5),Conds(c),0,0,'ThisTargetFactor','QuadrantsCong');
                    obj.PlotSVMProjectionsScores1D_Learning(ClassifierResults_ndD{2},ClassifierOpts,Sp(6),Conds(c),0,1,'ThisTargetFactor','QuadrantsCong');
                    
                    % Choose the data we want to look at
                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(7),Conds(c),'MeanStd','corr','ThisTargetFactor','QuadrantsCong');
                    obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                        Sp(8),Conds(c),'Image','corr','ThisTargetFactor','QuadrantsCong');
                  
                    if 0 % if we want to plot correlation of representations in time
                        h2(Cond)=obj.FigParams.RenderFigure(1,[]);
                        [h2{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h2{Cond},2);
                        obj.PutSGtitle4Figure(ClassifierOpts,ExtraStr);
                        
                        obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                            Sp(1),Conds(c),'Line','PreStimScoreCorr','ThisTargetFactor','QuadrantsInCong');
                        
                        obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                            Sp(2),Conds(c),'Line','PreStimScoreCorr','ThisTargetFactor','QuadrantsCong');
                    end
                end
            end
            h=[h h1];
        end
        function ExtraStr=AddStr4ClassifierTitle(obj,ClassifierOpts,Cond,varargin) % adds extra information about the classifier
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ExtraStr='';
            if contains(ClassifierOpts.Name,'Congruency')
                CongTxt={'InCong','Cong','All'};
                LimFactorTrialVal=ClassifierOpts.LimFactorTrialVal{Cond};
                if isnan(LimFactorTrialVal);LimFactorTrialVal=[2 2];end
                ExtraStr=sprintf('Trn:%s|Tst:%s',CongTxt{LimFactorTrialVal(1)+1},CongTxt{LimFactorTrialVal(2)+1});               
            end                
        end
        function h=QuantifySubSpaceBhvCorr_Learning(obj,ClassifierResults,ClassifierOpts,varargin) % quanitfies relationship between subspaces and behavioral model factors during learning
            % this function is mainly used with 'Learning_Cat_Shape_Rule_Xgen'
            % classfier test condition
            %@ClassifierResults: for 'Learning_Cat_Shape_Rule_Xgen'
            %@ClassifierOpts:    for 'Learning_Cat_Shape_Rule_Xgen'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % preprocess classifier resutls
            ClassifierResults_ndD{1}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0);
            ClassifierResults_ndD{2}= obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1,0);
            Cond=1;
            Conds=[Cond];%length(ClassifierOpts.TrainCond);
            nConds=length(Conds);
            % define the factors we want to look at
            BhvFactors2Plot=[{'Hybrid_RPE'      }
                {'Hybrid_W_Color1' }
                {'Hybrid_W_Color2' }
                {'Hybrid_W_Shape1' }
                {'Hybrid_W_Shape2' }
                {'InferAF_Bfeature'}
                {'Hybrid_W_Diff1'  }
                {'Hybrid_W_Diff2'  }];
            nFactors2Plot=length(BhvFactors2Plot);
            for c=1:nConds
                h(Cond)=obj.FigParams.RenderFigure(1,[]);
                [h{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h{Cond},nFactors2Plot);
                obj.PutSGtitle4Figure(ClassifierOpts);
                
                arrayfun(@(x) obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                    Sp(x),Conds(c),'CorrBhvMdl','CorrBhvMdl','ThisTargetFactor','QuadrantsInCong','BhvMdlFactor',BhvFactors2Plot{x}),1:nFactors2Plot,'UniformOutput',0);
                
                h1(Cond)=obj.FigParams.RenderFigure(1,[]);
                [h1{Cond},Sp]=obj.FigParams.RenderSubplots([],[],h1{Cond},nFactors2Plot);
                obj.PutSGtitle4Figure(ClassifierOpts);
                
                arrayfun(@(x) obj.PlotSVMProjectionsScores2DPEV_Learning(ClassifierResults_ndD{1},ClassifierResults_ndD{2},ClassifierOpts,...
                    Sp(x),Conds(c),'CorrBhvMdl','CorrBhvMdl','ThisTargetFactor','QuadrantsCong','BhvMdlFactor',BhvFactors2Plot{x}),1:nFactors2Plot,'UniformOutput',0);
            end
            h=[h h1];
        end
        function h=PlotSVMProjectionsScores1D(obj,ClassifierResults,ClassifierOpts,Sp,Cond,IsAvg,Dim2ndFlag,varargin) % plots score magnitude for each trial or trail averaged
            %@cell structure of output of the classifer projection of validation data
            %@IsAvg if IsAvg flag is on then it takes the average of the scores
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if ~isempty(obj.ThisTargetFactor) % if we have provided Target factor then use it
                TargetFactor=obj.ThisTargetFactor;
                Levels=[];
            else
                [Levels,TargetFactor,~,~,~,~,TestFactorTxt]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);              
            end
            nLevels=length(Levels);
            
            if isfield(ClassifierResults(Cond),'TrialRange')
                if ~isfield(ClassifierResults(1).TrialRange(1).Rep(1),TestFactorTxt) % if we don't have FactorData then return
                    return;
                end
                for rep=1:ClassifierOpts.Nrep
                    % grab trials and tile them based on different values of factor we care about
                    [FactorDataInd{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults(Cond).TrialRange(obj.TrlRngNum).Rep(rep).(TestFactorTxt),TargetFactor,Levels);
                    
                    % grab score values now based on number of the trial in a specific repetition
                    Scores(rep,:)=cellfun(@(x) ClassifierResults(Cond).TrialRange(obj.TrlRngNum).Scores{rep}(x,:,:),FactorDataInd{rep},'UniformOutput',0);
                end
            else
                if ClassifierOpts.RunCrossTemporalClassifer % then we are only intrested in the scores on the diagonal
                    DiagTimInds=find(eye(ClassifierOpts.TimeMatrixSize))';
                else
                    DiagTimInds=1:ClassifierOpts.TimeMatrixSize(2);
                end
                for rep=1:ClassifierOpts.Nrep
                    % grab trials and tile them based on different values of factor we care about
                    [FactorDataInd{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults(Cond).Rep(rep).(TestFactorTxt),TargetFactor,Levels);
                    
                    % grab score values now based on number of the trial in a specific repetition
                    Scores(rep,:)=cellfun(@(x) ClassifierResults(Cond).Scores{rep}(x,:,DiagTimInds),FactorDataInd{rep},'UniformOutput',0);
                end
            end
            Levels=FactorLevels;
            nLevels=length(Levels);
            Scores=arrayfun(@(x) cell2mat(Scores(:,x)),1:length(FactorLevels),'UniformOutput',0);           
            
            % plot the data now
            [Col]=obj.GetColorPalet4Factor(TargetFactor,[]);
            Ylbl=[TargetFactor ' Encoding Axis'];
            Title=[ClassifierOpts.Name];
            if IsAvg
                % take average of all of the scores
                Scores=transpose(cell2mat(arrayfun(@(x) abs(mean(squeeze(Scores{x}(:,1,:)),1))',1:nLevels,'UniformOutput',0)));
                h=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,Scores,[],AnalysisOpts.Xlabel,...
                    Ylbl,obj.ThisColor,3,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,'STD_method','bootstrap');
            else
                h=arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,squeeze(Scores{x}(:,1,:)),[],AnalysisOpts.Xlabel,...
                    Ylbl,Col(x,:),3,Title,'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                    'SmoothingMethod',obj.SmoothingMethod,'STD_method','bootstrap'),1:nLevels,'UniformOutput',0);
                if contains(TargetFactor,'Color') | contains(TargetFactor,'Shape')
                    phasebar('location','se','deg','size',0.3)
                end
                axis tight 
                xticks([-0.4 -0.2 0 0.2 0.4 0.6 0.8])
                xtickangle(0)
            end
        end
        function h=PlotSVMProjectionsScores1D_Learning(obj,ClassifierResults,ClassifierOpts,Sp,Cond,IsAvg,Dim2ndFlag,varargin) % plots score magnitude for each trial or trail averaged during learning
            %@cell structure of output of the classifer projection of validation data
            %@IsAvg if IsAvg flag is on then it takes the average of the scores
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
                        
            if ~isempty(obj.ThisTargetFactor) % if we have provided Target factor then use it
                TargetFactor=obj.ThisTargetFactor;
                Levels=[];
            else
                [Levels,TargetFactor]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag);
            end
            [~,ThisDimTargetFactor]=obj.getClassifierDimInfo(ClassifierOpts,Dim2ndFlag); % get this dimension target factor
            % look if test for congruent or incongruent trials is included here?
            if contains(ClassifierOpts.Name,'Congruency')
                LimFactorTrialVal=ClassifierOpts.LimFactorTrialVal{Cond};
                if isnan(LimFactorTrialVal);LimFactorTrialVal=[2 2];end
                if (strcmp(TargetFactor,'QuadrantsInCong') & LimFactorTrialVal(2)==1) | (strcmp(TargetFactor,'QuadrantsCong') & LimFactorTrialVal(2)==0)
                    return
                end
            end
            % grab the score data for this condition
            nTrialRange=length(ClassifierResults(Cond).TrialRange);
            for TrlRng=1:nTrialRange
                for rep=1:ClassifierOpts.Nrep
                    % grab trials and tile them based on different values of factor we care about
                    [FactorDataInd{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep).TestDataAllFactors,TargetFactor,Levels);
                    
                    % grab score values now based on number of the trial in a specific repetition
                    Scores(TrlRng).TrialRange(rep,:)=cellfun(@(x) ClassifierResults(Cond).TrialRange(TrlRng).Scores{rep}(x,:,:),FactorDataInd{rep},'UniformOutput',0);
                end
                % reorganize score values
                Levels=FactorLevels;
                nLevels=length(Levels);
                Scores2(TrlRng).TrialRange=arrayfun(@(x) cell2mat(Scores(TrlRng).TrialRange(:,x)),1:length(FactorLevels),'UniformOutput',0);
            end
            
            Col=obj.GetTargetFactorColor(TargetFactor); % get color for this target factor 
            
            % plot the data now
            Ylbl=[TargetFactor ' Encoding Axis']; Title=[ThisDimTargetFactor];%;[ClassifierOpts.Name];
            if IsAvg
                % take average of all of the scores
                Scores=transpose(cell2mat(arrayfun(@(x) abs(mean(squeeze(Scores{x}(:,1,:)),1))',1:nLevels,'UniformOutput',0)));
                h=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,Scores,[],AnalysisOpts.Xlabel,...
                    Ylbl,obj.ThisColor,1,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax);
            else
                ColBin=obj.ManData.BinData([],nTrialRange,1,4);
                h=arrayfun(@(TrlRng) arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,squeeze(Scores2(TrlRng).TrialRange{x}(:,1,:)),[],AnalysisOpts.Xlabel,...
                    Ylbl,Col(x,:)/ColBin(nTrialRange-TrlRng+1),3,Title,'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                    'SmoothingMethod',obj.SmoothingMethod),1:nLevels,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                
                if contains(TargetFactor,'Color') | contains(TargetFactor,'Shape')
                    phasebar('location','se','deg','size',0.3)
                end
            end
        end
        function Col=GetTargetFactorColor(obj,TargetFactor) % gets color for a specific target factor 
            global AnalysisOpts
            
            if strcmp(TargetFactor,'ColorML') % then use the color corresponding to the stimulus
                Col=AnalysisOpts.MorphlevelsColRGBInc50;
                colormap(AnalysisOpts.MorphlevelsColRGBInc50);
            elseif strcmp(TargetFactor,'ShapeML')
                Col=AnalysisOpts.MorphlevelsShpRGBInc50;
                colormap(AnalysisOpts.MorphlevelsShpRGBInc50);
            elseif strcmp(TargetFactor,'Quadrants')
                Col=[AnalysisOpts.MorphlevelsColRGBInc50(1,:);AnalysisOpts.MorphlevelsColRGBInc50(5,:);...
                    [22,216,246]/255;[246,22,216]/255];
            elseif strcmp(TargetFactor,'QuadrantsInCong')
                Col=[AnalysisOpts.MorphlevelsColRGBInc50(1,:);AnalysisOpts.MorphlevelsColRGBInc50(5,:)];
            elseif strcmp(TargetFactor,'QuadrantsCong')
                Col=[AnalysisOpts.MorphlevelsColRGBInc50(5,:);AnalysisOpts.MorphlevelsColRGBInc50(1,:)];
            else
                Col=obj.FigParams.getColorPalet(nLevels);
            end           
        end
        function [Levels,TargetFactor,ObservedFieldName,TrainCond,TestCond,DimTxt,TestFactorTxt,...
                TrainFactorTxt,LevelFieldName,TrainCondTxt,TestCondTxt,DimNum]=...
                getClassifierDimInfo(obj,ClassifierOpts,Dim2ndFlag) % outputs fields about each dimension
            if  Dim2ndFlag==0
                DimTxt='';
                Levels= ClassifierOpts.Levels{1};TargetFactor=ClassifierOpts.TargetFactors{1};
                ObservedFieldName='Observed';LevelFieldName='Levels';
                TrainCond=ClassifierOpts.TrainCond;TestCond=ClassifierOpts.TestCond;
                DimNum=1;
            elseif Dim2ndFlag==1 || Dim2ndFlag==2 %then this is the 2nd dimension of the data
                DimTxt='2';
                Levels= ClassifierOpts.Levels_2ndD{1};TargetFactor=ClassifierOpts.TargetFactors_2ndD{1};
                ObservedFieldName='Observed_2ndD';LevelFieldName='Levels_2ndD';
                TrainCond=ClassifierOpts.TrainCond2;TestCond=ClassifierOpts.TestCond2;
                DimNum=2;
            elseif Dim2ndFlag==3 %then this is the 3nd dimension of the data
                 DimTxt='3';
                Levels= ClassifierOpts.Levels_3ndD{1};TargetFactor=ClassifierOpts.TargetFactors_3ndD{1};
                ObservedFieldName='Observed_3ndD';LevelFieldName='Levels_3ndD';
                TrainCond=ClassifierOpts.TrainCond3;TestCond=ClassifierOpts.TestCond3; 
                DimNum=3;
            end
            TestFactorTxt=sprintf('Test%sDataAllFactors',DimTxt);           
            TrainFactorTxt=sprintf('Train%sDataAllFactors',DimTxt);
            TestCondTxt=sprintf('TestCond%s',DimTxt);           
            TrainCondTxt=sprintf('TrainCond%s',DimTxt);
        end
        function [h,MetricVal,TimeMetricVals]=PlotSVMPerfMetric(obj,ClassifierResults,ClassifierOpts,PerfMetric,Sp,Cond,varargin) % plots Accuracy or AUC magnitude for each trial or trail averaged
            %@ClassifierResults cell structure of output of the classifer projection of validation data
            %@PerfType can be'AUC' 'Accuracy' 'no_IDdims' or 'Posterior'
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % plot the data now
            Col=obj.FigParams.getSingleColor(obj.ThisColor);
            LineStyle=obj.FigParams.getSingleLineStyle(obj.ThisLineStyle);
                       
            [~,TargetFactorTxt,~,~,~,~,~,~,~,TrainCondTxt,TestCondTxt,DimNum]=obj.getClassifierDimInfo(ClassifierOpts,obj.LookatDim2); 
                                   
            Ylbl =['Classifier ' lower(PerfMetric)];%[TargetFactorTxt ' ' PerfMetric];
            if isempty(obj.ThisTitle)
                Title=[{[TargetFactorTxt ' Tst ' obj.ManData.ConvMat2Char(ClassifierOpts.(TestCondTxt){Cond}),...
                    ' Trn ' obj.ManData.ConvMat2Char(ClassifierOpts.(TrainCondTxt){Cond})]}];%{obj.ManData.RepDashSpace(ClassifierOpts.Name)};...
            else
                Title=obj.ThisTitle;
            end         
            
            LegTxt=[TargetFactorTxt(1:3) ' D' num2str(DimNum) ' Trn' obj.ManData.ConvMat2Char(ClassifierOpts.(TrainCondTxt){Cond}),...
                'Tst' obj.ManData.ConvMat2Char(ClassifierOpts.(TestCondTxt){Cond})];
            if isfield(ClassifierResults(Cond),'TrialRange')
                MetricVal=squeeze(ClassifierResults(Cond).TrialRange(obj.TrlRngNum).(PerfMetric));
            else
                MetricVal=squeeze(ClassifierResults(Cond).(PerfMetric));
            end
            
            if ClassifierOpts.RunCrossTemporalClassifer & size(MetricVal,3)>1
                % plot accuracy as image
                [h,~,~,TimeMetricVals,~,MetricVal]=obj.FigParams.Image(AnalysisOpts.Time,AnalysisOpts.Time,mean(MetricVal,3),...
                    {AnalysisOpts.Xlabel ;['Test ' ' R' obj.ManData.ConvMat2Char(ClassifierOpts.(TestCondTxt){Cond})]},...
                    {AnalysisOpts.Xlabel ;['Train ' ' R' obj.ManData.ConvMat2Char(ClassifierOpts.(TrainCondTxt){Cond})]},...
                    'Perf',ClassifierOpts.Name,Sp,'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'caxis_limits',ClassifierOpts.caxis_limits_XTemp,...
                    'WidthSmoothing',obj.WidthSmoothing,'WidthSmoothingDim2',obj.WidthSmoothing,'SmoothingMethod','movmean');%ClassifierOpts.caxis_limits);
                v=axis;
                xticks(v(1):0.2:v(2));
                xtickangle(0);
                yticks(v(3):0.2:v(4));
                ytickangle(0);
            else
                [h,~,~,~,MetricVal,TimeMetricVals]=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,MetricVal',[],AnalysisOpts.Xlabel,Ylbl,Col,...
                    obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,...
                    'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',LegTxt,...
                    'STD_method','bootstrap','LegendLoc','best','p_line_style',LineStyle,'p_MarkerNpnts',10,...
                    'p_marker',obj.ThisMarker,'p_marker_size',obj.ThisMarkerSize,'ThisTitle',obj.ThisTitle,...
                    'ThisXLabel',obj.ThisXLabel,'ThisYLabel',obj.ThisYLabel,'SubtractBaseLine',obj.SubtractBaseLine,...
                    'NPnts_SubtractBaseLine',obj.NPnts_SubtractBaseLine,'performtrend_stattest',obj.performtrend_stattest);
                subtitle(obj.ThisSubtitle)
                
                % add stats
                if iscell(obj.StatTest);ThisStatTest=obj.StatTest{DimNum};else ThisStatTest=[];end % then we have multiple dimensions
                
                if isfield(ThisStatTest,PerfMetric) % add a line for each of the significant clusters
                    if length(ThisStatTest)==1;Cond=1;end % then this is the statistical test for this condition
                    axis tight
                    SigPlotDone=obj.FigParams.plot_significance_level(ThisStatTest(Cond).(PerfMetric).clusters,...
                        ThisStatTest(Cond).(PerfMetric).statsummery,AnalysisOpts.Time,...
                        ClassifierOpts.caxis_limits,Col,[],[],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);
                else
                    SigPlotDone=0;
                end
                % adjust ylim with regard to stat test results
                v=axis;
                % ylim([min(ClassifierOpts.caxis_limits(1),v(3)) max(ClassifierOpts.caxis_limits(2),v(4))]);
                axis tight 
                xticks(v(1):0.2:v(2))
                xtickangle(0)
                if ~obj.NormalizebyMax & ~SigPlotDone | ClassifierOpts.enforceAxisLimits
                    if strcmp(ClassifierOpts.caxis_limits,'auto')
                        YLims=v(3:4);
                    else
                        YLims=ClassifierOpts.caxis_limits;
                        obj.FigParams.SetAxisTicks('y',ClassifierOpts.caxis_limits,0.1);
                    end
                    ylim([YLims(1) max(YLims(2),v(4))]);
                end
                if ~obj.NormalizebyMax
                    if isfield(ClassifierOpts,'ChanceLevel');ChanceLevel=ClassifierOpts.ChanceLevel;else;ChanceLevel=0.5;end
                    obj.FigParams.PlotHorizontalLine(ChanceLevel,Sp,[0.5 0.5 0.5],'p_line_style','--');
                end
                v=axis;
                if (v(4)-v(3))<0.5
                    yticks((floor(v(3) * 10) / 10):0.05:v(4))
                else
                    yticks((floor(v(3) * 10) / 10):0.1:v(4))
                end
            end
        end
        function h=PlotSVMGeneraliztionIndex(obj,ClassifierResults,ClassifierResultsXgen,ClassifierOpts,PerfMetric,Sp,Cond,CondXgen,TimeIndMax,Ar,varargin) % plots index of generalizaiton by dividng Main condition and cross generization condition
            %@ClassifierResults cell structure of output of the classifer projection of validation data
            %@ClassifierResultsXgen cell structure of output of the classifer projection of xrule generalization data
            %@PerfType can be'AUC' 'Accuracy' 'no_IDdims' or 'Posterior'
            %@ Ar area
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % plot the data now
            Col=obj.FigParams.getSingleColor(obj.ThisColor);
            Ylbl =[ClassifierOpts.TargetFactors{1} ' ' PerfMetric];
            Title=[obj.ManData.RepDashSpace(ClassifierOpts.Name)];
            LegTxt=[' Trn' obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                'Tst' obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond})];
            if isfield(ClassifierResults(Cond),'TrialRange')
                MetricVal=squeeze(ClassifierResults(Cond).TrialRange(obj.TrlRngNum).(PerfMetric));
                MetricValXgen=squeeze(ClassifierResultsXgen(CondXgen).TrialRange(obj.TrlRngNum).(PerfMetric));
            else
                MetricVal=squeeze(ClassifierResults(Cond).(PerfMetric));
                MetricValXgen=squeeze(ClassifierResultsXgen(CondXgen).(PerfMetric));
            end
            % divide the averge performance per time point in two conditions
            GeneralizationIndex=[mean(MetricValXgen,2)./mean(MetricVal,2)]';
            % find time point that we have the max  in the time
            if ~isempty(TimeIndMax)
                [~,MaxPerfIndex]=max(mean(MetricValXgen,2));
                MaxIndex=GeneralizationIndex(MaxPerfIndex);
                PlotMode=2; % plot it in a bar
                h=obj.FigParams.PlotMeanStd(find(strcmp(Ar,AnalysisOpts.AreaNames)),MaxIndex,[],AnalysisOpts.Xlabel,Ylbl,Col,...
                    PlotMode,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,...
                    'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',LegTxt,...
                    'STD_method','bootstrap','LegendLoc','southeast');
                ylim([0.5 1.5])
            else
                h=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,GeneralizationIndex,[],AnalysisOpts.Xlabel,Ylbl,Col,...
                    obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,...
                    'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',LegTxt,...
                    'STD_method','bootstrap','LegendLoc','southeast');
            end
            subtitle(obj.ThisSubtitle)
            
            % add stats
            if isfield(obj.StatTest,PerfMetric) % add a line for each of the significant clusters
                if length(obj.StatTest)==1;Cond=1;end % then this is the statistical test for this condition
                obj.FigParams.plot_significance_level(obj.StatTest(Cond).(PerfMetric).clusters,...
                    obj.StatTest(Cond).(PerfMetric).statsummery,AnalysisOpts.Time,ClassifierOpts.caxis_limits,Col,[]);
            end
            
            % adjust ylim with regard to stat test results
            v=axis;
            ylim([min(ClassifierOpts.caxis_limits(1),v(3)) max(ClassifierOpts.caxis_limits(2),v(4))]);
            
        end        
        function PlotSVMAllPerfMetrics(obj,ClassifierResults,ClassifierOpts,Sp,Cond,varargin) % plots all of the metrics of classifer performance in one plot 'AUC' 'Accuracy' 'no_IDdims'
            %@ClassifierResults cell structure of output of the classifer projection of validation data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            Cols=obj.FigParams.getColorPalet(3); % one color per metric
            if ClassifierOpts.RunCrossTemporalClassifer  % we only care about the diagonal
                DiagTimInds=find(eye(ClassifierOpts.TimeMatrixSize))';
                ClassifierResults(Cond).Accuracy=ClassifierResults(Cond).Accuracy(DiagTimInds);
                ClassifierResults(Cond).AUC=ClassifierResults(Cond).AUC(DiagTimInds);
            end
            PerfMetrics={'Accuracy'};%,'AUC'};%,'no_IDdims'};
            % Plot AUC and Accuracy
            hp{1}=obj.PlotSVMPerfMetric(ClassifierResults,ClassifierOpts,PerfMetrics{1},Sp,Cond,'ThisColor',Cols(1,:),'MeanStdPlotType',3);
%            hp{2}=obj.PlotSVMPerfMetric(ClassifierResults,ClassifierOpts,PerfMetrics{2},Sp,Cond,'ThisColor',Cols(2,:),'MeanStdPlotType',3);
%            yyaxis right
%            hp{3}=obj.PlotSVMPerfMetric(ClassifierResults,ClassifierOpts,PerfMetrics{3},Sp,Cond,'ThisColor',Cols(3,:),'MeanStdPlotType',3);
            ylim auto
            legend(PerfMetrics(~cellfun(@isempty,hp)),'Location','southeast');
            legend('boxoff');
            
        end
        function h=PlotXtempAccuracy(obj,ClassifierResults,ClassifierOpts,Sp,Cond,varargin) % plots image of Xtemp accuracy
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            TimeLabel=strrep(AnalysisOpts.SpkCntStartFieldName,'_',' ');
            % this is not xtemporal just plot accuracy in a line plot
            h=obj.PlotSVMPerfMetric(ClassifierResults,ClassifierOpts,'Accuracy',Sp,Cond,...
                'NormalizebyMax',obj.NormalizebyMax,'MeanStdPlotType',obj.MeanStdPlotType,'LookatDim2',obj.LookatDim2,...
                'SubtractBaseLine',obj.SubtractBaseLine,'NPnts_SubtractBaseLine',obj.NPnts_SubtractBaseLine);
            
        end
        function PutSGtitle4Figure(obj,ClassifierOpts,AddStr)
            global AnalysisOpts
            % AddStr is additional String
            if ~exist('AddStr','var');AddStr='';end
            SGTitle=[ {ClassifierOpts.Name };...
                {[ClassifierOpts.AnalysisOpts.SpkCntStartFieldName '|' ClassifierOpts.AnalysisOpts.TrlSpkTimeFieldName '|' ClassifierOpts.AnalysisOpts.Area2look{1},...
                '|' ClassifierOpts.AnalysisOpts.Animal '|']};...
                {['N=' num2str(ClassifierOpts.IncludedNeu4Ana_Num) '|nS=' num2str(ClassifierOpts.IncludedNeu4Ana_AnimalNum(1)) '|nC=' num2str(ClassifierOpts.IncludedNeu4Ana_AnimalNum(2))]};...
                AddStr];
            
            SGTitle=cellfun(@(x) obj.ManData.RepDashSpace(x),SGTitle,'UniformOutput',0);
            sgt = sgtitle(SGTitle,'Color','blue');
            sgt.FontSize = 7;
            sgt.HorizontalAlignment='center';
            sgt.Interruptible='off';
            sgt.Margin=1;
            sgt.BackgroundColor=[1 1 1];
            sgt.EdgeColor=[1 0 0];
        end
        function PutSGtitle4ClassifierComparision(obj,Tasks2Compare,ClassifierOpts,Col,AddStr) % puts SG title for classifier comparision figure
            global AnalysisOpts
            % AddStr is additional String
            if ~exist('AddStr','var');AddStr='';end
            AreaStatTxt=[];
            for Area=Tasks2Compare.Area2Look
                ThisAreaInds=strcmp(Tasks2Compare.Area,Area{1});
                
                N=obj.ManData.ConvMat2Char(cellfun(@(x) x.IncludedNeu4Ana_Num,ClassifierOpts(ThisAreaInds),'UniformOutput',1));
                nS=obj.ManData.ConvMat2Char(cellfun(@(x) x.IncludedNeu4Ana_AnimalNum(1),ClassifierOpts(ThisAreaInds),'UniformOutput',1));
                nC=obj.ManData.ConvMat2Char(cellfun(@(x) x.IncludedNeu4Ana_AnimalNum(2),ClassifierOpts(ThisAreaInds),'UniformOutput',1));
                AreaStatTxt=cat(1,AreaStatTxt,{['N ' Area{1} '=' N '|nS=' nS '|nC=' nC]});
            end
            if isempty(Col);Col=repmat([1 0 0],[length(Tasks2Compare.MainTasks),1]);end
            MainTaskTxt=obj.ManData.ConvMat2Char(arrayfun(@(x) sprintf('\\color[rgb]{%0.1f %0.1f %0.1f}%s',Col(x,1),Col(x,2),Col(x,3),Tasks2Compare.MainTasks{x}),1:length(Tasks2Compare.MainTasks),'UniformOutput',0));
            SGTitle=[ {['\color{blue}' Tasks2Compare.ComparisonName]};MainTaskTxt;...
                {['\color{blue}' Tasks2Compare.SpkCntStartFieldName{1} '|' Tasks2Compare.TrlSpkTimeFieldName{1},'|' ClassifierOpts{1}.AnalysisOpts.Animal '|']};...
                AreaStatTxt;...
                AddStr];
            
            SGTitle=cellfun(@(x) obj.ManData.RepDashSpace(x),SGTitle,'UniformOutput',0);
            sgt = sgtitle(SGTitle);
            sgt.FontSize = 7;
            sgt.HorizontalAlignment='left';
            sgt.Interruptible='off';
            sgt.Margin=1;
            sgt.BackgroundColor=[1 1 1];
            sgt.EdgeColor=[1 0 0];
        end
        % series of functions for 2d plots of different components of the
        % classifier
        function h=Plot2DXTemporalClassifierResults(obj,ClassifierResults,ClassifierOpts,PlotMode,Conds,ComparisionOpts,varargin) % plots the results from classifer analysis
            %@ClassifierResults ClassifierOpts: if you are comparing(CompareConds) conditions then put each condition in a cell
            %@PlotMode dictates which type of plots we want
            %@Conds (Cell or double) index of the conditions you want be plotted. If this a 'CompareConds' then each cell has to have one value
            % 'XTemp' plots crosstemporal performance with accuracy
            % 'CondDetail' Plots details of each condition indicated by variable Conds
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare variables
            NConds=length(ClassifierResults);
            % load each dimension in a differrent varibale so it is easier
            % to manipulate them
            if ~strcmp(PlotMode,'CompareConds')
                % preprocess classifier results to have them in an easier shape
                ClassifierResults_1ndD=obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,0,0); % process first Dimension
                ClassifierResults_2ndD=obj.PreprocessClassifierResults(ClassifierResults,ClassifierOpts,1,0); % process first Dimension
            else
                % preprocess classifier results to have them in an easier shape
                ClassifierResults_1ndD=arrayfun(@(x) obj.PreprocessClassifierResults(ClassifierResults{x},ClassifierOpts{x},0,0),1:NConds,'UniformOutput',0);
                ClassifierResults_2ndD=arrayfun(@(x) obj.PreprocessClassifierResults(ClassifierResults{x},ClassifierOpts{x},1,0),1:NConds,'UniformOutput',0);
            end
            NNeu=size(ClassifierResults_1ndD(1).TrialRange(1).Beta{1},2);
            switch PlotMode
                case 'CondDetail' % plot detail of one condition
                    h=obj.FigParams.RenderFigure(1,[]);
                    [h,Sp]=obj.FigParams.RenderSubplots(2,3,h{1},[]);
                    
                    % plot accuracy of each condition
                    % together
                    h1=obj.PlotXtempAccuracy(ClassifierResults_1ndD,ClassifierOpts,Sp(1),Conds,'ThisColor',1,'NormalizebyMax',1,'MeanStdPlotType',3);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_2ndD,ClassifierOpts,Sp(1),Conds,'ThisColor',2,'NormalizebyMax',1,'MeanStdPlotType',3);
                    ylabel([ClassifierOpts.TargetFactors{1} '/' ClassifierOpts.TargetFactors_2ndD{1} ' Norm Accuracy']);
                    subtitle([AnalysisOpts.TrlSpkTimeFieldName ' ' AnalysisOpts.Area2look{1}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],ClassifierOpts.TargetFactors{1},ClassifierOpts.TargetFactors_2ndD{1});
                    
                    % Plot accuracy again without normalizing
                    h1=obj.PlotXtempAccuracy(ClassifierResults_1ndD,ClassifierOpts,Sp(2),Conds,'ThisColor',1,'NormalizebyMax',0,'MeanStdPlotType',1);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_2ndD,ClassifierOpts,Sp(2),Conds,'ThisColor',2,'NormalizebyMax',0,'MeanStdPlotType',1);
                    ylabel([ClassifierOpts.TargetFactors{1} '/' ClassifierOpts.TargetFactors_2ndD{1} ' Accuracy'])
                    subtitle([AnalysisOpts.TrlSpkTimeFieldName ' ' AnalysisOpts.Area2look{1}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],ClassifierOpts.TargetFactors{1},ClassifierOpts.TargetFactors_2ndD{1});
                    
                    %  Plot projection of scores into 1D space for each of
                    %  the dimensions
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_1ndD,ClassifierOpts,Sp(3),Conds,0,0);
                    obj.PlotSVMProjectionsScores1D(ClassifierResults_2ndD,ClassifierOpts,Sp(4),Conds,0,1);
                    
                    % plot projection in 2 dimensions
                    obj.PlotSVMProjectionsScores2D(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(5),Conds,0)
                    subtitle([AnalysisOpts.TrlSpkTimeFieldName ' ' AnalysisOpts.Area2look{1}],'FontWeight','bold','Color','blue')
                    
                    % plot angle between classifiers in time
                    obj.PlotAngleBetEncodingAxes(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(6),Conds)
                case 'CompareConds' % compares differnt conditions
                    h=obj.FigParams.RenderFigure(1,[]);
                    [h,Sp]=obj.FigParams.RenderSubplots(2,3,h{1},[]);
                    %prepare variables
                    
                    SGTitle=arrayfun(@(x) [ComparisionOpts.TaskInd{x} ' ' ComparisionOpts.TrlSpkTimeFieldName{x} ' ' ComparisionOpts.Area{x} ' ' AnalysisOpts.Animal],1:length(ComparisionOpts.Cond),'UniformOutput',0);
                    SGTitle=obj.ManData.RepDashSpace(SGTitle)';
                    sgt = sgtitle(['Comparing Conditions:'; SGTitle],'Color','blue');
                    sgt.FontSize = 15;
                    
                    % Plot accuracy of first result without normalizing
                    h1=obj.PlotXtempAccuracy(ClassifierResults_1ndD{1},ClassifierOpts{1},Sp(1),Conds{1},'ThisColor',1,'NormalizebyMax',0,'MeanStdPlotType',1);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_2ndD{1},ClassifierOpts{1},Sp(1),Conds{1},'ThisColor',2,'NormalizebyMax',0,'MeanStdPlotType',1);
                    ylabel([ClassifierOpts{1}.TargetFactors{1} '/' ClassifierOpts{1}.TargetFactors_2ndD{1} ' Accuracy'])
                    subtitle([ComparisionOpts.TrlSpkTimeFieldName{1} ' ' ComparisionOpts.Area{1}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],{ClassifierOpts{1}.TargetFactors{1} ClassifierOpts{1}.TargetFactors_2ndD{1}},'Location','best')
                    ylim([0.4 0.9])
                    % Plot accuracy of second result without normalizing
                    h1=obj.PlotXtempAccuracy(ClassifierResults_1ndD{2},ClassifierOpts{2},Sp(2),Conds{2},'ThisColor',1,'NormalizebyMax',0,'MeanStdPlotType',1);
                    h2=obj.PlotXtempAccuracy(ClassifierResults_2ndD{2},ClassifierOpts{2},Sp(2),Conds{2},'ThisColor',2,'NormalizebyMax',0,'MeanStdPlotType',1);
                    ylabel([ClassifierOpts{2}.TargetFactors{1} '/' ClassifierOpts{2}.TargetFactors_2ndD{1} ' Accuracy'])
                    subtitle([ComparisionOpts.TrlSpkTimeFieldName{2} ' ' ComparisionOpts.Area{2}],'FontWeight','bold','Color','blue')
                    legend([h1 h2],{ClassifierOpts{2}.TargetFactors{1} ClassifierOpts{2}.TargetFactors_2ndD{1}},'Location','best')
                    ylim([0.4 0.9])
                    
                    % plot projection in 2 dimensions
                    obj.PlotSVMProjectionsScores2D(ClassifierResults_1ndD{1},ClassifierResults_2ndD{1},ClassifierOpts{1},Sp(3),Conds{1},0);
                    subtitle([ComparisionOpts.TrlSpkTimeFieldName{1} ' ' ComparisionOpts.Area{1}],'FontWeight','bold','Color','blue')
                    obj.PlotSVMProjectionsScores2D(ClassifierResults_1ndD{2},ClassifierResults_2ndD{2},ClassifierOpts{2},Sp(4),Conds{2},0);
                    subtitle([ComparisionOpts.TrlSpkTimeFieldName{2} ' ' ComparisionOpts.Area{2}],'FontWeight','bold','Color','blue')
                    
                    % plot angle between classifiers in time for both
                    % conditions
                    h1=obj.PlotAngleBetEncodingAxes(ClassifierResults_1ndD{1},ClassifierResults_2ndD{1},ClassifierOpts{1},Sp(5),Conds{1},'ThisColor',3);
                    h2=obj.PlotAngleBetEncodingAxes(ClassifierResults_1ndD{2},ClassifierResults_2ndD{2},ClassifierOpts{2},Sp(5),Conds{2},'ThisColor',4);
                    legend([h1 h2],{[ComparisionOpts.TrlSpkTimeFieldName{1} '(1)'] [ComparisionOpts.TrlSpkTimeFieldName{2} '(2)'] },'Location','best');
                case 'Learning' % plot results for learning conditions
                    h=obj.FigParams.RenderFigure(1,[]);
                    [h,Sp]=obj.FigParams.RenderSubplots(2,4,h{1},[]);
                    TimeIndColCat=find(AnalysisOpts.Time>=0 & AnalysisOpts.Time<0.3);
                    TimeIndResp=find(AnalysisOpts.Time>=0.3 & AnalysisOpts.Time<0.5);
                    
                    sgt = sgtitle([{obj.ManData.RepDashSpace(ClassifierOpts.Name)}; { ['nNeurons:' num2str(NNeu)]}],'Color','blue');
                    sgt.FontSize = 15;
                    % plot evolution of correlation between dimensions during learning
                    % plot accuracy in time during learning for first dimension
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_1ndD,ClassifierOpts,'Accuracy',Sp(1),Conds,[],1);
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_1ndD,ClassifierOpts,'Accuracy',Sp(2),Conds,1,1);
                    
                    % plot accuracy in time during learning for second dimension
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_2ndD,ClassifierOpts,'Accuracy',Sp(3),Conds,[],2);
                    obj.PlotSVMPerfMetric_Learning(ClassifierResults_2ndD,ClassifierOpts,'Accuracy',Sp(4),Conds,2,2);
                    
                    % plot evolution of angle between dimensions during learning
                    obj.PlotAngleBetEncodingAxes_Learning(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(5),Conds,[]);
                    obj.PlotAngleBetEncodingAxes_Learning(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(6),Conds,1);
                    
                    % plot evolution of Corr between dimensions during learning
                    obj.PlotAngleBetEncodingAxes_Learning(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(7),Conds,[],'ClassifierAngleCalMethod','Corr');
                    obj.PlotAngleBetEncodingAxes_Learning(ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp(8),Conds,1,'ClassifierAngleCalMethod','Corr');
                    
            end
            
            % save off the figures
            % [~,~,PopulationAnaFigFileName]=obj.ManData.GetFileName(['Classifier'],['Classifier_' ClassifierOpts.Name '_' AnalysisOpts.CurrentCh_AreaName '_' AnalysisOpts.SpkCntStartFieldName '_' PlotMode],'SaveInResults',1,'WantedDate','ALL');
            % obj.FigParams.SaveFigSeries([],PopulationAnaFigFileName,[h],'SaveEachFrame',0);
        end
        function PlotSVMProjectionsScores2D(obj,ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp,Cond,IsAvg,TimPeriod,varargin) % plots score magnitude for each trial or trail averaged in 2D
            %@cell structure of output of the classifer projection of validation data
            %@IsAvg if IsAvg flag is on then it takes the average of the scores
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            PlotMethod='AbsDiff';  % are we ploting the absolute difference of encoding between objects?
            
            if ~isfield(ClassifierResults_1ndD(1).TrialRange(1).Rep(1),'TestDataAllFactors') % if we don't gave Factor data
                return;
            end
            [Levels1,TargetFactor1,~,TrainCond1,TestCond1,DimTxt,TestFactorTxt1]=obj.getClassifierDimInfo(ClassifierOpts,obj.LookatDim2(1));
            [Levels2,TargetFactor2,~,TrainCond2,TestCond2,DimTxt,TestFactorTxt2]=obj.getClassifierDimInfo(ClassifierOpts,obj.LookatDim2(2));
             
            % for now we are taking the relevant factor is the first
            % dimension's factor and sort trials based on that
            TargetFactor=obj.ThisTargetFactor;%'QuadrantsInCong';%'Quadrants';%ClassifierOpts.TargetFactors{1};
            % let's look at the quadrants [1:red bunny, 2:green tee, 3:green bunny, 4:red tee]
            
            for rep=1:ClassifierOpts.Nrep
                % grab trials and tile them based on different values of factor we care about
                [FactorDataInd1{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults_1ndD(Cond).TrialRange(obj.TrlRngNum).Rep(rep).(TestFactorTxt1),...
                    TargetFactor,Levels1,'TakeCorrectTrlsOnly',obj.TakeCorrectTrlsOnly);
                [FactorDataInd2{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults_2ndD(Cond).TrialRange(obj.TrlRngNum).Rep(rep).(TestFactorTxt2),...
                    TargetFactor,Levels2,'TakeCorrectTrlsOnly',obj.TakeCorrectTrlsOnly);
                               
                % grab score values now based on number of the trial in a specific repetition
                Scores_1ndD(rep,:)=cellfun(@(x) ClassifierResults_1ndD(Cond).TrialRange(obj.TrlRngNum).Scores{rep}(x,:,:),FactorDataInd1{rep},'UniformOutput',0);
                Scores_2ndD(rep,:)=cellfun(@(x) ClassifierResults_2ndD(Cond).TrialRange(obj.TrlRngNum).Scores{rep}(x,:,:),FactorDataInd2{rep},'UniformOutput',0);
            end
            Scores_1ndD=arrayfun(@(x) cell2mat(Scores_1ndD(:,x)),1:length(FactorLevels),'UniformOutput',0);
            Scores_1ndD=cellfun(@(x) mean(squeeze(x(:,1,:)),1),Scores_1ndD,'UniformOutput',0);
            Scores_2ndD=arrayfun(@(x) cell2mat(Scores_2ndD(:,x)),1:length(FactorLevels),'UniformOutput',0);
            Scores_2ndD=cellfun(@(x) mean(squeeze(x(:,1,:)),1),Scores_2ndD,'UniformOutput',0);
            NTim=size(Scores_1ndD{1},2);
            nLevels=length(FactorLevels);
            
            [Col]=obj.GetColorPalet4Factor(TargetFactor,[]);

            subplot(Sp)
            %[red bunny, green tee, green bunny, red tee]
            TimeInd=AnalysisOpts.Time>=TimPeriod(1) & AnalysisOpts.Time<=TimPeriod(2);
            if strcmp(PlotMethod,'AbsDiff')
                AbsDiffPairs=[1 4;2 3]; % these are the pairs of objects when we use ColorMLComb as factor
                nLevels=size(AbsDiffPairs,1);
                for  p=1:nLevels
                    x=obj.ManData.SmoothData(abs(Scores_1ndD{AbsDiffPairs(p,1)}-Scores_1ndD{AbsDiffPairs(p,2)}),obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod);
                    y=obj.ManData.SmoothData(abs(Scores_2ndD{AbsDiffPairs(p,1)}-Scores_2ndD{AbsDiffPairs(p,2)}),obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod);
                    x=x(TimeInd);y=y(TimeInd);
                    z=zeros(1,sum(TimeInd));
                    col_ind=1:length(x);
                    ThisCol=cell2mat(arrayfun(@(y) Col(p,:)'*y,col_ind,'uniformoutput',0));
                    col=zeros(size(z,1),size(z,2),3);col(1,:,:)=ThisCol'/max(ThisCol(:));
                    surface([x;x],[y;y],[z;z],[col;col],...%[col;col],...
                        'facecol','no',...
                        'edgecol','interp',...
                        'linew',2.5,...
                        'LineStyle','-');
                end
            else            
                for p=1:nLevels
                    x=obj.ManData.SmoothData(Scores_1ndD{p}(TimeInd),obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod);
                    y=obj.ManData.SmoothData(Scores_2ndD{p}(TimeInd),obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod);
                    z=zeros(1,sum(TimeInd));
                    col_ind=1:length(x);
                    ThisCol=cell2mat(arrayfun(@(y) Col(p,:)'*y,col_ind,'uniformoutput',0));
                    col=zeros(size(z,1),size(z,2),3);col(1,:,:)=ThisCol'/max(ThisCol(:));
                    surface([x;x],[y;y],[z;z],[col;col],...%[col;col],...
                        'facecol','no',...
                        'edgecol','interp',...
                        'linew',2.5,...
                        'LineStyle','-');
                end
            end
            Xlbl=[TargetFactor1 ' Encoding Axis'];
            Ylbl=[TargetFactor2 ' Encoding Axis'];
            
            Title=[obj.ManData.RepDashSpace([ClassifierOpts.Name]); {['Trn1:' obj.ManData.ConvMat2Char(TrainCond1{Cond}),...
                ' Tst1:' obj.ManData.ConvMat2Char(TestCond1{Cond}),...
                '|Trn2:' obj.ManData.ConvMat2Char(TrainCond2{Cond}),...
                ' Tst2:' obj.ManData.ConvMat2Char(TestCond2{Cond})]}];
            
            title(Title);xlabel(Xlbl);ylabel(Ylbl)
            obj.FigParams.FormatAxes(gca);
            
            %             % plot the data now
            %             Ylbl=[TargetFactor ' Encoding Axis'];
            %             Title=[ClassifierOpts.Name];
            %             if IsAvg
            %                 % take average of all of the scores
            %                 Scores=transpose(cell2mat(arrayfun(@(x) abs(mean(squeeze(Scores{x}(:,1,:)),1))',1:nLevels,'UniformOutput',0)));
            %                 obj.FigParams.PlotMeanStd(AnalysisOpts.Time,Scores,[],AnalysisOpts.Xlabel,...
            %                     Ylbl,obj.ThisColor,1,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',1)
            %             else
            %                 arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,squeeze(Scores{x}(:,1,:)),[],AnalysisOpts.Xlabel,...
            %                     Ylbl,Col(x,:),1,Title,'Sp',Sp,'AppendTitles',1),1:nLevels,'UniformOutput',0);
            %                 if contains(TargetFactor,'Color') | contains(TargetFactor,'Shape')
            %                     phasebar('location','se','deg','size',0.3)
            %                 end
            %             end
        end
        function h=PlotAngleBetEncodingAxes(obj,ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp,Cond,varargin) % plots angle between encoding axis in time
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare data first by cacculting angle between classifers
            EncodeAng_deg=obj.CalculateAngleBetEncodingAxes(ClassifierResults_1ndD(Cond).TrialRange(obj.TrlRngNum).Beta,ClassifierResults_2ndD(Cond).TrialRange(obj.TrlRngNum).Beta);
            % plot the data now
            if isempty(obj.ThisColor)
                Col=obj.FigParams.getColorPalet(1);
            else
                Col=obj.ThisColor;
            end
            
            Ylbl =['Angle(Deg)'];
            Title=['Angle bet Encoding Axes'];
            h=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,EncodeAng_deg',[],AnalysisOpts.Xlabel,Ylbl,Col,obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax);
        end
        function EncodeAng_deg=CalAngleBtweenShapeColor(obj,ClassifierOpts,ClassifierResults_ndD,varargin)% clacluates angle between shape and color subspace using learning data 
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            % use Learning3D_Shape_Color_Response_Xgen_Orhto data for this test 

            PairsDims=[1 2;1 3;3 2;1 2;1 3;3 2;1 2;1 3;3 2;...
                1 1;1 1;1 1;2 2;2 2;2 2;3 3;3 3;3 3;...
                1 1;1 1;1 1;2 2;2 2;2 2;3 3;3 3;3 3]; % which dimensions are we comparing with each other 

            PairsCond=[1 1;1 1;1 1;2 2;2 2;2 2;3 3;3 3;3 3;...
                1 4;2 5;3 6;1 4;2 5;3 6;1 4;2 5;3 6;...
                2 3;1 3;2 1;2 3;1 3;2 1;2 3;1 3;2 1];

            for d=1:size(PairsDims,1)
                BetaAxis1=ClassifierResults_ndD{PairsDims(d,1)}(PairsCond(d,1)).TrialRange(1).Beta;
                BetaAxis2=ClassifierResults_ndD{PairsDims(d,2)}(PairsCond(d,2)).TrialRange(1).Beta;
                EncodeAng_deg(d).Ang=obj.CalculateAngleBetEncodingAxes(BetaAxis1,BetaAxis2);
                EncodeAng_deg(d).PairDims=PairsDims(d,:);
            end
            
            Factors={'Shape','Color','Response'};           
            txt={'','2','3'};
            TimeInd=AnalysisOpts.Time>=0.1 & AnalysisOpts.Time<=0.3;
            
            % plot angle between shape-color shape-response and color-response for each rule 
            figure
            for d=1:9
                Rule1nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,1)}]){PairsCond(d,1)};
                Rule2nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,2)}]){PairsCond(d,2)};
                subplot(3,3,d)
                hold on
                plot(AnalysisOpts.Time,movmean(EncodeAng_deg(d).Ang',15,2))
                yyaxis right
                bar(0,mean(EncodeAng_deg(d).Ang(TimeInd)),'BarWidth',0.1,'facecolor','none')
                title(sprintf('%s%i-%s%i',Factors{PairsDims(d,1)},Rule1nd,Factors{PairsDims(d,2)},Rule2nd))
                legend('Bef Swtch');
                xlim([-0.2 0.6]);
            end

            % plot angle between shape/color/resp before/after switch for each rule
            figure
            k=1;
            for d=10:18
                Rule1nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,1)}]){PairsCond(d,1)};
                Rule2nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,2)}]){PairsCond(d,2)};
                subplot(3,3,k)
                hold on
                plot(AnalysisOpts.Time,movmean(EncodeAng_deg(d).Ang',15,2))
                yyaxis right
                bar(0,mean(EncodeAng_deg(d).Ang(TimeInd)),'BarWidth',0.1,'facecolor','none')
                title(sprintf('%s%i-%s%i',Factors{PairsDims(d,1)},Rule1nd,Factors{PairsDims(d,2)},Rule2nd))
                legend('Bef Swtch-after swtch');
                xlim([-0.2 0.6]);
                k=k+1;
            end

            % plot angle for shape/color/resp across rules for before switch
            figure
            k=1;
            for d=19:27
                Rule1nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,1)}]){PairsCond(d,1)};
                Rule2nd=ClassifierOpts.(['TrainCond' txt{PairsDims(d,2)}]){PairsCond(d,2)};
                subplot(3,3,k)
                hold on
                plot(AnalysisOpts.Time,movmean(EncodeAng_deg(d).Ang',15,2))
                yyaxis right
                bar(0,mean(EncodeAng_deg(d).Ang(TimeInd)),'BarWidth',0.1,'facecolor','none')
                title(sprintf('%s%i-%s%i',Factors{PairsDims(d,1)},Rule1nd,Factors{PairsDims(d,2)},Rule2nd))
                legend('Bef Swtch');
                xlim([-0.2 0.6]);
                k=k+1;
            end
        end
        function EncodeAng_deg=CalculateAngleBetEncodingAxes(obj,BetaAxis1,BetaAxis2,varargin) % calculate angle between encoding axes(classifier Hyperplanes)
            %BetaAxis1 & 2  is the hyperplane weights for axes organized as
            % cell array with size Nrep and matrixes with size
            % (NTim*NNeurons)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            opts.TakeMeanHyperplane=1; % are we average across repetition to get the hyperplane?
            
            Nreps=length(BetaAxis1);
            NTim=size(BetaAxis1{1},1);
            switch obj.ClassifierAngleCalMethod
                case 'Angle'
                    if opts.TakeMeanHyperplane
                        warning('Taking Mean Hyperplane to calculate angles')
                        BetaAxisAvg1=mean(obj.ManData.ReshapeCell2Mat(BetaAxis1,3),3);
                        BetaAxisAvg2=mean(obj.ManData.ReshapeCell2Mat(BetaAxis2,3),3);
                        [EncodeAng_deg]=arrayfun(@(tim) obj.ManData.GetAngleBetVectors(BetaAxisAvg1(tim,:),...
                            BetaAxisAvg2(tim,:)),1:NTim,'uniformoutput',1)';
                    else
                        [EncodeAng_deg]=transpose(cell2mat(arrayfun(@(rep) arrayfun(@(tim) obj.ManData.GetAngleBetVectors(BetaAxis1{rep}(tim,:),...
                            BetaAxis2{rep}(tim,:)),1:NTim,'uniformoutput',1)',1:Nreps,'UniformOutput',0)));
                    end
                case 'Corr'
                    if opts.TakeMeanHyperplane
                        warning('Taking Mean correlation to calculate angles')
                        
                        BetaAxisAvg1=mean(obj.ManData.ReshapeCell2Mat(BetaAxis1,3),3);
                        BetaAxisAvg2=mean(obj.ManData.ReshapeCell2Mat(BetaAxis2,3),3);
                        [EncodeAng_deg]=arrayfun(@(tim) corr(BetaAxisAvg1(tim,:)',...
                            BetaAxisAvg2(tim,:)'),1:NTim,'uniformoutput',1)';
                    else
                        [EncodeAng_deg]=transpose(cell2mat(arrayfun(@(rep) arrayfun(@(tim) corr(BetaAxis1{rep}(tim,:)',...
                            BetaAxis2{rep}(tim,:)'),1:NTim,'uniformoutput',1)',1:Nreps,'UniformOutput',0)));
                    end
            end
        end
        function EncodeAng_deg=CalculateAngleBetEncodingAxesSpkCnt(obj,BetaAxis1,BetaAxis2,varargin) % calculate angle between encoding axes(classifier Hyperplanes) with Spikecount classifiers
            %BetaAxis1 & 2  is the hyperplane weights for axes organized as
            % cell array with size Nrep and matrixes with size
            % (NTim*NNeurons)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            opts.TakeMeanHyperplane=1; % are we average across repetition to get the hyperplane?
            
            Nreps=size(BetaAxis1,2);
            switch obj.ClassifierAngleCalMethod
                case 'Angle'
                    if opts.TakeMeanHyperplane
                        warning('Taking Mean Hyperplane to calculate angles')
                        
                        BetaAxisAvg1=mean(BetaAxis1,2);
                        BetaAxisAvg2=mean(BetaAxis2,2);
                        [EncodeAng_deg]=obj.ManData.GetAngleBetVectors(BetaAxisAvg1,BetaAxisAvg2);
                    else
                        [EncodeAng_deg]=arrayfun(@(rep) obj.ManData.GetAngleBetVectors(BetaAxis1(:,rep),...
                            BetaAxis2(:,rep)),1:Nreps,'UniformOutput',0);
                    end
                case 'Corr'
                    if opts.TakeMeanHyperplane
                        warning('Taking Mean correlation to calculate angles')
                        BetaAxisAvg1=mean(BetaAxis1,2);
                        BetaAxisAvg2=mean(BetaAxis2,2);
                        [EncodeAng_deg]=corr(BetaAxisAvg1,BetaAxisAvg2);
                    else
                        [EncodeAng_deg]=arrayfun(@(rep) corr(BetaAxis1(:,rep),...
                            BetaAxis2(:,rep)),1:Nreps,'UniformOutput',0);
                    end
            end
        end
        function ThisFactorResp=GetTestFactorLevels(obj,ClassifierResults,TargetFactorDim,TestFactorTxt,FactorDataInd,Cond,TrlRng,rep)
            global AnalysisOpts
            % get the labels for the test samples
            if strcmp(TargetFactorDim,'ColorCat') | strcmp(TargetFactorDim,'ShapeCat');TargetFactorDim=[TargetFactorDim(1:5) 'ML'];end
            FactorInd=contains(AnalysisOpts.FactorInds2Keep,TargetFactorDim);%(1:4));
            ThisFactorResp=ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep).(TestFactorTxt)(cell2mat(FactorDataInd{rep}),FactorInd);
            if contains(TargetFactorDim,'Shape') | contains(TargetFactorDim,'Color')
                ThisFactorResp=obj.ManData.CategorizeMorphlevel(ThisFactorResp);
            end
        end
        function Factor=AdjustObjCategory4Factor(obj,Factor)
            global AnalysisOpts
            
            if ~strcmp(AnalysisOpts.FactorInds2Keep{1},'ColorML') | ~strcmp(AnalysisOpts.FactorInds2Keep{2},'ShapeML')
                error('This function can not be applied on this data, check data structure');end
            
            Factor=[obj.ManData.CategorizeMorphlevel(Factor(:,1)),obj.ManData.CategorizeMorphlevel(Factor(:,2)),...
                Factor(:,3:end)];
            
        end
        function [h,varargout]=PlotSVMProjectionsScores2DPEV_Learning(obj,ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp,Cond,PlotType,Metric,Dims,varargin) % plots PEV of two distibutions of scores
            %@cell structure of output of the classifer projection of validation data
            %@Metric can be 'corr' or 'kldiv' correlation or KL divergence
            % this function tiles the test trials based on the target factor specified all fo the further calculations 
            % on the score values is based on the nature of the tiling
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            varargout=cell(1);
            TargetFactor=obj.ThisTargetFactor;%'QuadrantsInCong';%'Quadrants';%ClassifierOpts.TargetFactors{1};
            % look if test for congruent or incongruent trials is included here?
            if contains(ClassifierOpts.Name,'Congruency')
                LimFactorTrialVal=ClassifierOpts.LimFactorTrialVal{Cond};
                if isnan(LimFactorTrialVal);LimFactorTrialVal=[2 2];end
                if (strcmp(TargetFactor,'QuadrantsInCong') & LimFactorTrialVal(2)==1) | (strcmp(TargetFactor,'QuadrantsCong') & LimFactorTrialVal(2)==0)
                    return
                end
            end
            nTrialRange=length(ClassifierResults_1ndD(Cond).TrialRange);
            TrialRangeSet=ClassifierOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            [LvlsTestFactor1,TargetFactorDim1,~,TrainCond1,TestCond1,Dim1Txt,TestFactorTxt1,TrainFactorTxt1,LevelFieldName1]=...
                obj.getClassifierDimInfo(ClassifierOpts,Dims(1));
            [LvlsTestFactor2,TargetFactorDim2,~,TrainCond2,TestCond2,Dim2Txt,TestFactorTxt2,TrainFactorTxt2,LevelFieldName2]=...
                obj.getClassifierDimInfo(ClassifierOpts,Dims(2));

            % determine title
            if isempty(obj.ThisTitle)
                Title=[ {[TargetFactorDim1 ' Trn:' obj.ManData.ConvMat2Char(TrainCond1{Cond}),...
                    '|Tst:' obj.ManData.ConvMat2Char(TestCond1{Cond})]};...
                    {[TargetFactorDim2 ' Trn:' obj.ManData.ConvMat2Char(TrainCond2{Cond}),...
                    '|Tst:' obj.ManData.ConvMat2Char(TestCond2{Cond})]}];
            else
                Title=obj.ThisTitle;
            end
            %get scores 
            for TrlRng=1:nTrialRange
                for rep=1:ClassifierOpts.Nrep
                    % grab trials and tile them based on different values
                    % of factor we care about % this is tiling test factors
                    % based on the TargetFactor
                    [FactorDataInd1{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults_1ndD(Cond).TrialRange(TrlRng).Rep(rep).(TestFactorTxt1),TargetFactor,ClassifierOpts.(LevelFieldName1){1});
                    [FactorDataInd2{rep}  ~          ]=obj.TileTrialsbasedonFactor(ClassifierResults_2ndD(Cond).TrialRange(TrlRng).Rep(rep).(TestFactorTxt2),TargetFactor,ClassifierOpts.(LevelFieldName2){1});
                    
                    % grab score values now based on number of the trial in a specific repetition
                    Scores_1ndD(TrlRng).TrialRange(rep,:)=cellfun(@(x) ClassifierResults_1ndD(Cond).TrialRange(TrlRng).Scores{rep}(x,:,:),FactorDataInd1{rep},'UniformOutput',0);
                    Scores_2ndD(TrlRng).TrialRange(rep,:)=cellfun(@(x) ClassifierResults_2ndD(Cond).TrialRange(TrlRng).Scores{rep}(x,:,:),FactorDataInd2{rep},'UniformOutput',0);
                    
                    % get all of the factor values for these trials
                    AllFactorVals_1ndD(TrlRng).TrialRange(rep,:)=cellfun(@(x) ClassifierResults_1ndD(Cond).TrialRange(TrlRng).Rep(rep).(TestFactorTxt1)(x,:),FactorDataInd1{rep},'UniformOutput',0);
                    AllFactorVals_2ndD(TrlRng).TrialRange(rep,:)=cellfun(@(x) ClassifierResults_2ndD(Cond).TrialRange(TrlRng).Rep(rep).(TestFactorTxt2)(x,:),FactorDataInd2{rep},'UniformOutput',0);
                    
                    % get the response category of the morph level based on the desired factor only for the first dimension
                    ThisFactorResp=obj.GetTestFactorLevels(ClassifierResults_1ndD,TargetFactorDim1,TestFactorTxt1,FactorDataInd1,Cond,TrlRng,rep);
                    ThisFactorResp2=obj.GetTestFactorLevels(ClassifierResults_2ndD,TargetFactorDim2,TestFactorTxt2,FactorDataInd2,Cond,TrlRng,rep);                 
                end
                % reorganize factor values
                AllFactorVals_1ndD(TrlRng).TrialRange=arrayfun(@(x) cell2mat(AllFactorVals_1ndD(TrlRng).TrialRange(:,x)),1:length(FactorLevels),'UniformOutput',0);
                AllFactorVals_2ndD(TrlRng).TrialRange=arrayfun(@(x) cell2mat(AllFactorVals_2ndD(TrlRng).TrialRange(:,x)),1:length(FactorLevels),'UniformOutput',0);
                
                AllFactorVals_1ndD_RS(TrlRng).TrialRange=cell2mat(AllFactorVals_1ndD(TrlRng).TrialRange');
                AllFactorVals_2ndD_RS(TrlRng).TrialRange=cell2mat(AllFactorVals_2ndD(TrlRng).TrialRange');

                % take average of the factors in case we need them in the future
                AllFactorVals_1ndD_avg(TrlRng).TrialRange=mean(obj.ManData.ReshapeCell2Mat(AllFactorVals_1ndD(TrlRng).TrialRange,3),3);
                AllFactorVals_2ndD_avg(TrlRng).TrialRange=mean(obj.ManData.ReshapeCell2Mat(AllFactorVals_2ndD(TrlRng).TrialRange,3),3);

                %% check if factors across dimensions match with each other
                if size(AllFactorVals_1ndD_RS(TrlRng).TrialRange,1)==size(AllFactorVals_2ndD_RS(TrlRng).TrialRange,1)
                    TestFactors=obj.AdjustObjCategory4Factor(AllFactorVals_1ndD_RS(TrlRng).TrialRange)==obj.AdjustObjCategory4Factor(AllFactorVals_2ndD_RS(TrlRng).TrialRange);
                    if sum(TestFactors(:)==0) & ClassifierOpts.EqualizeTrialsXConds
                        error('Trial types are not corresponding in this analysis');
                    elseif sum(TestFactors(:)==0) & ~ClassifierOpts.EqualizeTrialsXConds
                        warning('Trial types are not corresponding in this analysis');
                    end
                end
                %% warning this magnitude flip is only correct to use when factor of 1ndD matches Target factor
                % get the magnitude for first dimension as well
                % to perfrom this either we shoud have Target factor as
                % qudrant and the first dimension factor as shape or clor 
                % Or the factor of the first dimension should match the TargetFactor
                if contains(TargetFactor(1:5),TargetFactorDim1(1:5)) | (contains(TargetFactor,'Quadrants') & (contains(TargetFactorDim1,'Shape') | contains(TargetFactorDim1,'Color')))
                    MagnitudeFlip=ThisFactorResp';MagnitudeFlip=sort(unique(MagnitudeFlip),2,'ascend');
                    ScoresMag_1ndD(TrlRng).TrialRange=arrayfun(@(x) cell2mat(Scores_1ndD(TrlRng).TrialRange(:,x)),MagnitudeFlip,'UniformOutput',0);
                    ScoresMag_1ndD(TrlRng).TrialRange=arrayfun(@(x) squeeze(ScoresMag_1ndD(TrlRng).TrialRange{x}(:,x,:)),MagnitudeFlip,'UniformOutput',0);
                    ScoresMag_1ndD_RS(TrlRng).TrialRange=cell2mat(ScoresMag_1ndD(TrlRng).TrialRange');
                end
                
                % get the scores for both dimensions
                Scores_1ndD_Org(TrlRng).TrialRange=arrayfun(@(x) cell2mat(Scores_1ndD(TrlRng).TrialRange(:,x)),1:length(FactorLevels),'UniformOutput',0);
                Scores_1ndD(TrlRng).TrialRange=cellfun(@(x) squeeze(x(:,1,:)),Scores_1ndD_Org(TrlRng).TrialRange,'UniformOutput',0);
                Scores_1ndD_Flip(TrlRng).TrialRange=cellfun(@(x) squeeze(x(:,2,:)),Scores_1ndD_Org(TrlRng).TrialRange,'UniformOutput',0);

               
                Scores_2ndD_Org(TrlRng).TrialRange=arrayfun(@(x) cell2mat(Scores_2ndD(TrlRng).TrialRange(:,x)),1:length(FactorLevels),'UniformOutput',0);
                Scores_2ndD(TrlRng).TrialRange=cellfun(@(x) squeeze(x(:,1,:)),Scores_2ndD_Org(TrlRng).TrialRange,'UniformOutput',0);
                Scores_2ndD_Flip(TrlRng).TrialRange=cellfun(@(x) squeeze(x(:,2,:)),Scores_2ndD_Org(TrlRng).TrialRange,'UniformOutput',0);

                % concatinate the scores
                Scores_1ndD_RS(TrlRng).TrialRange=cell2mat(Scores_1ndD(TrlRng).TrialRange');
                Scores_2ndD_RS(TrlRng).TrialRange=cell2mat(Scores_2ndD(TrlRng).TrialRange');
                
                % take the mean of the scores for the second dimension as  we might need it for compression 
                Scores_2ndD_avg(TrlRng).TrialRange=mean(obj.ManData.ReshapeCell2Mat(Scores_2ndD(TrlRng).TrialRange,3),3);
                Scores_2ndD_avg_avg(TrlRng).TrialRange=mean(mean(obj.ManData.ReshapeCell2Mat(Scores_2ndD(TrlRng).TrialRange,3),3),1);
                
                Scores_2ndD_avg_Flip(TrlRng).TrialRange=mean(obj.ManData.ReshapeCell2Mat(Scores_2ndD_Flip(TrlRng).TrialRange,3),3);
                Scores_2ndD_avg_avg_Flip(TrlRng).TrialRange=mean(mean(obj.ManData.ReshapeCell2Mat(Scores_2ndD_Flip(TrlRng).TrialRange,3),3),1);
               
                % get the magnitude based on each dimension category 
                TargetFactorDim1Ch=TargetFactorDim1;TargetFactorDim2Ch=TargetFactorDim2;
                if strcmp(TargetFactorDim1,'ColorCat') & length(AnalysisOpts.FactorInds2Keep)==9;TargetFactorDim1Ch='ColorML';elseif strcmp(TargetFactorDim1,'ShapeCat') & length(AnalysisOpts.FactorInds2Keep)==9;TargetFactorDim1Ch='ShapeML';end
                if strcmp(TargetFactorDim2,'ColorCat') & length(AnalysisOpts.FactorInds2Keep)==9;TargetFactorDim2Ch='ColorML';elseif strcmp(TargetFactorDim2,'ShapeCat') & length(AnalysisOpts.FactorInds2Keep)==9;TargetFactorDim2Ch='ShapeML';end
                AdjFactors_1nD=obj.AdjustObjCategory4Factor(AllFactorVals_1ndD_RS(TrlRng).TrialRange);
                AdjFactors_2nD=obj.AdjustObjCategory4Factor(AllFactorVals_2ndD_RS(TrlRng).TrialRange);
                
                TargFactorIndDim_1nD=contains(AnalysisOpts.FactorInds2Keep,TargetFactorDim1Ch);
                TargFactorIndDim_2nD=contains(AnalysisOpts.FactorInds2Keep,TargetFactorDim2Ch);
                Levels_1nD=sort(unique(AdjFactors_1nD(:,TargFactorIndDim_1nD)));
                Levels_2nD=sort(unique(AdjFactors_2nD(:,TargFactorIndDim_2nD)));
                
                Scores_1ndD_RS_MagCat(TrlRng).TrialRange=nan*ones(size(Scores_1ndD_RS(TrlRng).TrialRange));
                Scores_2ndD_RS_MagCat(TrlRng).TrialRange=nan*ones(size(Scores_2ndD_RS(TrlRng).TrialRange));
                Scores_1ndD_Org_RS(TrlRng).TrialRange=obj.ManData.ReshapeCell2Mat(Scores_1ndD_Org(TrlRng).TrialRange,62);
                Scores_2ndD_Org_RS(TrlRng).TrialRange=obj.ManData.ReshapeCell2Mat(Scores_2ndD_Org(TrlRng).TrialRange,62);
                
                LevelsTrls_1nD=arrayfun(@(x) AdjFactors_1nD(:,TargFactorIndDim_1nD)==x,Levels_1nD,'uniformoutput',0);
                LevelsTrls_2nD=arrayfun(@(x) AdjFactors_2nD(:,TargFactorIndDim_2nD)==x,Levels_2nD,'uniformoutput',0);
               
                Scores_1ndD_RS_MagCat(TrlRng).TrialRange(LevelsTrls_1nD{1},:)=squeeze(Scores_1ndD_Org_RS(TrlRng).TrialRange(LevelsTrls_1nD{1},1,:));
                Scores_2ndD_RS_MagCat(TrlRng).TrialRange(LevelsTrls_2nD{1},:)=squeeze(Scores_2ndD_Org_RS(TrlRng).TrialRange(LevelsTrls_2nD{1},1,:));
                
                if length(Levels_1nD)>1
                    Scores_1ndD_RS_MagCat(TrlRng).TrialRange(LevelsTrls_1nD{2},:)=squeeze(Scores_1ndD_Org_RS(TrlRng).TrialRange(LevelsTrls_1nD{2},2,:));
                end
                if length(Levels_2nD)>1
                    Scores_2ndD_RS_MagCat(TrlRng).TrialRange(LevelsTrls_2nD{2},:)=squeeze(Scores_2ndD_Org_RS(TrlRng).TrialRange(LevelsTrls_2nD{2},2,:));
                end
            end           
            NTim=size(Scores_2ndD_RS(1).TrialRange,2);
            %% calculate metrics
            switch Metric
                case 'corr'
                    ScoresMetric=arrayfun(@(TrlRng) arrayfun(@(x) corr(Scores_1ndD_RS(TrlRng).TrialRange(:,x),Scores_2ndD_RS(TrlRng).TrialRange(:,x)),1:NTim),1:nTrialRange,'UniformOutput',0);
                    % ScoresMetric=arrayfun(@(y) arrayfun(@(x) corr(Scores_1ndD{y}(:,x),Scores_2ndD{y}(:,x)),1:NTim),1:nLevels,'UniformOutput',0);
                case 'kldiv'
                    X=[-0.7:0.2:0.7];
                    for TrlRng=1:nTrialRange
                        P=arrayfun(@(x) (histc(Scores_1ndD_RS(TrlRng).TrialRange(:,x),X)+eps),1:NTim,'UniformOutput',0);
                        Q=arrayfun(@(x) (histc(Scores_2ndD_RS(TrlRng).TrialRange(:,x),X)+eps),1:NTim,'UniformOutput',0);
                        ScoresMetric{TrlRng}=arrayfun(@(x) kldiv(X,Q{x}'/sum(Q{x}),P{x}'/sum(P{x})),1:NTim);
                    end
                case 'PreStimScoreCorr' % correlate perstimulus score with post stim score values
                    if contains(TargetFactorDim1,'Rule') | contains(TargetFactorDim1,'Response')
                        warning('first dimension has to be shape or color');h=[];return
                    end
                    TimRange=sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % look at different time points 0 -0.1;-0.1 -0.2;-0.2 -0.3;-0.3 -0.4;-0.4 -0.6;
                    TimRangeStimEncoding=sort( ClassifierOpts.SpkCountPeriod(1,:),2,'descend'); % look at time points for response
                    nTimRange=size(TimRange,1);
                    % correlate magnetude of representation 
                    Scores_1ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(ScoresMag_1ndD_RS,'TrialRange',62);
                   % if contains(TargetFactor,'InCong');Scores_1ndD_AllTrlRng=-1*Scores_1ndD_AllTrlRng;end
                %    Scores_1ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(Scores_1ndD_RS,'TrialRange',62);
                 %% below code is when we correlate with each individual trial
                if ~AnalysisOpts.PopulationAna.UseAvg_BeleifStimScoreCorr
                    for k=1:nTimRange
                        LineLegTxt{k}=sprintf('%0.1f->%0.1f',TimRange(k,1),TimRange(k,2));
                        TimeInd=AnalysisOpts.Time<=TimRange(k,1) & AnalysisOpts.Time>=TimRange(k,2);
                        Scores_2ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(Scores_2ndD_RS,'TrialRange',62);
                        [ScoresMetric{k},p]=obj.ManData.Correlation(mean(Scores_2ndD_AllTrlRng(:,TimeInd),2),...
                            mean(Scores_1ndD_AllTrlRng,1),0,'Modified_MannKendall');
                     %   p=p*AnalysisOpts.NTim; % correct for multiple comparisions
                        pa{k}=p<(0.05);
                    end
                else
                    %% below code is when we correlate with average
                    % Retrieve scores for rule encoding from the averaged 2nd dimension scores
                    MeanScoresMag_1ndD_RS=arrayfun(@(x) mean(ScoresMag_1ndD_RS(x).TrialRange,1)',1:nTrialRange,'uniformoutput',0);
                    AvgStimEncoding=cell2mat(MeanScoresMag_1ndD_RS)';

                    BeliefEncoding = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg_avg_Flip, 'TrialRange', 2);

                    TimeInd=AnalysisOpts.Time<=TimRange(1) & AnalysisOpts.Time>=TimRange(2);
                    TimeIndStim=AnalysisOpts.Time<=TimRangeStimEncoding(1) & AnalysisOpts.Time>=TimRangeStimEncoding(2);

                    MeanBelief= mean(BeliefEncoding(:,TimeInd),2);
                    MeanStimEncoding=AvgStimEncoding;%mean(AvgStimEncoding(:,TimeIndStim),2);
                    [a,p] = obj.ManData.Correlation(MeanBelief,MeanStimEncoding,0,'Modified_MannKendall');
                    X=MeanBelief;Y=MeanStimEncoding;
                    ScoresMetric{1}=a;
                    % Correct p-value for multiple comparisons
                   % p = p * 1;
                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl='Task belief encoding';Ylbl=['Avg Stimulus Encoding ' obj.ThisTargetFactor];
                 %   PlotType='Scatter';
                    LineLegTxt{1}='';
                end
                case 'BeleifRespScoreCorr' % correlate belief with response location encoding
                    if contains(TargetFactorDim1,'Shape') | contains(TargetFactorDim1,'Color')
                        warning('first dimension has to be response location');h=[];return
                    end
                    TimRange=sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % look at different time points 0 -0.1;-0.1 -0.2;-0.2 -0.3;-0.3 -0.4;-0.4 -0.6;
                    nTimRange=size(TimRange,1);
                    TimRangeResp=sort( ClassifierOpts.SpkCountPeriod(1,:),2,'descend'); % look at time points for response
                   
                    %% below code is when we correlate with each individual trial
                    if ~AnalysisOpts.PopulationAna.UseAvg_BeleifRespScoreCorr
                        % correlate magnetude of representation
                        Scores_1ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(ScoresMag_1ndD_RS,'TrialRange',62);
                     %   if contains(TargetFactor,'InCong');Scores_1ndD_AllTrlRng=-1*Scores_1ndD_AllTrlRng;end
                        %    Scores_1ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(Scores_1ndD_RS,'TrialRange',62);
                        for k=1:nTimRange
                            LineLegTxt{k}=sprintf('%0.1f->%0.1f',TimRange(k,1),TimRange(k,2));
                            TimeInd=AnalysisOpts.Time<=TimRange(k,1) & AnalysisOpts.Time>=TimRange(k,2);
                            Scores_2ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(Scores_2ndD_RS,'TrialRange',62);
                            [ScoresMetric{k},p]=obj.ManData.Correlation(mean(Scores_2ndD_AllTrlRng(:,TimeInd),2),...
                                mean(Scores_1ndD_AllTrlRng,1),0,'Modified_MannKendall');
                            p=p*AnalysisOpts.NTim; % correct for multiple comparisions
                            pa{k}=p<(0.05);
                        end
                    else
                        %% below code is when we correlate with average
                        % Retrieve scores for rule encoding from the averaged 2nd dimension scores
                        MeanScoresMag_1ndD_RS=arrayfun(@(x) mean(ScoresMag_1ndD_RS(x).TrialRange,1)',1:nTrialRange,'uniformoutput',0);
                        AvgRespEncoding=cell2mat(MeanScoresMag_1ndD_RS)';

                        BeliefEncoding = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg_avg_Flip, 'TrialRange', 2);

                        TimeInd=AnalysisOpts.Time<=TimRange(1) & AnalysisOpts.Time>=TimRange(2);
                        TimeIndResp=AnalysisOpts.Time<=TimRangeResp(1) & AnalysisOpts.Time>=TimRangeResp(2);

                        MeanBelief= mean(BeliefEncoding(:,TimeInd),2);
                        MeanResponseEncoding=mean(AvgRespEncoding(:,TimeIndResp),2);
                        [a,p] = obj.ManData.Correlation(MeanBelief,MeanResponseEncoding,0,'Modified_MannKendall');
                        X=MeanBelief;Y=MeanResponseEncoding;

                        % Correct p-value for multiple comparisons
                        p = p * 1;
                        % Perform significance test based on adjusted p-value threshold
                        pa = p < (0.05);
                        Xlbl='Task belief encoding';Ylbl='Response Location Encoding';
                        PlotType='Scatter';
                    end

                case 'RulePreStimCompres' % correlate rule prestim with amount of compression
                    if contains(TargetFactorDim1,'Rule');warning('first dimension has to be shape or color');h=[];return
                    end
                    TimRange=sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend');%[0 -0.1;-0.1 -0.2;-0.2 -0.3;-0.3 -0.4;-0.4 -0.6;0 -0.6]; % look at different time points
                    nTimRange=size(TimRange,1);
                    % take the compression index from test conditions of
                    % the second dimesion here(the dimension that has rule)
                    
                    %  CompIndex=obj.ManData.ReshapeCell2Mat(arrayfun(@(x) -log(ClassifierResults_2ndD.TrialRange(x).(['Subspace' Dim2Txt 'Compression2'])),...
                    %    1:nTrialRange,'UniformOutput',0),62)  ; % old     compression index calculation
                    CompIndex=obj.ManData.ReshapeCell2Mat(obj.ExtraData.Trl.Full,64)'; % use encoding axis compression index

                    % Retrieve scores for rule encoding from the averaged 2nd dimension scores
                    if TrainCond2{1}(1)==1;BeliefScoreSign=-1;elseif TrainCond2{1}(1)==3;BeliefScoreSign=1;end
                    Scores_2ndD_AllTrlRng = BeliefScoreSign*obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg, 'TrialRange', 62);
                    
                    for k=1:nTimRange
                        LineLegTxt{k}=sprintf('%0.1f->%0.1f',TimRange(k,1),TimRange(k,2));
                        TimeInd=AnalysisOpts.Time<=TimRange(k,1) & AnalysisOpts.Time>=TimRange(k,2);
                        [ScoresMetric{k},p]=obj.ManData.Correlation(mean(Scores_2ndD_AllTrlRng(:,TimeInd),2),CompIndex,0,'Modified_MannKendall'); % don't remove outliers
                      %  p=p*AnalysisOpts.NTim; % correct for multiple comparisions
                        pa{k}=p<(0.05);
                    end
                case 'CorrBeliefBhvPerfScatter' % correlate rule belief with behavioral performance
                    if contains(TargetFactorDim1,'Rule');warning('first dimension has to be shape or color');h=[];return
                    end
                    TimRange= sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % Define time points of interest
                    TimeInd = AnalysisOpts.Time >= ClassifierOpts.SpkCountPeriod(1, 1) & ...
                        AnalysisOpts.Time <= ClassifierOpts.SpkCountPeriod(1, 2);

                    % Retrieve scores for rule encoding from the averaged 2nd dimension scores
                    % reverse the direction to acount for labels
               %     if TrainCond2{1}(1)==1;BeliefScoreSign=-1;elseif TrainCond2{1}(1)==3;BeliefScoreSign=1;end
                    Scores_2ndD_AllTrlRng = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg, 'TrialRange', 62);
                    % get the behavioral performance for each trial 
                    Bhv_AllTrlRng=obj.ManData.ReshapeStruct2Mat(AllFactorVals_1ndD_avg,'TrialRange',62);

                    % find the factors we want to correlate the data with
                    if contains(obj.ThisTitle,'color','IgnoreCase',true)
                        BhvFactor='Color';
                    elseif contains(obj.ThisTitle,'shape','IgnoreCase',true)
                        BhvFactor='Shape';
                    end

                    % adjust the level of avegraing 
                    if contains(obj.ThisTitle,'10','IgnoreCase',true)
                        NtrlsAvgBhv='10';
                    elseif contains(obj.ThisTitle,'50','IgnoreCase',true)
                        NtrlsAvgBhv='50';
                    else
                        NtrlsAvgBhv='10';
                    end

                    BhvFactorInd=cellfun(@(x) find(strcmp(AnalysisOpts.FactorInds2Keep,x)),{['BhvPerf' BhvFactor NtrlsAvgBhv]});
                    
                    BhvPerfTrl=Bhv_AllTrlRng(:,BhvFactorInd);
                    % Calculate the mean of the belief index within a specific time period
                    MeanBelief = mean(Scores_2ndD_AllTrlRng(:, TimeInd), 2);

                    % Generate line legend text based on time range
                    LineLegTxt = sprintf('%0.1f->%0.1f', TimRange(1), TimRange(2));

                    % Calculate the correlation between mean scores and compression index
                    [X,Y]=obj.ManData.removeoutliers(MeanBelief,BhvPerfTrl,[]);% remove outliers from data
                    [a,p] = obj.ManData.Correlation(MeanBelief,BhvPerfTrl,0,'Modified_MannKendall');

                    % Correct p-value for multiple comparisons
                    p = p * 1;

                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl='Task belief encoding';Ylbl='Behavioral Performance';
                    PlotType='Scatter';
                case 'CorrBeliefBhvPerfScatterAvg' % correlate rule belief with behavioral performance using average for trial blocks
                    if contains(TargetFactorDim1,'Rule');warning('first dimension has to be shape or color');h=[];return
                    end
                     % find the factors we want to correlate the data with
                    if contains(obj.ThisTitle,'color','IgnoreCase',true)
                        BhvFactor='Color';
                    elseif contains(obj.ThisTitle,'shape','IgnoreCase',true)
                        BhvFactor='Shape';
                    end
                  
                    % adjust the level of avegraing 
                    if contains(obj.ThisTitle,'10','IgnoreCase',true)
                        NtrlsAvgBhv='10';
                    elseif contains(obj.ThisTitle,'50','IgnoreCase',true)
                        NtrlsAvgBhv='50';
                    else
                        NtrlsAvgBhv='10';
                    end

                    TimRange= sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % Define time points of interest
                    TimeInd = AnalysisOpts.Time >= ClassifierOpts.SpkCountPeriod(1, 1) & ...
                        AnalysisOpts.Time <= ClassifierOpts.SpkCountPeriod(1, 2);

                    % get average belief encoding
                    BeliefEncoding = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg_avg_Flip, 'TrialRange', 2);                    
                    MeanBelief= mean(BeliefEncoding(:,TimeInd),2);
 
                     % get the behavioral performance for each trial                   
                    Bhv_AllTrlRng=arrayfun(@(x) mean(AllFactorVals_1ndD_avg(x).TrialRange,1)',1:nTrialRange,'uniformoutput',0);
                    Bhv_AllTrlRng=cell2mat(Bhv_AllTrlRng)';

                    BhvFactorInd=cellfun(@(x) find(strcmp(AnalysisOpts.FactorInds2Keep,x)),{['BhvPerf' BhvFactor NtrlsAvgBhv]});                    
                    BhvPerfTrl=Bhv_AllTrlRng(:,BhvFactorInd);
                   
                    % Generate line legend text based on time range
                    LineLegTxt = sprintf('%0.1f->%0.1f', TimRange(1), TimRange(2));

                    % Calculate the correlation between mean scores and compression index
                    [a,p] = obj.ManData.Correlation(MeanBelief,BhvPerfTrl,0,'Modified_MannKendall');
                    X=MeanBelief;Y=BhvPerfTrl;

                    % Correct p-value for multiple comparisons
                    p = p * 1;

                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl='Task belief encoding';Ylbl='Avg Behavioral Performance';
                    PlotType='Scatter';    
                case 'RulePreStimCompresScatter' % correlate rule prestim with amount of compression shows scatter plot
                    % Check if the target factor in the first dimension is 'Rule'
                    if contains(TargetFactorDim1, 'Rule')
                        % Display a warning and exit the function if the first dimension is not 'shape' or 'color'
                        warning('first dimension has to be shape or color');
                        h = []; % Clear the handle (not shown in the provided code)
                        return; % Exit the function
                    end
                    
                    % Define the time range for a   nalysis
                    TimRange = sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % Define time points of interest
                    nTimRange = size(TimRange, 1);
                    
                    % Calculate the compression index for the second dimension (rule) for each trial
                    CompIndex=log(obj.ManData.ReshapeCell2Mat(obj.ExtraData.Trl.Full,64)');
                    % Calculate the mean of the compression index within a specific time period
                    TimeIndComp = AnalysisOpts.Time >= ClassifierOpts.SpkCountPeriod(1, 1) & ...
                        AnalysisOpts.Time <= ClassifierOpts.SpkCountPeriod(1, 2);
                    CompIndex = mean(CompIndex(:, TimeIndComp), 2);
                    
                    % Retrieve scores for rule encoding from the averaged 2nd dimension scores
                 %   if TrainCond2{1}(1)==1;BeliefScoreSign=-1;elseif TrainCond2{1}(1)==3;BeliefScoreSign=1;end
                    Scores_2ndD_AllTrlRng = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg, 'TrialRange', 62);
                  
                    % Generate line legend text based on time range
                    LineLegTxt = sprintf('%0.1f->%0.1f', TimRange(1), TimRange(2));
                    
                    % Define time indices based on the specified time range
                    TimeInd = AnalysisOpts.Time <= TimRange(1) & AnalysisOpts.Time >= TimRange(2);
                    
                    % Calculate the correlation between mean scores and compression index
                    X=mean(Scores_2ndD_AllTrlRng(:, TimeInd), 2);
                    Y=CompIndex;
                    [X,Y]=obj.ManData.removeoutliers(X,Y,[]);% remove outliers from data
                    [a,p] = obj.ManData.Correlation(X,Y,0,'Modified_MannKendall');
                    
                    % Correct p-value for multiple comparisons
                    p = p * 1;
                    
                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl='Task belief encoding';Ylbl='Compression Index';
                    PlotType='Scatter';
                    if obj.CalOnlyStat;varargout{1}=p;end
                case 'RulePreStimCompresScatterAvg' % correlate rule prestim with amount of compression shows scatter plot avegrage
                    % Check if the target factor in the first dimension is 'Rule'
                    if contains(TargetFactorDim1, 'Rule')
                        % Display a warning and exit the function if the first dimension is not 'shape' or 'color'
                        warning('first dimension has to be shape or color');
                        h = []; % Clear the handle (not shown in the provided code)
                        return; % Exit the function
                    end
                    
                    % Define the time range for a   nalysis
                    TimRange = sort( ClassifierOpts.SpkCountPeriod(3,:),2,'descend'); % Define time points of interest
                    nTimRange = size(TimRange, 1);
                    
                    % Calculate the compression index for the second dimension (rule) for each trial
                    CompIndex=obj.ExtraData.TrlAvg.All;
                    CompIndex=log(CompIndex);
                    CompIndex=obj.ManData.SmoothData(CompIndex,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);

                    % Calculate the mean of the compression index within a specific time period
                    TimeIndComp = AnalysisOpts.Time >= ClassifierOpts.SpkCountPeriod(1, 1) & ...
                        AnalysisOpts.Time <= ClassifierOpts.SpkCountPeriod(1, 2);
                    CompIndex = mean(CompIndex(:, TimeIndComp), 2);
                    
                    % Retrieve scores for rule encoding from the averaged 2nd dimension scores
               %     if TrainCond2{1}(1)==1;BeliefScoreSign=-1;elseif TrainCond2{1}(1)==3;BeliefScoreSign=1;end
                    Scores_2ndD_AllTrlRng = obj.ManData.ReshapeStruct2Mat(Scores_2ndD_avg_avg_Flip, 'TrialRange', 2);
                  
                    % Generate line legend text based on time range
                    LineLegTxt = sprintf('%0.1f->%0.1f', TimRange(1), TimRange(2));
                    
                    % Define time indices based on the specified time range
                    TimeInd = AnalysisOpts.Time <= TimRange(1) & AnalysisOpts.Time >= TimRange(2);
                    
                    % Calculate the correlation between mean scores and compression index
                    X=mean(Scores_2ndD_AllTrlRng(:, TimeInd), 2);
                    Y=CompIndex;
                %    [X,Y]=obj.ManData.removeoutliers(X,Y,[]);% remove outliers from data
                    [a,p] = obj.ManData.Correlation(X,Y,0,'Modified_MannKendall');
                    
                    % Correct p-value for multiple comparisons
                    p = p * 1;
                    
                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl='Task belief encoding';Ylbl='Compression Index';
                    PlotType='Scatter';   
                    if obj.CalOnlyStat;varargout{1}=p;end
                case 'StimEncodingCompresScatterAvg' % correlate stimulus encoding with amount of compression shows scatter plot avegrage
                    % Check if the target factor in the first dimension is 'Rule'
                    if contains(TargetFactorDim1, 'Rule')
                        % Display a warning and exit the function if the first dimension is not 'shape' or 'color'
                        warning('first dimension has to be shape or color');
                        h = []; % Clear the handle (not shown in the provided code)
                        return; % Exit the function
                    end
                                        
                    % Calculate the compression index for the second dimension (rule) for each trial
                    CompIndex=obj.ExtraData.TrlAvg.All;
                    CompIndex=log(CompIndex);
                    CompIndex=obj.ManData.SmoothData(CompIndex,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);

                    % Calculate the mean of the compression index within a specific time period
                    TimRange=ClassifierOpts.SpkCountPeriod(1,:);
                    TimeIndComp = AnalysisOpts.Time >= ClassifierOpts.SpkCountPeriod(1, 1) & ...
                        AnalysisOpts.Time <= ClassifierOpts.SpkCountPeriod(1, 2);
                    CompIndex = mean(CompIndex(:, TimeIndComp), 2);
                   
                    % calculate the mean of stimulus encoding
                    MeanScoresMag_1ndD_RS=arrayfun(@(x) mean(ScoresMag_1ndD_RS(x).TrialRange,1)',1:nTrialRange,'uniformoutput',0);
                    AvgStimEncoding=cell2mat(MeanScoresMag_1ndD_RS)';
                 
                    % Define time indices based on the specified time range
                    AvgStimEncoding=mean(AvgStimEncoding(:,TimeIndComp),2);

                    % Generate line legend text based on time range
                    LineLegTxt = sprintf('%0.1f->%0.1f', TimRange(1), TimRange(2));
                    
                    % Calculate the correlation between mean scores and compression index
                    X=AvgStimEncoding;
                    Y=CompIndex;
                    [a,p] = obj.ManData.Correlation(X,Y,0,'Modified_MannKendall');
                    
                    % Correct p-value for multiple comparisons
                    p = p * 1;
                    
                    % Perform significance test based on adjusted p-value threshold
                    pa = p < (0.05);
                    Xlbl=['Stimulus' TargetFactorDim1 'encoding'];Ylbl='Compression Index';
                    PlotType='Scatter';      
                case 'CorrBhvMdl' % correlate to behavioral model
                    if contains(TargetFactorDim1,'Rule') | contains(TargetFactorDim1,'Response')
                        warning('first dimension has to be shape or color');h=[];return;end
                    Scores_1ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(ScoresMag_1ndD_RS,'TrialRange',62);
                    Scores_2ndD_AllTrlRng=obj.ManData.ReshapeStruct2Mat(Scores_2ndD_RS,'TrialRange',62);
                    BhvModel_AllTrlRng=obj.ManData.ReshapeStruct2Mat(AllFactorVals_1ndD_RS,'TrialRange',62);
                    ThisFactorNames=AnalysisOpts.factornames([1:2 10:35]);
                    BhvMdlFactorInd=find(strcmp(ThisFactorNames,obj.BhvMdlFactor));
                    
                    [ScoresMetric{1},p{1}]=corr(BhvModel_AllTrlRng(:,BhvMdlFactorInd),Scores_1ndD_AllTrlRng);
                    [ScoresMetric{2},p{2}]=corr(BhvModel_AllTrlRng(:,BhvMdlFactorInd),Scores_2ndD_AllTrlRng);
                    p{1}=p{1}*AnalysisOpts.NTim; % correct for multiple comparisions
                    pa{1}=p{1}<(0.05);
                    p{2}=p{2}*AnalysisOpts.NTim; % correct for multiple comparisions
                    pa{2}=p{2}<(0.05); 
                    PlotType='Line';
                case 'CompressionIndex'
                    % use LookatDim2 to show which condition of compression
                    % you want to look at/Train1 or Test2 and always we are looking at the data from Dimension 2
                    % get compression index during learning   
                    PlotType='MeanStd';
                    if obj.LookatDim2==1
                        RuleTxt=num2str(TrainCond2{1});
                        if ClassifierOpts.TrainTrlNumRange{Cond}(4)==0
                            nTrialRange=1; % only one of them is needed the rest are repetitions of the same thing                                                        
                        end
                    else
                        RuleTxt=num2str(TestCond2{1});
                    end
                    if ~isfield(ClassifierResults_2ndD(Cond).TrialRange(1),['Subspace' Dim2Txt 'Compression' num2str(obj.LookatDim2)])
                        warning('We do not have subspace data for compression index');
                        h=[];return;
                    end
                    ScoresMetric=arrayfun(@(x) mean(-log(ClassifierResults_2ndD(Cond).TrialRange(x).(['Subspace' Dim2Txt 'Compression' num2str(obj.LookatDim2)]))),...
                        1:nTrialRange,'UniformOutput',0); 
                    obj.ThisTitle=sprintf('Compression Index Rule:%s',RuleTxt);  
                case 'QuadrantCompressionImage' % shows evolution of objects in color and shape axis during learning 
                    if strcmp(TargetFactorDim1,'ColorCat') & strcmp(TargetFactorDim2,'ShapeCat')
                        % then the first dimension is color and second dimension is shape
                        ScoresColor=Scores_1ndD;ScoresShape=Scores_2ndD;
                    elseif strcmp(TargetFactorDim2,'ColorCat') & strcmp(TargetFactorDim1,'ShapeCat')    
                        % then the first dimension is shape and second dimension is color
                        ScoresColor=Scores_2ndD;ScoresShape=Scores_1ndD;
                    else
                        warning('This Analysis is only possible when dim1 is color and dim2 is shape or vice versa')
                        h=[];return
                    end
                    % we assume that Train1:2 Test1:3 and Train2:1 and Test2:3
                    TimeInd=AnalysisOpts.Time<=0.25 & AnalysisOpts.Time>=0.15;
                    ColorAxis=arrayfun(@(TrlRng) arrayfun(@(obj) mean(mean(ScoresColor(TrlRng).TrialRange{obj}(:,TimeInd),2),1),...
                        1:4),1:nTrialRange,'UniformOutput',0);
                    ShapeAxis=arrayfun(@(TrlRng) arrayfun(@(obj) mean(mean(ScoresShape(TrlRng).TrialRange{obj}(:,TimeInd),2),1),...
                        1:4),1:nTrialRange,'UniformOutput',0);
                case 'CompressionEncodingAxis' % calculate compression based on the encoding axis
                    % 4 objects correspond to [Shape Color] category [1 1],[2 2],
                    % [1 2],[2 1] %[red bunny, green tee, green bunny, red tee]
                    % calculate compression index across time for each learning stage
                    if strcmp(TargetFactorDim1,'ColorCat') & strcmp(TargetFactorDim2,'ShapeCat')
                        % then the first dimension is color and second dimension is shape
                        ScoresColor=Scores_1ndD;ScoresShape=Scores_2ndD;
                    elseif strcmp(TargetFactorDim2,'ColorCat') & strcmp(TargetFactorDim1,'ShapeCat')    
                        % then the first dimension is shape and second dimension is color
                        ScoresColor=Scores_2ndD;ScoresShape=Scores_1ndD;
                    else
                        warning('This Analysis is only possible when dim1 is color and dim2 is shape or vice versa')
                        h=[];return
                    end
                    SubtractMeanEncoding=0; % are we subtracting mean encoding
                    if SubtractMeanEncoding                       
                        ColorAxisTime=arrayfun(@(TrlRng) arrayfun(@(obj) ScoresColor(TrlRng).TrialRange{obj}-mean(ScoresColor(TrlRng).TrialRange{obj}(:,AnalysisOpts.Time<0),2),...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                        ShapeAxisTime=arrayfun(@(TrlRng)  arrayfun(@(obj) ScoresShape(TrlRng).TrialRange{obj}-mean(ScoresShape(TrlRng).TrialRange{obj}(:,AnalysisOpts.Time<0),2),...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                    else
                        ColorAxisTime=arrayfun(@(TrlRng) arrayfun(@(obj) ScoresColor(TrlRng).TrialRange{obj},...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                        ShapeAxisTime=arrayfun(@(TrlRng)  arrayfun(@(obj) ScoresShape(TrlRng).TrialRange{obj},...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                    end
                    [CompressionEncoding,EncodingDist]=obj.CalQuadrantCompressionEncodingAxis(ShapeAxisTime,ColorAxisTime);
                     % choose which factor we are looking at
                     if contains(obj.ThisExtraTargetFactor,'EncodingDist')% then we are looking at encoding distances
                         EncodingField=erase(obj.ThisExtraTargetFactor,'EncodingDist_');
                         ScoresMetric=EncodingDist.([EncodingField 'Avg']);
                         ScoresMetric=obj.ManData.SmoothData(ScoresMetric,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);
                     elseif contains(obj.ThisExtraTargetFactor,'EncodingAxis') % then we are looking at encoidng axis for four objects                        
                         PlotType='QuadrantObjsTime';
                     else% then we are looking at compression index
                         if strcmp(obj.ThisExtraTargetFactor,'QuadrantsCong')
                             ScoresMetric=CompressionEncoding.TrlAvg.Cong;
                         elseif strcmp(obj.ThisExtraTargetFactor,'QuadrantsInCong')
                             ScoresMetric=CompressionEncoding.TrlAvg.InCong;
                         else
                             ScoresMetric=CompressionEncoding.TrlAvg.All;
                         end
                         ScoresMetric=log(ScoresMetric); 
                         ScoresMetric=obj.ManData.SmoothData(ScoresMetric,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);
                     end
                     obj.ThisTitle=[obj.ThisTitle obj.ThisExtraTargetFactor]; 
                     varargout={CompressionEncoding};
                case 'CompressionAxisAnalysis'
                    % looks at the compression axis
                    % 4 objects correspond to [Shape Color] category [1 1],[2 2],
                    % [1 2],[2 1] %[red bunny, green tee, green bunny, red tee]
                    % calculate compression index across time for each learning stage
                    if strcmp(TargetFactorDim1,'ColorCat') & strcmp(TargetFactorDim2,'ShapeCat')
                        % then the first dimension is color and second dimension is shape
                        ScoresColor=Scores_1ndD;ScoresShape=Scores_2ndD;
                    elseif strcmp(TargetFactorDim2,'ColorCat') & strcmp(TargetFactorDim1,'ShapeCat')    
                        % then the first dimension is shape and second dimension is color
                        ScoresColor=Scores_2ndD;ScoresShape=Scores_1ndD;
                    else
                        warning('This Analysis is only possible when dim1 is color and dim2 is shape or vice versa')
                        h=[];return
                    end
                    SubtractMeanEncoding=0; % are we subtracting mean encoding
                    if SubtractMeanEncoding                       
                        ColorAxisTime=arrayfun(@(TrlRng) arrayfun(@(obj) ScoresColor(TrlRng).TrialRange{obj}-mean(ScoresColor(TrlRng).TrialRange{obj}(:,AnalysisOpts.Time<0),2),...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                        ShapeAxisTime=arrayfun(@(TrlRng)  arrayfun(@(obj) ScoresShape(TrlRng).TrialRange{obj}-mean(ScoresShape(TrlRng).TrialRange{obj}(:,AnalysisOpts.Time<0),2),...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                    else
                        ColorAxisTime=arrayfun(@(TrlRng) arrayfun(@(obj) ScoresColor(TrlRng).TrialRange{obj},...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                        ShapeAxisTime=arrayfun(@(TrlRng)  arrayfun(@(obj) ScoresShape(TrlRng).TrialRange{obj},...
                            1:4,'UniformOutput',0),1:nTrialRange,'UniformOutput',0);
                    end
                    h=obj.PlotCompressionAxisAnalysis(ColorAxisTime,ShapeAxisTime);
                    return

                case 'TransferEntropy'
                    % calculates the correlation between shared
                    % representations of color and response 
                    % the data should be organized like this 
                    % Scores_1ndD_RS = Response Scores[ {ColorCat1} {ColorCat2}]
                    % Scores_1ndD_RS = ColorCat Scores[ {ColorCat1} {ColorCat2}]
                    if ~strcmp(TargetFactor,'ColorCat') | ~strcmp(TargetFactorDim1,'ResponseLoc') | ~strcmp(TargetFactorDim2,'ColorCat')
                        warning('Transfer entropy analysis cant be applied here. Check above conditions')
                        h=[];return
                    end
                    Cats=1:2;
                    if  AnalysisOpts.SubtractMean4Entropy==1  % subtract based on the category
                        AnalysisOpts.EntropyUseResp4MeanSub=0;
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction                  
                        SubtractMeanVoid=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SGTITLE='Subtract Mean Feature';
                    elseif  AnalysisOpts.SubtractMean4Entropy==2 % subtract based on the correct incorrect and color category
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanVoid=SubtractMean;% handle for mean subtraction
                         SGTITLE='Subtract Mean Reward';
                    elseif AnalysisOpts.SubtractMean4Entropy==0 % don't subtract mean 
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanVoid=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SGTITLE='No Subtract Mean';
                    end
                    SmoothEntData=@(x) obj.ManData.SmoothData(x,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                 
                    IndReward=contains(AnalysisOpts.FactorInds2Keep,'Reward');
                    IndColor=contains(AnalysisOpts.FactorInds2Keep,'ColorML');
                    IndResponse=contains(AnalysisOpts.FactorInds2Keep,'ResponseLoc');
                
                    % get the relevant scores 
                    RespScores=Scores_1ndD_RS_MagCat(TrlRng).TrialRange;
                    ColorScores=Scores_2ndD_RS_MagCat(TrlRng).TrialRange;
                   
                    RespFactors=cellfun(@(x) obj.AdjustObjCategory4Factor(x),AllFactorVals_1ndD.TrialRange,'UniformOutput',0);
                    ColorFactors=cellfun(@(x) obj.AdjustObjCategory4Factor(x),AllFactorVals_2ndD.TrialRange,'UniformOutput',0);
                   
                    RespFactorsConCat =cell2mat(cellfun(@(x) x',RespFactors,'UniformOutput',0))';
                    ColorFactorsConCat=cell2mat(cellfun(@(x) x',ColorFactors,'UniformOutput',0))';
                    IndCol=arrayfun(@(x) RespFactorsConCat(:,IndColor)==x,1:2,'UniformOutput',0);
                    RespScores=cellfun(@(x) RespScores(x,:),IndCol,'UniformOutput',0);
                    ColorScores=cellfun(@(x) ColorScores(x,:),IndCol,'UniformOutput',0);

                    %%
                    if AnalysisOpts.SubtractMean4Entropy==1
                        % take the mean of each classifier for each of its categories
                        RespScoresConcat=cell2mat(cellfun(@(x) x',RespScores,'UniformOutput',0))';
                        ColorScoresConcat=cell2mat(cellfun(@(x) x',ColorScores,'UniformOutput',0))';

                        IndResp=arrayfun(@(x) RespFactorsConCat(:,IndResponse)==x,unique(RespFactorsConCat(:,IndResponse))','UniformOutput',0);
                        RespScores=SubtractMean(arrayfun(@(x) (RespScoresConcat(IndResp{x},:)),1:2,'UniformOutput',0));
                        if AnalysisOpts.EntropyUseResp4MeanSub % use response
                            ColorScores=SubtractMean(arrayfun(@(x) (ColorScoresConcat(IndResp{x},:)),1:2,'UniformOutput',0));
                        else
                            ColorScores=cell2mat(arrayfun(@(x) (ColorScoresConcat(IndResp{x},:))',1:2,'UniformOutput',0))';
                        end
                        RespFactorsConCat=cell2mat(cellfun(@(x) RespFactorsConCat(x,:)',IndResp,'UniformOutput',0))';

                        % return it back to color
                        IndCol=arrayfun(@(x) RespFactorsConCat(:,IndColor)==x,1:2,'UniformOutput',0);
                        RespScores=cellfun(@(x) RespScores(x,:),IndCol,'UniformOutput',0);
                        ColorScores=cellfun(@(x) ColorScores(x,:),IndCol,'UniformOutput',0);

                        if ~AnalysisOpts.EntropyUseResp4MeanSub
                            ColorScores=SubtractMeanNoConcat(arrayfun(@(x) (ColorScores{x}),Cats,'UniformOutput',0));
                        end
                    end
                    % find correct and incorrect trials 
                    indCorrectResp=cellfun(@(x) x(:,IndReward)==1,RespFactors,'UniformOutput',0);
                    indInCorrectResp=cellfun(@(x) x(:,IndReward)==0,RespFactors,'UniformOutput',0);
                    
                    indCorrectColor=cellfun(@(x) x(:,IndReward)==1,ColorFactors,'UniformOutput',0);
                    indInCorrectColor=cellfun(@(x) x(:,IndReward)==0,ColorFactors,'UniformOutput',0);
                   
                    % subtract the mean from scores (flip response because of mismatch labels between color and response) then
                    % concatinate both categories
                    RespScoresCorr=SubtractMeanVoid(arrayfun(@(x) RespScores{x}(indCorrectResp{x},:),Cats,'UniformOutput',0));
                    RespScoresInCorr=SubtractMeanVoid(arrayfun(@(x) RespScores{x}(indInCorrectResp{x},:),Cats,'UniformOutput',0));
                    ColorScoresCorr=SubtractMeanVoid(arrayfun(@(x) ColorScores{x}(indCorrectColor{x},:),Cats,'UniformOutput',0));
                    ColorScoresInCorr=SubtractMeanVoid(arrayfun(@(x) ColorScores{x}(indInCorrectColor{x},:),Cats,'UniformOutput',0));
                 
                    % concatinate all mean subtractedscores               
                    RespScoresAll=[RespScoresCorr;RespScoresInCorr];
                    ColorScoresAll=[ColorScoresCorr;ColorScoresInCorr];
                   
                    % correlate the scores with each other                   
                    [aCorr{1},pCorr{1}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresCorr),SmoothEntData(ColorScoresCorr));
                    [aCorr{2},pCorr{2}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresInCorr),SmoothEntData(ColorScoresCorr));
                    Conds2Look=1:2;
                    if ~isempty(ColorScoresInCorr)
                     %   [aCorr{3},pCorr{3}]=obj.ManData.CorrelateMats(RespScoresInCorr,ColorScoresInCorr);
                        [aCorr{3},pCorr{3}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresAll),SmoothEntData(ColorScoresAll));
                        Conds2Look=1:3;
                    end
                    % flip correlation values 
                    aCorr=cellfun(@(x) x,aCorr,'uniformoutput',0);
                    ConditionTitle={'Corr CorrectRes-CorrectColor Trl','Corr InCorrectResp-InCorrectColor Trl','Corr bet All Trials'};%'Corr IncorrectResp-CorrectColor Trls'
                   % obj.WidthSmoothing=10;obj.WidthSmoothingDim2=10;pvalsig=0.001;
                   sgtitle(SGTITLE);
                    for ec=Conds2Look % loop on eontropy conditions
                        axes(Sp(ec));
                            % plot image of correlation 
                            [~,TimeIndX,TimeIndY]=obj.FigParams.Image(AnalysisOpts.Time,AnalysisOpts.Time,aCorr{ec},...
                                {AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},'Corr',[Title; ConditionTitle{ec}],Sp(ec),'OriginLine',5,'OriginLine_width',1,...
                                'WidthSmoothing',obj.WidthSmoothing,'WidthSmoothingDim2',obj.WidthSmoothing,'SmoothingMethod','','imageplotfunc','pcolor','caxis_limits',obj.caxis_limits);
                         
                            % plot significance image superimposed on it
                            if AnalysisOpts.PlotEntropySig
                                obj.PlotSignificanceImage(pCorr{ec}(TimeIndX,TimeIndY),AnalysisOpts.Time(TimeIndX),AnalysisOpts.Time(TimeIndY),aCorr{ec}(TimeIndX,TimeIndY),AnalysisOpts.pvalEntropyAnalysis);
                            end
                            % plot digaonal of the correlation matrix
                            %      obj.FigParams.PlotMeanStd(AnalysisOpts.Time,diag(aCorr{ec})',[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            %      'k',3,[Title; ConditionTitle{ec}],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','movmean','Sp',Sp(ec));
                    end
                        % generate time axis for this 
                        opts.PopulationAna.PSTHbin=AnalysisOpts.PopulationAna.PSTHbin;
                        opts.SpkParams.PSTH_BinShift=AnalysisOpts.SpkParams.PSTH_BinShift;
                        opts.SpkParams.BaselineDelay=(AnalysisOpts.ThisTimeAxisEnd-AnalysisOpts.ThisTimeAxisStart);
                        opts.SpkParams.PeriodLength=2*opts.SpkParams.BaselineDelay;
                        ProjTime=-(sum(TimeIndY)-1)*opts.SpkParams.PSTH_BinShift:opts.SpkParams.PSTH_BinShift:(sum(TimeIndY)-1)*opts.SpkParams.PSTH_BinShift;%(-opts.SpkParams.BaselineDelay+opts.SpkParams.PSTH_BinShift):opts.SpkParams.PSTH_BinShift:(opts.SpkParams.BaselineDelay-opts.SpkParams.PSTH_BinShift);%obj.ManData.GenerateTimeAxis('leading',opts);

                        % project the mean of the correct on the diagonal and add it to the plots
                        SigCorr=aCorr{1}(TimeIndX,TimeIndY);
                       % SigCorr(pCorr{1}(TimeIndX,TimeIndY)>=0.05 | aCorr{1}(TimeIndX,TimeIndY)<=0)=-1;
                        [MeanProjDiagCorrect,SumProjDiagCorrect,MeanProjDiagCorrectPos,MeanProjDiagCorrectNeg]=obj.ManData.ProjectontoMatDiag(SigCorr,0);
                        obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagCorrectPos,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            'r',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','',...
                            'Sp',Sp(4),'LegendTxt','CorrectPos','IsthisAxisTime',0);
                        % fit a gaussian to the curve 
                         gaussianModel = fit(ProjTime', MeanProjDiagCorrectPos', 'gauss1');
%                          obj.FigParams.PlotMeanStd(ProjTime,gaussianModel(ProjTime)',[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
%                             'r',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','',...
%                             'Sp',Sp(4),'LegendTxt','','IsthisAxisTime',0,'p_line_style','--');

                        if 0
                            obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagCorrectNeg,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                                'b',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','',...
                                'Sp',Sp(4),'LegendTxt','CorrectNeg','IsthisAxisTime',0);
                        
                            % project the mean of the correct on the diagonal and add it to the plots
                            [MeanProjDiagInCorrect,SumProjDiagInCorrect]=obj.ManData.ProjectontoMatDiag(aCorr{2},0);
                            obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagInCorrect,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                                'g',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','',...
                                'Sp',Sp(4),'LegendTxt','InCorrect','IsthisAxisTime',0);

                            % project the mean of the all trails on the diagonal and add it to the plots
                            [MeanProjDiagCorrect,SumProjDiagCorrect]=obj.ManData.ProjectontoMatDiag(aCorr{3},0);
                            obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagCorrect,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                                'k',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','',...
                                'Sp',Sp(4),'LegendTxt','All','IsthisAxisTime',0);
                        end
                       
                        % add vertical line
                        MeanTime=gaussianModel.b1;%ProjTime(find(MeanProjDiagCorrectPos>=mean(MeanProjDiagCorrectPos),1,'first'));
                        obj.FigParams.PlotVerticalLine(MeanTime,Sp(4),2,'p_line_style','--');
                        obj.FigParams.PlotVerticalLine(0,Sp(4),1,'p_line_style','--');
                        Ticks=[-0.2:0.05:0.2];
                        v=axis;
                        text(MeanTime,v(4),num2str(MeanTime,4));
                        %  xlim([ProjTime(1) ProjTime(end)]);
                      %  Ticks=[ProjTime(1):0.1:ProjTime(end)];
                        xticks(Ticks);
                        xticklabels(obj.ManData.CovertDouble2CellStr(Ticks));  
                        xtickangle(45);axis tight
                      %  xlim([AnalysisOpts.ThisTimeAxisStart AnalysisOpts.ThisTimeAxisEnd])

                        h=[];

        
                case 'TransferEntropyOld'
                    % calculates the correlation between shared
                    % representations of color and response 
                    % the data should be organized like this 
                    % Scores_1ndD_RS = Response Scores[ {ColorCat1} {ColorCat2}]
                    % Scores_1ndD_RS = ColorCat Scores[ {ColorCat1} {ColorCat2}]
                    if ~strcmp(TargetFactor,'ColorCat') | ~strcmp(TargetFactorDim1,'ResponseLoc') | ~strcmp(TargetFactorDim2,'ColorCat')
                        warning('Transfer entropy analysis cant be applied here. Check above conditions')
                        h=[];return
                    end
                    Cats=1:2;
                    if  AnalysisOpts.SubtractMean4Entropy==1  % subtract based on the category
                        AnalysisOpts.EntropyUseResp4MeanSub=0;
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction                  
                        SubtractMeanVoid=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SGTITLE='Subtract Mean Feature';
                    elseif  AnalysisOpts.SubtractMean4Entropy==2 % subtract based on the correct incorrect and color category
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x-repmat(mean(x,1),[size(x,1) 1]),Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanVoid=SubtractMean;% handle for mean subtraction
                         SGTITLE='Subtract Mean Reward';
                    elseif AnalysisOpts.SubtractMean4Entropy==0 % don't subtract mean 
                        SubtractMean=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanNoConcat=@(Mat) (cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SubtractMeanVoid=@(Mat) cell2mat(cellfun(@(x) x,Mat,'uniformoutput',0)'); % handle for mean subtraction
                        SGTITLE='No Subtract Mean';
                    end
                    SmoothEntData=@(x) obj.ManData.SmoothData(x,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                 
                    IndReward=contains(AnalysisOpts.FactorInds2Keep,'Reward');
                    IndColor=contains(AnalysisOpts.FactorInds2Keep,'ColorML');
                    IndResponse=contains(AnalysisOpts.FactorInds2Keep,'ResponseLoc');
                
                    % get the relevant scores 
                    RespScores=Scores_1ndD(TrlRng).TrialRange;
                    ColorScores=Scores_2ndD(TrlRng).TrialRange;
                   
                    RespFactors=cellfun(@(x) obj.AdjustObjCategory4Factor(x),AllFactorVals_1ndD.TrialRange,'UniformOutput',0);
                    ColorFactors=cellfun(@(x) obj.AdjustObjCategory4Factor(x),AllFactorVals_2ndD.TrialRange,'UniformOutput',0);
                    %%
                    if AnalysisOpts.SubtractMean4Entropy==1
                        % take the mean of each classifier for each of its categories
                        RespFactorsConCat =cell2mat(cellfun(@(x) x',RespFactors,'UniformOutput',0))';
                        ColorFactorsConCat=cell2mat(cellfun(@(x) x',ColorFactors,'UniformOutput',0))';
                        RespScoresConcat=cell2mat(cellfun(@(x) x',RespScores,'UniformOutput',0))';
                        ColorScoresConcat=cell2mat(cellfun(@(x) x',ColorScores,'UniformOutput',0))';

                        IndResp=arrayfun(@(x) RespFactorsConCat(:,IndResponse)==x,unique(RespFactorsConCat(:,IndResponse))','UniformOutput',0);
                        RespScores=SubtractMean(arrayfun(@(x) (RespScoresConcat(IndResp{x},:)),1:2,'UniformOutput',0));
                        if AnalysisOpts.EntropyUseResp4MeanSub % use response
                            ColorScores=SubtractMean(arrayfun(@(x) (ColorScoresConcat(IndResp{x},:)),1:2,'UniformOutput',0));
                        else
                            ColorScores=cell2mat(arrayfun(@(x) (ColorScoresConcat(IndResp{x},:))',1:2,'UniformOutput',0))';
                        end
                        RespFactorsConCat=cell2mat(cellfun(@(x) RespFactorsConCat(x,:)',IndResp,'UniformOutput',0))';

                        % return it back to color
                        IndCol=arrayfun(@(x) RespFactorsConCat(:,IndColor)==x,1:2,'UniformOutput',0);
                        RespScores=cellfun(@(x) RespScores(x,:),IndCol,'UniformOutput',0);
                        ColorScores=cellfun(@(x) ColorScores(x,:),IndCol,'UniformOutput',0);

                        if ~AnalysisOpts.EntropyUseResp4MeanSub
                            ColorScores=SubtractMeanNoConcat(arrayfun(@(x) (ColorScores{x}),Cats,'UniformOutput',0));
                        end
                    end
                    % find correct and incorrect trials 
                    indCorrectResp=cellfun(@(x) x(:,IndReward)==1,RespFactors,'UniformOutput',0);
                    indInCorrectResp=cellfun(@(x) x(:,IndReward)==0,RespFactors,'UniformOutput',0);
                    
                    indCorrectColor=cellfun(@(x) x(:,IndReward)==1,ColorFactors,'UniformOutput',0);
                    indInCorrectColor=cellfun(@(x) x(:,IndReward)==0,ColorFactors,'UniformOutput',0);
                   
                    % subtract the mean from scores (flip response because
                    % of mismatch labels between color and response) then
                    % concatinate both categories
                   
                    RespScoresCorr=SubtractMeanVoid(arrayfun(@(x) RespScores{x}(indCorrectResp{x},:),Cats,'UniformOutput',0));
                    RespScoresInCorr=SubtractMeanVoid(arrayfun(@(x) RespScores{x}(indInCorrectResp{x},:),Cats,'UniformOutput',0));
                    ColorScoresCorr=SubtractMeanVoid(arrayfun(@(x) ColorScores{x}(indCorrectColor{x},:),Cats,'UniformOutput',0));
                    ColorScoresInCorr=SubtractMeanVoid(arrayfun(@(x) ColorScores{x}(indInCorrectColor{x},:),Cats,'UniformOutput',0));
                    % concatinate all mean subtractedscores               
                    RespScoresAll=[RespScoresCorr;RespScoresInCorr];
                    ColorScoresAll=[ColorScoresCorr;ColorScoresInCorr];
                     % correlate the scores with each other                   
                    [aCorr{1},pCorr{1}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresCorr),SmoothEntData(ColorScoresCorr));
                    [aCorr{2},pCorr{2}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresInCorr),SmoothEntData(ColorScoresCorr));
                    Conds2Look=1:2;
                    if ~isempty(ColorScoresInCorr)
                     %   [aCorr{3},pCorr{3}]=obj.ManData.CorrelateMats(RespScoresInCorr,ColorScoresInCorr);
                        [aCorr{3},pCorr{3}]=obj.ManData.CorrelateMats(SmoothEntData(RespScoresAll),SmoothEntData(ColorScoresAll));
                        Conds2Look=1:3;
                    end
                    % flip correlation values 
                    aCorr=cellfun(@(x) -x,aCorr,'uniformoutput',0);
                    ConditionTitle={'Corr CorrectRes-CorrectColor Trl','Corr InCorrectResp-InCorrectColor Trl','Corr bet All Trials'};%'Corr IncorrectResp-CorrectColor Trls'
                   % obj.WidthSmoothing=10;obj.WidthSmoothingDim2=10;pvalsig=0.001;
                   sgtitle(SGTITLE);
                    for ec=Conds2Look % loop on eontropy conditions
                        axes(Sp(ec));
                            % plot image of correlation 
                            [~,TimeIndX,TimeIndY]=obj.FigParams.Image(AnalysisOpts.Time,AnalysisOpts.Time,aCorr{ec},...
                                {AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},'Corr',[Title; ConditionTitle{ec}],Sp(ec),'OriginLine',5,'OriginLine_width',1,...
                                'WidthSmoothing',obj.WidthSmoothing,'WidthSmoothingDim2',obj.WidthSmoothing,'SmoothingMethod','','imageplotfunc','pcolor','caxis_limits',obj.caxis_limits);
                         
                            % plot significance image superimposed on it
                            if AnalysisOpts.PlotEntropySig
                                obj.PlotSignificanceImage(pCorr{ec}(TimeIndX,TimeIndY),AnalysisOpts.Time(TimeIndX),AnalysisOpts.Time(TimeIndY),aCorr{ec}(TimeIndX,TimeIndY),AnalysisOpts.pvalEntropyAnalysis);
                            end
                            % plot digaonal of the correlation matrix
                            %      obj.FigParams.PlotMeanStd(AnalysisOpts.Time,diag(aCorr{ec})',[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            %      'k',3,[Title; ConditionTitle{ec}],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','movmean','Sp',Sp(ec));
                    end
                        % generate time axis for this 
                        opts.PopulationAna.PSTHbin=AnalysisOpts.PopulationAna.PSTHbin;
                        opts.SpkParams.PSTH_BinShift=AnalysisOpts.SpkParams.PSTH_BinShift;
                        opts.SpkParams.BaselineDelay=(AnalysisOpts.Time(end)-AnalysisOpts.Time(1));
                        opts.SpkParams.PeriodLength=2*opts.SpkParams.BaselineDelay;
                        ProjTime=-opts.SpkParams.BaselineDelay:opts.SpkParams.PSTH_BinShift:opts.SpkParams.BaselineDelay;%obj.ManData.GenerateTimeAxis('leading',opts);

                        % project the mean of the correct on the diagonal and add it to the plots
                        [MeanProjDiagCorrect,SumProjDiagCorrect]=obj.ManData.ProjectontoMatDiag(aCorr{1}');
                        obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagCorrect,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            'r',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','movmean',...
                            'Sp',Sp(4),'LegendTxt','Correct','IsthisAxisTime',0);
                        xlim([AnalysisOpts.ThisTimeAxisStart AnalysisOpts.ThisTimeAxisEnd])
                      
                        % project the mean of the correct on the diagonal and add it to the plots
                        [MeanProjDiagInCorrect,SumProjDiagInCorrect]=obj.ManData.ProjectontoMatDiag(aCorr{2}');
                        obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagInCorrect,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            'g',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','movmean',...
                            'Sp',Sp(4),'LegendTxt','InCorrect','IsthisAxisTime',0);
                        xlim([AnalysisOpts.ThisTimeAxisStart AnalysisOpts.ThisTimeAxisEnd])

                        % project the mean of the all trails on the diagonal and add it to the plots
                        [MeanProjDiagCorrect,SumProjDiagCorrect]=obj.ManData.ProjectontoMatDiag(aCorr{3}');
                        obj.FigParams.PlotMeanStd(ProjTime,MeanProjDiagCorrect,[],{AnalysisOpts.Xlabel;'ColorCat'},{AnalysisOpts.Xlabel;'Response'},...
                            'k',1,[Title],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod','movmean',...
                            'Sp',Sp(4),'LegendTxt','All','IsthisAxisTime',0);
                        xlim([AnalysisOpts.ThisTimeAxisStart AnalysisOpts.ThisTimeAxisEnd   ])
                       
                        % add vertical line
                        obj.FigParams.PlotVerticalLine(0,Sp(4),1);    
                        axis tight
                        h=[];
            end
            % update title if we have changed it 
            if ~isempty(obj.ThisTitle);Title=obj.ThisTitle;end
            if obj.CalOnlyStat;h=[];return;end % in this case we were just calculatign the stat test
            switch PlotType
                case 'MeanStd'                                      
                    colormap(Sp,copper(nTrialRange));                
                    Col=copper(nTrialRange);
                    if ~iscell(ScoresMetric);ScoresMetric=arrayfun(@(x) ScoresMetric(x,:),1:nTrialRange,'UniformOutput',0);end
                    
                    [h,~,~,ScoresMetricMean]=arrayfun(@(TrlRng) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ScoresMetric{TrlRng},[],AnalysisOpts.Xlabel,...
                        [],Col(TrlRng,:),1,[],'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod),1:nTrialRange,'UniformOutput',0);
                    
                    % run stat tests on the trend of the data
                    %                     TitleTrendStatTest=obj.ManData.PerformAllTrend_StatTest(1:nTrialRange,ScoresMetricMean,0.05);
                    %                     Title=[Title;TitleTrendStatTest];
                    
                    % if we are performing trend stat test on this data as well
                    if obj.performtrend_stattest
                        ScoresMetricMean=transpose(cell2mat(arrayfun(@(x) mean(ScoresMetricMean{x},1)',1:nTrialRange,'UniformOutput',0)));
                        [~,p_value]=obj.ManData.Correlation([1:nTrialRange]',ScoresMetricMean,0,'Modified_MannKendall');

                       % [clusters,statsummery]=obj.ManData.DifferentiateSigClusters2(p_value);

                        obj.FigParams.plot_significance_level([],...
                            p_value,AnalysisOpts.Time,'auto','k',[],[],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);
                    end

                    Ylbl=[{Metric} ; { [ClassifierOpts.TargetFactors{1} ' ' ClassifierOpts.TargetFactors_2ndD{1}]}];
                    title(Title);ylabel(Ylbl)
                    if nTrialRange>1
                        hCbar=colorbar;
                        L=hCbar.Ticks(end);
                        hCbar.Ticks=hCbar.Ticks(1):L/(nTrialRange-1):hCbar.Ticks(end);
                        hCbar.TickLabels=arrayfun(@(x) num2str(x),1:nTrialRange,'UniformOutput',0);
                        hCbar.Label.String='Trials from switch';
                        hCbar.FontSize=10;
                    end
                    axis tight
                    varargout{2}=ScoresMetric;
                case 'Line' % line plot of the results with significance
                    colormap(Sp,jet(nTimRange));
                    Col=jet(nTimRange);
                    h=arrayfun(@(TimRange) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ScoresMetric{TimRange},[],AnalysisOpts.Xlabel,...
                        [],Col(TimRange,:),1,[],'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',LineLegTxt{TimRange}),1:nTimRange,'UniformOutput',0);                   
                    Ylbl=[{Metric} ; { [ClassifierOpts.TargetFactors{1} ' ' ClassifierOpts.TargetFactors_2ndD{1}]}];
                   
                    if obj.performtrend_stattest % we assume we that we have already performed the stat test here
                       % [clusters,statsummery]=obj.ManData.DifferentiateSigClusters2(p);

                        obj.FigParams.plot_significance_level([],...
                            p,AnalysisOpts.Time,'auto','k',[],[],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);
                    else
                        [X,P]=obj.ManData.DifferentiateSigClusters(find(pa{nTimRange}),p(pa{nTimRange})); % differentiate clusters
                        obj.FigParams.plot_significance_level(X,P,AnalysisOpts.Time,[max(ScoresMetric{nTimRange})],Col(nTimRange,:),[],[],'WidthSmoothing',obj.WidthSmoothing,...
                            'SmoothingMethod',obj.SmoothingMethod);
                    end
                    %  ylim([0 max(ScoresMetric{nTimRange})+0.1])
                    title(Title);ylabel(Ylbl)
                    axis tight
                    varargout{2}=ScoresMetric;
                case 'CorrBhvMdl'
                    nTimRange=length(ScoresMetric);
                    Col=copper(nTimRange);
                    LegTxt=[ClassifierOpts.TargetFactors(1) ClassifierOpts.TargetFactors_2ndD(1)];
                    h=arrayfun(@(TimRange) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ScoresMetric{TimRange},[],AnalysisOpts.Xlabel,...
                        [],Col(TimRange,:),1,[],'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',LegTxt{TimRange},'LegendLoc','southwest'),1:nTimRange,'UniformOutput',0);
                    Ylbl=[Metric ' Encoding Axis'];
                    for TimRange=1:nTimRange
                        [X,P]=obj.ManData.DifferentiateSigClusters(find(pa{TimRange}),p{TimRange}(pa{TimRange})); % differentiate clusters
                        obj.FigParams.plot_significance_level(X,P,AnalysisOpts.Time,[0.3+0.05*(TimRange-1)],Col(TimRange,:),[]);
                    end
                    ylim([-0.4 0.4])
                    title(sprintf('%s to %s',obj.ManData.RepDashSpace(obj.BhvMdlFactor),TargetFactor));ylabel(Ylbl)
                    varargout{2}=ScoresMetric;
                case 'Image'
                    if iscell(ScoresMetric)
                        ScoresMetric=obj.ManData.ReshapeCell2Mat(ScoresMetric,2);
                    end
                    h=obj.FigParams.Image(AnalysisOpts.Time,TrialRange,ScoresMetric,...
                        AnalysisOpts.Xlabel,['Trial'],Metric,Title,Sp,'OriginLine',2,...
                        'WidthSmoothing',obj.WidthSmoothing,'WidthSmoothingDim2',obj.WidthSmoothingDim2);
                    colormap(Sp,parula);
                    varargout{2}=ScoresMetric;
                case 'QuadrantObjs'
                    subplot(Sp)
                    ObjTxt={'RB','GT','GB','RT'};
                    Col=copper(nTrialRange);
                    for TrlRng=[1 nTrialRange]%floor(nTrialRange/2) 
                        arrayfun(@(ThisObj) text(ColorAxis{TrlRng}(ThisObj),ShapeAxis{TrlRng}(ThisObj),ObjTxt{ThisObj},...
                            'Color',Col(TrlRng,:),'FontSize',14),1:4)
                    end
                    xlabel('Color Encoding Axis');                   
                    ylabel('Shape Encoding Axis');
                    hCbar=colorbar;
                    hCbar.Ticks=1:nTrialRange;
                    hCbar.Label.String='Trials from switch';hCbar.Label.FontSize=12;
                    hCbar.FontSize=12;
                    varargout{2}=ColorAxis;
                    varargout{3}=ShapeAxis;
                case 'QuadrantObjsTime'% plots Quadrant Objects in time 
                    Col={'r','g','g','r'};
                    width=[3 1 3 1];
                    ObjTxt={'RB','GT','GB','RT'};
                    gcf
                    % plot first learning step 
                    Sp=subplot(221);
                    arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ColorAxisTime{1}{x},[],AnalysisOpts.Xlabel,...
                        [],Col{x},3,'Color Encoding Axis Trn2/Tst3 - Learning step 1','Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'p_line_width',width(x), 'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',ObjTxt{x},'LegendLoc','southwest'),1:4);
                    Sp=subplot(222);
                    arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ShapeAxisTime{1}{x},[],AnalysisOpts.Xlabel,...
                        [],Col{x},3,'Shape Encoding Axis Trn1/Tst3 - Learning step 1','Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'p_line_width',width(x),'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',ObjTxt{x},'LegendLoc','southwest'),1:4);
                    % plot last learning step
                    Sp=subplot(223);
                    arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ColorAxisTime{end}{x},[],AnalysisOpts.Xlabel,...
                        [],Col{x},3,'Color Encoding Axis Trn2/Tst3 - Learning step last','Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'p_line_width',width(x), 'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',ObjTxt{x},'LegendLoc','southwest'),1:4);
                    Sp=subplot(224);
                    arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ShapeAxisTime{end}{x},[],AnalysisOpts.Xlabel,...
                        [],Col{x},3,'Shape Encoding Axis Trn1/Tst3 - Learning step last','Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,...
                        'p_line_width',width(x),'SmoothingMethod',obj.SmoothingMethod,'LegendTxt',ObjTxt{x},'LegendLoc','southwest'),1:4);                                       
                    varargout{2}=ColorAxisTime;
                    varargout{3}=ShapeAxisTime;
                case 'Scatter'               
                    Title=[Title ; {sprintf('a:%0.4f,p:%0.6f',a,p)}];
                    % Create scatter plot
                    [h]=obj.FigParams.ScatterPlot(X,Y,obj.ThisColor,Xlbl,Ylbl,Title,Sp,0); 

                    hold on;
                    % Calculate regression line
                    coefficients = polyfit(X,Y, 1);
                    regressionLine = polyval(coefficients, X);
                    
                    % Plot regression line
                    plot(X, regressionLine, 'k', 'LineWidth', 2);
                    
                    v=axis;
                    xlim([v(1)-0.025 v(2)+0.025])
                    ylim([v(3)-0.025 v(4)+0.025])
                    % Add legend
                    legend(Metric, 'Regression Line', 'Location', 'Best'); 
                    varargout{2}=X;
                    varargout{3}=Y;
            end
            obj.FigParams.FormatAxes(gca);
        end
     
        function h=PlotCompressionAxisAnalysis(obj,ColorAxisTime,ShapeAxisTime)
            global AnalysisOpts
            %% plot Xcorr values
            for i=1:16
                Color=obj.ManData.ReshapeCell2Mat(ColorAxisTime{i},1)';
                Shape=obj.ManData.ReshapeCell2Mat(ShapeAxisTime{i},1)';
                Color=obj.ManData.SmoothData(Color,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                Shape=obj.ManData.SmoothData(Shape,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                
                % calculate covariance at each time point
                Cov=arrayfun(@(x) cov(Color(:,x),Shape(:,x)),1:141,'UniformOutput',0);
                CovCol(:,i)=cellfun(@(x) x(1,1),Cov);
                CovSh(:,i)=cellfun(@(x) x(2,2),Cov);
                CovColSh1(:,i)=cellfun(@(x) x(1,2),Cov);
                CovColSh2(:,i)=cellfun(@(x) x(2,1),Cov);
            end
            h1=obj.FigParams.RenderFigure(1,[]);
            Col=copper(16);MM=10;
            subplot(221);hold on
            arrayfun(@(x) plot(AnalysisOpts.Time,CovCol(:,x),'color',Col(x,:)),1:16);title('color');xlabel('Time from Sample On')
            subplot(222);hold on
            arrayfun(@(x) plot(AnalysisOpts.Time,CovSh(:,x),'color',Col(x,:)),1:16);title('shape');xlabel('Time from Sample On')
            subplot(223);hold on
            arrayfun(@(x) plot(AnalysisOpts.Time,CovColSh1(:,x),'color',Col(x,:)),1:16);title('colorshape');xlabel('Time from Sample On')
            subplot(224);hold on
            arrayfun(@(x) plot(AnalysisOpts.Time,CovColSh2(:,x),'color',Col(x,:)),1:16);title('colorshape');xlabel('Time from Sample On')
                                   
            %% plot superimpose rectangles during learning
            h2=obj.FigParams.RenderFigure(1,[]);
            
            Col=copper(16);
            k=1;
            for T=[0:0.05:0.4]
                Ta=find(AnalysisOpts.Time>=T,1,'first');
                subplot(3,3,k)
                for i=[1:16]
                    
                    data_x=obj.ManData.ReshapeCell2Mat(ColorAxisTime{i},1)';
                    data_y=obj.ManData.ReshapeCell2Mat(ShapeAxisTime{i},1)';
                    
                    data_x=obj.ManData.SmoothData(data_x,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    data_y=obj.ManData.SmoothData(data_y,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    
                    Cov=arrayfun(@(x) cov(data_x(:,x),data_y(:,x)),1:141,'UniformOutput',0);
                    
                    data_x=data_x(:,Ta);
                    data_y=data_y(:,Ta);
                    cov_matrix = Cov{Ta};
                    CovRectangle(data_x,data_y,cov_matrix,Ta,Col,i,0)
                    % CovEllipse(data_x,data_y,cov_matrix,T,Col,i)
                    % CovParralelogram(data_x,data_y,cov_matrix,Ta,Col,i,0)
                end
                k=k+1;
            end
            
            %% plot encoding for each object
            h3=obj.FigParams.RenderFigure(16,[]);
            Col=copper(16);
            for i=[1:16 ]
                k=1;figure(h3{i})
                for T=[0:0.05:0.4]
                    Ta=find(AnalysisOpts.Time>=T,1,'first');
                    
                    subplot(3,3,k)
                    data_x=obj.ManData.ReshapeCell2Mat(ColorAxisTime{i},1)';
                    data_y=obj.ManData.ReshapeCell2Mat(ShapeAxisTime{i},1)';
                    
                    data_x=obj.ManData.SmoothData(data_x,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    data_y=obj.ManData.SmoothData(data_y,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    
                    Cov=arrayfun(@(x) cov(data_x(:,x),data_y(:,x)),1:141,'UniformOutput',0);
                    
                    data_x=data_x(:,Ta);
                    data_y=data_y(:,Ta);
                    cov_matrix = Cov{Ta};
                    CovRectangle(data_x,data_y,cov_matrix,Ta,Col,i,2)
                    %CovParralelogram(data_x,data_y,cov_matrix,Ta,Col,i,1)
                    k=k+1;
                end
            end
            
            %% plot encoding for each object with distribution of encodings
            Col=copper(16);
            h4=obj.FigParams.RenderFigure(16,[]);
            
            for i=[1:16 ]
                k=1;figure(h4{i})
                for T=[0:0.05:0.4]
                    Ta=find(AnalysisOpts.Time>=T,1,'first');
                    
                    subplot(3,3,k)
                    data_x=obj.ManData.ReshapeCell2Mat(ColorAxisTime{i},1)';
                    data_y=obj.ManData.ReshapeCell2Mat(ShapeAxisTime{i},1)';
                    
                    data_x=obj.ManData.SmoothData(data_x,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    data_y=obj.ManData.SmoothData(data_y,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                    
                    Cov=arrayfun(@(x) cov(data_x(:,x),data_y(:,x)),1:141,'UniformOutput',0);
                    
                    data_x=data_x(:,Ta);
                    data_y=data_y(:,Ta);
                    cov_matrix = Cov{Ta};
                    CovRectangle(data_x,data_y,cov_matrix,Ta,Col,i,1)
                    %CovParralelogram(data_x,data_y,cov_matrix,Ta,Col,i,1)
                    k=k+1;
                end
            end
            
            h=[h1 h2 h3 h4];
        end
        function h=PlotSVMProjectionsScores2DPEV(obj,ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp,Cond,TimPeriod,Metric,varargin) % plots PEV of two distibutions of scores
            %@cell structure of output of the classifer projection of validation data
            %@Metric can be 'corr' or 'kldiv' correlation or KL divergence
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if ~isfield(ClassifierResults_1ndD(1).TrialRange(1).Rep(1),'TestDataAllFactors') % if we don't gave Factor data
                return;
            end
            
            TargetFactor=obj.ThisTargetFactor;%'QuadrantsInCong';%'Quadrants';%ClassifierOpts.TargetFactors{1};
            for rep=1:ClassifierOpts.Nrep
                % grab trials and tile them based on different values of factor we care about
                [FactorDataInd{rep},FactorLevels]=obj.TileTrialsbasedonFactor(ClassifierResults_1ndD(Cond).TrialRange(obj.TrlRngNum).Rep(rep).TestDataAllFactors,TargetFactor,ClassifierOpts.Levels{1});
                
                % grab score values now based on number of the trial in a specific repetition
                Scores_1ndD(rep,:)=cellfun(@(x) ClassifierResults_1ndD(Cond).TrialRange(obj.TrlRngNum).Scores{rep}(x,:,:),FactorDataInd{rep},'UniformOutput',0);
                Scores_2ndD(rep,:)=cellfun(@(x) ClassifierResults_2ndD(Cond).TrialRange(obj.TrlRngNum).Scores{rep}(x,:,:),FactorDataInd{rep},'UniformOutput',0);
            end
            Scores_1ndD=arrayfun(@(x) cell2mat(Scores_1ndD(:,x)),1:length(FactorLevels),'UniformOutput',0);
            Scores_1ndD=cellfun(@(x) squeeze(x(:,1,:)),Scores_1ndD,'UniformOutput',0);
            Scores_2ndD=arrayfun(@(x) cell2mat(Scores_2ndD(:,x)),1:length(FactorLevels),'UniformOutput',0);
            Scores_2ndD=cellfun(@(x) squeeze(x(:,1,:)),Scores_2ndD,'UniformOutput',0);
            Scores_1ndD_RS=cell2mat(Scores_1ndD');
            Scores_2ndD_RS=cell2mat(Scores_2ndD');
            NTim=size(Scores_2ndD_RS,2);
            %% calculate metrics
            switch Metric
                case 'corr'
                    ScoresMetric=arrayfun(@(x) corr(Scores_1ndD_RS(:,x),Scores_2ndD_RS(:,x)),1:NTim);
                    % ScoresMetric=arrayfun(@(y) arrayfun(@(x) corr(Scores_1ndD{y}(:,x),Scores_2ndD{y}(:,x)),1:NTim),1:nLevels,'UniformOutput',0);
                case 'kldiv'
                    X=[-0.7:0.2:0.7];
                    P=arrayfun(@(x) (histc(Scores_1ndD_RS(:,x),X)+eps),1:NTim,'UniformOutput',0);
                    Q=arrayfun(@(x) (histc(Scores_2ndD_RS(:,x),X)+eps),1:NTim,'UniformOutput',0);
                    ScoresMetric=arrayfun(@(x) kldiv(X,Q{x}'/sum(Q{x}),P{x}'/sum(P{x})),1:NTim);
            end
            
            [Col]=obj.GetColorPalet4Factor(TargetFactor,[]);
            
            TimeInd=AnalysisOpts.Time>=TimPeriod(1) & AnalysisOpts.Time<=TimPeriod(2);
            h=obj.FigParams.PlotMeanStd(AnalysisOpts.Time,ScoresMetric,[],AnalysisOpts.Xlabel,...
                [],Col(1,:),1,[],'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);
            
            Title=[obj.ManData.RepDashSpace([ClassifierOpts.Name]); {['Trn1:' obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond{Cond}),...
                ' Tst1:' obj.ManData.ConvMat2Char(ClassifierOpts.TestCond{Cond}),...
                '|Trn2:' obj.ManData.ConvMat2Char(ClassifierOpts.TrainCond2{Cond}),...
                ' Tst2:' obj.ManData.ConvMat2Char(ClassifierOpts.TestCond2{Cond})]}];
            Ylbl=[Metric ' ' ClassifierOpts.TargetFactors_2ndD{1} ' Encoding Axis'];
            title(Title);ylabel(Ylbl)
            obj.FigParams.FormatAxes(gca);
        end
        function [CurrColorPalett,Col,FactorMarker,FactorLineStyle]=GetColorPalet4Factor(obj,TargetFactor,ColInd)% unify color palets for factors
            global AnalysisOpts
           
            Col=[];
            if (contains(TargetFactor,'ColorML') || contains(TargetFactor,'ShapeML')) && ~isempty(ColInd)
                TargetFactor=[TargetFactor(1:5) 'Cat'];
            end
            % if we need more colors then get more
            if ColInd>size(AnalysisOpts.ColorCatColors,1) 
                AnalysisOpts.ColorCatColors=obj.FigParams.getOthercolormap(AnalysisOpts.ColorCatColors_ColorName,ColInd,1); 
                AnalysisOpts.ShapeCatColors=obj.FigParams.getOthercolormap(AnalysisOpts.ShapeCatColors_ColorName,ColInd,1); 
                AnalysisOpts.ResponseLocColors=obj.FigParams.getOthercolormap(AnalysisOpts.ResponseLocColors_ColorName,ColInd,1);
            end
            if contains(TargetFactor,'ColorCat')                
                CurrColorPalett=AnalysisOpts.ColorCatColors;
            elseif contains(TargetFactor,'ColorML') 
                CurrColorPalett=AnalysisOpts.ColorMLColors;
            elseif contains(TargetFactor,'ShapeCat')
                CurrColorPalett=AnalysisOpts.ShapeCatColors;
            elseif contains(TargetFactor,'ShapeML')
                CurrColorPalett=AnalysisOpts.ShapeMLColors;
            elseif contains(TargetFactor,'Response')
                CurrColorPalett=AnalysisOpts.ResponseLocColors;
            elseif contains(TargetFactor,'Reward')
                CurrColorPalett=AnalysisOpts.RewardColors;
            elseif contains(TargetFactor,'RT')
                CurrColorPalett=AnalysisOpts.RTColors;
            elseif contains(TargetFactor,'Time')
                CurrColorPalett=AnalysisOpts.TimeColors;
            elseif contains(TargetFactor,'Rule')
                CurrColorPalett=AnalysisOpts.RuleColors;
            elseif contains(TargetFactor,'Quadrants')
                CurrColorPalett=[AnalysisOpts.ColorMLColors(1,:);AnalysisOpts.ColorMLColors(5,:);...
                    [22,216,246]/255;[246,22,216]/255];
            elseif contains(TargetFactor,'QuadrantsInCong')
                CurrColorPalett=[AnalysisOpts.ColorMLColors(1,:);AnalysisOpts.ColorMLColors(5,:)];
            elseif contains(TargetFactor,'Area')
                 CurrColorPalett=AnalysisOpts.AreaColors;               
            end
            if ~isempty(ColInd);Col=CurrColorPalett(ColInd,:);end
           
            IndFactor=contains({'Color','Shape','Response','Reward','Rule'},TargetFactor(1:4),'IgnoreCase',true);
            if sum(IndFactor)==0
                FactorMarker='none';FactorLineStyle='-';
            else
                % define line marker for factor as well
                FactorMarker=AnalysisOpts.FactorMarkers{IndFactor};
                % define line style for the factor
                FactorLineStyle=AnalysisOpts.FactorLineStyle{IndFactor};
            end
        end
        
        % series of function for ploting during learning
        function [h,MetricVals,TimeMetricVals]=PlotSVMPerfMetric_Learning(obj,ClassifierResults,ClassifierOpts,PerfMetric,Sp,Cond,TimeInd,TrnTstNum,varargin) % plots Accuracy or AUC magnitude for each trial or trail averaged
            %@ClassifierResults cell structure of output of the classifer projection of validation data
            %@PerfType can be'AUC' 'Accuracy' 'no_IDdims' or 'Posterior'
            %@TimeInd: Indices we want to to average and look at in a line plot
            %@TrnTstNum is it train and test condition 1 or 2
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare varibales
            nTrialRange=length(ClassifierResults(Cond).TrialRange);
            if TrnTstNum==1
                TargetFactorTxt=ClassifierOpts.TargetFactors{1};
                TrainCondTxt=sprintf('TrainCond');
                TestCondTxt=sprintf('TestCond');
            elseif TrnTstNum==2
                TargetFactorTxt=ClassifierOpts.TargetFactors_2ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);
            elseif TrnTstNum==3
                TargetFactorTxt=ClassifierOpts.TargetFactors_3ndD{1};
                TrainCondTxt=sprintf('TrainCond%i',TrnTstNum);
                TestCondTxt=sprintf('TestCond%i',TrnTstNum);    
            end
            [~,TrainTimInd,TestTimInd,nXtimePnt,TimeMatrixSize]=obj.GetTimeRangeforThisCond(ClassifierOpts);
            %TrialRangeSet=max([ClassifierOpts.TrainTrlNumRange{Cond}(2:4);ClassifierOpts.TestTrlNumRange{Cond}(2:4)],[],1);
            TrialRangeSet=ClassifierOpts.TestTrlNumRange{Cond}(2:4);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):abs(TrialRangeSet(1))];if isempty(TrialRange);TrialRange=1;end
            TrainCond=ClassifierOpts.(TrainCondTxt){Cond};
            TestCond=ClassifierOpts.(TestCondTxt){Cond};
            if isempty(obj.ThisTitle)
                Title=[{[TargetFactorTxt ' Tst ' obj.ManData.ConvMat2Char(ClassifierOpts.(TestCondTxt){Cond}),...
                    ' Trn ' obj.ManData.ConvMat2Char(ClassifierOpts.(TrainCondTxt){Cond})]}];%{obj.ManData.RepDashSpace(ClassifierOpts.Name)}
            else
                Title=obj.ThisTitle;
            end
            XTMP=contains(ClassifierOpts.Name,'XTMP');
            % get data for this metric first
            MetricVals=obj.ManData.ReshapeStruct2Mat(ClassifierResults(Cond).TrialRange,PerfMetric,4);
            if nTrialRange==1
                MetricVals=permute(MetricVals,[3 2 1]);              
            end
            
            % now take average across repetitions and squeeze
            if (isempty(TimeInd) & nTrialRange>1 & isempty(obj.PlotType))  | (XTMP & isempty(TimeInd) & isempty(obj.PlotType))
               
                % if we have the XTMP then reshape this matrix
                if XTMP 
                    MetricVals=reshape(MetricVals,[size(MetricVals,1) TimeMatrixSize]);
                    MetricVals=permute(MetricVals,[3 2 1]);
                    TrialRange=AnalysisOpts.Time;
                    XLABEL={AnalysisOpts.Xlabel ;['Test  ' ' R' obj.ManData.ConvMat2Char(ClassifierOpts.(TestCondTxt){Cond})]};
                    YLABEL={AnalysisOpts.Xlabel ;['Train ' ' R' obj.ManData.ConvMat2Char(ClassifierOpts.(TrainCondTxt){Cond})]};
                    caxis_Limits=ClassifierOpts.caxis_limits_XTemp;ThisWidthSmoothingDim2=obj.WidthSmoothing;OrgLine=1;
                else
                    XLABEL=AnalysisOpts.Xlabel;
                    YLABEL=['Trial Set ' num2str(TrialRangeSet(2))];YTICKSs=TrialRange;
                    caxis_Limits='auto';
                    ThisWidthSmoothingDim2=obj.WidthSmoothingDim2;
                    OrgLine=0; % no origin line
                end

                % image plot
                MetricVals=squeeze(mean(MetricVals,3))';
              
                % plot accuracy as image
                [h,~,~,TimeMetricVals,~,MetricVals]=obj.FigParams.Image(AnalysisOpts.Time,TrialRange,MetricVals,...
                    XLABEL,YLABEL,'Perf',Title,Sp,'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'OriginLine',OrgLine,'caxis_limits',caxis_Limits,...
                    'WidthSmoothing',obj.WidthSmoothing,'WidthSmoothingDim2',...
                    ThisWidthSmoothingDim2,'SmoothingMethod','movmean','imageplotfunc','surf');

                % set axis labels
                obj.FigParams.SetBothTimeAxisTicks('x','auto',AnalysisOpts.PaperSpec.TimeAxisSteps,AnalysisOpts.PaperSpec.TimeAxisSteps,'auto','auto');
                if XTMP
                    obj.FigParams.SetBothTimeAxisTicks('y','auto',AnalysisOpts.PaperSpec.TimeAxisSteps,AnalysisOpts.PaperSpec.TimeAxisSteps,'auto','auto');
                else
                    yticks(YTICKSs);
                end

                % if we are addign significance
                if ~isempty(obj.StatTest)
                    obj.PlotSignificanceImage(obj.StatTest{TrnTstNum}.(PerfMetric),AnalysisOpts.Time,TrialRange,MetricVals,obj.ImgPlotSigPval);
                end
            elseif isempty(TimeInd) & nTrialRange>1 & strcmp(obj.PlotType,'Line') % line plot % this is when we are plotting the learning data with line 
                MetricValsOrg=squeeze(MetricVals);
                MetricVals=squeeze(mean(MetricVals,3))';
                % if we have more than 16 trial range then sample it every 5 trials so we can manage it
                MetricVals=obj.ManData.SmoothData(MetricVals,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);
                CurrnTrialRange=nTrialRange;
                if TrialRangeSet(3)==1;nTrialRange=length(1:5:CurrnTrialRange);MetricVals=MetricVals(1:5:CurrnTrialRange,:);end
               
                Col=copper(nTrialRange);
                if ~iscell(MetricVals);MetricVals=arrayfun(@(x) MetricVals(x,:),1:nTrialRange,'UniformOutput',0);end
                [h,~,~,~,MetricVals,TimeMetricVals]=arrayfun(@(TrlRng) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,MetricVals{TrlRng},[],AnalysisOpts.Xlabel,...
                    [],Col(TrlRng,:),1,[],'Sp',Sp,'AppendTitles',1,'WidthSmoothing',obj.WidthSmoothing,'performtrend_stattest',obj.performtrend_stattest,...
                    'SmoothingMethod',obj.SmoothingMethod,'STD_method','bootstrap'),1:nTrialRange,'UniformOutput',0);
                Ylbl=[{PerfMetric} ; {TargetFactorTxt}];
                title(Title);ylabel(Ylbl)
                if nTrialRange>1
                    hCbar=colorbar;
                    hCbar.Ticks=1:nTrialRange;
                    hCbar.Label.String='Trials from switch';hCbar.Label.FontSize=12;
                    hCbar.FontSize=12;
                end

                %% add trend stat test for each time point
                %% this is the Jttred stat test plot code
%                 MetricValsOrg=obj.ManData.SmoothData(MetricValsOrg,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
%                 MetricValsOrg=obj.ManData.SmoothData(MetricValsOrg,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',1);
%                 pTimeTrend=obj.ManData.LearningTimeTrendStatTest(MetricValsOrg);
%                 pa_TimeTrend=pTimeTrend<AnalysisOpts.pval_TimeTrendTest;
%                % [TimeInd]=obj.FigParams.LimitTimeAxis(AnalysisOpts.Time,'Time');
%                % obj.FigParams.AddSignificanceStar(AnalysisOpts.Time(TimeInd),pa_TimeTrend(TimeInd),'k',Sp,'SigStar_fontsize',7);
%                 [X,P]=obj.ManData.DifferentiateSigClusters(find(pa_TimeTrend),pTimeTrend(pa_TimeTrend)); % differentiate clusters
%                 obj.FigParams.plot_significance_level(X,P,AnalysisOpts.Time,'auto','k',[],[],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);

                %% this is the trial shuffle stat test plot code
                if ~isempty(obj.StatTestTrlShuff)
                    obj.FigParams.plot_significance_level(obj.StatTestTrlShuff{TrnTstNum}.(PerfMetric).clusters,...
                        obj.StatTestTrlShuff{TrnTstNum}.(PerfMetric).statsummery,AnalysisOpts.Time,'auto','k',[],[],'WidthSmoothing',obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod);
                end
                axis tight
                v=axis;
                xticks(v(1):0.2:v(2))
                xtickangle(0)
                if (v(4)-v(3))<0.5
                    yticks((floor(v(3) * 10) / 10):0.05:v(4))
                else
                    yticks((floor(v(3) * 10) / 10):0.1:v(4))
                end

            elseif islogical(TimeInd) % line plot
                MetricVals=squeeze(mean(MetricVals(:,TimeInd,:,:),2));
                Col=obj.FigParams.getSingleColor(obj.ThisColor);
                Ylbl =[TargetFactorTxt ' ' PerfMetric];
               
                [h,~,~,~,MetricVals,TimeMetricVals,Title]=obj.FigParams.PlotMeanStd(TrialRange,MetricVals,[],'Trials',Ylbl,Col,obj.MeanStdPlotType,'','Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax,...
                    'WidthSmoothing',obj.WidthSmoothing,'performtrend_stattest',obj.performtrend_stattest,...
                    'SmoothingMethod',obj.SmoothingMethod,'STD_method','bootstrap');
                %yticks(TrialRange);
                % do ttest on the first and last point against chance trial range
                [~,p]=ttest(MetricVals,0.5);
                MeanPerf=mean(MetricVals,1);
                StatTxt=sprintf('%i:%0.2f p:%0.2f, %i:%0.2f p:%0.2f D=%0.2f',TrialRange(1),MeanPerf(1),p(1),TrialRange(nTrialRange),MeanPerf(nTrialRange),p(nTrialRange),MeanPerf(nTrialRange)-MeanPerf(1));
                Title=[Title;{StatTxt}];
                title(Title);

            elseif nTrialRange==1
                % get a color for this factor and for rule % the color is
                % based on the sum of training rules 
               [~,obj.ThisColor,obj.ThisMarker,obj.ThisLineStyle]=obj.GetColorPalet4Factor(TargetFactorTxt,sum(TestCond));%obj.ThisColor);
               % this is not xtemporal just plot accuracy in a line plot
                [h,MetricVals,TimeMetricVals]=obj.PlotSVMPerfMetric(ClassifierResults,ClassifierOpts,PerfMetric,Sp,Cond,...
                    'NormalizebyMax',obj.NormalizebyMax,'MeanStdPlotType',obj.MeanStdPlotType,'LookatDim2',obj.LookatDim2,...
                    'image_colormap',AnalysisOpts.ClassifierAccuracyColormap,'performtrend_stattest',obj.performtrend_stattest,...
                    'SubtractBaseLine',obj.SubtractBaseLine,'NPnts_SubtractBaseLine',obj.NPnts_SubtractBaseLine,...
                    'ThisColor',obj.ThisColor,'ThisMarker',obj.ThisMarker,'ThisMarkerSize',obj.ThisMarkerSize,'ThisLineStyle',obj.ThisLineStyle);                
            else % we are rading the values for spikecount periods
                Txt=sprintf('_SpkCntPrd%i',TimeInd);
                MetricVals=squeeze(obj.ManData.ReshapeStruct2Mat(ClassifierResults(Cond).TrialRange,[PerfMetric Txt],3));
                Col=obj.FigParams.getSingleColor(obj.ThisColor);
                Ylbl =[TargetFactorTxt ' ' PerfMetric];
                [h,~,~,~,MetricVals,TimeMetricVals]=obj.FigParams.PlotMeanStd(TrialRange,MetricVals,[],'Trials',Ylbl,Col,obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,...
                    'NormalizebyMax',obj.NormalizebyMax,'STD_method','bootstrap','performtrend_stattest',obj.performtrend_stattest);
                xticks(TrialRange);
            end
            
            % plot the data now
            subtitle(obj.ThisSubtitle)
        end
        function h=PlotSignificanceImage(obj,StatTest,X,Y,MetricVals,SigpVal,varargin) % plots a contour on significant values on the image
            % Display significance p-values we want to be shown: 0.05, 0.01, 0.001
            % Global variable for Analysis Options
            global AnalysisOpts
            
            % Process optional inputs using ParseParams
            obj = obj.ParseParams(varargin);
            
            % Initialize Zstat as NaN-filled array
            Zstat = nan * ones(size(MetricVals));
            
            % Find the maximum value in MetricVals
            MaxVal = max(MetricVals(:));
            
            % Fill in the contour matrix with significance values if clusters are defined
            if isfield(StatTest, 'clusters')
                for cl = 1:length(StatTest.clusters)
                    Zstat(StatTest.clusters{cl}) = StatTest.p_values(cl);
                end
            else
                Zstat = StatTest;
            end
            
            % Duplicate Zstat into a cell array
            Zstat = repmat({Zstat}, [1, 3]);
            
            % Create binary significance masks based on p-value thresholds
            Sig1 = Zstat{1} <= 0.05;
            Sig2 = Zstat{1} <= 0.01;
            Sig3 = Zstat{1} <= 0.001;
            
            % Set non-significant values to 0 and significant values to MaxVal
            Zstat{1}(Sig1) = MaxVal; Zstat{1}(~Sig1) = 0;
            Zstat{2}(Sig2) = MaxVal; Zstat{2}(~Sig2) = 0;
            Zstat{3}(Sig3) = MaxVal; Zstat{3}(~Sig3) = 0;
            
            % Map significance p-values to indices
            SigpValInd = arrayfun(@(x) find(x == [0.05, 0.01, 0.001]), SigpVal);
            
            % Hold the plot for subsequent additions
            hold all
            
            % Create meshgrid for contour plot
            [x, y] = meshgrid(X, Y);
            LW = [0.5, 2, 3];
            Ax=gca;MaxVal=Ax.CLim(2);
            % Plot contour lines for each significance level
            for i = SigpValInd
                [~, h] = contour(x, y, Zstat{i}, [MaxVal, MaxVal], ...
                    'linecolor', 'r', 'LineWidth', LW(i), 'ShowText', 'off');
            end
            
            % Limit the time axis using Figure Parameters
            obj.FigParams.SetTimeAxisLims();

        end
        function h=PlotAngleBetEncodingAxes_Learning(obj,ClassifierResults_1ndD,ClassifierResults_2ndD,ClassifierOpts,Sp,Cond,TimeInd,varargin) % plots angle between encoding axis in time
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % prepare varibales
            nTrialRange=length(ClassifierResults_1ndD(Cond).TrialRange);
            TrialRangeSet=max([ClassifierOpts.TrainTrlNumRange{Cond}(2:4);ClassifierOpts.TestTrlNumRange{Cond}(2:4)],[],1);
            TrialRange=[TrialRangeSet(2):TrialRangeSet(3):TrialRangeSet(1)];
            
            % plot the data now
            if isempty(obj.ThisColor)
                Col=obj.FigParams.getColorPalet(1);
            else
                Col=obj.ThisColor;
            end
            Title=[obj.ClassifierAngleCalMethod ' bet Encoding Axes'];
            if strcmp(obj.ClassifierAngleCalMethod,'Angle')
                Ylbl='Angle(Deg)';
            elseif strcmp(obj.ClassifierAngleCalMethod,'Corr')
                Ylbl='Corr';
            end
            if isempty(TimeInd) % image plot
                % prepare data first by cacculting angle between classifers
                EncodeAng_deg=arrayfun(@(x)  obj.CalculateAngleBetEncodingAxes(ClassifierResults_1ndD(Cond).TrialRange(x).Beta,...
                    ClassifierResults_2ndD(Cond).TrialRange(x).Beta),1:nTrialRange,'UniformOutput',0);
                EncodeAng_deg=cell2mat(EncodeAng_deg)';
                % plot accuracy as image
                obj.FigParams.Image(AnalysisOpts.Time,TrialRange,EncodeAng_deg,...
                    AnalysisOpts.Xlabel,['Trial Set ' num2str(TrialRangeSet(2))],Ylbl,Title,Sp,'image_colormap','parula','OriginLine',2);%,'caxis_limits',[-180 180]);
                yticks(TrialRange);
            else % line plot the spkcnt classifier results
                Txt1=sprintf('Beta_SpkCntPrd%i',1);Txt2=sprintf('Beta_SpkCntPrd%i',2);
                % prepare data first by cacculting angle between classifers
                EncodeAng_deg=arrayfun(@(x)  obj.CalculateAngleBetEncodingAxesSpkCnt(ClassifierResults_1ndD(Cond).TrialRange(x).(Txt1),...
                    ClassifierResults_2ndD(Cond).TrialRange(x).(Txt2)),1:nTrialRange,'UniformOutput',0);
                EncodeAng_deg=cell2mat(EncodeAng_deg)';
                Col=obj.FigParams.getSingleColor(obj.ThisColor);
                h=obj.FigParams.PlotMeanStd(TrialRange,EncodeAng_deg',[],'Trials',Ylbl,Col,obj.MeanStdPlotType,Title,'Sp',Sp,'AppendTitles',1,'NormalizebyMax',obj.NormalizebyMax);
                xticks(TrialRange);
            end
            % plot the data now
            subtitle(obj.ThisSubtitle)
        end
        
        %% working on below code is POSTPONED till further notice%%%
        function PlotSVMResultsinPCspace(obj,ClassifierResults,ClassifierOpts,Sp,Cond,varargin) % plots aggregated values of
            %@cell structure of output of the classifer projection of validation data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            NTim=length(Observed);
            if NTim>length(AnalysisOpts.Time);warning('Timing for classifer doesnt match');end
            nLevels=length(ClassifierOpts.Levels{1});
            
            for rep=1:ClassifierOpts.Nrep
                % grab trials and tile them based on different values of factor we care about
                [FactorDataInd{rep},FactorLevels]=TileTrialsbasedonFactor(ClassifierResults(Cond).Rep(rep).TestDataAllFactors,ClassifierOpts.TargetFactors{1},ClassifierOpts.Levels{1});
                %  [FactorDataInd{rep},FactorLevels]=TileTrialsbasedonFactor(ClassifierResults.Rep(rep).TestDataAllFactors,'ShapeML',ClassifierOpts.Levels{1});
                
                % grab score values now based on number of the trial in a specific repetition
                Scores(rep,:)=cellfun(@(x) ClassifierResults(Cond).Scores{rep}(x,:,:),FactorDataInd{rep},'UniformOutput',0);
            end
            Scores=arrayfun(@(x) cell2mat(Scores(:,x)),1:length(FactorLevels),'UniformOutput',0);
            
            if strcmp(ClassifierOpts.TargetFactors{1},'ColorML') % then use the color corresponding to the stimulus
                Col=AnalysisOpts.MorphlevelsColRGBInc50;
                colormap(AnalysisOpts.MorphlevelsColRGBInc50);
            elseif strcmp(ClassifierOpts.TargetFactors{1},'ShapeML')
                Col=AnalysisOpts.MorphlevelsShpRGBInc50;
                colormap(AnalysisOpts.MorphlevelsShpRGBInc50);
            else
                Col=obj.FigParams.getColorPalet(nLevels);
            end
            
            % plot the data now
            Ylbl=[ClassifierOpts.TargetFactors{1} ' Encoding Axis'];
            Title=[ClassifierOpts.Name];
            arrayfun(@(x) obj.FigParams.PlotMeanStd(AnalysisOpts.Time,squeeze(Scores{x}(:,1,:)),[],AnalysisOpts.Xlabel,...
                Ylbl,Col(x,:),1,Title,'Sp',Sp),1:nLevels,'UniformOutput',0);
            phasebar('location','sw','deg','size',0.3)
        end
        %% working on above code is POSTPONED till further notice%%%
        function  [FactorDataInd,FactorLevels,TargFactorInd]=TileTrialsbasedonFactor(obj,AllFactorData,TargetFactor,FactorLevels,varargin) % reports trial indexs based on the factor values
            %@FactorDataInd:  data for each factor
            %@TargetFactor: should be only one factor we want to sort the data for
            %@FactorDataInd & FactorLevels: corresponding number of trials and factor levels in a cell array
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs

            if size(AllFactorData,2)==length(AnalysisOpts.factornames);AnalysisOpts.FactorInds2Keep=AnalysisOpts.factornames;end
            
            if strcmp(TargetFactor,'ColorCat');TargetFactor='ColorML';
                FactorLevels=[1 2];
                ColorCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,TargetFactor);
                AllFactorData(:,ColorCatFactorInd)=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ColorCatFactorInd));
            elseif strcmp(TargetFactor,'ShapeCat');TargetFactor='ShapeML';
                 FactorLevels=[1 2];              
                ShapeCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,TargetFactor);
                AllFactorData(:,ShapeCatFactorInd)=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ShapeCatFactorInd));
            elseif strcmp(TargetFactor,'ResponseLoc');
                FactorLevels=[1 2];                            
            end
            
            %% find the values matching this factor
            if size(AllFactorData,2)<=length(AnalysisOpts.FactorInds2Keep) % if we have only kept a subset of variabels
                TargFactorInd=contains(AnalysisOpts.FactorInds2Keep,TargetFactor);
                RewardInd=contains(AnalysisOpts.FactorInds2Keep,'Reward');
            else
                TargFactorInd=contains(AnalysisOpts.factornames,TargetFactor);
                RewardInd=contains(AnalysisOpts.factornames,'Reward');
            end
                ThisFactor=AllFactorData(:,TargFactorInd);
                % are we limiting the trials only to correct trials 
                CorrIncorr=AllFactorData(:,RewardInd);
                if obj.TakeCorrectTrlsOnly;CorrIncorr=CorrIncorr==1;else;CorrIncorr=logical(ones(size(CorrIncorr,1),1));end
            
            if strcmp(TargetFactor,'RT')  % if this is RT then use hist to chunk the distribution
                MeanRT=nanmean(ThisFactor);StdRT=nanstd(ThisFactor);
                Edges=[min(ThisFactor) MeanRT-StdRT MeanRT+StdRT  max(ThisFactor)+0.001];
                FactorDataInd=arrayfun(@(x) find(ThisFactor>=Edges(x) & ThisFactor<Edges(x+1) & CorrIncorr),1:(length(Edges)-1),'UniformOutput',false);
                FactorLevels=arrayfun(@(x) mean([Edges(x) Edges(x+1)]),1:(length(Edges)-1));
                
            elseif contains(TargetFactor,'Hybrid_Q') ||  strcmp(TargetFactor,'Hybrid_Baxes') || strcmp(TargetFactor,'Time') ...
                    || contains(TargetFactor,'InferAF_Q') || strcmp(TargetFactor,'InferAF_Baxes') || strcmp(TargetFactor,'InferAF_Bfeature') % if this is Qval or axis belief then get value for one of them only
                ThisFactor=ThisFactor(1,:);
                MeanVal=nanmean(ThisFactor);StdVal=nanstd(ThisFactor);
                Edges=[min(ThisFactor) MeanVal-StdVal MeanVal+StdVal  max(ThisFactor)+0.001];
                FactorDataInd=arrayfun(@(x) find(ThisFactor>=Edges(x) & ThisFactor<Edges(x+1) & CorrIncorr),1:(length(Edges)-1),'UniformOutput',false);
                FactorLevels=arrayfun(@(x) mean([Edges(x) Edges(x+1)]),1:(length(Edges)-1));
            elseif strcmp(TargetFactor,'Quadrants')% we are looking at 4 quadrants of the object space
                %   if size(AllFactorData,2)==2 & sum(AllFactorData(:,1)==AnalysisOpts.StimulusMorphLevels) % then we are just reposting the morphllevel and don't have more data on this
                ShapeCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,'ShapeML');
                ColorCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,'ColorML');

                ThisFactorShapeCat=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ShapeCatFactorInd));
                ThisFactorColorCat=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ColorCatFactorInd));
                %                 else
                %                     % get shape and color factor data
                %                     ShapeCatFactorInd=obj.GetFactornameInd('ShapeCat');
                %                     ThisFactorShapeCat=AllFactorData(:,ShapeCatFactorInd);
                %                     ColorCatFactorInd=obj.GetFactornameInd('ColorCat');
                %                     ThisFactorColorCat=AllFactorData(:,ColorCatFactorInd);
                %                 end
                % we have 4 object cateogries ([0 0],[100 100],[0 100],[100 0])
                % which correspond to [Shape Color] category [1 1],[2 2],
                % [1 2],[2 1] %[red bunny, green tee, green bunny, red tee]
                CatComb=[[1 1];[2 2];[1 2];[2 1]];
                FactorDataInd=arrayfun(@(x) find(ThisFactorShapeCat==CatComb(x,1) & ThisFactorColorCat==CatComb(x,2) & CorrIncorr),...
                    1:4,'UniformOutput',false);
                FactorLevels=[1 2 3 4];
            elseif  strcmp(TargetFactor,'QuadrantsInCong') | strcmp(TargetFactor,'QuadrantsCong') % we are looking at 2 quadrants of the Incogruent object space
                %if size(AllFactorData,2)==2 & sum(sum(AllFactorData(:,1)==AnalysisOpts.StimulusMorphLevels)) % then we are just reposting the morphllevel and don't have more data on this
                ShapeCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,'ShapeML');
                ColorCatFactorInd=contains(AnalysisOpts.FactorInds2Keep,'ColorML');
                ThisFactorShapeCat=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ShapeCatFactorInd));
                ThisFactorColorCat=obj.ManData.CategorizeMorphlevel(AllFactorData(:,ColorCatFactorInd));
                %                 else
                %                     % get shape and color factor data
                %                     ShapeCatFactorInd=obj.GetFactornameInd('ShapeCat');
                %                     ThisFactorShapeCat=AllFactorData(:,ShapeCatFactorInd);
                %                     ColorCatFactorInd=obj.GetFactornameInd('ColorCat');
                %                     ThisFactorColorCat=AllFactorData(:,ColorCatFactorInd);
                %                 end
                if strcmp(TargetFactor,'QuadrantsInCong')
                    % we have 2 object cateogries ([0 0],[100 100])which correspond to [Shape Color] category [1 1],[2 2]%[red bunny, green tee]
                    CatComb=[[1 1];[2 2]];
                elseif strcmp(TargetFactor,'QuadrantsCong')
                    % we have 2 object cateogries ([0 100],[100 0])which correspond to [Shape Color] category [1 2],[2 1]%[green bunny,red tee]
                    CatComb=[[1 2];[2 1]];
                end
                FactorDataInd=arrayfun(@(x) find(ThisFactorShapeCat==CatComb(x,1) & ThisFactorColorCat==CatComb(x,2) & CorrIncorr),1:2,'UniformOutput',false);
                FactorLevels=[1 2];
            elseif strcmp(TargetFactor,'ColorMLComb') % combine trials from intermediate morph levels
                FactorInd=contains(AnalysisOpts.FactorInds2Keep,'ColorML');

                ThisFactor=AllFactorData(:,FactorInd);
                CombMLs={[0 0],[30 170], [70 130],[100 100]};
                FactorDataInd=cellfun(@(x) find(ThisFactor==x(1) | ThisFactor==x(2) & CorrIncorr),CombMLs,'UniformOutput',false);
                FactorLevels=[0,30,70,100];
            else
                %   FactorLevels=unique(ThisFactor);
                if iscell(FactorLevels)
                    FactorLevels=unique(cell2mat(FactorLevels));
                end
                FactorDataInd=arrayfun(@(x) find(ThisFactor==x & CorrIncorr),FactorLevels,'UniformOutput',false);
            end
        end
        function [MetricVal,MetricValMean]=GetPerfMetricData4Classifier(obj,ClassifierResults,PerfMetric,Cond,ShuffleFold,varargin)% gets a specific PerfMetric data for a classfier
            %@ShuffleFold if this a shuffle fold matrix
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isfield(ClassifierResults(Cond),'TrialRange')
                nTrlRng=length(ClassifierResults(Cond).TrialRange);
                if ShuffleFold
                    MetricVal=arrayfun(@(x) ClassifierResults(Cond).TrialRange(x).(PerfMetric),1:nTrlRng,'UniformOutput',0);
                    RepDim=4;
                else
                    MetricVal=arrayfun(@(x) ClassifierResults(Cond).TrialRange(x).(PerfMetric),1:nTrlRng,'UniformOutput',0);
                    RepDim=3; 
                end
            else
                MetricVal=squeeze(ClassifierResults(Cond).(PerfMetric))';
            end
            if isempty(AnalysisOpts.NRep2Use4StatTest) % if we are uing all of the repetitions
                % take mean of the data over repetitions
                MetricValMean=cellfun(@(x) squeeze(mean(x,RepDim)),MetricVal,'UniformOutput',0);
            else
                if ShuffleFold
                    MetricValMean=cellfun(@(x) squeeze(mean(x(:,:,:,AnalysisOpts.NRep2Use4StatTest),RepDim)),MetricVal,'UniformOutput',0);
                else
                    MetricValMean=cellfun(@(x) squeeze(mean(x(:,:,AnalysisOpts.NRep2Use4StatTest),RepDim)),MetricVal,'UniformOutput',0);
                end
            end
        end
        
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Statistical test METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        function StatTest=PerformStatTest(obj,ClassifierResults,ClassifierResults_Shuff,CorrectionMethod,Conds,varargin) % perform statistical test on classifier results
            % this function runs nonparametric statisctical test on all of
            % the performance metrics of classfier results use "Cluster
            % correction" or "Bonferroni Correction"
            % @ClassifierResults: preprocessed Classfiier results for observed data i.e. obj.ClassifierResults_Observed
            % @ClassifierResults_Shuff : preprocessed classifier results
            % @CorrectionMethod: 'Cluster','Bonf' correspond to
            % cluster-correction and bonferroni correction
            % for shuffled data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % define variables
            if isempty(Conds)
                Conds=1:length(ClassifierResults);
            end
            PerfMetricSet={'Accuracy'};%,'AUC'}; %what are the metrics we are intrested in
            if isempty(CorrectionMethod);CorrectionMethod='Cluster';end
            try
            % loop on the conditions and and performance metrics
            for n=1:length(Conds)
                Cond=Conds(n);
                nTrlRng=length(ClassifierResults(Cond).TrialRange);
                for PerfMetric=PerfMetricSet
                    PerfMetric=PerfMetric{1};
                    fprintf('\nRunning %s stat test on condition %i and metric:%s',CorrectionMethod,Cond,PerfMetric)
                    [~,MetricVal]=obj.GetPerfMetricData4Classifier(ClassifierResults,PerfMetric,Cond,0);
                    [~,MetricVal_Shuff]=obj.GetPerfMetricData4Classifier(ClassifierResults_Shuff,PerfMetric,Cond,1);
                    if isfield(ClassifierResults(Cond),'TrialRange')
                        % structue of MetricVal and MEtricValShuff is Rep*TrlRng*Time
                        MetricVal=obj.ManData.ReshapeCell2Mat(MetricVal,3);MetricVal=permute(MetricVal,[1 3 2]);
                        MetricVal_Shuff=obj.ManData.ReshapeCell2Mat(MetricVal_Shuff,3);MetricVal_Shuff=permute(MetricVal_Shuff,[2 3 1]);%                        
                    else
                        MetricVal=MetricVal';MetricVal_Shuff=MetricVal_Shuff';
                    end
                   
                    switch CorrectionMethod
                        case 'Cluster'
                            SmoothData4StatTest=1;
                            % perform clusted-corrected t-test
                            [StatTest(Cond).(PerfMetric).clusters, StatTest(Cond).(PerfMetric).p_values,...
                                StatTest(Cond).(PerfMetric).t_sums, StatTest(Cond).(PerfMetric).permutation_distribution,...
                                StatTest(Cond).(PerfMetric).statsummery]=obj.PerformClusterCorrected_tTest(MetricVal,...
                                MetricVal_Shuff, obj.ClustStatTst_dependent_samples,obj.ClustStatTst_p_threshold,...
                                obj.ClustStatTst_num_permutations,obj.ClustStatTst_two_sided,obj.ClustStatTst_num_clusters,SmoothData4StatTest);
                        case 'Bonferroni'
                            SmoothData4StatTest=1;
                             [StatTest(Cond).(PerfMetric).clusters, StatTest(Cond).(PerfMetric).p_values,...
                                StatTest(Cond).(PerfMetric).t_sums, StatTest(Cond).(PerfMetric).permutation_distribution,...
                                StatTest(Cond).(PerfMetric).statsummery]=obj.PerformBonferroniCorrected_tTest(MetricVal,...
                                MetricVal_Shuff, obj.ClustStatTst_dependent_samples,obj.ClustStatTst_p_threshold,...
                                obj.ClustStatTst_num_permutations,obj.ClustStatTst_two_sided,obj.ClustStatTst_num_clusters);                                      
                        case 'ClusterTrlShuffle'
                            SmoothData4StatTest=1; % we are not smoothing for this test because it is the order
                            % perform clusted-corrected t-test for trl shuffle correlation 
                            [StatTest(Cond).(PerfMetric).clusters, StatTest(Cond).(PerfMetric).p_values,...
                                StatTest(Cond).(PerfMetric).t_sums, StatTest(Cond).(PerfMetric).permutation_distribution,...
                                StatTest(Cond).(PerfMetric).statsummery]=obj.PerformClusterCorrected_tTestTrlShuffle(MetricVal,...
                                MetricVal_Shuff, obj.ClustStatTst_dependent_samples,obj.ClustStatTst_p_threshold,...
                                obj.ClustStatTst_num_permutations,obj.ClustStatTst_two_sided,obj.ClustStatTst_num_clusters,SmoothData4StatTest);
                    end
                end
            end
            catch me 
                obj.ManData.ThrowErrorTxt(me)
                StatTest=[];
            end
        end
       
        function StatTest=PerformStatTest_ModelifiedMannKendall(obj,ClassifierResults,CorrectionMethod,Conds,Dim,varargin) % perform statistical test on classifier results
            % this function runs nonparametric statisctical test on all of
            % the performance metrics of classfier results use "Cluster
            % correction" or "Bonferroni Correction"
            % @ClassifierResults: preprocessed Classfiier results for observed data i.e. obj.ClassifierResults_Observed
            % @ClassifierResults_Shuff : preprocessed classifier results
            % @CorrectionMethod: 'Cluster','Bonf' correspond to
            % cluster-correction and bonferroni correction
            % for shuffled data
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
                       
            SmoothData4StatTest=1; % we are not smoothing for this test because it is the order

            % define variables
            if isempty(Conds)
                Conds=1:length(ClassifierResults);
            end
            PerfMetricSet={'Accuracy'};%,'AUC'}; %what are the metrics we are intrested in
             try
                % loop on the conditions and and performance metrics
                for n=1:length(Conds)
                    Cond=Conds(n);
                    for PerfMetric=PerfMetricSet
                        PerfMetric=PerfMetric{1};
                        fprintf('\nRunning %s stat test on condition %i and metric:%s',CorrectionMethod,Cond,PerfMetric)
                        [~,MetricVal]=obj.GetPerfMetricData4Classifier(ClassifierResults,PerfMetric,Cond,0);
                        if isfield(ClassifierResults(Cond),'TrialRange')
                            % structue of MetricVal and MEtricValShuff is Rep*TrlRng*Time
                            MetricVal=obj.ManData.ReshapeCell2Mat(MetricVal,3);MetricVal=permute(MetricVal,[1 3 2]);
                        else
                            MetricVal=MetricVal';
                        end
                    end
                end
                if SmoothData4StatTest
                     [Observed]=obj.SmoothData4ClusterStatTest(MetricVal,[],3);
                   %   Observed=obj.ManData.SmoothData(MetricVal,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
                 end
               
                ObservedVal=squeeze(Observed);
                 %  ObservedCorr=ObservedCorr(2:16,:);ShuffleCorr=ShuffleCorr(:,2:16,:);
                TrlRng=[1:size(ObservedVal,1)]';
                NTim=size(ObservedVal,2);
                % Find the Kendall-tau values and associated quantifiers
                [~,p_value_uncred]=arrayfun(@(x) obj.ManData.Perform_Modified_MannKendall_StatTest(ObservedVal(:,x),TrlRng),1:NTim,'uniformoutput',0);

%                 if AnalysisOpts.Classifier_TrlShuff_TrendCorrMethodCode % which code we are using
%                     [tau, z_score, p_value_uncred, H] =arrayfun(@(x) Modified_MannKendall_test(TrlRng, ObservedVal(:,x)', ...
%                         AnalysisOpts.Modified_MannKendall_significance_value_tau, AnalysisOpts.Modified_MannKendall_significance_value_ac),1:NTim);
%                 else
%                     [H, p_value_uncred] =arrayfun(@(x) Mann_Kendall_Modified(ObservedVal(:,x)', ...
%                         AnalysisOpts.Modified_MannKendall_significance_value_tau),1:NTim);
%                 end
%                 % if we are doing this analysis in a pecific time frame then we should take the number of points
%                 % that we are showing into account
%                 if ~isempty(AnalysisOpts.Time2LookDim)
%                     Time2LookDim=AnalysisOpts.Time2LookDim{Dim};
%                 else 
%                     Time2LookDim=logical(ones(1,NTim));
%                 end
                p_value=cell2mat(p_value_uncred);

%                 if AnalysisOpts.Classifier_TrlShuff_UseBonferroni==1
%                     p_value_corrected_TimLim=p_value(Time2LookDim)*sum(Time2LookDim); % do the bonferroni correction
%                 elseif AnalysisOpts.Classifier_TrlShuff_UseBonferroni==2 % then do benjamini-Hotchbery correction
%                     [h, crit_p, adj_ci_cvrg, p_value_corrected_TimLim]=fdr_bh(p_value(Time2LookDim),AnalysisOpts.Classifier_TrlShuff_BenjaminiHochberg_FalseDiscoveryRate,...
%                         'pdep','yes');
%                 end
%                 p_value(Time2LookDim)=p_value_corrected_TimLim;

                StatTest(Cond).(PerfMetric).clusters=[];%obj.ManData.DifferentiateSigClusters2(p_value);
                StatTest(Cond).(PerfMetric).statsummery=p_value;
               % figure;plot(AnalysisOpts.Time,p_value);plot(AnalysisOpts.Time,p_value_uncred);
               % legend('Corrected pval','Uncorrected pval');
                %xlim([AnalysisOpts.PaperSpec.StrTime_SAMPLE_ON AnalysisOpts.PaperSpec.EndTime_SAMPLE_ON]);

                StatTest(Cond).(PerfMetric).p_values=[];
                StatTest(Cond).(PerfMetric).t_sums=[]; 
                StatTest(Cond).(PerfMetric).clustIdx=[];
                StatTest(Cond).(PerfMetric).permutation_distribution=[];            
            catch me 
                obj.ManData.ThrowErrorTxt(me)
                StatTest=[];
            end
        end
       
        
        function [clusters, p_values, t_sums, permutation_distribution,statsummery ]=PerformClusterCorrected_tTest(obj,Observed,Shuffle, dependent_samples,p_threshold, num_permutations, two_sided, num_clusters,SmoothData4StatTest,varargin)
            % Uses cluster-corrected t-test to compare distributions.
            % Permutation test (non-parametric test for significance) for dependent or independent measures of 1-D or 2-D data.
            % Based on Maris & Oostenveld 2007 for 1-D and 2-D vectors. The test statistic is T-Sum - the total of t-values within a cluster of contingent above-threshold data points. See:
            % Maris, E., & Oostenveld, R. (2007). Nonparametric statistical testing of EEG-and MEG-data. Journal of Neuroscience Methods, 164(1), 177190. https://doi.org/10.1016/j.jneumeth.2007.03.024
            % This function is using permutest witten by Edden M.Gerber
            % refer to permutest.m for description of inputs
            
            % turn empty values into default
            if isempty(dependent_samples); dependent_samples=false;end%indicate independant samples;
            if isempty(p_threshold);p_threshold=0.05;end
            if isempty(two_sided);two_sided=true;end%do two sided t test
            if isempty(num_clusters);num_clusters=inf;end % detect infinit number of trials
            %% for not we are not using this code from the citation above
%                         [clusters, p_values, t_sums, permutation_distribution] =...
%                             permutest(trial_group_1, trial_group_2, dependent_samples, ...
%                             p_threshold, num_permutations, two_sided, num_clusters );
            %x=repmat(Observed,[size(Shuffle,1) 1 1])-Shuffle; % differnce between shuffle and observed distribution
           
            if SmoothData4StatTest
                [Observed,Shuffle]=obj.SmoothData4ClusterStatTest(Observed,Shuffle,3);
            end

            % do some manipulation in the dimension until we fix this 
            [p_values, t_sums, clustIdx,permutation_distribution] = obj.ManData.ClusterMassCorrection_permutationTwoTail(Shuffle,Observed,p_threshold,two_sided,'ShowClustCorrectionPlot',1);
            clusters=arrayfun(@(x) find(clustIdx==x),unique(clustIdx(clustIdx~=0)),'UniformOutput',0);
            
            % create a summery matrix where for each time point in the clusters we assign a p-value
            if ~isempty(clusters)
                statsummery=arrayfun(@(x) p_values(x)*ones(size(clusters{x})),1:length(clusters),'UniformOutput',0);
            else
                statsummery=[];
            end
        end
        function [clusters, p_values, t_sums, permutation_distribution,statsummery ]=PerformClusterCorrected_tTestTrlShuffle(obj,Observed,Shuffle, dependent_samples,p_threshold, num_permutations, two_sided, num_clusters,SmoothData4StatTest,varargin)
            % clusterbased t-test for trial shuffle
            % Uses cluster-corrected t-test to compare distributions.
            % Permutation test (non-parametric test for significance) for dependent or independent measures of 1-D or 2-D data.
            % Based on Maris & Oostenveld 2007 for 1-D and 2-D vectors. The test statistic is T-Sum - the total of t-values within a cluster of contingent above-threshold data points. See:
            % Maris, E., & Oostenveld, R. (2007). Nonparametric statistical testing of EEG-and MEG-data. Journal of Neuroscience Methods, 164(1), 177190. https://doi.org/10.1016/j.jneumeth.2007.03.024
            % This function is using permutest witten by Edden M.Gerber
            % refer to permutest.m for description of inputs
            global AnalysisOpts
            % turn empty values into default
            if isempty(dependent_samples); dependent_samples=false;end%indicate independant samples;
            if isempty(p_threshold);p_threshold=0.05;end
            if isempty(two_sided);two_sided=true;end%do two sided t test
            if isempty(num_clusters);num_clusters=inf;end % detect infinit number of trials
            %% for not we are not using this code from the citation above
            ObservedOrg=Observed;ShuffleOrg=Shuffle;
            if SmoothData4StatTest
                % [Observed,Shuffle]=obj.SmoothData4ClusterStatTest(Observed,Shuffle,3);
                Observed=obj.ManData.SmoothData(Observed,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
                Shuffle=obj.ManData.SmoothData(Shuffle,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
            end

            if size(Shuffle,2)==2  %then we are only comparing two time points
                StatObsv=Observed(:,2,:)-Observed(:,1,:);
                StatShuff=Shuffle(:,2,:)-Shuffle(:,1,:);
            elseif strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Modified_MannKendall')
                significance_value_tau = AnalysisOpts.Modified_MannKendall_significance_value_tau;
                significance_value_ac = AnalysisOpts.Modified_MannKendall_significance_value_ac;
                ObservedCorr=squeeze(Observed);
                ShuffleCorr=squeeze(Shuffle);
                TrlRng=[1:size(ShuffleCorr,2)]';
                Nrep=size(ShuffleCorr,1);
                NTim=size(ObservedCorr,2);

                % Find the Kendall-tau values and associated quantifiers
                if AnalysisOpts.Classifier_TrlShuff_TrendCorrMethodCode==1;
                    [tau, z_score, p_value_uncred, H] =arrayfun(@(x) Modified_MannKendall_test(TrlRng, ObservedCorr(:,x)', significance_value_tau, significance_value_ac),1:NTim);
                else
                    [H, p_value_uncred] =arrayfun(@(x) Mann_Kendall_Modified(ObservedCorr(:,x)', ...
                        AnalysisOpts.Modified_MannKendall_significance_value_tau),1:NTim);
                end
%                 if AnalysisOpts.Classifier_TrlShuff_UseBonferroni==1
%                     p_values=p_value_uncred*NTim; % do the bonferroni correction
%                 elseif AnalysisOpts.Classifier_TrlShuff_UseBonferroni==2 % then do benjamini-Hotchbery correction
%                     [h, crit_p, adj_ci_cvrg, p_values]=fdr_bh(p_value_uncred,AnalysisOpts.Classifier_TrlShuff_BenjaminiHochberg_FalseDiscoveryRate,...
%                         'pdep','yes');
%                 else
                    p_values=p_value_uncred;
            %    end
                [clusters,statsummery]=obj.ManData.DifferentiateSigClusters2(p_values);
                statsummery=p_values;
                figure;plot(AnalysisOpts.Time,p_values);hold on;plot(AnalysisOpts.Time,p_value_uncred);
                legend('Corrected pval','Uncorrected pval');

                t_sums=[];permutation_distribution=[];
                return
            else
                % then we have shuffle throughout learning
                ObservedCorr=squeeze(Observed);
                ShuffleCorr=squeeze(Shuffle);
                %  ObservedCorr=ObservedCorr(2:16,:);ShuffleCorr=ShuffleCorr(:,2:16,:);
                TrlRng=[1:size(ShuffleCorr,2)]';
                Nrep=size(ShuffleCorr,1);
                NTim=size(ObservedCorr,2);
                % calculate correlation of performance and trial stage for each time point
                if strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Kendall')
                    CorrObsv=arrayfun(@(x) corr(TrlRng,ObservedCorr(:,x),'type','Kendall'),1:NTim);
                    CorrShuff=cell2mat(arrayfun(@(rep) arrayfun(@(x) corr(TrlRng,squeeze(ShuffleCorr(rep,:,x))','type','Kendall'),1:NTim)',1:Nrep,'UniformOutput',0))';
                elseif strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Regression')
                    CorrObsv=arrayfun(@(x) LinearRegression(TrlRng,ObservedCorr(:,x)),1:NTim);
                    CorrShuff=cell2mat(arrayfun(@(rep) arrayfun(@(x) LinearRegression(TrlRng,squeeze(ShuffleCorr(rep,:,x))),1:NTim)',1:Nrep,'UniformOutput',0))';
                elseif strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'Sigmoid')
                    [SlopeObsv,DifMinMaxObsv]=arrayfun(@(x) fitAndAdjustSigmoidLsq(TrlRng,ObservedCorr(:,x),...
                        0,num2str(AnalysisOpts.Time(x))),1:NTim);
                    for rep=1:Nrep
                        [SlopeShuff(rep,:),DifMinMaxShuff(rep,:)]=arrayfun(@(x) fitAndAdjustSigmoidLsq(TrlRng,squeeze(ShuffleCorr(rep,:,x))',0),1:NTim);
                    end
                    CorrShuff=(SlopeShuff);
                    CorrObsv=SlopeObsv;
                elseif strcmp(AnalysisOarrayfunarrayfunpts.Classifier_TrlShuff_TrendCorrMethod,'TheilSen')
                    CorrObsv=arrayfun(@(x) TheilSen([TrlRng,ObservedCorr(:,x)]),1:NTim);
                    CorrShuff=cell2mat(arrayfun(@(rep) arrayfun(@(x) TheilSen([TrlRng,squeeze(ShuffleCorr(rep,:,x))']),1:NTim)',1:Nrep,'UniformOutput',0))';
                elseif strcmp(AnalysisOpts.Classifier_TrlShuff_TrendCorrMethod,'CorrWbelief') % correlate with belief

                    BeliefEncodingObs=squeeze(AnalysisOpts.BeliefEncodingObs);
                    BeliefEncodingShuff=squeeze(AnalysisOpts.BeliefEncodingShuff);
                    TimeBelief=AnalysisOpts.Time<-0.1;
                    MeanBeliefObs=mean(BeliefEncodingObs(:,TimeBelief),2);
                    MeanBeliefShuff=mean(BeliefEncodingShuff(:,:,TimeBelief),3);
                    CorrObsv=arrayfun(@(x) LinearRegression(MeanBeliefObs,ObservedCorr(:,x)),1:NTim);
                    CorrShuff=cell2mat(arrayfun(@(rep) arrayfun(@(x) LinearRegression(squeeze(MeanBeliefShuff(rep,:))',squeeze(ShuffleCorr(rep,:,x))'),1:NTim)',1:Nrep,'UniformOutput',0))';
                end
                StatObsv=permute(CorrObsv,[3 1 2]);
                StatShuff=permute(CorrShuff,[1 3 2]);
            end
            [p_values, t_sums, clustIdx,permutation_distribution] = ...
                obj.ManData.ClusterMassCorrection_permutationTwoTail(StatShuff,StatObsv,AnalysisOpts.pvalClassifierAnalysisTrlShuff_ClusterCorrect,two_sided,'ShowClustCorrectionPlot',1);
            clusters=arrayfun(@(x) find(clustIdx==x),unique(clustIdx(clustIdx~=0)),'UniformOutput',0);

            % create a summery matrix where for each time point in the clusters we assign a p-value
            if ~isempty(clusters)
                statsummery=arrayfun(@(x) p_values(x)*ones(size(clusters{x})),1:length(clusters),'UniformOutput',0);
            else
                statsummery=[];
            end

        end
       
        function [Observed,Shuffle]=SmoothData4ClusterStatTest(obj,Observed,Shuffle,Dim)
            if Dim==3
                % smooth data as you would smooth when plotting the data
                Observed=obj.ManData.SmoothData(Observed,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
                Observed=obj.ManData.SmoothData(Observed,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                Shuffle=obj.ManData.SmoothData(Shuffle,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',3);
                Shuffle=obj.ManData.SmoothData(Shuffle,obj.WidthSmoothingDim2,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
            elseif Dim==2
                % smooth data as you would smooth when plotting the data
                Observed=obj.ManData.SmoothData(Observed,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
                Shuffle=obj.ManData.SmoothData(Shuffle,obj.WidthSmoothing,'SmoothingMethod',obj.SmoothingMethod,'DimSmoothing',2);
            end
        end

        function [clusters, p_values, t_sums, permutation_distribution,statsummery ]=PerformBonferroniCorrected_tTest(obj,trial_group_1, trial_group_2,dependent_samples,p_threshold,two_sided,varargin)
            if size(x,3)==1; trial_group_1=trial_group_1';trial_group_2=trial_group_2;
            else trial_group_1=permute(trial_group_1,[3 2 1]);trial_group_2=permute(trial_group_2,[3 2 1]);end
            if dependent_samples
                [a,p]=ttest(trial_group_1,trial_group_2);
            else
                [a,p]=ttest2(trial_group_1,trial_group_2);
            end
            n=1;t_sums=[];permutation_distribution=[];
            for pval=[0.05 0.001 0.001]
                clusters{n}=find(p<=pval);
                p_values(n)=pval-0.0001;
                n=n+1;
            end
            % create a summery matrix where for each time point in the clusters we assign a p-value
            if ~isempty(clusters)
                statsummery=arrayfun(@(x) p_values(x)*ones(size(clusters{x})),1:length(clusters),'UniformOutput',0);
            else
                statsummery=[];
            end
        end
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%AUX METHODS%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        %% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        % GLM
        function ConcatinateGLMfitdata(obj,GLMModelName,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ExtraTxt=obj.GetExtraStr4Cond('GLMfitSh');
            % see if concatinate file exists?
            [~,FileExist_GLMfitShConcat]=obj.LoadGLMfitfile(1,GLMModelName,'GLMfitShConcatExists');
            % if we are not rewriting then we are only cleaning up the data
            if ~AnalysisOpts.ReWriteGLMData & FileExist_GLMfitShConcat
                obj.ManData.DeleteFileSeries(['GLM'],ExtraTxt,1:AnalysisOpts.SingCellAna.GLMShuffleRuns); % deletes a series of file
                return
            end
            
            [GLMfit,FileExist]=obj.LoadGLMfitfile(1,GLMModelName,'GLMfitSh');
            if isempty(GLMfit);fprintf('\nShuffle files do not exist');return;end

            try  % try to save the file in the previously built file
                [~,~,FullPath]=obj.ManData.GetFileName('GLM',ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                MatFile=load(FullPath); % see if you can load the file
                % save each run if we are running it on the cluster
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' GLMModelName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            catch ME % if you catch error then delete file and save it again
                fprintf('\n%s',ME.message);
                obj.ManData.DeleteFile('GLM',ExtraTxt,1,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
                obj.ManData.SaveVar('GLM',GLMfit,['GLMfit_' GLMModelName ],ExtraTxt,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
            end
            % now delete the shuffle files
         %   [FileExist,SaveFileFullPath]=obj.ManData.DeleteFileSeries(['GLM'],ExtraTxt,1:AnalysisOpts.SingCellAna.GLMShuffleRuns); % deletes a series of file
        end
        function [FileExist_Main,FileExist_GLMfitShConcat,FileExist_GLMfitSh]=ExistGLMFiles(obj,Neu,GLMModelName,ShEachFileFlag,varargin) % checks if GLm files exist
            % ShEachFileFlag do we want to get each shuffle file
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            % see if the main file exists
            [~,FileExist_Main]=obj.LoadGLMfitfile(Neu,GLMModelName,'GLMfitExists');
            % see if the concatinated shuffle exists
            [~,FileExist_GLMfitShConcat]=obj.LoadGLMfitfile(Neu,GLMModelName,'GLMfitShConcatExists');
            % if the concatinated shuffle doesn't exist then check if any of the
            % single shuffles exist?
            if ShEachFileFlag
                [~,FileExist_GLMfitSh]=obj.LoadGLMfitfile(Neu,GLMModelName,'GLMfitShExists');
            else
                FileExist_GLMfitSh=arrayfun(@(x) FileExist_GLMfitShConcat(x)*ones(1,AnalysisOpts.SingCellAna.GLMShuffleRuns),1:length(Neu),'UniformOutput',0);
            end
            
        end
        % subspace
        function [SubspaceAnaResults,SubspaceAnaOpts]=LoadSubspaceAnaResults(obj,SubspaceAna_TaskName,varargin) % loads data from processed SubspaceAna results
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';
            else
                ShuffTxt='';
            end
            % define what type of test we want to do
            SubspaceAnaOpts=obj.DefineSubspaceAnaTestOptions(SubspaceAna_TaskName);
            fprintf(2,'\nLoading SubspaceAna results on task:%s|%s\n',SubspaceAna_TaskName,SubspaceAnaOpts.Name)
            FileNameSyntax=[SubspaceAnaOpts.AnaType '_' ShuffTxt SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            SubspaceAnaResults=obj.ManData.LoadVar('Subspace','SubspaceAnaResults',FileNameSyntax,0,'WantedCh','ALL');
            SubspaceAnaOpts=obj.ManData.LoadVar('Subspace','SubspaceAnaOpts',FileNameSyntax,0,'WantedCh','ALL');
        end
        function ConcatinateSubspaceFiles(obj,SubspaceAna_TaskName,varargin) % concatinates subspace files (shuffle or not) toghether
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if AnalysisOpts.DividSpockSubspace % check if we are loading shuffle data
                ShuffTxt='';
            elseif AnalysisOpts.CalShuffleSubspace | AnalysisOpts.CalShuffleAxB
                ShuffTxt='Shuf_';
            else
                ShuffTxt='';
            end
            
            % define what type of test we want to do
            SubspaceAnaOpts=obj.DefineSubspaceAnaTestOptions(SubspaceAna_TaskName);
            fprintf(2,'\nConcatinating subspace results on task:%s|%s\n',SubspaceAna_TaskName,SubspaceAnaOpts.Name)
            nConds=1:length(SubspaceAnaOpts.TrainCond);
            [~,~,~,~,nXTrlPnt]=arrayfun(@(x) obj.GetTrialRangeforThisCond(SubspaceAnaOpts,x),nConds,'UniformOutput',0);
            
            % decode which condition and trial range we are
            TrlRngInds=cell2mat(arrayfun(@(x) 1:nXTrlPnt{x}, nConds,'UniformOutput',0));
            CondInds  =cell2mat(arrayfun(@(x) x*ones(1,nXTrlPnt{x}), nConds,'UniformOutput',0));
            Nrep=SubspaceAnaOpts.Nrep;
            nCondsTot=length(CondInds);
            CondInds=cell2mat(arrayfun(@(x) CondInds+length(CondInds)*(x-1),1:Nrep,'UniformOutput',0));
            k=1;CurrentTrlRng=0;CurrentCond=0;Cexist=zeros(1,length(CondInds)) % inistialize values.
            % if there is not learning
            for C=1:length(CondInds) % loop on combination of all conditions
                % now decode what condition and trial range this belongs
                ThisCondLoc=mod(C,nCondsTot);ThisCondLoc(ThisCondLoc==0)=nCondsTot;
                Cond  =CondInds(ThisCondLoc);  % condition
                TrlRng=TrlRngInds(ThisCondLoc); % trial range
                rep=ceil(C/nCondsTot); % repetition
                
                if CurrentTrlRng~=TrlRng | CurrentCond~=Cond;k=1;end % reset if we are entring a new condition
                fprintf('\nLoading Condition:%i TrailRange:%i Rep:%i',Cond,TrlRng,rep)
                FileNameSyntax=[SubspaceAnaOpts.AnaType '_' ShuffTxt 'C' num2str(C) '_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                try
                    % depending on the structure of the data save the results;
                    temp=obj.ManData.LoadVar('Subspace','SubspaceAnaResults',FileNameSyntax,0,'WantedCh','ALL');
                    if isfield(temp,'TrialRange')
                        SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(k)=temp.TrialRange.Rep;
                    else
                        SubspaceAnaResults(Cond)=temp;
                    end
                    if isfield(temp,'AxBAnalysisTitles')
                        SubspaceAnaResults(Cond).AxBAnalysisTitles=temp.AxBAnalysisTitles;
                    end
                    Cexist(C)=1; % record which condition exists
                    k=k+1;
                catch % <<this is temporary solution >> has to be removed
                    % SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(rep)=SubspaceAnaResults(Cond).TrialRange(TrlRng).Rep(rep-1);
                    warning('Error concatinating data for subspace this line needs to be corrected');
                end
                CurrentTrlRng=TrlRng;
                CurrentCond=Cond;
            end
            FileNameSyntax=[SubspaceAnaOpts.AnaType '_' ShuffTxt 'C' num2str(Cexist(find(Cexist==1,1,'first'))) '_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            SubspaceAnaOpts=obj.ManData.LoadVar('Subspace','SubspaceAnaOpts',FileNameSyntax,0,'WantedCh','ALL');
            % save the results in a concatinated file
            % save off the variables
            obj.ManData.SaveVar('Subspace',SubspaceAnaResults,'SubspaceAnaResults',...
                [SubspaceAnaOpts.AnaType  '_' ShuffTxt SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedCh','ALL');
            obj.ManData.SaveVar('Subspace',SubspaceAnaOpts,'SubspaceAnaOpts',...
                [SubspaceAnaOpts.AnaType  '_' ShuffTxt SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)],'WantedCh','ALL');
            % delete the files now
            for C=1:length(CondInds)
                FileNameSyntax=[SubspaceAnaOpts.AnaType '_' ShuffTxt 'C' num2str(C) '_' SubspaceAnaOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Subspace',FileNameSyntax,1,'WantedCh','ALL');
            end
        end
        % classifier
        function [ClassifierResults,ClassifierOpts,DateTime,ClassifierResults_Shuff]=LoadClassiferResults(obj,Classifier_TaskName,varargin) % loads data from processed classfier results
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            ClassifierResults_Shuff=[];
            %if we have already loaded the data don't load it again
            if ~isempty(obj.ClassifierResults_Loaded) & ~obj.CalShuff
                ClassifierResults=obj.ClassifierResults_Loaded;
                ClassifierOpts=obj.ClassifierOpts_Loaded;
                DateTime=[];
                return
            end
            if ~isempty(obj.ClassifierResults_Shuff) & obj.CalShuff
                ClassifierResults_Shuff=obj.ClassifierResults_Shuff;
                ClassifierResults=obj.ClassifierResults_Observed;
                ClassifierOpts=obj.ClassifierOptsShuff_Loaded;
                DateTime=[];
                return
            end
                
            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';
            else
                ShuffTxt='';
            end
            if ~isempty(AnalysisOpts.Classifier_FileCond)
                ShuffTxt=[ShuffTxt 'C' num2str(AnalysisOpts.Classifier_FileCond) '_'];
            end
            
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(Classifier_TaskName);
            fprintf(2,'\nLoading Classfier results on task:%s|%s\n',Classifier_TaskName,ClassifierOpts.Name)
           
            FileNameSyntax=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            % load time of date of the file generation
            DateTime=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
            obj.LimitFileDateTime(DateTime,AnalysisOpts.Classifier_FileDateTimeTh,1);
            % load main data now
            ClassifierResults=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
            if obj.CalShuff       
                 DateTime=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                 obj.LimitFileDateTime(DateTime,AnalysisOpts.Classifier_FileDateTimeTh,1);    
                 ClassifierResults_Shuff=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');                      
            end
            ClassifierOpts=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
            % ClassifierResults=obj.FixClassifierResultsError(ClassifierResults);                       
        end
        function ClassifierResults=FixClassifierResultsError(~,ClassifierResults)
             % if we have made an error in saving then fix it
            if isfield(ClassifierResults ,'TrialRange')
                if isfield(ClassifierResults(1).TrialRange ,'TrialRange')
                    for c=1:length(ClassifierResults)
                        for i=1:length(ClassifierResults(c).TrialRange )
                            ClassifierResultstemp(c).TrialRange(i)=ClassifierResults(c).TrialRange(i).TrialRange;
                        end
                    end
                    ClassifierResults=ClassifierResultstemp;
                    clear ClassifierResultstemp
                end
            end
        end
         function ConcatinateClassifierFilesOld(obj,Classifier_TaskName,varargin) % concatinates classifier files (shuffle or not) toghether
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';            
            else
                ShuffTxt='';
            end
            
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(Classifier_TaskName);
            fprintf(2,'\nConcatinating classfier results on task:%s|%s\n',Classifier_TaskName,ClassifierOpts.Name)
              
            % load classifier options to see we have done the partitioning
            FileNameSyntax=['_' ShuffTxt 'C1_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            [ClassifierOptsC1,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
            if ~isempty(ClassifierOptsC1);ClassifierOpts=ClassifierOptsC1;end
            if ~FileExist
                if obj.LookforConcatinatedClassifierFile(ClassifierOpts,ShuffTxt) & ~AnalysisOpts.ReWriteClassifierData
                    return
                else
                    error('first file does not exist...');
                end
            end
            
            AnalysisOpts.DividSpockClassifier=ClassifierOpts.AnalysisOpts.DividSpockClassifier;          
            [~,~,nXTrlPnt,CondTot]=obj.GetClassifierSpockRunConds(ClassifierOpts);
            AnalysisOpts.DividSpockClassifier_TrlRng=cell2mat(nXTrlPnt);      
            [~,~,~,~,CondInds,TrlRngInds,RepInds]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            
            % if there is not learning
            for C=1:length(CondTot) % loop on combination of all conditions
                % now decode what condition and trial range this belongs
                FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                try 
                    % check if this file has been recently generated
                    DateTime=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                    obj.LimitFileDateTime(DateTime,AnalysisOpts.Classifier_FileDateTimeTh,0);
                    % depending on the structure of the data save the results
                    
                    [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                    if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                    
                    if AnalysisOpts.DividSpockClassifier==1 % if we are using condition and trial range
                        TrlRng=TrlRngInds(C);Cond=CondInds(C);
                        fprintf('\nLoading Condition:%i TrailRange:%i',Cond,TrlRng)
                        if isfield(temp,'TrialRange')
                            ClassifierResults(Cond).TrialRange(TrlRng)=[temp.TrialRange];
                        else
                            ClassifierResults(Cond)=temp;
                        end
                    elseif AnalysisOpts.DividSpockClassifier==2 % if we are using repetiions
                        rep=C; % here C is the current repetition
                        fprintf('\nLoading repetition:%i',rep)
                        for Cond=CondInds
                            for TrlRng=1:TrlRngInds{Cond}
                                ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep)=temp(Cond).TrialRange(TrlRng).Rep;
                            end
                        end
                    elseif AnalysisOpts.DividSpockClassifier==3 % if we are using repetiions and condition/trialrng
                        TrlRng=TrlRngInds(C);Cond=CondInds(C); % here C is the current repetition
                        fprintf('\nLoading condition:%i',C)
                        if obj.CalShuff % also laod shuffle varibale save repetitions for each fold
                            rep=RepInds(C);
                            ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep)=temp.TrialRange.Rep;
                            [temp]=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');
                            ClassifierResults_Shuffled(Cond).TrialRange(TrlRng).Rep(rep).FoldRep=temp.TrialRange.Rep;
                        else
                            ClassifierResults(Cond).TrialRange(TrlRng).Rep=temp.TrialRange.Rep;
                        end                    
                    end
                catch me% if we have error finding these files then skip and check if we have the full file
                    obj.ManData.ThrowErrorTxt(me);
                    % if the file aready exists the skip this for now
                    FileNameSyntaxFinal=['_' ShuffTxt  ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                    [~,~,FileNameFinal]=obj.ManData.GetFileName('Classifier',FileNameSyntaxFinal,'WantedDate','ALL');
                    if exist(FileNameFinal,'file') % if we have the
                        DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntaxFinal,0,'WantedDate','ALL');
                        obj.LimitFileDateTime(DateTimeFinal,AnalysisOpts.Classifier_FileDateTimeTh,1);
                        warning('Target full file already exists using that instead ...');return
                    else
                        error('The file conditions are not processed correctly. Reprocess this condition ... ')
                    end
                end
            end
            % save the results in a concatinated file
            % save off the variables, before delete existing files
            ExtraStrSave=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
            if obj.CalShuff % save ClassifierResults_Shuffled variable for shuffle as well
                obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSave,'WantedDate','ALL');
            end
            % delete the files now
            for C=1:length(CondTot)
                FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                obj.ManData.DeleteFile('Classifier',FileNameSyntax,1,'WantedDate','ALL');
            end
        end
       
        function ConcatinateClassifierFiles(obj,Classifier_TaskName,varargin) % concatinates classifier files (shuffle or not) toghether
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
        
            if obj.CalShuffTrlOrder==1;obj.CalShuff=1;end % if we are shuffling the trial order then we are  shuffleing

            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';            
            else
                ShuffTxt='';
            end
            
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(Classifier_TaskName);
            fprintf(2,'\nConcatinating classfier results on task:%s|%s\n',Classifier_TaskName,ClassifierOpts.Name)           
            
            % load classifier options to see we have done the partitioning
            FileNameSyntax=['_' ShuffTxt 'C1_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            [ClassifierOptsC1,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
            if ~isempty(ClassifierOptsC1)
                ClassifierOpts=ClassifierOptsC1;
                AnalysisOpts.UseRep4Cluster=ClassifierOpts.AnalysisOpts.UseRep4Cluster;
            end 
            
             % if we already have created the concatinated file recently and
            % we are not rewriting this data then use the concatinated file
            ConCatinatedExist=obj.LookforConcatinatedClassifierFile(ClassifierOpts,ShuffTxt); 
            % before anything check if all of the file we care about exist 
            [~,AllFilesExist]=obj.ExistClassifierFiles(ClassifierOpts,'CalShuff',obj.CalShuff);
            AllFilesExist=isempty(AllFilesExist);

            if ConCatinatedExist & ~AnalysisOpts.ReWriteClassifierData
                return
            elseif ConCatinatedExist & AnalysisOpts.ReWriteClassifierData & FileExist & AllFilesExist
                % we will continue running this function 
            elseif ConCatinatedExist & AnalysisOpts.ReWriteClassifierData & (~FileExist | ~AllFilesExist)
                error('Some of files to be concatinated does not exist...');
            end
                       
            AnalysisOpts.DividSpockClassifier=ClassifierOpts.AnalysisOpts.DividSpockClassifier;          
            [~,~,nXTrlPnt,CondTot]=obj.GetClassifierSpockRunConds(ClassifierOpts);
            AnalysisOpts.DividSpockClassifier_TrlRng=cell2mat(nXTrlPnt);      
            [~,~,~,~,CondInds,TrlRngInds,RepInds]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            
            % if there is not learning
            for C=1:length(CondTot) % loop on combination of all conditions
                % now decode what condition and trial range this belongs
                FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                try 
                    % check if this file has been recently generated
                    DateTime=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                    obj.LimitFileDateTime(DateTime,AnalysisOpts.Classifier_FileDateTimeTh,0);
                    % depending on the structure of the data save the results
                    
                    
                    if AnalysisOpts.DividSpockClassifier==1 % if we are using condition and trial range
                        [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                        TrlRng=TrlRngInds(C);Cond=CondInds(C);
                        fprintf('\nLoading Condition:%i TrailRange:%i',Cond,TrlRng)
                        if isfield(temp,'TrialRange')
                            ClassifierResults(Cond).TrialRange(TrlRng)=[temp.TrialRange];
                        else
                            ClassifierResults(Cond)=temp;
                        end
                    elseif AnalysisOpts.DividSpockClassifier==2 % if we are using repetiions
                         [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                        rep=C; % here C is the current repetition
                        fprintf('\nLoading repetition:%i',rep)
                        for Cond=CondInds
                            for TrlRng=1:TrlRngInds{Cond}
                                ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep)=temp(Cond).TrialRange(TrlRng).Rep;
                            end
                        end
                    elseif AnalysisOpts.DividSpockClassifier==3 % if we are using repetiions and condition/trialrng
                        if obj.CalShuff % also laod shuffle varibale save repetitions for each fold
                            if AnalysisOpts.UseRep4Cluster==0
                            % for this we go through repetitions first %
                            % take average across them and then exit for loop
                            UniqRepInds=unique(RepInds);UniqCondInds=unique(CondInds);UniqTrlRngInds=unique(TrlRngInds);                           
                            for Cond=UniqCondInds
                                for TrlRng=UniqTrlRngInds
                                    clear ResultsObs ResultsShuff ResultsShuffNew
                                    for rep=UniqRepInds
                                        C=find(RepInds==rep & TrlRngInds==TrlRng & CondInds==Cond);
                                        FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                                        % load both shuffle and observed variables
                                        if rep==(ClassifierOpts.NrepShufperFold+1) % load observed
                                            fprintf('\nLoading Observed condition:%i,Rep:%i,TrlRng:%i,Cond:%i',C,rep,TrlRng,Cond)
                                            [tempObs,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                                            if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                                            ResultsObs=tempObs.TrialRange.Rep;
                                        else      % load shuffle
                                            fprintf('\nLoading Shuffle condition:%i,Rep:%i,TrlRng:%i,Cond:%i',C,rep,TrlRng,Cond)
                                            [tempShuff]=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');
                                            % save them in a structure
                                            ResultsShuff(rep,:)=tempShuff.TrialRange.Rep;
                                        end
                                    end
                                    % take average of repetitions for observed                                    
                                    ClassifierResults(Cond).TrialRange(TrlRng).Rep=obj.AverageRepData(ResultsObs,ClassifierOpts);
                                    % take average of repetitions for shuffle
                                    for ss=1:ClassifierOpts.NrepShufperFold
                                        ResultsShuffNew(ss)=obj.AverageRepData(ResultsShuff(ss,:),ClassifierOpts);
                                    end
                                    ClassifierResults_Shuffled(Cond).TrialRange(TrlRng).Rep.FoldRep=ResultsShuffNew;
                                end
                            end
                            elseif AnalysisOpts.UseRep4Cluster==1 % if we are concatinating each repetition
                              
                                UniqRepInds=unique(RepInds);UniqCondInds=unique(CondInds);UniqTrlRngInds=unique(TrlRngInds);
                                for rep=UniqRepInds
                                    clear ResultsObs ResultsShuff ResultsShuffNew
                                    C=rep;
                                    FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                                    % load both shuffle and observed variables
                                    if rep==(ClassifierOpts.NrepShufperFold+1) % load observed
                                        fprintf('\nLoading Observed condition:%i,Rep:%i',C,rep)
                                        [tempObs,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                                        ResultsObs=tempObs;
                                    else      % load shuffle
                                        fprintf('\nLoading Shuffle condition:%i,Rep:%i',C,rep)
                                        [tempShuff]=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');
                                        % save them in a structure
                                        ResultsShuff=tempShuff;
                                    end

                                    for Cond=UniqCondInds
                                        for TrlRng=UniqTrlRngInds
                                            if rep==(ClassifierOpts.NrepShufperFold+1)
                                                % take average of repetitions for observed
                                                ClassifierResults(Cond).TrialRange(TrlRng).Rep=obj.AverageRepData(ResultsObs(Cond).TrialRange(TrlRng).Rep,ClassifierOpts);
                                            else
                                                % take average of repetitions for shuffle
                                                ClassifierResults_Shuffled(Cond).TrialRange(TrlRng).Rep.FoldRep(rep)=obj.AverageRepData(ResultsShuff(Cond).TrialRange(TrlRng).Rep,ClassifierOpts);
                                            end
                                        end
                                    end
                                end
                            end
                            break % leave this loop
                        else
                            [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                            if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                            TrlRng=TrlRngInds(C);Cond=CondInds(C); % here C is the current repetition
                            fprintf('\nLoading condition:%i',C)
                            ClassifierResults(Cond).TrialRange(TrlRng).Rep=temp.TrialRange.Rep;
                        end                    
                    end
                catch me% if we have error finding these files then skip and check if we have the full file
                    obj.ManData.ThrowErrorTxt(me);
                    % if the file aready exists the skip this for now
                    FileNameSyntaxFinal=['_' ShuffTxt  ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                    [~,~,FileNameFinal]=obj.ManData.GetFileName('Classifier',FileNameSyntaxFinal,'WantedDate','ALL');
                    if exist(FileNameFinal,'file') % if we have the
                        DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntaxFinal,0,'WantedDate','ALL');
                        obj.LimitFileDateTime(DateTimeFinal,AnalysisOpts.Classifier_FileDateTimeTh,1);
                        warning('Target full file already exists using that instead ...');return
                    else
                        error('The file conditions are not processed correctly. Reprocess this condition ... ')
                    end
                end
            end
            % save the results in a concatinated file
            % save off the variables, before delete existing files
            ExtraStrSave=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
            if obj.CalShuff % save ClassifierResults_Shuffled variable for shuffle as well
                obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSave,'WantedDate','ALL');
            end
            if (AnalysisOpts.DeleteClassifierShuffleFiles & obj.CalShuff) | ~obj.CalShuff
                % delete the files now
                for C=1:length(CondTot)
                    FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                    obj.ManData.DeleteFile('Classifier',FileNameSyntax,1,'WantedDate','ALL');
                end
            end    
        end
        function ConcatinateClassifierFilesPartial(obj,Classifier_TaskName,varargin) % concatinates classifier files (shuffle or not) toghether
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
        
            if obj.CalShuffTrlOrder==1;obj.CalShuff=1;end % if we are shuffling the trial order then we are  shuffleing

            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';            
            else
                ShuffTxt='';
            end
            
            % define what type of test we want to do
            ClassifierOpts=obj.DefineClassifierTestOptions(Classifier_TaskName);
            fprintf(2,'\nConcatinating classfier results on task:%s|%s\n',Classifier_TaskName,ClassifierOpts.Name)           
            
            % load classifier options to see we have done the partitioning
            FileNameSyntax=['_' ShuffTxt 'C1_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            [ClassifierOptsC1,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierOpts',FileNameSyntax,0,'WantedDate','ALL');
            if ~isempty(ClassifierOptsC1)
                ClassifierOpts=ClassifierOptsC1;
                AnalysisOpts.UseRep4Cluster=ClassifierOpts.AnalysisOpts.UseRep4Cluster;
            end 
            
             % if we already have created the concatinated file recently and
            % we are not rewriting this data then use the concatinated file
            ConCatinatedExist=obj.LookforConcatinatedClassifierFile(ClassifierOpts,ShuffTxt); 
            % before anything check if all of the file we care about exist 
            [~,AllFilesExist]=obj.ExistClassifierFiles(ClassifierOpts,'CalShuff',obj.CalShuff);
            AllFilesExist=isempty(AllFilesExist);

            if ConCatinatedExist & ~AnalysisOpts.ReWriteClassifierData
                return
            elseif ConCatinatedExist & AnalysisOpts.ReWriteClassifierData & FileExist & AllFilesExist
                % we will continue running this function 
            elseif ConCatinatedExist & AnalysisOpts.ReWriteClassifierData & (~FileExist | ~AllFilesExist)
                error('Some of files to be concatinated does not exist...');
            end
                       
            AnalysisOpts.DividSpockClassifier=ClassifierOpts.AnalysisOpts.DividSpockClassifier;          
            [~,~,nXTrlPnt,CondTot]=obj.GetClassifierSpockRunConds(ClassifierOpts);
            AnalysisOpts.DividSpockClassifier_TrlRng=cell2mat(nXTrlPnt);      
            [~,~,~,~,CondInds,TrlRngInds,RepInds]=obj.ReadClassifierSpockRunConds(ClassifierOpts);
            
            % if there is not learning
            for C=1:length(CondTot) % loop on combination of all conditions
                % now decode what condition and trial range this belongs
                FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                try 
                    % check if this file has been recently generated
                    DateTime=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                    obj.LimitFileDateTime(DateTime,AnalysisOpts.Classifier_FileDateTimeTh,0);
                    % depending on the structure of the data save the results
                    
                    
                    if AnalysisOpts.DividSpockClassifier==1 % if we are using condition and trial range
                        [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                        TrlRng=TrlRngInds(C);Cond=CondInds(C);
                        fprintf('\nLoading Condition:%i TrailRange:%i',Cond,TrlRng)
                        if isfield(temp,'TrialRange')
                            ClassifierResults(Cond).TrialRange(TrlRng)=[temp.TrialRange];
                        else
                            ClassifierResults(Cond)=temp;
                        end
                    elseif AnalysisOpts.DividSpockClassifier==2 % if we are using repetiions
                         [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                        rep=C; % here C is the current repetition
                        fprintf('\nLoading repetition:%i',rep)
                        for Cond=CondInds
                            for TrlRng=1:TrlRngInds{Cond}
                                ClassifierResults(Cond).TrialRange(TrlRng).Rep(rep)=temp(Cond).TrialRange(TrlRng).Rep;
                            end
                        end
                    elseif AnalysisOpts.DividSpockClassifier==3 % if we are using repetiions and condition/trialrng
                        if obj.CalShuff % also laod shuffle varibale save repetitions for each fold
                            if AnalysisOpts.UseRep4Cluster==0
                            % for this we go through repetitions first %
                            % take average across them and then exit for loop
                            UniqRepInds=unique(RepInds);UniqCondInds=unique(CondInds);UniqTrlRngInds=unique(TrlRngInds);                           
                            for Cond=UniqCondInds
                                for TrlRng=UniqTrlRngInds
                                    clear ResultsObs ResultsShuff ResultsShuffNew
                                    for rep=UniqRepInds
                                        C=find(RepInds==rep & TrlRngInds==TrlRng & CondInds==Cond);
                                        FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                                        % load both shuffle and observed variables
                                        if rep==(ClassifierOpts.NrepShufperFold+1) % load observed
                                            fprintf('\nLoading Observed condition:%i,Rep:%i,TrlRng:%i,Cond:%i',C,rep,TrlRng,Cond)
                                            [tempObs,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                                            if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                                            ResultsObs=tempObs.TrialRange.Rep;
                                        else      % load shuffle
                                            fprintf('\nLoading Shuffle condition:%i,Rep:%i,TrlRng:%i,Cond:%i',C,rep,TrlRng,Cond)
                                            [tempShuff]=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');
                                            % save them in a structure
                                            ResultsShuff(rep,:)=tempShuff.TrialRange.Rep;
                                        end
                                    end
                                    % take average of repetitions for observed                                    
                                    ClassifierResults(Cond).TrialRange(TrlRng).Rep=obj.AverageRepData(ResultsObs,ClassifierOpts);
                                    % take average of repetitions for shuffle
                                    for ss=1:ClassifierOpts.NrepShufperFold
                                        ResultsShuffNew(ss)=obj.AverageRepData(ResultsShuff(ss,:),ClassifierOpts);
                                    end
                                    ClassifierResults_Shuffled(Cond).TrialRange(TrlRng).Rep.FoldRep=ResultsShuffNew;
                                end
                            end
                            elseif AnalysisOpts.UseRep4Cluster==1 % if we are concatinating each repetition
                              
                                UniqRepInds=unique(RepInds);UniqCondInds=unique(CondInds);UniqTrlRngInds=unique(TrlRngInds);
                                for rep=UniqRepInds
                                    clear ResultsObs ResultsShuff ResultsShuffNew
                                    C=rep;
                                    FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                                    % load both shuffle and observed variables
                                    if rep==(ClassifierOpts.NrepShufperFold+1) % load observed
                                        fprintf('\nLoading Observed condition:%i,Rep:%i',C,rep)
                                        [tempObs,FileExist]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                                        if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                                        ResultsObs=tempObs;
                                    else      % load shuffle
                                        fprintf('\nLoading Shuffle condition:%i,Rep:%i',C,rep)
                                        [tempShuff]=obj.ManData.LoadVar('Classifier','ClassifierResults_Shuffled',FileNameSyntax,0,'WantedDate','ALL');
                                        % save them in a structure
                                        ResultsShuff=tempShuff;
                                    end

                                    for Cond=UniqCondInds
                                        for TrlRng=UniqTrlRngInds
                                            if rep==(ClassifierOpts.NrepShufperFold+1)
                                                % take average of repetitions for observed
                                                ClassifierResults(Cond).TrialRange(TrlRng).Rep=obj.AverageRepData(ResultsObs(Cond).TrialRange(TrlRng).Rep,ClassifierOpts);
                                            else
                                                % take average of repetitions for shuffle
                                                ClassifierResults_Shuffled(Cond).TrialRange(TrlRng).Rep.FoldRep(rep)=obj.AverageRepData(ResultsShuff(Cond).TrialRange(TrlRng).Rep,ClassifierOpts);
                                            end
                                        end
                                    end
                                end
                            end
                            break % leave this loop
                        else
                            [temp,FileExist,FileName]=obj.ManData.LoadVar('Classifier','ClassifierResults',FileNameSyntax,0,'WantedDate','ALL');
                            if ~FileExist; error('This condition is not generated. Checking if we have the full file ...');end
                  
                            TrlRng=TrlRngInds(C);Cond=CondInds(C); % here C is the current repetition
                            fprintf('\nLoading condition:%i',C)
                            ClassifierResults(Cond).TrialRange(TrlRng).Rep=temp.TrialRange.Rep;
                        end                    
                    end
                catch me% if we have error finding these files then skip and check if we have the full file
                    obj.ManData.ThrowErrorTxt(me);
                    % if the file aready exists the skip this for now
                    FileNameSyntaxFinal=['_' ShuffTxt  ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                    [~,~,FileNameFinal]=obj.ManData.GetFileName('Classifier',FileNameSyntaxFinal,'WantedDate','ALL');
                    if exist(FileNameFinal,'file') % if we have the
                        DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntaxFinal,0,'WantedDate','ALL');
                        obj.LimitFileDateTime(DateTimeFinal,AnalysisOpts.Classifier_FileDateTimeTh,1);
                        warning('Target full file already exists using that instead ...');return
                    else
                        error('The file conditions are not processed correctly. Reprocess this condition ... ')
                    end
                end
            end
            % save the results in a concatinated file
            % save off the variables, before delete existing files
            ExtraStrSave=['_' ShuffTxt ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            obj.ManData.DeleteFile('Classifier',ExtraStrSave,1,'WantedDate','ALL');   % first delete existing file
            obj.ManData.SaveVar('Classifier',ClassifierOpts,'ClassifierOpts',ExtraStrSave,'WantedDate','ALL');
            obj.ManData.SaveVar('Classifier',ClassifierResults,'ClassifierResults',ExtraStrSave,'WantedDate','ALL');
            if obj.CalShuff % save ClassifierResults_Shuffled variable for shuffle as well
                obj.ManData.SaveVar('Classifier',ClassifierResults_Shuffled,'ClassifierResults_Shuffled',ExtraStrSave,'WantedDate','ALL');
            end
            if (AnalysisOpts.DeleteClassifierShuffleFiles & obj.CalShuff) | ~obj.CalShuff
                % delete the files now
                for C=1:length(CondTot)
                    FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                    obj.ManData.DeleteFile('Classifier',FileNameSyntax,1,'WantedDate','ALL');
                end
            end    
        end
      
        function out=LookforConcatinatedClassifierFile(obj,ClassifierOpts,ShuffTxt)
            global AnalysisOpts
            FileNameSyntaxFinal=['_' ShuffTxt  ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            [~,~,FileNameFinal]=obj.ManData.GetFileName('Classifier',FileNameSyntaxFinal,'WantedDate','ALL');
            if exist(FileNameFinal,'file') % if we have the concatinated file 
                DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntaxFinal,0,'WantedDate','ALL');
                out=obj.LimitFileDateTime(DateTimeFinal,AnalysisOpts.Classifier_FileDateTimeTh,0);               
            else 
                out=false;
            end
            if out;warning('Target full file already exists using that instead ...');end
        end
        function [out,NonExist,IndFile,ConcatFile,CondInds,TrlRngInds]=ExistClassifierFiles(obj,Classifier_TaskName,varargin) % check if classifier files exist
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if obj.CalShuff % check if we are loading shuffle data
                ShuffTxt='Shuf_';
            elseif AnalysisOpts.DividSpockClassifier
                ShuffTxt='';
            else
                ShuffTxt='';
            end
            
            % define what type of test we want to do
            if isstruct(Classifier_TaskName)
                ClassifierOpts=Classifier_TaskName;
            else
                ClassifierOpts=obj.DefineClassifierTestOptions(Classifier_TaskName);
            end
            %   fprintf(2,'\nChecking classifier results task file:%s|%s\n',Classifier_TaskName,ClassifierOpts.Name)
            %% loop on conditions
            [nConds,nCondsShuffle,nXTrlPnt,CondTot]=obj.GetClassifierSpockRunConds(ClassifierOpts);

            % check if the concatinated file exists
            FileNameSyntax=['_' ShuffTxt  ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
            [~,~,FileName]=obj.ManData.GetFileName('Classifier',FileNameSyntax,'WantedDate','ALL');          
            ConcatFile=exist(FileName,'file');
            
            if ConcatFile & ((AnalysisOpts.DeleteClassifierShuffleFiles & obj.CalShuff) | ~obj.CalShuff) % if we have deleted the shuffle files or this is not shuffle
                DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                ConcatFile=DateTimeFinal>AnalysisOpts.Classifier_FileDateTimeTh; % if this is an old file then ignore it
            else
                ConcatFile=0; % otherwise we are going to look for files regardless of concatinated file
            end
            
            % if there is not learning
            for C=1:length(CondTot) % loop on combination of all conditions
                % now decode what condition and trial range this belongs              
                FileNameSyntax=['_' ShuffTxt 'C' num2str(C) '_' ClassifierOpts.Name '_' AnalysisOpts.Area2look{1} '_' AnalysisOpts.SpkCntStartFieldName '_' AnalysisOpts.TrlSpkTimeFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin)];
                
                % check if this file has been recently generated
                [~,~,FileName]=obj.ManData.GetFileName('Classifier',FileNameSyntax,'WantedDate','ALL');

                %  Check the date of the file 
                DateTimeFinal=obj.ManData.LoadVar('Classifier','DateTime',FileNameSyntax,0,'WantedDate','ALL');
                DateTimeFinalOK=DateTimeFinal>AnalysisOpts.Classifier_FileDateTimeTh; % if this is an old file then ignore it
                IndFile(C)=exist(FileName,'file') & DateTimeFinalOK;
            end
            % get a unique number for it is easier to decide
            if ConcatFile;out=ones(1,length(IndFile));else;out=IndFile;end
            NonExist=find(out==0);
        end
        function [nConds,nCondsShuffle,nXTrlPnt,CondTot]=GetClassifierSpockRunConds(obj,ClassifierOpts) % gets the conditions of run for classifier 
            global AnalysisOpts
            
            NCondsTest=ClassifierOpts.NConds;
            % get the learning trials if there are any
            [~,~,~,~,nXTrlPnt]=arrayfun(@(x) obj.GetTrialRangeforThisCond(ClassifierOpts,x),1:NCondsTest,'UniformOutput',0);
            
            if AnalysisOpts.DividSpockClassifier==1 % if we are dividing based on condition/trial range
                % get combination of trials and conditions
                nConds=cell2mat(arrayfun(@(x) (1:nXTrlPnt{x})+sign((x-1))*sum(cell2mat(nXTrlPnt(1:(x-1)))),1:NCondsTest,'UniformOutput',0));
                nCondsShuffle=nConds;
            elseif AnalysisOpts.DividSpockClassifier==2 % if we are dividing based on repetitions
                nConds=1:ClassifierOpts.Nrep;nCondsShuffle=nConds;
            elseif AnalysisOpts.DividSpockClassifier==3 %if we are dividing shuffles based on repetitions  and  condition/trial range and main based on repetitions
                % get combination of trials and conditions
                nConds=cell2mat(arrayfun(@(x) (1:nXTrlPnt{x})+sign((x-1))*sum(cell2mat(nXTrlPnt(1:(x-1)))),...
                    1:NCondsTest,'UniformOutput',0));
                % add the repetition now for shuffle
                % nCondsShuffle=cell2mat(arrayfun(@(y) nConds+sign((y-1))*length(nConds)*(y-1),1:ClassifierOpts.NrepShuf,'UniformOutput',0));
                if AnalysisOpts.UseRep4Cluster
                    nCondsShuffle=1:(ClassifierOpts.NrepShufperFold+1);
                else
                    nCondsShuffle=cell2mat(arrayfun(@(y) nConds+sign((y-1))*length(nConds)*(y-1),1:(ClassifierOpts.NrepShufperFold+1),'UniformOutput',0));
                end
            end
            if obj.CalShuff;CondTot=nCondsShuffle;else;CondTot=nConds;end
               % report the end results 
            fprintf(2,'\nCondSet:%s, TrlRngSet:%s, DividSpockClassifier:%i',obj.ManData.ConvMat2Char(CondTot),...
                obj.ManData.ConvMat2Char(cell2mat(nXTrlPnt)),AnalysisOpts.DividSpockClassifier)                 
        end
        function [ShuffTxt,CondSet,TrlRngSet,RepSet,CondInds,TrlRngInds,RepInds]=ReadClassifierSpockRunConds(obj,ClassifierOpts) % read current state we are in spock run
            global AnalysisOpts
            
            % prepare the varibales
            if obj.CalShuff & obj.CalShuffTrlOrder
                ShuffTxt=sprintf('Shuf_C%i_',AnalysisOpts.DividSpockClassifier_Cond);
                fprintf(2,'\n***************Running SHUFFLE Trial Order Classifier Condition %i',AnalysisOpts.DividSpockClassifier_Cond);
            elseif obj.CalShuff & ~obj.CalShuffTrlOrder
                ShuffTxt=sprintf('ShLb_C%i_',AnalysisOpts.DividSpockClassifier_Cond);
                fprintf(2,'\n***************Running SHUFFLE label Classifier Condition %i',AnalysisOpts.DividSpockClassifier_Cond);
            elseif ~obj.CalShuff & AnalysisOpts.DividSpockClassifier
                ShuffTxt=sprintf('C%i_',AnalysisOpts.DividSpockClassifier_Cond);
                fprintf(2,'\n***************Running NORMAL Classifier Condition %i',AnalysisOpts.DividSpockClassifier_Cond);
             else 
                ShuffTxt='';  
            end
           % initialize all varibales 
           CondSet=[];TrlRngSet=[];RepSet=[];CondInds=[];TrlRngInds=[];RepInds=[];
            if AnalysisOpts.DividSpockClassifier==1 % devide by all of the combinations but keep repetitions
                rng(AnalysisOpts.DividSpockClassifier_Cond);
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockClassifier_TrlRng(x),1:ClassifierOpts.NConds,'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockClassifier_TrlRng(x)),1:ClassifierOpts.NConds,'UniformOutput',0));
                CondSet  =CondInds(AnalysisOpts.DividSpockClassifier_Cond);
                TrlRngSet=TrlRngInds(AnalysisOpts.DividSpockClassifier_Cond);
                RepSet=1:ClassifierOpts.Nrep;RepInds=[];
            elseif AnalysisOpts.DividSpockClassifier==2 % if we are dividing the classifier runs by repetitions
                rng(AnalysisOpts.DividSpockClassifier_Cond);
                CondSet=1:ClassifierOpts.NConds;CondInds=CondSet;
                RepSet=1; RepInds=[];% only do one repetition 
                [~,~,~,~,TrlRngSet]=arrayfun(@(x) obj.GetTrialRangeforThisCond(ClassifierOpts,x),1:ClassifierOpts.NConds,'UniformOutput',0);
                TrlRngInds=TrlRngSet;                
            elseif AnalysisOpts.DividSpockClassifier==3 % if we are dividing the classifier runs by repetitions and TrlRng and Combs
                rng(AnalysisOpts.DividSpockClassifier_Cond);
                TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockClassifier_TrlRng(x),1:ClassifierOpts.NConds,'UniformOutput',0));
                CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockClassifier_TrlRng(x)),1:ClassifierOpts.NConds,'UniformOutput',0));
                RepSet=1:ClassifierOpts.Nrep;
                RepInds=RepSet;
                if ~obj.CalShuff
                    CondSet  =CondInds(AnalysisOpts.DividSpockClassifier_Cond);
                    TrlRngSet=TrlRngInds(AnalysisOpts.DividSpockClassifier_Cond);
                elseif obj.CalShuff & ~AnalysisOpts.UseRep4Cluster
                    % RepInds=cell2mat(arrayfun(@(x) x*ones(1,length(TrlRngInds)),1:ClassifierOpts.NrepShuf,'UniformOutput',0));
                    RepInds=cell2mat(arrayfun(@(x) x*ones(1,length(TrlRngInds)),1:(ClassifierOpts.NrepShufperFold+1),'UniformOutput',0));
                    TrlRngInds=repmat(TrlRngInds,[1 ClassifierOpts.NrepShufperFold+1]);
                    CondInds  =repmat(CondInds,[1 ClassifierOpts.NrepShufperFold+1]);
                    RepSet=RepInds(AnalysisOpts.DividSpockClassifier_Cond);
                    CondSet  =CondInds(AnalysisOpts.DividSpockClassifier_Cond);
                    TrlRngSet=TrlRngInds(AnalysisOpts.DividSpockClassifier_Cond);
                elseif obj.CalShuff & AnalysisOpts.UseRep4Cluster % use only repetition to run on cluster cluster
                    TrlRngInds=cell2mat(arrayfun(@(x) 1:AnalysisOpts.DividSpockClassifier_TrlRng(x),1:ClassifierOpts.NConds,'UniformOutput',0));
                    CondInds  =cell2mat(arrayfun(@(x) x*ones(1,AnalysisOpts.DividSpockClassifier_TrlRng(x)),1:ClassifierOpts.NConds,'UniformOutput',0));
                    RepInds=1:(ClassifierOpts.NrepShufperFold+1);
                    RepSet=RepInds(AnalysisOpts.DividSpockClassifier_Cond);
                    CondSet  =unique(CondInds);
                    TrlRngSet=TrlRngInds;
                end
            else      
                CondInds=[];RepInds=[];
                [~,~,~,~,nXTrlPnt]=arrayfun(@(x) obj.GetTrialRangeforThisCond(ClassifierOpts,x),1:ClassifierOpts.NConds,'UniformOutput',0);
                TrlRngSet=nXTrlPnt;
                CondSet=1:ClassifierOpts.NConds;
                RepSet=1:ClassifierOpts.Nrep;
            end

            if AnalysisOpts.GetOnlyShuffLabelsClassifier
                CondInds=[];RepInds =[];
                [~,~,~,~,nXTrlPnt]=arrayfun(@(x) obj.GetTrialRangeforThisCond(ClassifierOpts,x),1:ClassifierOpts.NConds,'UniformOutput',0);
                TrlRngSet=cellfun(@(x) 1:x,nXTrlPnt,'Uniformoutput',0);
                CondSet=1:ClassifierOpts.NConds;
                RepSet=1:ClassifierOpts.Nrep;
            end
            if iscell(TrlRngSet);TrlRngSetNum=cell2mat(TrlRngSet);else;TrlRngSetNum=TrlRngSet;end
            % report the end results 
            fprintf(2,'\nUseRep4Cluster:%i CondSet:%s, TrlRngSet:%s, RepSet:%s,DividSpockClassifier_Cond:%i,DividSpockClassifier:%i',AnalysisOpts.UseRep4Cluster,obj.ManData.ConvMat2Char(CondSet),...
                obj.ManData.ConvMat2Char(TrlRngSetNum),obj.ManData.ConvMat2Char(RepSet),AnalysisOpts.DividSpockClassifier_Cond,AnalysisOpts.DividSpockClassifier)
        end
        function [FigFileName,OutFileName]=GetClassifierAnaTestOutputImgFileName(obj,AnalysisName,TestName,AreaNum,PageNum,Ext,AnalysisType,SpkCntStartFieldName,PSTHbin,varargin) % gets the saved images names
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            if strcmp(AnalysisType,'Comparision')
                [ComparisonOpts]=cellfun(@(x) obj.ClassifierComparisionOpts(x),TestName,'UniformOutput',0); % gate the options for this test
                TestName=cellfun(@(x) x.ComparisonName,ComparisonOpts,'UniformOutput',0);
                AllTrialsTxt=[];
                CompareTxt='_Compare';
                SaveTxt=CompareTxt;
            else
                [ClassifierOpts]=cellfun(@(x) obj.DefineClassifierTestOptions(x),TestName,'UniformOutput',0); % gate the options for this test
                TestName=cellfun(@(x) x.Name,ClassifierOpts,'UniformOutput',0);
                AllTrialsTxt=['_' AnalysisOpts.TrlSpkTimeFieldName];
                CompareTxt=[''];SaveTxt=['_' TestName{1}];
            end
            if ~isempty(PageNum) & strcmp(Ext,'eps');PageTxt=sprintf('_f%i',PageNum);else;PageTxt='';end
            k=1;
            for Ar=AreaNum
                for TstNameInd=1:length(TestName)
                    ThisTestName=TestName{TstNameInd};
                    % get the file name
                    [~,~,FileName]=obj.ManData.GetFileName(AnalysisName,...
                        ['_' ThisTestName CompareTxt '_' AnalysisOpts.AreaNames{Ar} '_' SpkCntStartFieldName AllTrialsTxt '_' num2str(PSTHbin)],...
                        'SaveInResults',1,'WantedDate','ALL','SavedinSameNameFolder',1);
                    FigFileName{k}=[FileName(1:end-4) PageTxt '.' Ext];
                    % this saved in a folder thne
                    k=k+1;
                end
            end
            % generate an output file name so we can save these file names
            % based on the date of the analysis
            [~,~,OutFileName]=obj.ManData.GetFileName(AnalysisName,...
                ['_AnalysisResults' CompareTxt SaveTxt '_' SpkCntStartFieldName '_' num2str(PSTHbin)],...
                'SaveInResults',1,'WantedDate','ALL','SavedinSameNameFolder',1);
        end
        %GLM
        function [GLMfit,FileExist,GLMfitAnalysisOpts,FileName]=LoadGLMfitfile(obj,Neu2load,GLMModelName,FileType,varargin)
            % @Neu number of the neuron in the AnalysisOpts.Ch_2look
            % @LoadShuffleFlag are we loading the suffled data for this
            % channel
            % FileType the type of file we are looking for 'SummeryFile','GLMfit'
            % 'GLMfitSh' 'GLMfitShConcat' add 'Exists' to the end if you want to only
            % see if the file exists
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isscalar(GLMModelName);GLMModelName=AnalysisOpts.SingCellAna.GLMMdlNameSet{GLMModelName};end
            % if we only want to see if the file exists
            if contains(FileType,'Exists');FileType=strrep(FileType,'Exists','');CheckifFileExistsOnly=1;else;CheckifFileExistsOnly=0;end
            % load files
            k=1;
            for Neu=Neu2load
                fprintf('\nLoading GLM fit %s for Neuron %i',FileType,Neu) % load summery file for this fit
                obj.TrialFunc.UpdateCurrentCh(Neu);
                [ExtraStr,ExtraStrVar]=obj.GetExtraStr4Cond(FileType);
                switch FileType
                    case {'SummeryFile','GLMfit'}
                        [temp,FileExist(Neu),FileName{Neu}]=obj.ManData.LoadVar('GLM',['GLMfit' ExtraStrVar '_' GLMModelName],ExtraStr,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'CheckifFileExistsOnly',CheckifFileExistsOnly);
                        if ~isempty(temp)
                            GLMfit(k)=temp;k=k+1;
                        end
                    case 'GLMfitSh'
                        [GLMfit,FileExist{Neu},FileName{Neu}]=obj.ManData.LoadVarSeries2('GLM',['GLMfit' ExtraStrVar '_' GLMModelName],[],ExtraStr,1:AnalysisOpts.SingCellAna.GLMShuffleRuns,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'CheckifFileExistsOnly',CheckifFileExistsOnly);
                    case 'GLMfitShConcat'
                        [GLMfit,FileExist(Neu),FileName{Neu}]=obj.ManData.LoadVar('GLM',['GLMfit' ExtraStrVar '_' GLMModelName],ExtraStr,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'CheckifFileExistsOnly',CheckifFileExistsOnly);
                    case 'ModelComp' % load model comparision files
                        ExtraStr=obj.GetExtraStr4Cond('SummeryFile');
                        [temp,FileExist(Neu),FileName{Neu}]=obj.ManData.LoadVar('GLM',['ModelComp_' GLMModelName],ExtraStr,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'CheckifFileExistsOnly',CheckifFileExistsOnly);
                        if ~isempty(temp)
                            GLMfit(k)=temp;k=k+1;
                        else % run model comparision analysis on this and resave it again 
                            ThisAnalysisOpts=AnalysisOpts;
                            PopulationAnalysis(AnalysisOpts.RunonCluster, 0, AnalysisOpts.Ch_2look_ChNum(Neu), AnalysisOpts.Ch_2look_AreaNum(Neu), [1],'ProcessingStep',12,'SpkCntStartFieldName','SAMPLE_ON','PopulationAna.PSTHbin',100,'DividSpockClassifier_Cond',1,'DividSpockClassifier_TrlRng',ones(1,7),'DividSpockGLM_Cond',1);
                            AnalysisOpts=ThisAnalysisOpts;obj.TrialFunc.RevertCh_2look;
                            PopulationAnalysis(AnalysisOpts.RunonCluster, 0, AnalysisOpts.Ch_2look_ChNum(Neu), AnalysisOpts.Ch_2look_AreaNum(Neu), [1],'ProcessingStep',13,'SpkCntStartFieldName','SAMPLE_ON','PopulationAna.PSTHbin',100,'DividSpockClassifier_Cond',1,'DividSpockClassifier_TrlRng',ones(1,7),'DividSpockGLM_Cond',1);
                            AnalysisOpts=ThisAnalysisOpts;obj.TrialFunc.RevertCh_2look;
                            [temp,FileExist(Neu),FileName{Neu}]=obj.ManData.LoadVar('GLM',['ModelComp_' GLMModelName],ExtraStr,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum,'CheckifFileExistsOnly',CheckifFileExistsOnly);
                            GLMfit(k)=temp;k=k+1;
                        end
                end
            end
            if ~exist('GLMfit','var');GLMfit=[];end
            [GLMfitAnalysisOpts]=obj.ManData.LoadVar('GLM','AnalysisOpts',ExtraStr,0,'WantedCh',AnalysisOpts.CurrentCh_ChNum);
        end
        function [ExtraStr,VarExtraStr]=GetExtraStr4Cond(obj,Condition,varargin) %get the ExtraStr for each analysis condition
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if AnalysisOpts.SingCellAna.GLM_UseSingFactorShuff & contains(Condition,'Sh')
                ExtraShuffTxt='SingFact';
                Condition='GLMfitShConcat';
            else
                ExtraShuffTxt='';
                VarExtraStr='';
            end

            switch Condition
                case 'GLMfit'
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) ExtraShuffTxt];
                case 'GLMfitSh'
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) '_Shuf' ExtraShuffTxt AnalysisOpts.ShuffleStr];
                    VarExtraStr='Sh';
                case 'GLMfitShConcat' % concatinated file for shuffles
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) '_Shuf' ExtraShuffTxt];
                    VarExtraStr='Sh';
                case 'SummeryFile'
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) '_Summery'];
                    VarExtraStr='SingFact';
                case 'ModelComp'
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) '_MdlCmp_Run' AnalysisOpts.GLMmdlCompStr];
                case 'GLMareaSummery' % summery for each area
                    ExtraStr=['SingCellAna' AnalysisOpts.ExtraGLMStr '_' AnalysisOpts.CurrentCh_AreaName  '_' AnalysisOpts.SpkCntStartFieldName '_' num2str(AnalysisOpts.PopulationAna.PSTHbin) '_AreaSummery'];
                    VarExtraStr='SingFact';
            end

            if ~AnalysisOpts.SingCellAna.GLM_UseSingFactorShuff
                VarExtraStr=''; % extra str to add for variable
            end
        end
        function ClassifierOpts=ReportNeuronNumbers(obj,ClassifierOpts,IncludedNeurons,varargin)
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            AnalysisOpts.IncludedNeu4Ana_Num=sum(IncludedNeurons);
            AnalysisOpts.IncludedNeu4Ana_Animal=AnalysisOpts.Ch_2look_Animal(IncludedNeurons);
            AnalysisOpts.IncludedNeu4Ana_AnimalNum=cellfun(@(x) sum(strcmp(AnalysisOpts.IncludedNeu4Ana_Animal,x)),{'Silas','Chico'});
            fprintf('\nTotal number of neurons for this analysis:%i, Silas: %i, Chico: %i',AnalysisOpts.IncludedNeu4Ana_Num,AnalysisOpts.IncludedNeu4Ana_AnimalNum(1),AnalysisOpts.IncludedNeu4Ana_AnimalNum(2));
            ClassifierOpts.IncludedNeu4Ana_Num=AnalysisOpts.IncludedNeu4Ana_Num;
            ClassifierOpts.IncludedNeu4Ana_Animal=AnalysisOpts.IncludedNeu4Ana_Animal;
            ClassifierOpts.IncludedNeu4Ana_AnimalNum=AnalysisOpts.IncludedNeu4Ana_AnimalNum;
        end
        function out=LimitFileDateTime(obj,FileDateTime,FileDateTimeTh,GiveError,varargin) % limits date time for the generation of a file
            % if the date and time of the generation of this file is lower
            % than the MinFileDateTime it generates an error
            % @FileDateTimeTh is the input to datetime funcion so it can
            % be YYYY,MM,DD for mat or anything else
            global AnalysisOpts
            obj=obj.ParseParams(varargin) ; %%Process optional inputs
            
            if isempty(FileDateTime);fprintf('\nCurrent Date is empty');out=[];return;end
            FileDateTimeTh=datetime(FileDateTimeTh);
            out=FileDateTime>=FileDateTimeTh;
            if  ~out
                if GiveError
                    warning('\nThe current file is older than %s Operation aborted ...',FileDateTimeTh);
                else
                    warning('\nThe current file is older than %s ...',FileDateTimeTh);
                end
            end
        end
        
    end
end








